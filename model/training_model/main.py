from transformers import T5ForConditionalGeneration, RobertaTokenizer
import torch
import string_formatter


def test_different_temperatures():
  """æ¸¬è©¦ä¸åŒæº«åº¦åƒæ•¸çš„æ•ˆæœ"""

  # è¼‰å…¥æ¨¡å‹
  model_path = "commit-model-ep8-ba4-le1e-10000dt"
  tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')
  model = T5ForConditionalGeneration.from_pretrained(model_path)
  model.eval()

  if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.pad_token_id = tokenizer.eos_token_id

  # æ¸¬è©¦ç”¨çš„ diff
  test_diff_remove = """
    diff --git a/Car.java b/Car.java
    index 5aa7953..c0cd4ed 100644
    --- a/Car.java
    +++ b/Car.java
    @@ -1,7 +1,7 @@
    public class Car {
    -    String name;
    }
    """

  test_diff_rename = """
  diff --git a/Car.java b/Car.java
  index 5aa7953..c0cd4ed 100644
  --- a/Car.java
  +++ b/Car.java
  @@ -1,7 +1,7 @@
  public class Car {
  -    String name;
  +    String car_name;
  }
  """

  test_diff_add = """
    diff --git a/Car.java b/Car.java
    index 218bbe3..0972a20 100644
    --- a/Car.java
    +++ b/Car.java
    @@ -1,3 +1,35 @@
    public class Car {
    +    String id;
    +
    +    public Car(String id) {
    +        this.id = id;
    +    }
    +
    +    public String getId() {
    +        return id;
    +    }
    """

  # æ¸…ç† diff
  cleaned_diff = string_formatter.clean_text(test_diff_add)

  # ğŸ” è¨ºæ–·è¼¸å…¥å…§å®¹
  print("ğŸ” è¨ºæ–·è¼¸å…¥å…§å®¹:")
  print("=" * 60)
  print(f"ğŸ“ åŸå§‹ diff é•·åº¦: {len(test_diff_add)}")
  print(f"ğŸ§¹ æ¸…ç†å¾Œé•·åº¦: {len(cleaned_diff)}")
  print(f"ğŸ”¤ æ¸…ç†å¾Œå…§å®¹:\n{cleaned_diff}")
  print("=" * 60)

  # æº«åº¦åƒæ•¸
  temperatures = [0.2, 0.4]

  # Tokenize ä¸€æ¬¡å°±å¥½
  inputs = tokenizer(
      cleaned_diff,
      return_tensors="pt",
      max_length=512,
      truncation=True,
      padding=True
  )

  results = []

  for temp in temperatures:
    print(f"\nğŸŒ¡ï¸ æº«åº¦: {temp}")

    # ç”Ÿæˆå¤šæ¬¡çœ‹è®ŠåŒ–
    messages = []
    for i in range(3):  # æ¯å€‹æº«åº¦ç”Ÿæˆ3æ¬¡
      with torch.no_grad():
        output = model.generate(
            inputs.input_ids,
            max_length=512,
            temperature=temp,
            do_sample=True,
            top_p=0.9,
            repetition_penalty=1.2,
            pad_token_id=tokenizer.pad_token_id,
        )

      # è§£ç¢¼
      decoded = tokenizer.decode(output[0], skip_special_tokens=True)
      messages.append(decoded.strip())

    # é¡¯ç¤ºçµæœ
    for i, msg in enumerate(messages, 1):
      print(f"  ç¬¬{i}æ¬¡: '{msg}'")

    results.append({
      'temperature': temp,
      'messages': messages
    })

if __name__ == "__main__":
  test_different_temperatures()
