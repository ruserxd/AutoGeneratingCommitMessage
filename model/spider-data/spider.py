import os
import json
import time
import requests
import re
from datetime import datetime
from dotenv import load_dotenv
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass
import logging


@dataclass
class CrawlerConfig:
    """çˆ¬èŸ²é…ç½®é¡"""
    max_skip_streak: int = 50
    repo_pages: int = 2  # å¢åŠ æœå°‹é æ•¸
    repo_per_page: int = 5  # å¢åŠ æ¯é æ•¸é‡
    max_too_long: int = 50
    max_input_length: int = 10000
    max_retries: int = 3
    request_delay: float = 0.5
    per_page_commits: int = 100
    target_repos: List[str] = None  # æŒ‡å®šè¦æŠ“å–çš„å­˜å„²åº«
    max_repos_per_run: int = 1  # æ¯æ¬¡åŸ·è¡Œè™•ç†çš„æœ€å¤§å°ˆæ¡ˆæ•¸


@dataclass
class RepoInfo:
    """Repository è³‡è¨Šé¡"""
    owner: str
    name: str
    full_name: str
    stars: int
    forks: int
    language: str
    created_at: str
    updated_at: str


@dataclass
class CommitData:
    """Commit è³‡æ–™é¡"""
    input: str
    output: str


class GitHubAPIClient:
    """GitHub API å®¢æˆ¶ç«¯"""
    
    def __init__(self, token: str):
        self.token = token
        self.headers = {"Authorization": f"token {token}"}
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def _make_request(self, url: str, params: Dict = None, max_retries: int = 3) -> requests.Response:
        """ç™¼èµ·è«‹æ±‚ä¸¦è™•ç†é‡è©¦æ©Ÿåˆ¶"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(url, params=params)
                
                # è™•ç† API é™åˆ¶
                if response.status_code == 403:
                    reset_time = int(response.headers.get('X-RateLimit-Reset', time.time() + 3600))
                    wait_time = reset_time - int(time.time()) + 10
                    logging.warning(f"API é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                    time.sleep(wait_time)
                    continue
                
                # è™•ç†ç©º repository
                if response.status_code == 409:
                    return response
                
                response.raise_for_status()
                return response
                
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                logging.warning(f"è«‹æ±‚å¤±æ•—ï¼Œé‡è©¦ç¬¬ {attempt + 1} æ¬¡: {e}")
                time.sleep(2 ** attempt)
        
        raise Exception("é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸")
    
    def search_repositories(self, query: str, sort: str = "stars", 
                          order: str = "desc", pages: int = 1, per_page: int = 5) -> List[RepoInfo]:
        """æœå°‹ repositories"""
        repos = []
        for page in range(1, pages + 1):
            url = "https://api.github.com/search/repositories"
            params = {
                "q": query,
                "sort": sort,
                "order": order,
                "per_page": per_page,
                "page": page
            }
            
            response = self._make_request(url, params)
            data = response.json()
            
            for item in data["items"]:
                repo = RepoInfo(
                    owner=item["owner"]["login"],
                    name=item["name"],
                    full_name=item["full_name"],
                    stars=item["stargazers_count"],
                    forks=item["forks_count"],
                    language=item["language"],
                    created_at=item["created_at"],
                    updated_at=item["updated_at"]
                )
                repos.append(repo)
            
            time.sleep(1)  # é¿å…éå¿«è«‹æ±‚
        
        return repos
    
    def get_commits(self, owner: str, repo: str, per_page: int = 100, page: int = 1) -> List[Dict]:
        """ç²å– commit åˆ—è¡¨"""
        url = f"https://api.github.com/repos/{owner}/{repo}/commits"
        params = {"per_page": per_page, "page": page}
        
        response = self._make_request(url, params)
        
        if response.status_code == 409:
            return []  # ç©º repository
        
        return response.json()
    
    def get_commit_detail(self, owner: str, repo: str, sha: str) -> Dict:
        """ç²å– commit è©³ç´°è³‡è¨Š"""
        url = f"https://api.github.com/repos/{owner}/{repo}/commits/{sha}"
        response = self._make_request(url)
        return response.json()


class DataStorage:
    """è³‡æ–™å­˜å„²ç®¡ç†é¡"""
    
    def __init__(self, base_dir: str):
        self.base_dir = base_dir
        os.makedirs(base_dir, exist_ok=True)
        
        self.training_data_dir = os.path.join(base_dir, "training-data")
        os.makedirs(self.training_data_dir, exist_ok=True)

        # æª”æ¡ˆè·¯å¾‘
        self.seen_sha_path = os.path.join(base_dir, "seen_commits.json")
        self.completed_repos_path = os.path.join(base_dir, "completed_repos.json")
        self.repo_progress_path = os.path.join(base_dir, "repo_progress.json")
    
    def load_seen_shas(self) -> Dict[str, Set[str]]:
        """è¼‰å…¥å·²è™•ç†çš„ commit SHA"""
        if os.path.exists(self.seen_sha_path):
            with open(self.seen_sha_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                # è½‰æ›ç‚º set æé«˜æŸ¥è©¢æ•ˆç‡
                return {repo: set(shas) for repo, shas in data.items()}
        return {}
    
    def save_seen_shas(self, seen_shas: Dict[str, Set[str]]) -> None:
        """ä¿å­˜å·²è™•ç†çš„ commit SHA"""
        # è½‰æ›ç‚º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
        save_data = {repo: list(shas) for repo, shas in seen_shas.items()}
        with open(self.seen_sha_path, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    def load_completed_repos(self) -> Dict:
        """è¼‰å…¥å·²å®Œæˆçš„ repository åˆ—è¡¨"""
        if os.path.exists(self.completed_repos_path):
            with open(self.completed_repos_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    return {repo: {"completed_at": "unknown", "total_commits": 0} for repo in data}
                return data
        return {}
    
    def save_completed_repos(self, completed_repos: Dict) -> None:
        """ä¿å­˜å·²å®Œæˆçš„ repository åˆ—è¡¨"""
        with open(self.completed_repos_path, "w", encoding="utf-8") as f:
            json.dump(completed_repos, f, ensure_ascii=False, indent=2)
    
    def load_repo_progress(self) -> Dict:
        """è¼‰å…¥ repository è™•ç†é€²åº¦"""
        if os.path.exists(self.repo_progress_path):
            with open(self.repo_progress_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}
    
    def save_repo_progress(self, repo_progress: Dict) -> None:
        """ä¿å­˜ repository è™•ç†é€²åº¦"""
        with open(self.repo_progress_path, "w", encoding="utf-8") as f:
            json.dump(repo_progress, f, ensure_ascii=False, indent=2)
    
    def save_repo_data(self, repo_name: str, data: List[CommitData]) -> Tuple[str, str]:
        """ä¿å­˜ repository è³‡æ–™ä¸¦è¿”å›æª”æ¡ˆè·¯å¾‘"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_repo_name = repo_name.replace("/", "_")
        
        # ä¿å­˜ä¸»è¦è³‡æ–™
        data_path = os.path.join(self.training_data_dir, f"{safe_repo_name}_{timestamp}.json")
        serializable_data = [{"input": item.input, "output": item.output} for item in data]
        with open(data_path, "w", encoding="utf-8") as f:
            json.dump(serializable_data, f, ensure_ascii=False, indent=2)
        
        return data_path, f"{safe_repo_name}_{timestamp}.json"
    
    def append_repo_temp_data(self, repo_name: str, data: List[CommitData]) -> None:
        """è¿½åŠ å„²å­˜ä¸­é€”æš«å­˜çš„è³‡æ–™ï¼ˆcommit message èˆ‡ patchï¼‰"""
        safe_repo_name = repo_name.replace("/", "_")
        temp_path = os.path.join(self.training_data_dir, f"{safe_repo_name}_temp.json")

        serializable_data = [{"input": item.input, "output": item.output} for item in data]

        if os.path.exists(temp_path):
            with open(temp_path, "r", encoding="utf-8") as f:
                existing = json.load(f)
        else:
            existing = []

        existing.extend(serializable_data)
        with open(temp_path, "w", encoding="utf-8") as f:
            json.dump(existing, f, ensure_ascii=False, indent=2)



class JavaPatchExtractor:
    """Java patch æå–å™¨"""
    
    @staticmethod
    def extract_java_patch(commit_data: Dict, repo_info: RepoInfo) -> Optional[CommitData]:
        """æå– Java patch è³‡è¨Š"""
        message = commit_data["commit"]["message"]
        
        # éæ¿¾å«ä¸­æ–‡çš„ commit message
        if re.search(r'[\u4e00-\u9fff]', message):
            return None
        
        files = commit_data.get("files", [])
        java_patches = []
        
        for file_data in files:
            filename = file_data.get("filename", "")
            patch = file_data.get("patch", "")
            
            if not filename.endswith(".java") or not patch:
                continue
            
            # æª¢æŸ¥æ˜¯å¦ä¸»è¦æ˜¯è¨»è§£ä¿®æ”¹
            if JavaPatchExtractor._is_mostly_comments(patch):
                return None
            
            # ç”Ÿæˆå®Œæ•´çš„ Git diff æ ¼å¼
            full_patch = JavaPatchExtractor._format_patch(filename, patch)
            java_patches.append(full_patch)
        
        if not java_patches:
            return None
        
        return CommitData(
            input="\n\n".join(java_patches),
            output=message.strip()
        )
    
    @staticmethod
    def _is_mostly_comments(patch: str) -> bool:
        """æª¢æŸ¥ patch æ˜¯å¦ä¸»è¦æ˜¯è¨»è§£ä¿®æ”¹"""
        lines = patch.splitlines()
        added_lines = [
            line[1:].strip() 
            for line in lines 
            if line.startswith("+") and not line.startswith("+++")
        ]
        
        if not added_lines:
            return False
        
        comment_indicators = ["//", "*", "/*", "*/"]
        comment_lines = sum(
            1 for line in added_lines
            if any(line.startswith(indicator) for indicator in comment_indicators)
        )
        
        return comment_lines / len(added_lines) > 0.8
    
    @staticmethod
    def _format_patch(filename: str, patch: str) -> str:
        """æ ¼å¼åŒ– patch ç‚ºå®Œæ•´çš„ Git diff æ ¼å¼"""
        diff_header = f"diff --git a/{filename} b/{filename}\n"
        file_header = f"--- a/{filename}\n+++ b/{filename}\n"
        return diff_header + file_header + patch


class JavaRepoCrawler:
    """Java Repository çˆ¬èŸ²ä¸»é¡"""
    
    def __init__(self, config: CrawlerConfig, token: str, base_dir: str):
        self.config = config
        self.api_client = GitHubAPIClient(token)
        self.storage = DataStorage(base_dir)
        self.extractor = JavaPatchExtractor()
        
        # è¨­ç½®æ—¥èªŒ
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def crawl_complete_repo(self, repo_info: RepoInfo, seen_shas: Dict[str, Set[str]], 
                           repo_progress: Dict) -> List[CommitData]:
        """å®Œæ•´æŠ“å–ä¸€å€‹ repository çš„æ‰€æœ‰ Java commits"""
        full_name = repo_info.full_name
        self.logger.info(f"é–‹å§‹å®Œæ•´æŠ“å–ï¼š{full_name} (â­{repo_info.stars})")
        
        # åˆå§‹åŒ–å°ˆæ¡ˆç‰¹å®šçš„ SHA è¿½è¹¤
        if full_name not in seen_shas:
            seen_shas[full_name] = set()
        repo_seen_shas = seen_shas[full_name]
        
        # æª¢æŸ¥é€²åº¦
        progress = self._load_or_create_progress(repo_info, repo_progress)
        
        results = []
        page = progress["last_page"]
        skip_streak = 0
        too_long_count = 0
        total_processed = progress["total_processed"]
        
        try:
            while True:
                commits = self.api_client.get_commits(
                    repo_info.owner, repo_info.name, 
                    self.config.per_page_commits, page
                )
                
                if not commits:
                    self.logger.info(f"ç¬¬ {page} é ç„¡æ›´å¤š commitï¼Œå°ˆæ¡ˆæŠ“å–å®Œæˆ")
                    break
                
                self.logger.info(f"è™•ç†ç¬¬ {page} é ï¼Œå…± {len(commits)} å€‹ commit")
                
                page_results = self._process_commits_page(
                    commits, repo_info, repo_seen_shas, 
                    skip_streak, too_long_count, total_processed
                )
                
                results.extend(page_results['commits'])
                 # âœ… å³æ™‚ä¿å­˜æš«å­˜æª”
                if page_results['commits']:
                    self.storage.append_repo_temp_data(full_name, page_results['commits'])
                skip_streak = page_results['skip_streak']
                too_long_count = page_results['too_long_count']
                total_processed = page_results['total_processed']
                
                # æ›´æ–°é€²åº¦
                self._update_progress(progress, page, len(results), total_processed)
                self.storage.save_repo_progress(repo_progress)
                
                page += 1
                
                # å®šæœŸå ±å‘Šé€²åº¦
                if page % 10 == 0:
                    self.logger.info(f"é€²åº¦å ±å‘Šï¼šå·²è™•ç† {page} é ï¼Œæ”¶é›† {len(results)} ç­†æœ‰æ•ˆè³‡æ–™")
        
        except Exception as e:
            self.logger.error(f"æŠ“å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
        
        # æ¨™è¨˜å®Œæˆ
        self._mark_completed(progress, len(results), page - 1)
        self.storage.save_repo_progress(repo_progress)
        
        self.logger.info(f"å°ˆæ¡ˆ {full_name} æŠ“å–å®Œæˆï¼çµ±è¨ˆï¼šè™•ç†äº† {total_processed} å€‹ commitï¼Œç²å¾— {len(results)} ç­†æœ‰æ•ˆ Java è³‡æ–™")
        
        return results
    
    def _load_or_create_progress(self, repo_info: RepoInfo, repo_progress: Dict) -> Dict:
        """è¼‰å…¥æˆ–å‰µå»ºé€²åº¦è¨˜éŒ„"""
        full_name = repo_info.full_name
        if full_name in repo_progress:
            progress = repo_progress[full_name]
            self.logger.info(f"å¾ç¬¬ {progress.get('last_page', 1)} é ç¹¼çºŒï¼Œå·²æ”¶é›† {progress.get('collected_count', 0)} ç­†")
            return progress
        else:
            progress = {
                "owner": repo_info.owner,
                "name": repo_info.name,
                "full_name": full_name,
                "stars": repo_info.stars,
                "start_time": datetime.now().isoformat(),
                "last_page": 1,
                "collected_count": 0,
                "total_processed": 0,
                "status": "processing"
            }
            repo_progress[full_name] = progress
            return progress
    
    def _process_commits_page(self, commits: List[Dict], repo_info: RepoInfo, 
                             repo_seen_shas: Set[str], skip_streak: int, 
                             too_long_count: int, total_processed: int) -> Dict:
        """è™•ç†ä¸€é çš„ commits"""
        results = []
        
        for commit in commits:
            sha = commit["sha"]
            total_processed += 1
            
            if sha in repo_seen_shas:
                self.logger.debug(f"Commit {sha[:7]} å·²å­˜åœ¨ï¼Œè·³é")
                continue
            
            try:
                detail = self.api_client.get_commit_detail(repo_info.owner, repo_info.name, sha)
                data = self.extractor.extract_java_patch(detail, repo_info)
                
                if data:
                    if len(data.input) > self.config.max_input_length:
                        too_long_count += 1
                        self.logger.debug(f"Commit {sha[:7]} éé•·è·³éï¼ˆ{too_long_count}/{self.config.max_too_long}ï¼‰")
                        if too_long_count >= self.config.max_too_long:
                            self.logger.warning("éé•· commit éå¤šï¼Œä½†ç¹¼çºŒè™•ç†...")
                        continue

                    results.append(data)
                    repo_seen_shas.add(sha)
                    # è®€å–ç›®å‰æ‰€æœ‰ repo çš„ seen_shaï¼Œå†æ›´æ–°ç›®å‰é€™å€‹ repo çš„
                    all_seen_shas = self.storage.load_seen_shas()
                    all_seen_shas[repo_info.full_name] = repo_seen_shas
                    self.storage.save_seen_shas(all_seen_shas)

                    skip_streak = 0
                    self.logger.debug(f"Commit {sha[:7]} saved")

                else:
                    skip_streak += 1
                    if skip_streak % 100 == 0:
                        self.logger.info(f"å·²è·³é {skip_streak} å€‹ç„¡ Java è®Šæ›´çš„ commit")
                    
                    if skip_streak >= self.config.max_skip_streak:
                        self.logger.warning(f"é€£çºŒè·³é {self.config.max_skip_streak} å€‹ commitï¼Œä½†ç¹¼çºŒè™•ç†...")
                        skip_streak = 0
                
                time.sleep(self.config.request_delay)
                
            except Exception as e:
                self.logger.warning(f"Commit {sha[:7]} è™•ç†éŒ¯èª¤: {e}")
        
        return {
            'commits': results,
            'skip_streak': skip_streak,
            'too_long_count': too_long_count,
            'total_processed': total_processed
        }
    
    def _update_progress(self, progress: Dict, page: int, collected_count: int, total_processed: int) -> None:
        """æ›´æ–°é€²åº¦"""
        progress["last_page"] = page
        progress["collected_count"] = collected_count
        progress["total_processed"] = total_processed
    
    def _mark_completed(self, progress: Dict, final_count: int, total_pages: int) -> None:
        """æ¨™è¨˜ç‚ºå®Œæˆç‹€æ…‹"""
        progress["status"] = "completed"
        progress["end_time"] = datetime.now().isoformat()
        progress["final_count"] = final_count
        progress["total_pages"] = total_pages
    
    def run(self) -> None:
        """åŸ·è¡Œçˆ¬èŸ²ä¸»æµç¨‹ - æ”¹é€²ç‰ˆ"""
        self.logger.info("é–‹å§‹è™•ç†...")
        
        # è¼‰å…¥ç‹€æ…‹
        seen_shas = self.storage.load_seen_shas()
        completed_repos = self.storage.load_completed_repos()
        repo_progress = self.storage.load_repo_progress()
        
        # å ±å‘Šç¾æœ‰ç‹€æ…‹
        self.logger.info(f"ğŸ“Š ç¾æœ‰ç‹€æ…‹ï¼šå·²å®Œæˆ {len(completed_repos)} å€‹å°ˆæ¡ˆ")
        
        # æŒ‡å®šäº†ç‰¹å®šçš„å­˜å„²åº«
        if self.config.target_repos:
            self.logger.info(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šçš„å­˜å„²åº«ï¼š{self.config.target_repos}")
            repo_list = self._get_specific_repos(self.config.target_repos)
        else:
            # æ“´å¤§æœå°‹ç¯„åœï¼Œå¢åŠ å¤šæ¨£æ€§
            self.logger.info(f"ğŸ” æœå°‹ç†±é–€ Java å°ˆæ¡ˆ...")
            repo_list = self._search_diverse_repos()
        
        # éæ¿¾å·²å®Œæˆçš„å°ˆæ¡ˆ
        new_repos = self._filter_new_repos(repo_list, completed_repos)
        
        if not new_repos:
            self.logger.info("âŒ æ²’æœ‰æ–°çš„ repository éœ€è¦è™•ç†")
            self._suggest_next_steps(completed_repos)
            return
        
        self.logger.info(f"âœ… æ‰¾åˆ° {len(new_repos)} å€‹æ–°çš„ repository")
        
        # ğŸ”¥ æ”¹é€²ï¼šè™•ç†å¤šå€‹å°ˆæ¡ˆè€Œä¸æ˜¯åªè™•ç†ä¸€å€‹
        processed_count = 0
        max_repos_per_run = self.config.max_repos_per_run
        
        for i, repo_info in enumerate(new_repos[:max_repos_per_run]):
            self.logger.info(f"ğŸš€ è™•ç†å°ˆæ¡ˆ {i+1}/{min(len(new_repos), max_repos_per_run)}: {repo_info.full_name}")
            
            try:
                # æŠ“å–è³‡æ–™
                repo_results = self.crawl_complete_repo(repo_info, seen_shas, repo_progress)
                
                # ä¿å­˜çµæœ
                self._save_results(repo_info, repo_results, completed_repos)
                processed_count += 1
                
                # ä¿å­˜ä¸­é–“ç‹€æ…‹
                self.storage.save_seen_shas(seen_shas)
                self.storage.save_completed_repos(completed_repos)
                self.storage.save_repo_progress(repo_progress)
                
            except Exception as e:
                self.logger.error(f"âŒ è™•ç†å°ˆæ¡ˆ {repo_info.full_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue  # ç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹å°ˆæ¡ˆï¼Œè€Œä¸æ˜¯ç›´æ¥å¤±æ•—
        
        # æœ€çµ‚ä¿å­˜
        self.storage.save_seen_shas(seen_shas)
        self.storage.save_completed_repos(completed_repos)
        self.storage.save_repo_progress(repo_progress)
        
        # ç¸½çµå ±å‘Š
        self._print_final_summary(processed_count, new_repos, completed_repos)
    
    def _search_diverse_repos(self) -> List[RepoInfo]:
        """æœå°‹å¤šæ¨£åŒ–çš„ repositories"""
        all_repos = []
        
        # æœå°‹ç­–ç•¥1ï¼šæŒ‰æ˜Ÿæ˜Ÿæ•¸
        self.logger.info("ğŸŒŸ æœå°‹æŒ‰æ˜Ÿæ˜Ÿæ•¸æ’åºçš„å°ˆæ¡ˆ...")
        repos_by_stars = self.api_client.search_repositories(
            "language:Java", 
            sort="stars", 
            pages=self.config.repo_pages, 
            per_page=self.config.repo_per_page
        )
        all_repos.extend(repos_by_stars)
        
        # æœå°‹ç­–ç•¥2ï¼šæŒ‰æœ€è¿‘æ›´æ–°
        self.logger.info("ğŸ”„ æœå°‹æœ€è¿‘æ›´æ–°çš„å°ˆæ¡ˆ...")
        repos_by_updated = self.api_client.search_repositories(
            "language:Java", 
            sort="updated", 
            pages=self.config.repo_pages, 
            per_page=self.config.repo_per_page
        )
        all_repos.extend(repos_by_updated)
        
        # æœå°‹ç­–ç•¥3ï¼šæŒ‰ fork æ•¸
        self.logger.info("ğŸ´ æœå°‹æŒ‰ fork æ•¸æ’åºçš„å°ˆæ¡ˆ...")
        repos_by_forks = self.api_client.search_repositories(
            "language:Java", 
            sort="forks", 
            pages=self.config.repo_pages, 
            per_page=self.config.repo_per_page
        )
        all_repos.extend(repos_by_forks)
        
        # å»é‡ä¸¦ä¿æŒé †åº
        unique_repos = {}
        for repo in all_repos:
            if repo.full_name not in unique_repos:
                unique_repos[repo.full_name] = repo
        
        repo_list = list(unique_repos.values())
        self.logger.info(f"ğŸ” æœå°‹åˆ° {len(repo_list)} å€‹ä¸é‡è¤‡çš„å°ˆæ¡ˆ")
        
        return repo_list
    
    def _suggest_next_steps(self, completed_repos: Dict) -> None:
        """å»ºè­°ä¸‹ä¸€æ­¥æ“ä½œ"""
        self.logger.info("ğŸ’¡ å»ºè­°ï¼š")
        
        if len(completed_repos) == 0:
            self.logger.info("  - æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œ GitHub Token")
            self.logger.info("  - ç¢ºèªæœå°‹æ¢ä»¶æ˜¯å¦æ­£ç¢º")
        elif len(completed_repos) < 5:
            self.logger.info("  - å¢åŠ  repo_pages æˆ– repo_per_page ä¾†æœå°‹æ›´å¤šå°ˆæ¡ˆ")
            self.logger.info("  - æˆ–è€…ä½¿ç”¨ target_repos æŒ‡å®šç‰¹å®šå°ˆæ¡ˆ")
        else:
            self.logger.info("  - è€ƒæ…®ä½¿ç”¨ä¸åŒçš„æœå°‹é—œéµå­—")
            self.logger.info("  - æˆ–è€…æ¸…ç† completed_repos.json é‡æ–°é–‹å§‹")
            self.logger.info("  - æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šè¨“ç·´è³‡æ–™")
    
    def _print_final_summary(self, processed_count: int, new_repos: List[RepoInfo], completed_repos: Dict) -> None:
        """æ‰“å°æœ€çµ‚ç¸½çµ"""
        self.logger.info("=" * 60)
        self.logger.info(f"ğŸ‰ æœ¬æ¬¡åŸ·è¡Œå®Œæˆï¼")
        self.logger.info(f"ğŸ“Š æœ¬æ¬¡è™•ç†ï¼š{processed_count} å€‹å°ˆæ¡ˆ")
        self.logger.info(f"ğŸ“ˆ ç¸½è¨ˆå®Œæˆï¼š{len(completed_repos)} å€‹å°ˆæ¡ˆ")
        
        if processed_count > 0:
            self.logger.info(f"âœ… æˆåŠŸè™•ç†çš„å°ˆæ¡ˆï¼š")
            for i in range(processed_count):
                if i < len(new_repos):
                    repo = new_repos[i]
                    commits = completed_repos.get(repo.full_name, {}).get('total_commits', 0)
                    self.logger.info(f"  ğŸš€ {repo.full_name}: {commits} ç­† commit")
        
        remaining = len(new_repos) - processed_count
        if remaining > 0:
            self.logger.info(f"â³ å‰©é¤˜å¾…è™•ç†ï¼š{remaining} å€‹å°ˆæ¡ˆ")
            self.logger.info("ğŸ’¡ ä¸‹æ¬¡åŸ·è¡Œå°‡ç¹¼çºŒè™•ç†å‰©é¤˜å°ˆæ¡ˆ")
    
    def _get_specific_repos(self, target_repos: List[str]) -> List[RepoInfo]:
        """ç²å–æŒ‡å®šçš„å­˜å„²åº«è³‡è¨Š"""
        repo_list = []
        for repo_name in target_repos:
            try:
                # ä½¿ç”¨ GitHub API ç²å–ç‰¹å®š repo çš„è³‡è¨Š
                url = f"https://api.github.com/repos/{repo_name}"
                response = self.api_client._make_request(url)
                item = response.json()
                
                repo = RepoInfo(
                    owner=item["owner"]["login"],
                    name=item["name"],
                    full_name=item["full_name"],
                    stars=item["stargazers_count"],
                    forks=item["forks_count"],
                    language=item["language"],
                    created_at=item["created_at"],
                    updated_at=item["updated_at"]
                )
                repo_list.append(repo)
                
            except Exception as e:
                self.logger.error(f"ç„¡æ³•ç²å–å­˜å„²åº« {repo_name}: {e}")
        
        return repo_list

    def _filter_new_repos(self, repo_list: List[RepoInfo], completed_repos: Dict) -> List[RepoInfo]:
        """éæ¿¾å‡ºæ–°çš„ repositories"""
        new_repos = []
        for repo in repo_list:
            if repo.full_name not in completed_repos:
                new_repos.append(repo)
            else:
                completed_info = completed_repos[repo.full_name]
                self.logger.info(f"è·³éå·²å®Œæ•´æŠ“å–çš„ repo: {repo.full_name}")
                self.logger.info(f"å®Œæˆæ™‚é–“: {completed_info.get('completed_at', 'unknown')}")
                self.logger.info(f"ç²å¾—è³‡æ–™: {completed_info.get('total_commits', 0)} ç­†")
        return new_repos
    
    def _save_results(self, repo_info: RepoInfo, repo_results: List[CommitData], completed_repos: Dict) -> None:
        """ä¿å­˜çµæœ"""
        safe_repo_name = repo_info.full_name.replace("/", "_")
        temp_path = os.path.join(self.storage.training_data_dir, f"{safe_repo_name}_temp.json")

        # âœ… è‹¥ä¸»ç¨‹å¼æ²’æœ‰çµæœï¼Œæ”¹ç”¨æš«å­˜æª”
        if not repo_results and os.path.exists(temp_path):
            with open(temp_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            repo_results = [CommitData(**item) for item in data]

        if repo_results:
            # ä¿å­˜è³‡æ–™æª”æ¡ˆ
            data_path, filename = self.storage.save_repo_data(repo_info.full_name, repo_results)
            self.logger.info(f"å°ˆæ¡ˆè³‡æ–™å·²å„²å­˜ï¼š{data_path}")
            self.logger.info(f"å…±ç²å¾— {len(repo_results)} ç­†æœ‰æ•ˆçš„ Java commit è³‡æ–™")

            # âœ… æˆåŠŸå¾Œæ¸…ç† temp æª”
            if os.path.exists(temp_path):
                os.remove(temp_path)

            completed_repos[repo_info.full_name] = {
                "completed_at": datetime.now().isoformat(),
                "total_commits": len(repo_results),
                "stars": repo_info.stars,
                "output_file": filename
            }
        else:
            self.logger.warning("æœ¬å°ˆæ¡ˆç„¡æœ‰æ•ˆçš„ Java commit è³‡æ–™")
            completed_repos[repo_info.full_name] = {
                "completed_at": datetime.now().isoformat(),
                "total_commits": 0,
                "stars": repo_info.stars,
                "note": "ç„¡æœ‰æ•ˆ Java commit è³‡æ–™"
            }




def main():
    """ä¸»å‡½æ•¸"""
    env_path = os.path.join(os.path.dirname(os.getcwd()), '.env')
    load_dotenv(env_path)
    
    github_token = os.getenv('GITHUB_TOKEN', '')
    if not github_token:
        print("âŒ éŒ¯èª¤ï¼šè«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š GITHUB_TOKEN")
        return
    
    # ğŸ” åœ¨åŸ·è¡Œå‰æª¢æŸ¥ç¾æœ‰ç‹€æ…‹
    base_dir = os.getcwd()
    storage = DataStorage(base_dir)
    
    completed_repos = storage.load_completed_repos()
    seen_shas = storage.load_seen_shas()
    
    print(f"ğŸ“Š ç¾æœ‰ç‹€æ…‹ï¼š")
    print(f"  - å·²å®Œæˆå°ˆæ¡ˆï¼š{len(completed_repos)} å€‹")
    print(f"  - è¿½è¹¤ SHA çš„å°ˆæ¡ˆï¼š{len(seen_shas)} å€‹")
    
    if completed_repos:
        print("ğŸ“‹ å·²å®Œæˆçš„å°ˆæ¡ˆï¼š")
        for repo_name, info in list(completed_repos.items())[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            commits = info.get('total_commits', 0)
            print(f"  ğŸš€ {repo_name}: {commits} ç­† commit")
        if len(completed_repos) > 5:
            print(f"  ... é‚„æœ‰ {len(completed_repos) - 5} å€‹å·²å®Œæˆçš„å°ˆæ¡ˆ")
    
    # é…ç½®
    config = CrawlerConfig(
        max_skip_streak=50,
        repo_pages=3,  # å¢åŠ æœå°‹é æ•¸
        repo_per_page=10,  # å¢åŠ æ¯é æ•¸é‡
        max_too_long=50,
        max_repos_per_run=1,  # æ¯æ¬¡è™•ç†å°ˆæ¡ˆæ•¸é‡
        # target_repos=["spring-projects/spring-boot", "apache/kafka"]  # å¦‚æœè¦æŒ‡å®šç‰¹å®šå°ˆæ¡ˆï¼Œå–æ¶ˆè¨»è§£
    )
    
    print(f"\nâš™ï¸  é…ç½®ï¼š")
    print(f"  - æœå°‹é æ•¸ï¼š{config.repo_pages}")
    print(f"  - æ¯é å°ˆæ¡ˆæ•¸ï¼š{config.repo_per_page}")
    print(f"  - æ¯æ¬¡è™•ç†å°ˆæ¡ˆæ•¸ï¼š{config.max_repos_per_run}")
    if config.target_repos:
        print(f"  - æŒ‡å®šå°ˆæ¡ˆï¼š{config.target_repos}")
    else:
        print(f"  - æœå°‹æ¨¡å¼ï¼šè‡ªå‹•æœå°‹ç†±é–€ Java å°ˆæ¡ˆ")
    
    # å‰µå»ºä¸¦åŸ·è¡Œçˆ¬èŸ²
    crawler = JavaRepoCrawler(config, github_token, base_dir)
    crawler.run()


if __name__ == "__main__":
    main()