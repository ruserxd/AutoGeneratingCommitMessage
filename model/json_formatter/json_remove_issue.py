import json
import re
import argparse
from typing import Dict, List, Any
from pathlib import Path


def remove_issue_tags(commit_message: str) -> str:
  """
  ç§»é™¤ commit message ä¸­çš„ Issue æ¨™ç±¤ï¼Œä¿æŒçµæ§‹

  Args:
      commit_message: åŸå§‹çš„ commit message

  Returns:
      ç§»é™¤æ¨™ç±¤å¾Œçš„ commit message
  """
  # ç§»é™¤ Issue: xxx æ ¼å¼çš„æ¨™ç±¤ï¼ˆé€šå¸¸åœ¨çµå°¾ï¼‰
  # æ”¯æ´å¤šç¨®æ ¼å¼ï¼šIssue: BS-157, Issue:#123, Issue:PROJ-999
  patterns = [
    r'\n\s*Issue:\s*[A-Z]*-?\w+\s*$',  # æ›è¡Œå¾Œçš„ Issue: BS-157
    r'\s*Issue:\s*[A-Z]*-?\w+\s*$',  # è¡Œæœ«çš„ Issue: BS-157
    r'\n\s*Issue:\s*[A-Z]*-?\w+',  # æ›è¡Œå¾Œçš„ Issue (ä¸åœ¨çµå°¾)
    r'\s+Issue:\s*[A-Z]*-?\w+',  # ç©ºæ ¼å¾Œçš„ Issue
  ]

  cleaned_message = commit_message

  # ä¾åºå¥—ç”¨å„ç¨®æ¨¡å¼
  for pattern in patterns:
    cleaned_message = re.sub(pattern, '', cleaned_message, flags=re.IGNORECASE)

  # æ¸…ç†å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
  lines = cleaned_message.split('\n')
  cleaned_lines = [line.strip() for line in lines if line.strip()]

  # é‡æ–°çµ„åˆ
  if len(cleaned_lines) <= 1:
    return cleaned_lines[0] if cleaned_lines else ""
  else:
    return '\n'.join(cleaned_lines)


def process_json_data(data: List[Dict[str, Any]]) -> tuple[
  List[Dict[str, Any]], Dict[str, int]]:
  """
  è™•ç† JSON è³‡æ–™ï¼Œç§»é™¤æ‰€æœ‰ output æ¬„ä½ä¸­çš„ Issue æ¨™ç±¤

  Args:
      data: åŒ…å«è¨“ç·´è³‡æ–™çš„ JSON é™£åˆ—

  Returns:
      è™•ç†å¾Œçš„ JSON è³‡æ–™å’Œçµ±è¨ˆè³‡è¨Š
  """
  processed_data = []
  stats = {
    'total': len(data),
    'issue_tags_found': 0,
    'modified': 0,
    'issue_patterns': {}
  }

  for item in data:
    if 'output' in item:
      original = item['output']
      cleaned = remove_issue_tags(original)

      # çµ±è¨ˆ Issue æ¨™ç±¤
      if re.search(r'Issue:\s*[A-Z]*-?\w+', original, re.IGNORECASE):
        stats['issue_tags_found'] += 1

        # æ”¶é›†ä¸åŒçš„ Issue æ¨¡å¼
        matches = re.findall(r'Issue:\s*([A-Z]*-?\w+)', original, re.IGNORECASE)
        for match in matches:
          stats['issue_patterns'][match] = stats['issue_patterns'].get(match,
                                                                       0) + 1

      # ä¿ç•™åŸå§‹è³‡æ–™çµæ§‹ï¼Œåªä¿®æ”¹ output æ¬„ä½
      processed_item = item.copy()
      processed_item['output'] = cleaned
      processed_data.append(processed_item)

      # çµ±è¨ˆä¿®æ”¹çš„é …ç›®
      if original != cleaned:
        stats['modified'] += 1
    else:
      # å¦‚æœæ²’æœ‰ output æ¬„ä½ï¼Œä¿æŒåŸæ¨£
      processed_data.append(item)

  return processed_data, stats


def process_file(input_file: str, output_file: str = None) -> None:
  """
  è™•ç† JSON æª”æ¡ˆ

  Args:
      input_file: è¼¸å…¥æª”æ¡ˆè·¯å¾‘
      output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
  """
  input_path = Path(input_file)

  # è¨­å®šè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
  if output_file is None:
    output_file = input_path.parent / f"{input_path.stem}_no_issues{input_path.suffix}"

  try:
    # è®€å– JSON æª”æ¡ˆ
    with open(input_file, 'r', encoding='utf-8') as f:
      data = json.load(f)

    print(f"ğŸ“‚ è¼‰å…¥æª”æ¡ˆ: {input_path.name}")
    print(f"ğŸ“Š ç¸½è³‡æ–™ç­†æ•¸: {len(data):,}")

    # é å…ˆçµ±è¨ˆåŒ…å« Issue æ¨™ç±¤çš„è³‡æ–™
    issue_count = 0
    for item in data:
      if 'output' in item and re.search(r'Issue:\s*[A-Z]*-?\w+', item['output'],
                                        re.IGNORECASE):
        issue_count += 1

    print(f"ğŸ·ï¸  åŒ…å« Issue: æ¨™ç±¤çš„è³‡æ–™: {issue_count:,} ç­†")

    if issue_count == 0:
      print("âœ… æ²’æœ‰ç™¼ç¾ Issue æ¨™ç±¤ï¼Œç„¡éœ€è™•ç†")
      return

    # è™•ç†è³‡æ–™
    processed_data, stats = process_json_data(data)

    # å„²å­˜è™•ç†å¾Œçš„è³‡æ–™
    with open(output_file, 'w', encoding='utf-8') as f:
      json.dump(processed_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“‹ è™•ç†çµæœ:")
    print(f"   ç™¼ç¾ Issue æ¨™ç±¤: {stats['issue_tags_found']:,} ç­†")
    print(f"   å¯¦éš›ä¿®æ”¹: {stats['modified']:,} ç­†")
    print(f"âœ… è™•ç†å®Œæˆï¼Œå·²å„²å­˜è‡³: {Path(output_file).name}")

    # é¡¯ç¤º Issue æ¨¡å¼çµ±è¨ˆ
    if stats['issue_patterns']:
      print(f"\nğŸ“ˆ ç™¼ç¾çš„ Issue é¡å‹ (å‰10å€‹):")
      sorted_patterns = sorted(stats['issue_patterns'].items(),
                               key=lambda x: x[1], reverse=True)
      for pattern, count in sorted_patterns[:10]:
        print(f"   Issue: {pattern} - {count} æ¬¡")

    # é¡¯ç¤ºè™•ç†ç¯„ä¾‹
    if stats['modified'] > 0:
      print(f"\nğŸ“ è™•ç†ç¯„ä¾‹:")
      count = 0
      for original_item, processed_item in zip(data, processed_data):
        if ('output' in original_item and
            original_item['output'] != processed_item['output'] and
            re.search(r'Issue:\s*[A-Z]*-?\w+', original_item['output'],
                      re.IGNORECASE)):

          original = original_item['output']
          cleaned = processed_item['output']

          print(f"åŸå§‹: {repr(original)}")
          print(f"æ¸…ç†: {repr(cleaned)}")
          print(f"è¦–è¦ºåŒ–:")
          print(f"  åŸå§‹: {original}")
          print(f"  æ¸…ç†: {cleaned}")
          print("-" * 60)

          count += 1
          if count >= 3:  # åªé¡¯ç¤ºå‰3å€‹ç¯„ä¾‹
            break

  except FileNotFoundError:
    print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {input_file}")
  except json.JSONDecodeError:
    print(f"âŒ éŒ¯èª¤: {input_file} ä¸æ˜¯æœ‰æ•ˆçš„ JSON æª”æ¡ˆ")
  except Exception as e:
    print(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


def preview_changes(input_file: str) -> None:
  """é è¦½æœƒè¢«ä¿®æ”¹çš„è³‡æ–™"""
  try:
    with open(input_file, 'r', encoding='utf-8') as f:
      data = json.load(f)

    print(f"ğŸ“‹ é è¦½æ¨¡å¼ - {Path(input_file).name}")
    print(f"ç¸½è³‡æ–™ç­†æ•¸: {len(data):,}")

    # æ‰¾å‡ºåŒ…å« Issue æ¨™ç±¤çš„é …ç›®
    issue_items = []
    issue_patterns = {}

    for i, item in enumerate(data):
      if 'output' in item and re.search(r'Issue:\s*[A-Z]*-?\w+', item['output'],
                                        re.IGNORECASE):
        original = item['output']
        cleaned = remove_issue_tags(original)
        if original != cleaned:
          issue_items.append((i + 1, original, cleaned))

          # æ”¶é›† Issue æ¨¡å¼
          matches = re.findall(r'Issue:\s*([A-Z]*-?\w+)', original,
                               re.IGNORECASE)
          for match in matches:
            issue_patterns[match] = issue_patterns.get(match, 0) + 1

    print(f"åŒ…å« Issue æ¨™ç±¤çš„è³‡æ–™: {len(issue_items):,} ç­†")

    if len(issue_items) == 0:
      print("âœ… æ²’æœ‰ç™¼ç¾éœ€è¦æ¸…ç†çš„ Issue æ¨™ç±¤")
      return

    # é¡¯ç¤º Issue æ¨¡å¼çµ±è¨ˆ
    if issue_patterns:
      print(f"\nğŸ·ï¸  ç™¼ç¾çš„ Issue é¡å‹:")
      sorted_patterns = sorted(issue_patterns.items(), key=lambda x: x[1],
                               reverse=True)
      for pattern, count in sorted_patterns:
        print(f"   Issue: {pattern} - {count} æ¬¡")

    # é¡¯ç¤ºå‰5ç­†æœƒè¢«è™•ç†çš„è³‡æ–™
    print(f"\nğŸ“ é è¦½å‰ 5 ç­†æœƒè¢«ä¿®æ”¹çš„è³‡æ–™:")
    for i, (idx, original, cleaned) in enumerate(issue_items[:5]):
      print(f"\nç¬¬ {idx} ç­†:")
      print(f"åŸå§‹: {repr(original)}")
      print(f"æ¸…ç†: {repr(cleaned)}")
      print(f"è¦–è¦ºåŒ–:")
      print(f"  åŸå§‹: {original}")
      print(f"  æ¸…ç†: {cleaned}")
      print("-" * 40)

    if len(issue_items) > 5:
      print(f"\n... é‚„æœ‰ {len(issue_items) - 5:,} ç­†é¡ä¼¼è³‡æ–™")

  except Exception as e:
    print(f"âŒ é è¦½å¤±æ•—: {str(e)}")


def test_patterns():
  """æ¸¬è©¦ä¸åŒçš„ Issue æ¨¡å¼"""
  test_cases = [
    "Add MultipartAutoConfigure to spring.factories\nUpdate META-INF/spring.factories to include MultipartAutoConfigure.\nAlso tweaked the class @Conditionals and Javadoc.\nIssue: BS-157",
    "Fix authentication bug\nIssue: JIRA-123",
    "Refactor database connection\nIssue:#456",
    "Update documentation Issue: DOC-789",
    "Simple commit without issue tag"
  ]

  print("ğŸ§ª æ¸¬è©¦ Issue æ¨™ç±¤ç§»é™¤:")
  print("=" * 60)

  for i, test_case in enumerate(test_cases, 1):
    print(f"\næ¸¬è©¦ {i}:")
    print(f"åŸå§‹: {repr(test_case)}")
    cleaned = remove_issue_tags(test_case)
    print(f"æ¸…ç†: {repr(cleaned)}")
    print(f"è¦–è¦ºåŒ–:")
    print(f"  åŸå§‹: {test_case}")
    print(f"  æ¸…ç†: {cleaned}")


def main():
  """ä¸»å‡½æ•¸"""
  parser = argparse.ArgumentParser(
      description='ç§»é™¤ Git commit message ä¸­çš„ Issue æ¨™ç±¤',
      formatter_class=argparse.RawDescriptionHelpFormatter,
      epilog='''
ç¯„ä¾‹:
  python remove_issues.py data.json                    # åŸºæœ¬ç”¨æ³•
  python remove_issues.py data.json -o clean_data.json # æŒ‡å®šè¼¸å‡ºæª”æ¡ˆ
  python remove_issues.py data.json --preview          # é è¦½æ¨¡å¼
  python remove_issues.py --test                       # æ¸¬è©¦æ­£è¦è¡¨é”å¼

æœƒè™•ç†çš„æ¨™ç±¤æ ¼å¼:
  Issue: BS-157    â†’ ç§»é™¤
  Issue: JIRA-123  â†’ ç§»é™¤
  Issue:#456       â†’ ç§»é™¤
  Issue: DOC-789   â†’ ç§»é™¤

è™•ç†ç­–ç•¥:
  - ç§»é™¤å„ç¨®æ ¼å¼çš„ Issue æ¨™ç±¤
  - ä¿æŒ commit message çš„å¤šè¡Œçµæ§‹
  - é€šå¸¸ç§»é™¤æœ€å¾Œä¸€è¡Œçš„ Issue æ¨™ç±¤
        '''
  )

  parser.add_argument('input_file', nargs='?', help='è¼¸å…¥çš„ JSON æª”æ¡ˆè·¯å¾‘')
  parser.add_argument('-o', '--output',
                      help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ (é è¨­: åŸæª”å_no_issues.json)')
  parser.add_argument('--preview', action='store_true',
                      help='é è¦½æ¨¡å¼ï¼Œåªé¡¯ç¤ºæœƒè¢«è™•ç†çš„è³‡æ–™')
  parser.add_argument('--test', action='store_true', help='æ¸¬è©¦æ­£è¦è¡¨é”å¼æ¨¡å¼')

  args = parser.parse_args()

  if args.test:
    test_patterns()
    return

  if not args.input_file:
    print("âŒ éŒ¯èª¤: è«‹æä¾›è¼¸å…¥æª”æ¡ˆè·¯å¾‘")
    parser.print_help()
    return

  # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
  if not Path(args.input_file).exists():
    print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {args.input_file}")
    return

  if args.preview:
    preview_changes(args.input_file)
  else:
    process_file(args.input_file, args.output)


if __name__ == "__main__":
  main()