import json
import os
import sys
from collections import Counter
from datetime import datetime


def analyze_first_words(data_path):
  """åˆ†ææ¯ç­†è³‡æ–™ output (commit message) çš„ç¬¬ä¸€å€‹å­—ä¸²åˆ†ä½ˆ"""
  print("ğŸ” åˆ†æ Commit Message ç¬¬ä¸€å€‹å­—ä¸²åˆ†ä½ˆ...")

  try:
    with open(data_path, 'r', encoding='utf-8') as f:
      data = json.load(f)

    if not isinstance(data, list):
      print("âŒ æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰è©²æ˜¯ list")
      return None, None

    first_words = []
    valid_data_count = 0

    for i, item in enumerate(data):
      if not isinstance(item, dict):
        continue

      if 'output' not in item:
        continue

      output_text = str(item['output']).strip()
      if not output_text:
        continue

      # åˆ†å‰²æˆå­—ä¸²ä¸¦å–ç¬¬ä¸€å€‹
      words = output_text.split()
      if not words:
        continue

      first_word = words[0]
      first_words.append(first_word)
      valid_data_count += 1

    if not first_words:
      print("âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•¸æ“š")
      return None, None

    # çµ±è¨ˆå­—ä¸²å‡ºç¾æ¬¡æ•¸
    word_counter = Counter(first_words)
    total_count = len(first_words)

    print(f"ğŸ“Š ç¸½å…±åˆ†æäº† {total_count} ç­†æœ‰æ•ˆæ•¸æ“š")
    print(f"ğŸ“Š ç™¼ç¾ {len(word_counter)} å€‹ä¸åŒçš„é¦–å­—ä¸²")
    print("\nğŸ“ˆ Commit Message é¦–å­—ä¸²åˆ†ä½ˆ (æŒ‰å‡ºç¾æ¬¡æ•¸æ’åº):")

    # è¨ˆç®—æ¯”ä¾‹ä¸¦é¡¯ç¤º
    word_stats = []
    for word, count in word_counter.most_common():
      ratio = count / total_count
      # æˆªæ–·éé•·çš„å­—ä¸²ç”¨æ–¼é¡¯ç¤º
      word_display = word if len(word) <= 20 else word[:17] + "..."
      print(
        f"  '{word_display}': {count:4d} æ¬¡ ({ratio:.3f} = {ratio * 100:.1f}%)")
      word_stats.append((word, count, ratio))

    return word_stats, data

  except Exception as e:
    print(f"âŒ åˆ†æå¤±æ•—: {e}")
    return None, None


def filter_by_first_word_ratio(data_path, threshold=0.003):
  """æ ¹æ“š commit message ç¬¬ä¸€å€‹å­—ä¸²å‡ºç¾æ¯”ä¾‹éæ¿¾æ•¸æ“š"""
  print(f"\nğŸ”§ é–‹å§‹éæ¿¾ Commit Message (é–¾å€¼: {threshold})")

  # åˆ†æå­—ä¸²åˆ†ä½ˆ
  word_stats, data = analyze_first_words(data_path)
  if not word_stats or not data:
    return None

  total_count = sum(count for _, count, _ in word_stats)

  # æ‰¾å‡ºéœ€è¦ä¿ç•™çš„å­—ä¸² (æ¯”ä¾‹ >= threshold)
  keep_words = set()
  remove_words = set()

  print(f"\nğŸ“‹ éæ¿¾çµæœ (é–¾å€¼ >= {threshold}):")
  for word, count, ratio in word_stats:
    word_display = word if len(word) <= 20 else word[:17] + "..."
    if ratio >= threshold:
      keep_words.add(word)
      print(f"  âœ… ä¿ç•™ '{word_display}': {ratio:.3f} ({count} ç­†)")
    else:
      remove_words.add(word)
      print(f"  âŒ ç§»é™¤ '{word_display}': {ratio:.3f} ({count} ç­†)")

  # éæ¿¾æ•¸æ“š
  filtered_data = []
  removed_count = 0
  removed_examples = []  # è¨˜éŒ„è¢«ç§»é™¤çš„ç¯„ä¾‹

  for item in data:
    if not isinstance(item, dict) or 'output' not in item:
      continue

    output_text = str(item['output']).strip()
    if not output_text:
      continue

    # ç²å–ç¬¬ä¸€å€‹å­—ä¸²
    words = output_text.split()
    if not words:
      continue

    first_word = words[0]

    if first_word in keep_words:
      filtered_data.append(item)
    else:
      removed_count += 1
      # è¨˜éŒ„å‰å¹¾å€‹è¢«ç§»é™¤çš„ç¯„ä¾‹
      if len(removed_examples) < 5:
        removed_examples.append({
          'first_word': first_word,
          'output': output_text
        })

  # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆå
  base_name = os.path.splitext(data_path)[0]
  timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
  output_path = f"{base_name}_filtered_commit_{threshold}.json"

  # ä¿å­˜éæ¿¾å¾Œçš„æ•¸æ“š
  try:
    with open(output_path, 'w', encoding='utf-8') as f:
      json.dump(filtered_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… éæ¿¾å®Œæˆ!")
    print(f"ğŸ“Š çµ±è¨ˆçµæœ:")
    print(f"  åŸå§‹æ•¸æ“š: {len(data)} ç­†")
    print(f"  ä¿ç•™æ•¸æ“š: {len(filtered_data)} ç­†")
    print(f"  ç§»é™¤æ•¸æ“š: {removed_count} ç­†")
    print(f"  ä¿ç•™æ¯”ä¾‹: {len(filtered_data) / len(data) * 100:.1f}%")
    print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {output_path}")

    # é¡¯ç¤ºä¿ç•™çš„ä¸»è¦å­—ä¸²é¡å‹
    print(f"\nğŸ“‹ ä¿ç•™çš„ä¸»è¦ Commit Message é–‹é ­:")
    for word, count, ratio in word_stats:
      if word in keep_words:
        word_display = word if len(word) <= 30 else word[:27] + "..."
        print(f"  ğŸ¯ '{word_display}': {count} ç­†")

    # é¡¯ç¤ºè¢«ç§»é™¤çš„ç¯„ä¾‹
    if removed_examples:
      print(f"\nğŸ—‘ï¸  è¢«ç§»é™¤çš„ç¯„ä¾‹:")
      for example in removed_examples:
        print(f"  âŒ '{example['first_word']}': {example['output']}")
        if len(removed_examples) >= 5:
          break

    return output_path

  except Exception as e:
    print(f"âŒ ä¿å­˜å¤±æ•—: {e}")
    return None


def main():
  """ä¸»å‡½æ•¸ - CLI æ¨¡å¼"""
  print("ğŸš€ Commit Message ç¬¬ä¸€å€‹å­—ä¸²éæ¿¾å·¥å…·")
  print("=" * 50)

  # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
  if len(sys.argv) != 2:
    print("âŒ ä½¿ç”¨æ–¹æ³•:")
    print(f"   python {sys.argv[0]} <æ•¸æ“šæª”æ¡ˆè·¯å¾‘>")
    print("\nç¯„ä¾‹:")
    print(f"   python {sys.argv[0]} sample_data/spring-boot-training.json")
    print("\nèªªæ˜:")
    print("   - åˆ†ææ¯ç­† output (commit message) çš„ç¬¬ä¸€å€‹å­—ä¸²")
    print("   - éæ¿¾æ‰å‡ºç¾æ¯”ä¾‹ä½æ–¼ 30% çš„å­—ä¸²é–‹é ­çš„è³‡æ–™")
    print("   - ä¾‹å¦‚: 'Remove' æ¯”ä¾‹ < 30% â†’ æ‰€æœ‰ 'Remove' é–‹é ­çš„éƒ½æœƒè¢«åˆªé™¤")
    return

  data_path = sys.argv[1]

  # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
  if not os.path.exists(data_path):
    print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {data_path}")
    return

  print(f"ğŸ“ è¼¸å…¥æª”æ¡ˆ: {data_path}")

  # åŸ·è¡Œéæ¿¾ (å›ºå®šé–¾å€¼ 0.03)
  output_path = filter_by_first_word_ratio(data_path, 0.007)

  if output_path:
    print(f"\nğŸ‰ éæ¿¾å®Œæˆï¼")
    print(f"ğŸ’¡ åœ¨è¨“ç·´ç¨‹å¼ä¸­ä½¿ç”¨: data_path = \"{output_path}\"")


if __name__ == "__main__":
  main()