import json
import sys
import argparse
from pathlib import Path
from transformers import RobertaTokenizer


def count_tokens(text, tokenizer):
  """è¨ˆç®—æ–‡æœ¬çš„ token æ•¸é‡"""
  if not text or not isinstance(text, str):
    return 0

  try:
    tokens = tokenizer.encode(text, add_special_tokens=True,
                              max_length=10000, truncation=False)
    return len(tokens)
  except Exception:
    # å¦‚æœæ–‡æœ¬å¤ªé•·å°è‡´éŒ¯èª¤ï¼Œä¼°ç®—é•·åº¦
    return len(text.split()) * 1.3  # ç²—ç•¥çš„ token ä¼°ç®—


def filter_json_by_length(input_file, max_input_length=2400,
    max_output_length=120):
  """
  éæ¿¾ JSON æª”æ¡ˆï¼Œç§»é™¤è¶…é•·çš„è¨˜éŒ„
  é è¨­ä½¿ç”¨å®Œæ•´è¨­å®šä»¥ä¿ç•™æœ€å¤šè³‡æ–™
  """

  # åˆå§‹åŒ– tokenizer
  print("ğŸ”„ è¼‰å…¥ tokenizer...")
  try:
    tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')
    print("âœ… Tokenizer è¼‰å…¥æˆåŠŸ")
  except Exception as e:
    print(f"âŒ éŒ¯èª¤: ç„¡æ³•è¼‰å…¥ tokenizer: {e}")
    return False

  # è®€å–æª”æ¡ˆ
  input_path = Path(input_file)
  if not input_path.exists():
    print(f"âŒ éŒ¯èª¤: æª”æ¡ˆä¸å­˜åœ¨ - {input_file}")
    return False

  print(f"ğŸ“– è®€å–æª”æ¡ˆ: {input_path.name}")
  try:
    with open(input_path, 'r', encoding='utf-8') as f:
      data = json.load(f)
  except json.JSONDecodeError as e:
    print(f"âŒ éŒ¯èª¤: JSON æ ¼å¼éŒ¯èª¤ - {e}")
    return False
  except Exception as e:
    print(f"âŒ éŒ¯èª¤: ç„¡æ³•è®€å–æª”æ¡ˆ - {e}")
    return False

  # ç¢ºä¿è³‡æ–™æ˜¯åˆ—è¡¨æ ¼å¼
  if not isinstance(data, list):
    if isinstance(data, dict):
      data = [data]
    else:
      print("âŒ éŒ¯èª¤: JSON æª”æ¡ˆå¿…é ˆåŒ…å«åˆ—è¡¨æˆ–å­—å…¸")
      return False

  # çµ±è¨ˆè³‡è¨Š
  stats = {
    'total': len(data),
    'kept': 0,
    'removed_input': 0,
    'removed_output': 0,
    'removed_both': 0,
    'removed_invalid': 0
  }

  # éæ¿¾è³‡æ–™
  filtered_data = []
  removed_examples = []

  print(f"ğŸ” é–‹å§‹éæ¿¾ {stats['total']:,} ç­†è¨˜éŒ„...")
  print(f"ğŸ“ é•·åº¦é™åˆ¶: INPUT â‰¤ {max_input_length}, OUTPUT â‰¤ {max_output_length}")

  for i, item in enumerate(data):
    # é€²åº¦é¡¯ç¤º
    if (i + 1) % 1000 == 0:
      print(f"  å·²è™•ç† {i + 1:,} ç­†...")

    # æª¢æŸ¥è³‡æ–™æ ¼å¼
    if not isinstance(item,
                      dict) or 'input' not in item or 'output' not in item:
      stats['removed_invalid'] += 1
      continue

    input_text = item['input']
    output_text = item['output']

    # è¨ˆç®—é•·åº¦
    input_length = count_tokens(input_text, tokenizer)
    output_length = count_tokens(output_text, tokenizer)

    # åˆ¤æ–·æ˜¯å¦è¶…é•·
    input_too_long = input_length > max_input_length
    output_too_long = output_length > max_output_length

    if input_too_long and output_too_long:
      stats['removed_both'] += 1
      if len(removed_examples) < 3:
        removed_examples.append(
          f"è¨˜éŒ„ {i + 1}: input({input_length}) + output({output_length}) éƒ½è¶…é•·")
    elif input_too_long:
      stats['removed_input'] += 1
      if len(removed_examples) < 3:
        removed_examples.append(f"è¨˜éŒ„ {i + 1}: input({input_length}) è¶…é•·")
    elif output_too_long:
      stats['removed_output'] += 1
      if len(removed_examples) < 3:
        removed_examples.append(f"è¨˜éŒ„ {i + 1}: output({output_length}) è¶…é•·")
    else:
      # ä¿ç•™é€™ç­†è¨˜éŒ„
      filtered_data.append(item)
      stats['kept'] += 1

  # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆå
  output_path = input_path.parent / f"{input_path.stem}_filtered{input_path.suffix}"

  # å„²å­˜çµæœ
  print(f"ğŸ’¾ å„²å­˜éæ¿¾çµæœ...")
  try:
    with open(output_path, 'w', encoding='utf-8') as f:
      json.dump(filtered_data, f, ensure_ascii=False, indent=2)
  except Exception as e:
    print(f"âŒ éŒ¯èª¤: ç„¡æ³•å„²å­˜æª”æ¡ˆ - {e}")
    return False

  # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
  total_removed = stats['total'] - stats['kept']
  keep_ratio = stats['kept'] / stats['total'] * 100

  # é¡¯ç¤ºçµæœå ±å‘Š
  print(f"\n{'=' * 50}")
  print("ğŸ‰ éæ¿¾å®Œæˆï¼")
  print(f"{'=' * 50}")
  print(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸:     {stats['total']:,}")
  print(f"âœ… ä¿ç•™è¨˜éŒ„:     {stats['kept']:,} ({keep_ratio:.1f}%)")
  print(f"âŒ ç§»é™¤è¨˜éŒ„:     {total_removed:,} ({100 - keep_ratio:.1f}%)")

  if total_removed > 0:
    print(f"\nğŸ“‹ ç§»é™¤åŸå› åˆ†æ:")
    print(f"   ğŸ”´ INPUT è¶…é•·:     {stats['removed_input']:,}")
    print(f"   ğŸ”´ OUTPUT è¶…é•·:    {stats['removed_output']:,}")
    print(f"   ğŸ”´ å…©è€…éƒ½è¶…é•·:     {stats['removed_both']:,}")
    if stats['removed_invalid'] > 0:
      print(f"   ğŸ”´ æ ¼å¼ä¸æ­£ç¢º:     {stats['removed_invalid']:,}")

  print(f"\nğŸ“‚ æª”æ¡ˆè¼¸å‡º:")
  print(f"   è¼¸å…¥: {input_path.name}")
  print(f"   è¼¸å‡º: {output_path.name}")

  if removed_examples:
    print(f"\nğŸ” ç§»é™¤ç¯„ä¾‹:")
    for example in removed_examples:
      print(f"   {example}")

  # å»ºè­°ä¸‹ä¸€æ­¥
  print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè­°:")
  if keep_ratio >= 90:
    print("   âœ… ä¿ç•™ç‡å¾ˆé«˜ï¼Œå¯ä»¥ç›´æ¥ç”¨æ–¼è¨“ç·´")
  elif keep_ratio >= 80:
    print("   âš ï¸  ä¿ç•™ç‡ä¸­ç­‰ï¼Œå»ºè­°æª¢æŸ¥ç§»é™¤çš„è¨˜éŒ„æ˜¯å¦é‡è¦")
  else:
    print("   ğŸš¨ ä¿ç•™ç‡è¼ƒä½ï¼Œè€ƒæ…®å¢åŠ é•·åº¦é™åˆ¶æˆ–æª¢æŸ¥è³‡æ–™å“è³ª")

  print(f"   ğŸ“ æ›´æ–° training.py ä¸­çš„è¨­å®š:")
  print(
    f"      max_input_length={max_input_length}, max_target_length={max_output_length}")

  return True


def main():
  """ä¸»å‡½å¼"""
  parser = argparse.ArgumentParser(
      description="éæ¿¾ JSON è¨“ç·´è³‡æ–™ï¼Œç§»é™¤è¶…å‡ºé•·åº¦é™åˆ¶çš„è¨˜éŒ„",
      formatter_class=argparse.RawDescriptionHelpFormatter,
      epilog="""
ğŸ¯ é è¨­è¨­å®š (å®Œæ•´è¨­å®šï¼Œä¿ç•™æœ€å¤šè³‡æ–™):
  --max-input 2400 --max-output 120

ğŸ”¥ å¿«é€Ÿä½¿ç”¨:
  python filter_json.py data.json                    # ä½¿ç”¨é è¨­è¨­å®š
  python filter_json.py data.json --max-input 1600   # è‡ªå®šç¾©INPUTé•·åº¦
  python filter_json.py *.json                       # æ‰¹é‡è™•ç†

ğŸ“Š åŸºæ–¼å¯¦éš›åˆ†æçš„å»ºè­°è¨­å®š:
  å®Œæ•´è¨­å®š: --max-input 2400 --max-output 120  (ä¿ç•™90-95%è³‡æ–™)
  å¹³è¡¡è¨­å®š: --max-input 1600 --max-output 80   (ä¿ç•™80-85%è³‡æ–™)  
  é«˜æ•ˆè¨­å®š: --max-input 1200 --max-output 50   (ä¿ç•™65-70%è³‡æ–™)
        """
  )

  parser.add_argument('json_files', nargs='+',
                      help='JSON æª”æ¡ˆè·¯å¾‘ (æ”¯æ´å¤šæª”æ¡ˆ)')
  parser.add_argument('--max-input', type=int, default=2400,
                      help='æœ€å¤§ input é•·åº¦ (tokens, é è¨­: 2400)')
  parser.add_argument('--max-output', type=int, default=120,
                      help='æœ€å¤§ output é•·åº¦ (tokens, é è¨­: 120)')

  args = parser.parse_args()

  # é©—è­‰åƒæ•¸
  if args.max_input <= 0 or args.max_output <= 0:
    print("âŒ éŒ¯èª¤: é•·åº¦é™åˆ¶å¿…é ˆå¤§æ–¼ 0")
    sys.exit(1)

  # è™•ç†å¤šå€‹æª”æ¡ˆ
  successful = 0
  failed = 0

  for json_file in args.json_files:
    print(f"\n{'ğŸ”„ è™•ç†æª”æ¡ˆ: ' + json_file:=^60}")

    success = filter_json_by_length(
        json_file,
        max_input_length=args.max_input,
        max_output_length=args.max_output
    )

    if success:
      successful += 1
    else:
      failed += 1

  # ç¸½é«”çµæœ
  total_files = len(args.json_files)
  print(f"\n{'ğŸ è™•ç†å®Œæˆ':=^60}")
  print(f"âœ… æˆåŠŸè™•ç†: {successful}/{total_files} å€‹æª”æ¡ˆ")
  if failed > 0:
    print(f"âŒ è™•ç†å¤±æ•—: {failed}/{total_files} å€‹æª”æ¡ˆ")

  if successful == total_files:
    print("\nğŸ‰ æ‰€æœ‰æª”æ¡ˆè™•ç†æˆåŠŸï¼å¯ä»¥é–‹å§‹è¨“ç·´äº†ï¼")
    sys.exit(0)
  else:
    sys.exit(1)


if __name__ == "__main__":
  main()