import json
import argparse
from pathlib import Path
from transformers import RobertaTokenizer


def count_tokens(text, tokenizer):
  """è¨ˆç®—æ–‡æœ¬çš„ token æ•¸é‡"""
  if not text or not isinstance(text, str):
    return 0

  try:
    tokens = tokenizer.encode(text, add_special_tokens=True, truncation=False)
    return len(tokens)
  except Exception:
    return len(text.split()) * 1.3  # ç²—ç•¥ä¼°ç®—


def filter_json_by_length(input_file, max_input_length=1600,
    max_output_length=64):
  """éæ¿¾ JSON æª”æ¡ˆï¼Œç§»é™¤è¶…é•·çš„è¨˜éŒ„"""

  # è¼‰å…¥ tokenizer
  print("ğŸ”„ è¼‰å…¥ tokenizer...")
  try:
    tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')
    print("âœ… Tokenizer è¼‰å…¥æˆåŠŸ")
  except Exception as e:
    print(f"âŒ ç„¡æ³•è¼‰å…¥ tokenizer: {e}")
    return False

  # è®€å–æª”æ¡ˆ
  input_path = Path(input_file)
  if not input_path.exists():
    print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {input_file}")
    return False

  print(f"ğŸ“– è®€å–æª”æ¡ˆ: {input_path.name}")
  try:
    with open(input_path, 'r', encoding='utf-8') as f:
      data = json.load(f)
  except Exception as e:
    print(f"âŒ è®€å–æª”æ¡ˆå¤±æ•—: {e}")
    return False

  if not isinstance(data, list):
    print("âŒ JSON æª”æ¡ˆå¿…é ˆåŒ…å«åˆ—è¡¨æ ¼å¼")
    return False

  # éæ¿¾è³‡æ–™
  filtered_data = []
  removed_count = 0

  print(f"ğŸ” é–‹å§‹éæ¿¾ {len(data):,} ç­†è¨˜éŒ„...")

  for i, item in enumerate(data):
    # æª¢æŸ¥æ ¼å¼
    if not isinstance(item,
                      dict) or 'input' not in item or 'output' not in item:
      removed_count += 1
      continue

    # è¨ˆç®—é•·åº¦
    input_length = count_tokens(item['input'], tokenizer)
    output_length = count_tokens(item['output'], tokenizer)

    # æª¢æŸ¥æ˜¯å¦è¶…é•·
    if input_length <= max_input_length and output_length <= max_output_length:
      filtered_data.append(item)
    else:
      removed_count += 1

  # å„²å­˜çµæœ
  output_path = input_path.parent / f"{input_path.stem}_filtered{input_path.suffix}"

  try:
    with open(output_path, 'w', encoding='utf-8') as f:
      json.dump(filtered_data, f, ensure_ascii=False, indent=2)
  except Exception as e:
    print(f"âŒ å„²å­˜å¤±æ•—: {e}")
    return False

  # é¡¯ç¤ºçµæœ
  total = len(data)
  kept = len(filtered_data)
  keep_ratio = kept / total * 100

  print(f"\n{'=' * 40}")
  print("ğŸ‰ éæ¿¾å®Œæˆï¼")
  print(f"{'=' * 40}")
  print(f"ğŸ“Š ç¸½è¨˜éŒ„:   {total:,}")
  print(f"âœ… ä¿ç•™:     {kept:,} ({keep_ratio:.1f}%)")
  print(f"âŒ ç§»é™¤:     {removed_count:,} ({100 - keep_ratio:.1f}%)")
  print(f"ğŸ“‚ è¼¸å‡º:     {output_path.name}")

  # å»ºè­°
  if keep_ratio >= 90:
    print("ğŸ’¡ ä¿ç•™ç‡å¾ˆé«˜ï¼Œå¯ä»¥ç›´æ¥è¨“ç·´")
  elif keep_ratio >= 70:
    print("ğŸ’¡ ä¿ç•™ç‡ä¸­ç­‰ï¼Œå»ºè­°æª¢æŸ¥è³‡æ–™")
  else:
    print("ğŸ’¡ ä¿ç•™ç‡è¼ƒä½ï¼Œè€ƒæ…®èª¿æ•´é•·åº¦é™åˆ¶")

  return True


def main():
  """ä¸»å‡½å¼"""
  parser = argparse.ArgumentParser(description="éæ¿¾ JSON è¨“ç·´è³‡æ–™")
  parser.add_argument('json_file', help='JSON æª”æ¡ˆè·¯å¾‘')
  parser.add_argument('--max-input', type=int, default=1600,
                      help='æœ€å¤§ input é•·åº¦ (é è¨­: 1600)')
  parser.add_argument('--max-output', type=int, default=64,
                      help='æœ€å¤§ output é•·åº¦ (é è¨­: 64)')

  args = parser.parse_args()

  # é©—è­‰åƒæ•¸
  if args.max_input <= 0 or args.max_output <= 0:
    print("âŒ é•·åº¦é™åˆ¶å¿…é ˆå¤§æ–¼ 0")
    return

  # åŸ·è¡Œéæ¿¾
  success = filter_json_by_length(
      args.json_file,
      max_input_length=args.max_input,
      max_output_length=args.max_output
  )

  if success:
    print("\nğŸ‰ è™•ç†æˆåŠŸï¼å¯ä»¥é–‹å§‹è¨“ç·´äº†ï¼")
  else:
    print("\nâŒ è™•ç†å¤±æ•—")


if __name__ == "__main__":
  main()