import json
import argparse
from pathlib import Path
from transformers import RobertaTokenizer


def load_config(config_file='../config.json'):
  """è¼‰å…¥è¨­å®šæª”"""
  config_path = Path(config_file)
  print(f"ğŸ” å°‹æ‰¾è¨­å®šæª”: {config_path.resolve()}")

  try:
    with open(config_path, 'r', encoding='utf-8') as f:
      config = json.load(f)
    print(f"âœ… è¼‰å…¥è¨­å®šæª”: {config_file}")
    return config
  except FileNotFoundError:
    print(f"âŒ æ‰¾ä¸åˆ°è¨­å®šæª”: {config_path.resolve()}")
    print("ä½¿ç”¨é è¨­è¨­å®š")
    return {"max_input": 512, "max_output": 512}
  except Exception as e:
    print(f"âŒ è¼‰å…¥è¨­å®šæª”å¤±æ•—: {e}")
    return {"max_input": 512, "max_output": 512}


def count_tokens(text, tokenizer):
  """è¨ˆç®— token æ•¸é‡"""
  if not text:
    return 0
  try:
    return len(tokenizer.encode(text, truncation=False))
  except:
    return len(text.split())


def filter_json_by_length(input_file, config_file='../config.json'):
  """éæ¿¾ JSON æª”æ¡ˆ"""

  # è¼‰å…¥è¨­å®š
  config = load_config(config_file)
  max_input = config.get('max_input', 512)
  max_output = config.get('max_output', 512)
  model_name = config.get('model_name', 'Salesforce/codet5-base')

  print(f"ğŸ”§ è¨­å®š: inputâ‰¤{max_input}, outputâ‰¤{max_output}")

  # è¼‰å…¥ tokenizer
  print(f"ğŸ”„ è¼‰å…¥ tokenizer...")
  try:
    tokenizer = RobertaTokenizer.from_pretrained(model_name)
    print("âœ… è¼‰å…¥æˆåŠŸ")
  except Exception as e:
    print(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
    return False

  # è®€å–è³‡æ–™
  try:
    with open(input_file, 'r', encoding='utf-8') as f:
      data = json.load(f)
    print(f"ğŸ“– è®€å– {len(data):,} ç­†è¨˜éŒ„")
  except Exception as e:
    print(f"âŒ è®€å–å¤±æ•—: {e}")
    return False

  # éæ¿¾è³‡æ–™
  filtered_data = []

  for item in data:
    if not isinstance(item,
                      dict) or 'input' not in item or 'output' not in item:
      continue

    input_len = count_tokens(item['input'], tokenizer)
    output_len = count_tokens(item['output'], tokenizer)

    if input_len <= max_input and output_len <= max_output:
      filtered_data.append(item)

  # å„²å­˜çµæœ
  input_path = Path(input_file)
  output_path = input_path.parent / f"{input_path.stem}_filtered{input_path.suffix}"

  try:
    with open(output_path, 'w', encoding='utf-8') as f:
      json.dump(filtered_data, f, ensure_ascii=False, indent=2)
  except Exception as e:
    print(f"âŒ å„²å­˜å¤±æ•—: {e}")
    return False

  # é¡¯ç¤ºçµæœ
  total = len(data)
  kept = len(filtered_data)
  keep_ratio = kept / total * 100 if total > 0 else 0

  print(f"\nğŸ‰ å®Œæˆï¼")
  print(f"ğŸ“Š ç¸½è¨ˆ: {total:,} â†’ ä¿ç•™: {kept:,} ({keep_ratio:.1f}%)")
  print(f"ğŸ“‚ è¼¸å‡º: {output_path.name}")

  return True


def main():
  parser = argparse.ArgumentParser(description="éæ¿¾ JSON è¨“ç·´è³‡æ–™")
  parser.add_argument('json_file', help='JSON æª”æ¡ˆè·¯å¾‘')
  parser.add_argument('--config', default='../config.json', help='è¨­å®šæª”è·¯å¾‘')

  args = parser.parse_args()

  success = filter_json_by_length(args.json_file, args.config)

  if success:
    print("âœ… è™•ç†æˆåŠŸï¼")
  else:
    print("âŒ è™•ç†å¤±æ•—")


if __name__ == "__main__":
  main()