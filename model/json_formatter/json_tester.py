import json
import random
from collections import Counter


def quick_data_analysis(json_file):
  """å¿«é€Ÿåˆ†æè¨“ç·´æ•¸æ“šè³ªé‡"""

  with open(json_file, 'r', encoding='utf-8') as f:
    data = json.load(f)

  print(f"ğŸ“Š æ•¸æ“šæ¦‚è¦½: {len(data)} ç­†")

  # æŠ½æ¨£æª¢æŸ¥
  samples = random.sample(data, min(20, len(data)))

  print("\nğŸ” éš¨æ©Ÿæ¨£æœ¬æª¢æŸ¥:")
  for i, item in enumerate(samples[:10], 1):
    if 'output' in item:
      output = item['output']
      print(f"  {i}. '{output}' (é•·åº¦: {len(output)})")

  # çµ±è¨ˆåˆ†æ
  outputs = [item.get('output', '') for item in data]

  # é•·åº¦åˆ†æ
  lengths = [len(output) for output in outputs if output]
  avg_length = sum(lengths) / len(lengths) if lengths else 0

  print(f"\nğŸ“ é•·åº¦çµ±è¨ˆ:")
  print(f"  å¹³å‡é•·åº¦: {avg_length:.1f}")
  print(f"  æœ€çŸ­: {min(lengths) if lengths else 0}")
  print(f"  æœ€é•·: {max(lengths) if lengths else 0}")

  # å¸¸è¦‹é–‹é ­è©
  first_words = []
  for output in outputs:
    if output:
      first_word = output.split()[0].lower() if output.split() else ''
      first_words.append(first_word)

  print(f"\nğŸ”¤ æœ€å¸¸è¦‹çš„é–‹é ­è©:")
  word_counts = Counter(first_words)
  for word, count in word_counts.most_common(10):
    percentage = count / len(first_words) * 100
    print(f"  {word}: {count} ({percentage:.1f}%)")

  # è³ªé‡å•é¡Œæª¢æ¸¬
  quality_issues = {
    'too_short': sum(1 for l in lengths if l < 10),
    'too_long': sum(1 for l in lengths if l > 70),
    'has_period': sum(1 for o in outputs if o.endswith('.') or o.endswith('ã€‚')),
    'too_generic': sum(1 for o in outputs if any(
        word in o.lower() for word in ['some', 'basic', 'stuff', 'misc']))
  }

  print(f"\nâš ï¸ è³ªé‡å•é¡Œ:")
  total = len(outputs)
  for issue, count in quality_issues.items():
    percentage = count / total * 100
    print(f"  {issue}: {count}/{total} ({percentage:.1f}%)")

  return {
    'total': len(data),
    'avg_length': avg_length,
    'quality_issues': quality_issues,
    'first_words': dict(word_counts.most_common(20))
  }


if __name__ == "__main__":
  import sys

  if len(sys.argv) > 1:
    result = quick_data_analysis(sys.argv[1])

    # çµ¦å‡ºå»ºè­°
    print(f"\nğŸ’¡ å»ºè­°:")
    if result['quality_issues']['too_generic'] > result['total'] * 0.3:
      print("  - è¨“ç·´æ•¸æ“šä¸­æœ‰å¤ªå¤šç± çµ±æè¿°ï¼Œå»ºè­°æ¸…ç†")
    if result['avg_length'] < 20:
      print("  - å¹³å‡é•·åº¦éçŸ­ï¼Œå¯èƒ½ç¼ºå°‘è©³ç´°æè¿°")
    if 'add' in result['first_words'] and result['first_words']['add'] > result[
      'total'] * 0.5:
      print("  - 'add'é–‹é ­éå¤šï¼Œç¼ºå°‘å¤šæ¨£æ€§")
  else:
    print("ä½¿ç”¨æ–¹æ³•: python quick_check.py your_data.json")