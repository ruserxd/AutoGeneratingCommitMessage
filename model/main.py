from transformers import T5ForConditionalGeneration, RobertaTokenizer
import torch
import string_formatter

def test_model():
    """æ¸¬è©¦æ¨¡å‹ç”ŸæˆåŠŸèƒ½"""    
    model_path = "./commit-model"
    tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')
    model = T5ForConditionalGeneration.from_pretrained(model_path)
    model.eval()
    
    # æ¸¬è©¦ç”¨çš„ diff
    text = """
        diff --git a/Car.java b/Car.java
        index 218bbe3..0972a20 100644
        --- a/Car.java
        +++ b/Car.java
        @@ -1,3 +1,35 @@
        public class Car {
        +    String id;
        +    String name;
        +    String year;

        +    public Car(String id, String name, String year) {
        +        this.id = id;
        +        this.name = name;
        +        this.year = year;
        +    }
        +
        +    public String getId() {
        +        return id;
        +    }
        +
        +    public void setId(String id) {
        +        this.id = id;
        +    }
        +
        +    public String getName() {
        +        return name;
        +    }
        +
        +    public void setName(String name) {
        +        this.name = name;
        +    }
        +
        +    public String getYear() {
        +        return year;
        +    }
        +
        +    public void setYear(String year) {
        +        this.year = year;
        +    }
        }
        \ No newline at end of file
        diff --git a/People.java b/People.java
        new file mode 100644
        index 0000000..1177eb8
        --- /dev/null
        +++ b/People.java
        @@ -0,0 +1,35 @@
        +public class People {
        +  String id;
        +  String name;
        +  String birthday;
        +
        +  public People(String id, String name, String birthday) {
        +    this.id = id;
        +    this.name = name;
        +    this.birthday = birthday;
        +  }
        +
        +  public String getId() {
        +    return id;
        +  }
        +
        +  public String getName() {
        +    return name;
        +  }
        +
        +  public String getBirthday() {
        +    return birthday;
        +  }
        +
        +  public void setId(String id) {
        +    this.id = id;
        +  }
        +
        +  public void setName(String name) {
        +    this.name = name;
        +  }
        +
        +  public void setBirthday(String birthday) {
        +    this.birthday = birthday;
        +  }
        +}
        diff --git a/Shop.java b/Shop.java
        new file mode 100644
        index 0000000..5b70055
        --- /dev/null
        +++ b/Shop.java
        @@ -0,0 +1,25 @@
        +public class Shop {
        +  String id;
        +  String name;
        +
        +  public Shop(String id, String name) {
        +    this.id = id;
        +    this.name = name;
        +  }
        +
        +  public String getId() {
        +    return id;
        +  }
        +
        +  public String getName() {
        +    return name;
        +  }
        +
        +  public void setId(String id) {
        +    this.id = id;
        +  }
        +
        +  public void setName(String name) {
        +    this.name = name;
        +  }
        +}"""

    test_diff = string_formatter.clean_text(text)

    print(f"ğŸ“ æ¸¬è©¦è¼¸å…¥:")
    print(test_diff[:200] + "..." if len(test_diff) > 200 else test_diff)
    
    # Tokenization
    inputs = tokenizer(
        test_diff,
        return_tensors="pt",
        max_length=256,  # ç¸®çŸ­é•·åº¦
        truncation=True,
        padding=True
    )
    
    print(f"ğŸ”¢ Input tokens: {inputs.input_ids.shape}")
    print(f"ğŸ”¢ First few tokens: {inputs.input_ids[0][:10]}")
    
    # ç”Ÿæˆ
    with torch.no_grad():
        output = model.generate(
            inputs.input_ids,
            max_length=25,              # é™åˆ¶é•·åº¦
            no_repeat_ngram_size=3,     # é˜²æ­¢3-gramé‡è¤‡
            repetition_penalty=1.3,     # é‡è¤‡æ‡²ç½°
            do_sample=True,             # å•Ÿç”¨æ¡æ¨£
            temperature=0.8,            # é™ä½ç¢ºå®šæ€§
            top_p=0.9,                  # top-pæ¡æ¨£
            pad_token_id=tokenizer.pad_token_id,
        )
    
    print(f"ğŸ”¢ Output tokens: {output.shape}")
    print(f"ğŸ”¢ Output token ids: {output[0]}")
    
    # è§£ç¢¼
    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)
    
    print(f"\nğŸ¯ æ¨¡å‹ç”Ÿæˆçµæœ:")
    print(f"'{decoded_output}'")
    
    return True

def diagnose_tokenizer():
    """è¨ºæ–· tokenizer å•é¡Œ"""
    
    print("\nğŸ” è¨ºæ–· tokenizer...")
    
    tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')
    
    # æª¢æŸ¥ç‰¹æ®Š tokens
    print(f"Vocab size: {tokenizer.vocab_size}")
    print(f"PAD token: {tokenizer.pad_token} (id: {tokenizer.pad_token_id})")
    print(f"EOS token: {tokenizer.eos_token} (id: {tokenizer.eos_token_id})")
    print(f"UNK token: {tokenizer.unk_token} (id: {tokenizer.unk_token_id})")
    
    # æ¸¬è©¦ä¸€äº›å¥‡æ€ªçš„ token ids
    strange_ids = [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
    print(f"\næª¢æŸ¥å¯ç–‘çš„ token ids:")
    for token_id in strange_ids:
        try:
            decoded = tokenizer.decode([token_id])
            print(f"  ID {token_id}: '{decoded}'")
        except:
            print(f"  ID {token_id}: ERROR")

if __name__ == "__main__":
    # è¨ºæ–· tokenizer
    diagnose_tokenizer()
    
    print("\n" + "="*50)
    
    # å®Œæ•´æ¸¬è©¦
    success = test_model()