[
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/bench/WatcherScheduleEngineBenchmark.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/bench/WatcherScheduleEngineBenchmark.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/bench/WatcherScheduleEngineBenchmark.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/bench/WatcherScheduleEngineBenchmark.java\n@@ -163,7 +163,7 @@ public void run() {\n                                 while (start.get()) {\n                                     NodesStatsResponse response = client.admin().cluster().prepareNodesStats(\"_master\").setJvm(true).get();\n                                     ByteSizeValue heapUsed = response.getNodes().get(0).getJvm().getMem().getHeapUsed();\n-                                    jvmUsedHeapSpace.inc(heapUsed.bytes());\n+                                    jvmUsedHeapSpace.inc(heapUsed.getBytes());\n                                     Thread.sleep(1000);\n                                 }\n                             } catch (InterruptedException ignored) {}",
    "output": "Remove duplicate methods in ByteSizeValue. Some methods have been renamed in elastic/elasticsearchelastic/elasticsearch#20560. This commit change a .bytes() call to a .getBytes() call"
  },
  {
    "input": "diff --git a/qa/rolling-upgrade/src/test/java/org/elasticsearch/upgrades/UpgradeClusterClientYamlTestSuiteIT.java b/qa/rolling-upgrade/src/test/java/org/elasticsearch/upgrades/UpgradeClusterClientYamlTestSuiteIT.java\n--- a/qa/rolling-upgrade/src/test/java/org/elasticsearch/upgrades/UpgradeClusterClientYamlTestSuiteIT.java\n+++ b/qa/rolling-upgrade/src/test/java/org/elasticsearch/upgrades/UpgradeClusterClientYamlTestSuiteIT.java\n@@ -28,7 +28,7 @@\n \n import java.io.IOException;\n \n-@TimeoutSuite(millis = 40 * TimeUnits.MINUTE) // some of the windows test VMs are slow as hell\n+@TimeoutSuite(millis = 5 * TimeUnits.MINUTE) // to account for slow as hell VMs\n public class UpgradeClusterClientYamlTestSuiteIT extends ESClientYamlSuiteTestCase {\n \n     @Override",
    "output": "Change the timeout of the rolling upgrades test from 40 mins to 5 mins to still allow accounting for slow VMs"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -82,6 +82,7 @@\n import org.elasticsearch.test.disruption.SlowClusterStateProcessing;\n import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.transport.TcpTransport;\n import org.elasticsearch.transport.TransportException;\n import org.elasticsearch.transport.TransportRequest;\n import org.elasticsearch.transport.TransportRequestOptions;\n@@ -183,6 +184,11 @@ private List<String> startCluster(int numberOfNodes, int minimumMasterNode, @Nul\n             .put(FaultDetection.PING_RETRIES_SETTING.getKey(), \"1\") // for hitting simulated network failures quickly\n             .put(\"discovery.zen.join_timeout\", \"10s\")  // still long to induce failures but to long so test won't time out\n             .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), \"1s\") // <-- for hitting simulated network failures quickly\n+            .put(TcpTransport.TCP_CONNECT_TIMEOUT.getKey(), \"10s\") // Network delay disruption waits for the min between this\n+                                                                   // value and the time of disruption and does not recover immediately\n+                                                                   // when disruption is stop. We should make sure we recover faster\n+                                                                   // then the default of 30s, causing ensureGreen and friends to time out\n+\n             .build();\n \n     @Override",
    "output": "Add a reduced TCP_CONNECT_TIMEOUT setting to DiscoveryWithServiceDisruptionsIT The default of 30s causes some tests to timeout when running ensureGreen and similar. This is because network delays simulation blocks connect until either the connect timeout expires or the disruption configured time stops. We do *not* immediately connect when the disruption is stopped"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHits.java b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHits.java\n--- a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHits.java\n+++ b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHits.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.search.internal;\n \n-import com.carrotsearch.hppc.IntObjectHashMap;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n@@ -29,15 +28,10 @@\n \n import java.io.IOException;\n import java.util.Arrays;\n-import java.util.IdentityHashMap;\n import java.util.Iterator;\n-import java.util.Map;\n \n import static org.elasticsearch.search.internal.InternalSearchHit.readSearchHit;\n \n-/**\n- *\n- */\n public class InternalSearchHits implements SearchHits {\n \n     public static InternalSearchHits empty() {",
    "output": "Remove unused imports"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/CapturingLogger.java b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/CapturingLogger.java\n--- a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/CapturingLogger.java\n+++ b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/CapturingLogger.java\n@@ -57,7 +57,7 @@ private static class MockAppender extends AbstractAppender {\n         public final List<String> trace = new ArrayList<>();\n \n         private MockAppender(final String name) throws IllegalAccessException {\n-            super(name, RegexFilter.createFilter(\".*(\\n.*)*\", new String[0], true, null, null), null);\n+            super(name, RegexFilter.createFilter(\".*(\\n.*)*\", new String[0], false, null, null), null);\n         }\n \n         @Override",
    "output": "Fix failing logging audit tests This commit fixes the logging audit tests which were broken due to an upstream change in core Elasticsearch relating to the fact that prefixes are no longer considered part of the log message, but are instead implemented via markers"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerConfigurationTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerConfigurationTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerConfigurationTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerConfigurationTests.java\n@@ -87,7 +87,7 @@ public void testResolveMultipleConfigs() throws Exception {\n \n     public void testDefaults() throws IOException {\n         final Path configDir = getDataPath(\"config\");\n-        final String level = randomFrom(Level.values()).toString();\n+        final String level = randomFrom(Level.TRACE, Level.DEBUG, Level.INFO, Level.WARN, Level.ERROR).toString();\n         final Settings settings = Settings.builder()\n             .put(Environment.PATH_CONF_SETTING.getKey(), configDir.toAbsolutePath())\n             .put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString())",
    "output": "Fix logger defaults test This commit fixes the test EvilLoggerConfigurationTests#testDefaults"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/test/framework/src/main/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/test/framework/src/main/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/test/framework/src/main/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -25,7 +25,6 @@\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.SuppressForbidden;\n import org.elasticsearch.common.io.PathUtils;\n-import org.elasticsearch.common.logging.LogConfigurator;\n import org.elasticsearch.plugins.PluginInfo;\n import org.junit.Assert;\n ",
    "output": "Remove unused import from BootstrapForTesting This commit removes an unused import for o.e.c.l.LogConfigurator from o.e.b.BootstrapForTesting"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java\n@@ -501,4 +501,21 @@ public void testParseFailsWithMultipleFields() throws IOException {\n         ParsingException e = expectThrows(ParsingException.class, () -> parseQuery(json));\n         assertEquals(\"[range] query doesn't support multiple fields, found [age] and [price]\", e.getMessage());\n     }\n+\n+    public void testParseFailsWithMultipleFieldsWhenOneIsDate() throws IOException {\n+        String json =\n+                \"{\\n\" +\n+                \"    \\\"range\\\": {\\n\" +\n+                \"      \\\"age\\\": {\\n\" +\n+                \"        \\\"gte\\\": 30,\\n\" +\n+                \"        \\\"lte\\\": 40\\n\" +\n+                \"      },\\n\" +\n+                \"      \\\"\" + DATE_FIELD_NAME + \"\\\": {\\n\" +\n+                \"        \\\"gte\\\": \\\"2016-09-13 05:01:14\\\"\\n\" +\n+                \"      }\\n\" +\n+                \"    }\\n\" +\n+                \"  }\";\n+        ParsingException e = expectThrows(ParsingException.class, () -> parseQuery(json));\n+        assertEquals(\"[range] query doesn't support multiple fields, found [age] and [\" + DATE_FIELD_NAME + \"]\", e.getMessage());\n+    }\n }",
    "output": "Add second test case for two fields in range query In this test one field is a number and the other is a date"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n@@ -431,4 +431,22 @@ public void testParseFailsWithMultipleFields() throws IOException {\n         e = expectThrows(ParsingException.class, () -> parseQuery(shortJson));\n         assertEquals(\"[match] query doesn't support multiple fields, found [message1] and [message2]\", e.getMessage());\n     }\n+\n+    public void testParseFailsWithTermsArray() throws Exception {\n+        String json1 = \"{\\n\" +\n+                \"  \\\"match\\\" : {\\n\" +\n+                \"    \\\"message1\\\" : {\\n\" +\n+                \"      \\\"query\\\" : [\\\"term1\\\", \\\"term2\\\"]\\n\" +\n+                \"    }\\n\" +\n+                \"  }\\n\" +\n+                \"}\";\n+        expectThrows(ParsingException.class, () -> parseQuery(json1));\n+\n+        String json2 = \"{\\n\" +\n+                \"  \\\"match\\\" : {\\n\" +\n+                \"    \\\"message1\\\" : [\\\"term1\\\", \\\"term2\\\"]\\n\" +\n+                \"  }\\n\" +\n+                \"}\";\n+        expectThrows(IllegalStateException.class, () -> parseQuery(json2));\n+    }\n }",
    "output": "Add test for match query parsing error when providing an array of terms Match query throws parsing errors when an array of terms is provided, we should test that to make sure this behaviour doesn't change. Relates to"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java\n@@ -74,7 +74,7 @@ public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, Routing\n             // short track if a NO is returned.\n             if (decision == Decision.NO) {\n                 if (logger.isTraceEnabled()) {\n-                    logger.trace(\"Can not allocate [{}] on node [{}] due to [{}]\", shardRouting, node.nodeId(), allocationDecider.getClass().getSimpleName());\n+                    logger.trace(\"Can not allocate [{}] on node [{}] due to [{}]\", shardRouting, node.node(), allocationDecider.getClass().getSimpleName());\n                 }\n                 // short circuit only if debugging is not enabled\n                 if (!allocation.debugDecision()) {",
    "output": "Add node name to decider trace logging Adds the entire DiscoveryNode object to the trace log in AllocationDeciders. The allocation decider logging at TRACE level can sometimes be helpful to determine why a shard is not getting allocated on specific nodes. Currently, we only log the node id for these messages. It will be helpful to also include the node name (esp. when dealing with a lot of nodes in the cluster)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n@@ -525,9 +525,11 @@ public void testShardStats() throws IOException {\n         expectedSubSequence.append(\"\\\",\\\"data_path\\\":\\\"\");\n         expectedSubSequence.append(shard.shardPath().getRootDataPath().toString());\n         expectedSubSequence.append(\"\\\",\\\"is_custom_data_path\\\":\").append(shard.shardPath().isCustomDataPath()).append(\"}\");\n-        assumeFalse(\"Some path weirdness on windows\", Constants.WINDOWS);\n-        assertTrue(xContent.contains(expectedSubSequence));\n-\n+        if (Constants.WINDOWS) {\n+            // Some path weirdness on windows\n+        } else {\n+            assertTrue(xContent.contains(expectedSubSequence));\n+        }\n         closeShards(shard);\n     }\n \n@@ -1014,7 +1016,7 @@ public IndexSearcher wrap(IndexSearcher searcher) throws EngineException {\n         assertThat(before.getMemorySizeInBytes(), equalTo(0L));\n         FieldDataStats after = null;\n         try (Engine.Searcher searcher = shard.acquireSearcher(\"test\")) {\n-            assumeTrue(\"we have to have more than one segment\", searcher.getDirectoryReader().leaves().size() > 1);\n+            assertThat(\"we have to have more than one segment\", searcher.getDirectoryReader().leaves().size(), greaterThan(1));\n             ifd.loadGlobal(searcher.getDirectoryReader());\n             after = shard.fieldData().stats(\"foo\");\n             assertEquals(after.getEvictions(), before.getEvictions());",
    "output": "Remove assumeX methods from IndexShardTests The cause early termination of tests, which means we don't clean up and close shards, but also don't cause a failure. This in turns makes TestRuleTemporaryFilesCleanup fail on windows (because it does try to clean up, but the files are referenced). Getting stuff like: ``` > C:\\jenkins\\workspace\\es_core_master_windows-2012-r2\\core\\build\\testrun\\test\\J3\\temp\\org.elasticsearch.index.shard.IndexShardTests_68B5E1103D78A58B-001\\tempDir-006\\indices\\_na_\\0\\translog\\translog-1.tlog: java.nio.file.AccessDeniedException: C:\\jenkins\\workspace\\es_core_master_windows-2012-r2\\core\\build\\testrun\\test\\J3\\temp\\org.elasticsearch.index.shard.IndexShardTests_68B5E1103D78A58B-001\\tempDir-006\\indices\\_na_\\0\\translog\\translog-1.tlog ```"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/xcontent/BaseXContentTestCase.java b/core/src/test/java/org/elasticsearch/common/xcontent/BaseXContentTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/xcontent/BaseXContentTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/xcontent/BaseXContentTestCase.java\n@@ -295,8 +295,8 @@ public void testBinaryValueWithOffsetLength() throws Exception {\n         assertResult(\"{'binary':null}\", () -> builder().startObject().field(\"binary\").value(null, 0, 0).endObject());\n \n         final byte[] randomBytes = randomBytes();\n-        final int offset = randomIntBetween(0, randomBytes.length);\n-        final int length = randomIntBetween(1, Math.max(1, randomBytes.length - offset));\n+        final int offset = randomIntBetween(0, randomBytes.length - 1);\n+        final int length = randomIntBetween(1, Math.max(1, randomBytes.length - offset - 1));\n \n         XContentBuilder builder = builder().startObject();\n         if (randomBoolean()) {",
    "output": "Fix offsets in BaseXContentTestCase.testBinaryValueWithOffsetLength The max value for randomIntBetween is inclusive, so we should use byte array length minus one to avoid an AIOB exception"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java\n--- a/core/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java\n+++ b/core/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java\n@@ -69,10 +69,6 @@ public IndexReader topLevelReader() {\n             return searcher.getIndexReader();\n         }\n \n-        public IndexSearcher topLevelSearcher() {\n-            return searcher;\n-        }\n-\n         public Map<String, Object> cache() {\n             if (cache == null) {\n                 cache = new HashMap<>();",
    "output": "Remove unused topLevelSearcher method from FetchSubPhase.HitContext"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/LoggingAuditTrailTests.java b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/LoggingAuditTrailTests.java\n--- a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/LoggingAuditTrailTests.java\n+++ b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/xpack/security/audit/logfile/LoggingAuditTrailTests.java\n@@ -673,7 +673,10 @@ public void testAuthenticationSuccessTransport() throws Exception {\n \n         // test disabled\n         CapturingLogger.output(logger.getName(), Level.INFO).clear();\n-        settings = Settings.builder().put(this.settings).put(\"xpack.security.audit.logfile.events.exclude\", \"authentication_success\").build();\n+        settings = Settings.builder()\n+                .put(this.settings)\n+                .put(\"xpack.security.audit.logfile.events.exclude\", \"authentication_success\")\n+                .build();\n         auditTrail = new LoggingAuditTrail(settings, clusterService, logger, threadContext);\n         auditTrail.authenticationSuccess(realm, user, \"_action\", message);\n         assertEmptyLog(logger);",
    "output": "Fix line length in LoggingAuditTrailTests.java"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -87,7 +87,9 @@ public class Version {\n     public static final Version V_5_0_0_alpha5 = new Version(V_5_0_0_alpha5_ID, org.apache.lucene.util.Version.LUCENE_6_1_0);\n     public static final int V_5_0_0_alpha6_ID = 5000006;\n     public static final Version V_5_0_0_alpha6 = new Version(V_5_0_0_alpha6_ID, org.apache.lucene.util.Version.LUCENE_6_2_0);\n-    public static final Version CURRENT = V_5_0_0_alpha6;\n+    public static final int V_5_0_0_beta1_ID = 5000026;\n+    public static final Version V_5_0_0_beta1 = new Version(V_5_0_0_beta1_ID, org.apache.lucene.util.Version.LUCENE_6_2_0);\n+    public static final Version CURRENT = V_5_0_0_beta1;\n \n     static {\n         assert CURRENT.luceneVersion.equals(org.apache.lucene.util.Version.LATEST) : \"Version must be upgraded to [\"\n@@ -100,6 +102,8 @@ public static Version readVersion(StreamInput in) throws IOException {\n \n     public static Version fromId(int id) {\n         switch (id) {\n+            case V_5_0_0_beta1_ID:\n+                return V_5_0_0_beta1;\n             case V_5_0_0_alpha6_ID:\n                 return V_5_0_0_alpha6;\n             case V_5_0_0_alpha5_ID:",
    "output": "Add Version [5.0.0.beta1]"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java\n--- a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java\n+++ b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java\n@@ -29,6 +29,7 @@\n import org.elasticsearch.action.admin.indices.segments.IndexShardSegments;\n import org.elasticsearch.action.admin.indices.segments.IndicesSegmentResponse;\n import org.elasticsearch.action.admin.indices.segments.ShardSegments;\n+import org.elasticsearch.action.admin.indices.settings.get.GetSettingsResponse;\n import org.elasticsearch.action.get.GetResponse;\n import org.elasticsearch.action.search.SearchRequestBuilder;\n import org.elasticsearch.action.search.SearchResponse;\n@@ -310,6 +311,14 @@ void assertBasicSearchWorks(String indexName) {\n         searchRsp = searchReq.get();\n         ElasticsearchAssertions.assertNoFailures(searchRsp);\n         assertEquals(numDocs, searchRsp.getHits().getTotalHits());\n+        GetSettingsResponse getSettingsResponse = client().admin().indices().prepareGetSettings(indexName).get();\n+        Version versionCreated = Version.fromId(Integer.parseInt(getSettingsResponse.getSetting(indexName, \"index.version.created\")));\n+        if (versionCreated.onOrAfter(Version.V_2_4_0)) {\n+            searchReq = client().prepareSearch(indexName).setQuery(QueryBuilders.existsQuery(\"field.with.dots\"));\n+            searchRsp = searchReq.get();\n+            ElasticsearchAssertions.assertNoFailures(searchRsp);\n+            assertEquals(numDocs, searchRsp.getHits().getTotalHits());\n+        }\n     }\n \n     boolean findPayloadBoostInExplanation(Explanation expl) {",
    "output": "Add field with dot in name to 2.4+ static bwc indexes This change adds a `field.with.dots` to all 2.4 bwc indicse and above. It also adds verification code to OldIndexBackwardsCompatibilityIT to ensure we upgrade the indices cleanly and the field is present"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/breaker/CircuitBreakerStats.java b/core/src/main/java/org/elasticsearch/indices/breaker/CircuitBreakerStats.java\n--- a/core/src/main/java/org/elasticsearch/indices/breaker/CircuitBreakerStats.java\n+++ b/core/src/main/java/org/elasticsearch/indices/breaker/CircuitBreakerStats.java\n@@ -49,7 +49,6 @@ public CircuitBreakerStats(String name, long limit, long estimated, double overh\n     }\n \n     public CircuitBreakerStats(StreamInput in) throws IOException {\n-        // limit is the maximum from the old circuit breaker stats for backwards compatibility\n         limit = in.readLong();\n         estimated = in.readLong();\n         overhead = in.readDouble();",
    "output": "Remove stale comment from CircuitBreakerStats"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.common.io.stream.Writeable;\n \n import java.io.IOException;\n+import java.util.Collections;\n import java.util.EnumSet;\n \n public class CommonStatsFlags implements Writeable, Cloneable {\n@@ -44,9 +45,7 @@ public class CommonStatsFlags implements Writeable, Cloneable {\n     public CommonStatsFlags(Flag... flags) {\n         if (flags.length > 0) {\n             clear();\n-            for (Flag f : flags) {\n-                this.flags.add(f);\n-            }\n+            Collections.addAll(this.flags, flags);\n         }\n     }\n ",
    "output": "Use Collections.addAll rather manually copying array"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStatsFlags.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.action.admin.indices.stats;\n \n-import org.elasticsearch.Version;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.io.stream.Writeable;\n@@ -63,11 +62,7 @@ public CommonStatsFlags(StreamInput in) throws IOException {\n         groups = in.readStringArray();\n         fieldDataFields = in.readStringArray();\n         completionDataFields = in.readStringArray();\n-        if (in.getVersion().onOrAfter(Version.V_5_0_0_alpha1)) {\n-            includeSegmentFileSizes = in.readBoolean();\n-        } else {\n-            includeSegmentFileSizes = false;\n-        }\n+        includeSegmentFileSizes = in.readBoolean();\n     }\n \n     @Override\n@@ -82,9 +77,7 @@ public void writeTo(StreamOutput out) throws IOException {\n         out.writeStringArrayNullable(groups);\n         out.writeStringArrayNullable(fieldDataFields);\n         out.writeStringArrayNullable(completionDataFields);\n-        if (out.getVersion().onOrAfter(Version.V_5_0_0_alpha1)) {\n-            out.writeBoolean(includeSegmentFileSizes);\n-        }\n+        out.writeBoolean(includeSegmentFileSizes);\n     }\n \n     /**",
    "output": "Remove bw comp layer that's not needed in CommonStatsFlags"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java b/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n--- a/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n@@ -386,6 +386,30 @@ public void writeTo(StreamOutput out) throws IOException {\n             out.writeLong(totalWriteKilobytes);\n         }\n \n+        public DeviceStats[] getDevicesStats() {\n+            return devicesStats;\n+        }\n+\n+        public long getTotalOperations() {\n+            return totalOperations;\n+        }\n+\n+        public long getTotalReadOperations() {\n+            return totalReadOperations;\n+        }\n+\n+        public long getTotalWriteOperations() {\n+            return totalWriteOperations;\n+        }\n+\n+        public long getTotalReadKilobytes() {\n+            return totalReadKilobytes;\n+        }\n+\n+        public long getTotalWriteKilobytes() {\n+            return totalWriteKilobytes;\n+        }\n+\n         @Override\n         public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n             if (devicesStats.length > 0) {",
    "output": "Add missing getters to FsInfo.IoStats class Without the getters there is no way to retrieve the values for its instance members from the java api, they only get printed out on the REST layer"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java\n@@ -66,7 +66,9 @@ void execute(Terminal terminal, String pluginName, Map<String, String> settings)\n \n         Path pluginDir = env.pluginsFile().resolve(pluginName);\n         if (Files.exists(pluginDir) == false) {\n-            throw new UserException(ExitCodes.USAGE, \"plugin \" + pluginName + \" not found; run 'elasticsearch-plugin list' to get list of installed plugins\");\n+            throw new UserException(\n+                    ExitCodes.USAGE,\n+                    \"plugin \" + pluginName + \" not found; run 'elasticsearch-plugin list' to get list of installed plugins\");\n         }\n \n         List<Path> pluginPaths = new ArrayList<>();",
    "output": "Remove length violation in RemovePluginCommand This commit removes a line-length violation in RemovePluginCommand.java and removes this file from the list of files for which the line-length check is suppressed"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/JarHellTests.java b/core/src/test/java/org/elasticsearch/bootstrap/JarHellTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/JarHellTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/JarHellTests.java\n@@ -117,6 +117,12 @@ public void testLog4jLeniency() throws Exception {\n         JarHell.checkJarHell(jars);\n     }\n \n+    public void testLog4jThrowableProxyLeniency() throws Exception {\n+        Path dir = createTempDir();\n+        URL[] jars = {makeJar(dir, \"foo.jar\", null, \"org.apache.logging.log4j.core.impl.ThrowableProxy.class\"), makeJar(dir, \"bar.jar\", null, \"org.apache.logging.log4j.core.impl.ThrowableProxy.class\")};\n+        JarHell.checkJarHell(jars);\n+    }\n+\n     public void testWithinSingleJar() throws Exception {\n         // the java api for zip file does not allow creating duplicate entries (good!) so\n         // this bogus jar had to be constructed with ant",
    "output": "Add test for Log4j throwable proxy leniency We have intentionally introduced leniency for ThrowableProxy from Log4j to work around a bug there. Yet, a test for this introduced leniency was not addded. This commit introduces such a test. Relates"
  },
  {
    "input": "diff --git a/modules/rank-eval/src/main/java/org/elasticsearch/index/rankeval/PrecisionAtN.java b/modules/rank-eval/src/main/java/org/elasticsearch/index/rankeval/PrecisionAtN.java\n--- a/modules/rank-eval/src/main/java/org/elasticsearch/index/rankeval/PrecisionAtN.java\n+++ b/modules/rank-eval/src/main/java/org/elasticsearch/index/rankeval/PrecisionAtN.java\n@@ -153,9 +153,11 @@ public static Rating mapTo(Integer rating) {\n \n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n         builder.startObject(NAME);\n         builder.field(SIZE_FIELD.getPreferredName(), this.n);\n         builder.endObject();\n+        builder.endObject();\n         return builder;\n     }\n ",
    "output": "Add additional json object level to PrecisionAtN rendering"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java b/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java\n--- a/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java\n+++ b/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java\n@@ -53,7 +53,7 @@ public void testOsStats() {\n         assertThat(stats.getTimestamp(), greaterThan(0L));\n         assertThat(stats.getCpu().getPercent(), anyOf(equalTo((short) -1),\n                 is(both(greaterThanOrEqualTo((short) 0)).and(lessThanOrEqualTo((short) 100)))));\n-        double[] loadAverage = stats.getCpu().loadAverage;\n+        double[] loadAverage = stats.getCpu().getLoadAverage();\n         if (loadAverage != null) {\n             assertThat(loadAverage.length, equalTo(3));\n         }",
    "output": "Fix bad merge"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/yaml/ClientYamlTestExecutionContext.java b/test/framework/src/main/java/org/elasticsearch/test/rest/yaml/ClientYamlTestExecutionContext.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/yaml/ClientYamlTestExecutionContext.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/yaml/ClientYamlTestExecutionContext.java\n@@ -75,8 +75,10 @@ public ClientYamlTestResponse callApi(String apiName, Map<String, String> params\n             response = e.getRestTestResponse();\n             throw e;\n         } finally {\n+            // if we hit a bad exception the response is null\n+            Object repsponseBody = response != null ? response.getBody() : null;\n             //we always stash the last response body\n-            stash.stashValue(\"body\", response.getBody());\n+            stash.stashValue(\"body\", repsponseBody);\n         }\n     }\n ",
    "output": "Fix possible NPE in ClientYamlTestExecutionContext"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n@@ -126,7 +126,6 @@\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicInteger;\n import java.util.concurrent.atomic.AtomicReference;\n-import java.util.function.IntFunction;\n \n import static java.util.Collections.emptyMap;\n import static org.elasticsearch.index.engine.Engine.Operation.Origin.PRIMARY;\n@@ -172,10 +171,10 @@ public void setUp() throws Exception {\n             codecName = \"default\";\n         }\n         defaultSettings = IndexSettingsModule.newIndexSettings(\"test\", Settings.builder()\n-                .put(IndexSettings.INDEX_GC_DELETES_SETTING, \"1h\") // make sure this doesn't kick in on us\n+                .put(IndexSettings.INDEX_GC_DELETES_SETTING.getKey(), \"1h\") // make sure this doesn't kick in on us\n                 .put(EngineConfig.INDEX_CODEC_SETTING.getKey(), codecName)\n                 .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)\n-                .put(IndexSettings.MAX_REFRESH_LISTENERS_PER_SHARD,\n+                .put(IndexSettings.MAX_REFRESH_LISTENERS_PER_SHARD.getKey(),\n                         between(10, 10 * IndexSettings.MAX_REFRESH_LISTENERS_PER_SHARD.get(Settings.EMPTY)))\n                 .build()); // TODO randomize more settings\n         threadPool = new TestThreadPool(getClass().getName());",
    "output": "Fix settings keys to be the actual keys rather than the toString() of the Setting"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java b/modules/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java\n--- a/modules/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java\n+++ b/modules/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java\n@@ -71,7 +71,6 @@\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n-import java.util.concurrent.atomic.AtomicBoolean;\n \n import static java.util.Collections.emptyList;\n ",
    "output": "Remove extraneous import"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/monitoring/src/main/java/org/elasticsearch/xpack/monitoring/resolver/node/NodeStatsResolver.java b/elasticsearch/x-pack/monitoring/src/main/java/org/elasticsearch/xpack/monitoring/resolver/node/NodeStatsResolver.java\n--- a/elasticsearch/x-pack/monitoring/src/main/java/org/elasticsearch/xpack/monitoring/resolver/node/NodeStatsResolver.java\n+++ b/elasticsearch/x-pack/monitoring/src/main/java/org/elasticsearch/xpack/monitoring/resolver/node/NodeStatsResolver.java\n@@ -103,11 +103,11 @@ public class NodeStatsResolver extends MonitoringIndexNameResolver.Timestamped<N\n             // Disk Info\n             \"node_stats.fs.data.spins\",\n             // Node IO Stats\n-            \"node_stats.fs.io_stats.operations\",\n-            \"node_stats.fs.io_stats.read_operations\",\n-            \"node_stats.fs.io_stats.write_operations\",\n-            \"node_stats.fs.io_stats.read_kilobytes\",\n-            \"node_stats.fs.io_stats.write_kilobytes\");\n+            \"node_stats.fs.io_stats.total.operations\",\n+            \"node_stats.fs.io_stats.total.read_operations\",\n+            \"node_stats.fs.io_stats.total.write_operations\",\n+            \"node_stats.fs.io_stats.total.read_kilobytes\",\n+            \"node_stats.fs.io_stats.total.write_kilobytes\");\n         FILTERS = Collections.unmodifiableSet(filters);\n     }\n ",
    "output": "Fix test on Linux; setting name missing 'total.'"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/test/SecurityIntegTestCase.java b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/test/SecurityIntegTestCase.java\n--- a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/test/SecurityIntegTestCase.java\n+++ b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/test/SecurityIntegTestCase.java\n@@ -119,7 +119,8 @@ private static Scope getCurrentClusterScope(Class<?> clazz) {\n     @BeforeClass\n     public static void initDefaultSettings() {\n         if (SECURITY_DEFAULT_SETTINGS == null) {\n-            SECURITY_DEFAULT_SETTINGS = new SecuritySettingsSource(defaultMaxNumberOfNodes(), randomBoolean(), createTempDir(), Scope.SUITE);\n+            SECURITY_DEFAULT_SETTINGS =\n+                    new SecuritySettingsSource(defaultMaxNumberOfNodes(), randomBoolean(), createTempDir(), Scope.SUITE);\n         }\n     }\n ",
    "output": "Fix line length"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java b/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java\n--- a/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java\n@@ -28,6 +28,7 @@\n \n import java.io.IOException;\n import java.util.Arrays;\n+import java.util.Objects;\n \n public class OsStats implements Writeable, ToXContent {\n \n@@ -38,9 +39,9 @@ public class OsStats implements Writeable, ToXContent {\n \n     public OsStats(long timestamp, Cpu cpu, Mem mem, Swap swap) {\n         this.timestamp = timestamp;\n-        this.cpu = cpu;\n-        this.mem = mem;\n-        this.swap = swap;\n+        this.cpu = Objects.requireNonNull(cpu, \"cpu must not be null\");\n+        this.mem = Objects.requireNonNull(mem, \"mem must not be null\");;\n+        this.swap = Objects.requireNonNull(swap, \"swap must not be null\");;\n     }\n \n     public OsStats(StreamInput in) throws IOException {",
    "output": "Make sure that mem, cpu and swap are never null in OsStats"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/actions/ActionWrapper.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/actions/ActionWrapper.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/actions/ActionWrapper.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/actions/ActionWrapper.java\n@@ -115,7 +115,9 @@ public ActionWrapper.Result execute(WatchExecutionContext ctx) {\n                                                     new Action.Result.ConditionFailed(action.type(), \"condition not met. skipping\"));\n                 }\n             } catch (RuntimeException e) {\n-                action.logger().error(\"failed to execute action [{}/{}]. failed to execute condition\", e, ctx.watch().id(), id);\n+                action.logger().error(\n+                        (Supplier<?>) () -> new ParameterizedMessage(\n+                                \"failed to execute action [{}/{}]. failed to execute condition\", ctx.watch().id(), id), e);\n                 return new ActionWrapper.Result(id, new Action.Result.ConditionFailed(action.type(),\n                                                 \"condition failed. skipping: {}\", e.getMessage()));\n             }",
    "output": "Fix additional exception logging call This commit modifies an exception logging calls to use a parameterized message from Log4j"
  },
  {
    "input": "diff --git a/test/logger-usage/src/test/java/org/elasticsearch/test/loggerusage/ESLoggerUsageTests.java b/test/logger-usage/src/test/java/org/elasticsearch/test/loggerusage/ESLoggerUsageTests.java\n--- a/test/logger-usage/src/test/java/org/elasticsearch/test/loggerusage/ESLoggerUsageTests.java\n+++ b/test/logger-usage/src/test/java/org/elasticsearch/test/loggerusage/ESLoggerUsageTests.java\n@@ -39,6 +39,11 @@\n \n public class ESLoggerUsageTests extends ESTestCase {\n \n+    // needed to avoid the test suite from failing for having no tests\n+    public void testSoThatTestsDoNotFail() {\n+\n+    }\n+\n     @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/20243\")\n     public void testLoggerUsageChecks() throws IOException {\n         for (Method method : getClass().getMethods()) {",
    "output": "Add empty test to ESLoggerUsageTests This commit adds an empty test to ESLoggerUsageTests to avoid the test suite from failing for having no tests after the existing tests were marked as awaits fix in 1d197eddcc2a5dea7d7608d76530e1c2b20f2cd0"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/logging/DeprecationLogger.java b/core/src/main/java/org/elasticsearch/common/logging/DeprecationLogger.java\n--- a/core/src/main/java/org/elasticsearch/common/logging/DeprecationLogger.java\n+++ b/core/src/main/java/org/elasticsearch/common/logging/DeprecationLogger.java\n@@ -36,10 +36,6 @@ public class DeprecationLogger {\n \n     private final Logger logger;\n \n-    public Logger getLogger() {\n-        return logger;\n-    }\n-\n     /**\n      * The \"Warning\" Header comes from RFC-7234. As the RFC describes, it's generally used for caching purposes, but it can be\n      * used for <em>any</em> warning.",
    "output": "Remove logger getter from DeprecationLogger This commit removes an unused getter for the logger field from the DeprecationLogger"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/OperationModeFileWatcher.java b/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/OperationModeFileWatcher.java\n--- a/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/OperationModeFileWatcher.java\n+++ b/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/OperationModeFileWatcher.java\n@@ -99,21 +99,16 @@ private synchronized void onChange(Path file) {\n                 } catch (IOException e) {\n                     logger.error(\n                             (Supplier<?>) () -> new ParameterizedMessage(\n-                                    \"couldn't read operation mode from [{}]\",\n-                                    licenseModePath.toAbsolutePath().toString()),\n-                            e);\n+                                    \"couldn't read operation mode from [{}]\", licenseModePath.toAbsolutePath()), e);\n                     return;\n                 }\n                 String operationMode = new String(content, StandardCharsets.UTF_8);\n                 try {\n                     currentOperationMode = OperationMode.resolve(operationMode);\n                 } catch (IllegalArgumentException e) {\n                     logger.error(\n-                            (Supplier<?>)\n-                                    () -> new ParameterizedMessage(\n-                                            \"invalid operation mode in [{}]\",\n-                                            licenseModePath.toAbsolutePath().toString()),\n-                            e);\n+                            (Supplier<?>) () -> new ParameterizedMessage(\n+                                    \"invalid operation mode in [{}]\", licenseModePath.toAbsolutePath()), e);\n                     return;\n                 }\n             }",
    "output": "Remove unnecessary calls to Path#toString This commit removes some unnecessary calls to Path#toString when logging a path in OperationFileModeWatcher#onChage. The calls to Path#toString are not necessary since the logging infrastructure will do this anyway"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/transform/search/ExecutableSearchTransform.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/transform/search/ExecutableSearchTransform.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/transform/search/ExecutableSearchTransform.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/transform/search/ExecutableSearchTransform.java\n@@ -23,9 +23,6 @@\n \n import static org.elasticsearch.xpack.watcher.transform.search.SearchTransform.TYPE;\n \n-/**\n- *\n- */\n public class ExecutableSearchTransform extends ExecutableTransform<SearchTransform, SearchTransform.Result> {\n \n     public static final SearchType DEFAULT_SEARCH_TYPE = SearchType.QUERY_THEN_FETCH;",
    "output": "Remove empty Javadocs in ExecutableSearchTransform This commit removes some inadvertent blank Javadocs for ExecutableSearchTransform"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/notification/email/attachment/HttpEmailAttachementParser.java b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/notification/email/attachment/HttpEmailAttachementParser.java\n--- a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/notification/email/attachment/HttpEmailAttachementParser.java\n+++ b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/notification/email/attachment/HttpEmailAttachementParser.java\n@@ -112,12 +112,11 @@ public Attachment toAttachment(WatchExecutionContext context, Payload payload,\n         } catch (IOException e) {\n             logger.error(\n                     (Supplier<?>) () -> new ParameterizedMessage(\n-                            \"Error executing HTTP request: [host[{}], port[{}], method[{}], path[{}]: [{}]\",\n+                            \"Error executing HTTP request: [host[{}], port[{}], method[{}], path[{}]\",\n                             httpRequest.host(),\n                             httpRequest.port(),\n                             httpRequest.method(),\n-                            httpRequest.path(),\n-                            e.getMessage()),\n+                            httpRequest.path()),\n                     e);\n         }\n ",
    "output": "Remove unnecessary logging of exception message This commit removes an unnecessary logging of an exception message from HttpEmailAttachementParser#toAttachment since the full exception is logged anyway"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/common/logging/EvilLoggerTests.java\n@@ -76,7 +76,7 @@ public void testLocationInfoTest() throws IOException {\n     }\n \n     private void assertLogLine(final String logLine, final Level level, final String location, final String message) {\n-        final Matcher matcher = Pattern.compile(\"\\\\[(.*)\\\\]\\\\[(.*)\\\\(.*\\\\)\\\\] \\\\[\\\\] (.*)\").matcher(logLine);\n+        final Matcher matcher = Pattern.compile(\"\\\\[(.*)\\\\]\\\\[(.*)\\\\(.*\\\\)\\\\] (.*)\").matcher(logLine);\n         assertTrue(logLine, matcher.matches());\n         assertThat(matcher.group(1), equalTo(level.toString()));\n         assertThat(matcher.group(2), equalTo(location));",
    "output": "Fix failing evil logger tests This commit fixes failing evil logger tests. The tests were failing after inadvertently configuring appenders on the parent and child logger"
  },
  {
    "input": "diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java\n--- a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java\n+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java\n@@ -28,6 +28,7 @@\n import com.microsoft.azure.storage.blob.CloudBlockBlob;\n import com.microsoft.azure.storage.blob.ListBlobItem;\n import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.blobstore.BlobMetaData;\n import org.elasticsearch.common.blobstore.support.PlainBlobMetaData;\n@@ -173,7 +174,7 @@ public void createContainer(String account, LocationMode mode, String container)\n             logger.trace(\"creating container [{}]\", container);\n             blobContainer.createIfNotExists();\n         } catch (IllegalArgumentException e) {\n-            logger.trace(() -> new ParameterizedMessage(\"fails creating container [{}]\", container), e);\n+            logger.trace((Supplier<?>) () -> new ParameterizedMessage(\"fails creating container [{}]\", container), e);\n             throw new RepositoryException(container, e.getMessage());\n         }\n     }",
    "output": "Add missing cast to logging message supplier This commit adds a missing cast to logging message supplier on a single invocation receiving a parameterized message parameter"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/InnerHitBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/InnerHitBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/InnerHitBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/InnerHitBuilderTests.java\n@@ -350,8 +350,9 @@ static InnerHitBuilder mutate(InnerHitBuilder instance) throws IOException {\n                 if (instance.getStoredFieldsContext() == null || randomBoolean()) {\n                     List<String> previous = instance.getStoredFieldsContext() == null ?\n                         Collections.emptyList() : instance.getStoredFieldsContext().fieldNames();\n-                    instance.setStoredFieldNames(randomValueOtherThan(previous,\n-                        () -> randomListStuff(16, () -> randomAsciiOfLengthBetween(1, 16))));\n+                    List<String> newValues = randomValueOtherThan(previous,\n+                            () -> randomListStuff(1, 16, () -> randomAsciiOfLengthBetween(1, 16)));\n+                    instance.setStoredFieldNames(newValues);\n                 } else {\n                     instance.getStoredFieldsContext().addFieldName(randomAsciiOfLengthBetween(1, 16));\n                 }\n@@ -377,7 +378,11 @@ static SearchSourceBuilder.ScriptField randomScript() {\n     }\n \n     static <T> List<T> randomListStuff(int maxSize, Supplier<T> valueSupplier) {\n-        int size = randomIntBetween(0, maxSize);\n+        return randomListStuff(0, maxSize, valueSupplier);\n+    }\n+\n+    static <T> List<T> randomListStuff(int minSize, int maxSize, Supplier<T> valueSupplier) {\n+        int size = randomIntBetween(minSize, maxSize);\n         List<T> list = new ArrayList<>(size);\n         for (int i = 0; i < size; i++) {\n             list.add(valueSupplier.get());",
    "output": "Fix test bug"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java b/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java\n@@ -27,6 +27,7 @@\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n import org.elasticsearch.cluster.routing.allocation.command.AllocateEmptyPrimaryAllocationCommand;\n import org.elasticsearch.cluster.routing.allocation.command.AllocateStalePrimaryAllocationCommand;\n+import org.elasticsearch.cluster.service.ClusterService;\n import org.elasticsearch.common.collect.ImmutableOpenIntMap;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.util.set.Sets;\n@@ -187,8 +188,8 @@ public void testForceStaleReplicaToBePromotedToPrimary() throws Exception {\n             // its possible that the shard has not completed initialization, even though the cluster health is yellow, so the\n             // search can throw an \"all shards failed\" exception.  We will wait until the shard initialization has completed before\n             // verifying the search hit count.\n-            assertBusy(() -> assertTrue(clusterService().state().routingTable().index(idxName).allPrimaryShardsActive()));\n-\n+            assertBusy(() -> assertTrue(client().admin().cluster().prepareState().get()\n+                                            .getState().routingTable().index(idxName).allPrimaryShardsActive()));\n         }\n         assertHitCount(client().prepareSearch(idxName).setSize(0).setQuery(matchAllQuery()).get(), useStaleReplica ? 1L : 0L);\n ",
    "output": "Fix test to use admin client to check the cluster state instead of a random node's cluster service"
  },
  {
    "input": "diff --git a/client/client-benchmark-noop-api-plugin/src/main/java/org/elasticsearch/plugin/noop/action/search/NoopSearchRequestBuilder.java b/client/client-benchmark-noop-api-plugin/src/main/java/org/elasticsearch/plugin/noop/action/search/NoopSearchRequestBuilder.java\n--- a/client/client-benchmark-noop-api-plugin/src/main/java/org/elasticsearch/plugin/noop/action/search/NoopSearchRequestBuilder.java\n+++ b/client/client-benchmark-noop-api-plugin/src/main/java/org/elasticsearch/plugin/noop/action/search/NoopSearchRequestBuilder.java\n@@ -248,14 +248,6 @@ public NoopSearchRequestBuilder setStats(List<String> statsGroups) {\n         return this;\n     }\n \n-    /**\n-     * Sets no fields to be loaded, resulting in only id and type to be returned per field.\n-     */\n-    public NoopSearchRequestBuilder setNoStoredFields() {\n-        sourceBuilder().noStoredFields();\n-        return this;\n-    }\n-\n     /**\n      * Indicates whether the response should contain the stored _source for every hit\n      */",
    "output": "Remove obsolete NoopSearchRequestBuilder#setNoStoredFields()"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/env/ShardLockObtainFailedException.java b/core/src/main/java/org/elasticsearch/env/ShardLockObtainFailedException.java\n--- a/core/src/main/java/org/elasticsearch/env/ShardLockObtainFailedException.java\n+++ b/core/src/main/java/org/elasticsearch/env/ShardLockObtainFailedException.java\n@@ -39,7 +39,7 @@ public ShardLockObtainFailedException(ShardId shardId, String message, Throwable\n \n     @Override\n     public String getMessage() {\n-        StringBuffer sb = new StringBuffer();\n+        StringBuilder sb = new StringBuilder();\n         sb.append(shardId.toString());\n         sb.append(\": \");\n         sb.append(super.getMessage());\n\ndiff --git a/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/phonetic/Nysiis.java b/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/phonetic/Nysiis.java\n--- a/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/phonetic/Nysiis.java\n+++ b/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/phonetic/Nysiis.java\n@@ -263,7 +263,7 @@ public String nysiis(String str) {\n         str = PAT_DT_ETC.matcher(str).replaceFirst(\"D\");\n \n         // First character of key = first character of name.\n-        StringBuffer key = new StringBuffer(str.length());\n+        StringBuilder key = new StringBuilder(str.length());\n         key.append(str.charAt(0));\n \n         // Transcode remaining characters, incrementing by one character each time",
    "output": "Use StringBuilder in favor of StringBuffer This removes all instances of StringBuffer that are removeable. Uncontended synchronization in Java is pretty cheap, but it's unnecessary"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java b/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java\n--- a/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java\n+++ b/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java\n@@ -104,7 +104,7 @@ public LicenseService(Settings settings, ClusterService clusterService, Clock cl\n     }\n \n     private void logExpirationWarning(long expirationMillis, boolean expired) {\n-        String expiredMsg = expired ? \"will expire\" : \"expired\";\n+        String expiredMsg = expired ? \"expired\" : \"will expire\";\n         String general = LoggerMessageFormat.format(null, \"\\n\" +\n             \"#\\n\" +\n             \"# License [{}] on [{}]. If you have a new license, please update it.\\n\" +",
    "output": "Fix license expiry logging"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java b/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java\n--- a/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java\n+++ b/elasticsearch/x-pack/license-plugin/src/main/java/org/elasticsearch/license/LicenseService.java\n@@ -104,7 +104,7 @@ public LicenseService(Settings settings, ClusterService clusterService, Clock cl\n     }\n \n     private void logExpirationWarning(long expirationMillis, boolean expired) {\n-        String expiredMsg = expired ? \"will expire\" : \"expired\";\n+        String expiredMsg = expired ? \"expired\" : \"will expire\";\n         String general = LoggerMessageFormat.format(null, \"\\n\" +\n             \"#\\n\" +\n             \"# License [{}] on [{}]. If you have a new license, please update it.\\n\" +",
    "output": "Fix license expiry logging"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptIT.java\n@@ -243,7 +243,7 @@ public void testInlineScript2() {\n         }\n     }\n \n-    public void testInlineScript3() {\n+    public void testInlineScriptWithDateRange() {\n         SearchResponse response = client()\n             .prepareSearch(\"idx\")\n             .addAggregation(",
    "output": "Use a better name for unit test method"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterModuleTests.java b/core/src/test/java/org/elasticsearch/cluster/ClusterModuleTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ClusterModuleTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterModuleTests.java\n@@ -105,7 +105,7 @@ public void testRegisterIndexDynamicSetting() {\n     public void testRegisterAllocationDeciderDuplicate() {\n         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () ->\n             new ClusterModule(Settings.EMPTY, clusterService,\n-                Collections.singletonList(new ClusterPlugin() {\n+                Collections.<ClusterPlugin>singletonList(new ClusterPlugin() {\n                     @Override\n                     public Collection<AllocationDecider> createAllocationDeciders(Settings settings, ClusterSettings clusterSettings) {\n                         return Collections.singletonList(new EnableAllocationDecider(settings, clusterSettings));",
    "output": "Make generics explicit to please ECJ"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n@@ -212,7 +212,7 @@ private Path download(Terminal terminal, String pluginId, Path tmpDir) throws Ex\n             final String stagingHash = System.getProperty(PROPERTY_STAGING_ID);\n             if (stagingHash != null) {\n                 url = String.format(Locale.ROOT,\n-                    \"https://staging.elastic.co/%1$s/download/elasticsearch-plugins/%2$s/%2$s-%3$s.zip\",\n+                    \"https://staging.elastic.co/%3$s-%1$s/download/elasticsearch-plugins/%2$s/%2$s-%3$s.zip\",\n                     stagingHash, pluginId, version);\n             } else {\n                 url = String.format(Locale.ROOT,",
    "output": "Fix staging url for official plugins This was incorrectly setup in #19996, without the version in the staging build id"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java b/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java\n--- a/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java\n+++ b/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java\n@@ -80,7 +80,7 @@ public Map<String, BaseInnerHits> getInnerHits() {\n     public void addInnerHitDefinition(BaseInnerHits innerHit) {\n         if (innerHits.containsKey(innerHit.getName())) {\n             throw new IllegalArgumentException(\"inner_hit definition with the name [\" + innerHit.getName() +\n-                    \"] already exists. Use a different inner_hit name\");\n+                    \"] already exists. Use a different inner_hit name or define one explicitly\");\n         }\n \n         innerHits.put(innerHit.getName(), innerHit);",
    "output": "Make exception message more descriptive"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java b/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java\n--- a/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java\n+++ b/core/src/main/java/org/elasticsearch/search/fetch/subphase/InnerHitsContext.java\n@@ -80,7 +80,7 @@ public Map<String, BaseInnerHits> getInnerHits() {\n     public void addInnerHitDefinition(BaseInnerHits innerHit) {\n         if (innerHits.containsKey(innerHit.getName())) {\n             throw new IllegalArgumentException(\"inner_hit definition with the name [\" + innerHit.getName() +\n-                    \"] already exists. Use a different inner_hit name\");\n+                    \"] already exists. Use a different inner_hit name or define one explicitly\");\n         }\n \n         innerHits.put(innerHit.getName(), innerHit);",
    "output": "Make exception message more descriptive Exception message should be more descriptive about what to do when inner_hit names colides"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/support/WatcherScriptTests.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/support/WatcherScriptTests.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/support/WatcherScriptTests.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/support/WatcherScriptTests.java\n@@ -15,18 +15,21 @@\n import org.elasticsearch.test.ESTestCase;\n \n import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Map;\n \n-import static java.util.Collections.emptyMap;\n-import static java.util.Collections.singletonMap;\n import static org.hamcrest.Matchers.equalTo;\n \n public class WatcherScriptTests extends ESTestCase {\n \n     public void testParseScript() throws IOException {\n+        final Map<String, Object> params =\n+                randomFrom(Collections.<String, Object>emptyMap(), Collections.singletonMap(\"foo\", (Object)\"bar\"), null);\n+\n         WatcherScript script = new WatcherScript(randomAsciiOfLengthBetween(1, 5),\n                                                 randomFrom(ScriptType.values()),\n-                                                randomBoolean() ? null : randomFrom(\"custom\", \"mustache\"),\n-                                                randomBoolean() ? null : randomFrom(emptyMap(), singletonMap(\"foo\", \"bar\")));\n+                                                randomFrom(\"custom\", \"mustache\", null),\n+                                                params);\n \n         try (XContentParser parser = createParser(script)) {\n             assertThat(WatcherScript.parse(parser), equalTo(script));",
    "output": "Change use of generics in test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java\n@@ -67,7 +67,7 @@ public class DiskThresholdDecider extends AllocationDecider {\n \n     public static final String NAME = \"disk_threshold\";\n \n-    private DiskThresholdSettings diskThresholdSettings;\n+    private final DiskThresholdSettings diskThresholdSettings;\n \n     @Inject\n     public DiskThresholdDecider(Settings settings, ClusterSettings clusterSettings) {",
    "output": "Make disk threshold settings final"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/internal/ShardSearchTransportRequestTests.java b/core/src/test/java/org/elasticsearch/search/internal/ShardSearchTransportRequestTests.java\n--- a/core/src/test/java/org/elasticsearch/search/internal/ShardSearchTransportRequestTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/internal/ShardSearchTransportRequestTests.java\n@@ -37,6 +37,7 @@\n import org.elasticsearch.snapshots.SnapshotId;\n import org.elasticsearch.test.ESTestCase;\n import org.elasticsearch.test.VersionUtils;\n+import org.junit.AfterClass;\n import org.junit.BeforeClass;\n \n import java.io.IOException;\n@@ -69,6 +70,11 @@ protected void configureSearch() {\n         namedWriteableRegistry = new NamedWriteableRegistry(entries);\n     }\n \n+    @AfterClass\n+    public static void afterClass() {\n+        namedWriteableRegistry = null;\n+    }\n+\n     public void testSerialization() throws Exception {\n         ShardSearchTransportRequest shardSearchTransportRequest = createShardSearchTransportRequest();\n         try (BytesStreamOutput output = new BytesStreamOutput()) {",
    "output": "Fix broken test Randomized testing requires that we clean all the static state in test classess"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -208,7 +208,7 @@ private void configureUnicastCluster(\n         // TODO: Rarely use default settings form some of these\n         Settings nodeSettings = Settings.builder()\n                 .put(settings)\n-                .put(NodeEnvironment.MAX_LOCAL_STORAGE_NODES_SETTING.getKey(), 4)\n+                .put(NodeEnvironment.MAX_LOCAL_STORAGE_NODES_SETTING.getKey(), numberOfNodes)\n                 .put(ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey(), minimumMasterNode)\n                 .build();\n ",
    "output": "Fix number of nodes in discovery disruption tests This commit fixes the number of max local storage nodes setting used in the discovery disruption tests. In some cases (randomly but rarely), the acked indexing test can run with five nodes instead of three, breaching the max local storage nodes configuration"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/SearchModule.java b/core/src/main/java/org/elasticsearch/search/SearchModule.java\n--- a/core/src/main/java/org/elasticsearch/search/SearchModule.java\n+++ b/core/src/main/java/org/elasticsearch/search/SearchModule.java\n@@ -19,13 +19,6 @@\n \n package org.elasticsearch.search;\n \n-import java.util.ArrayList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.TreeMap;\n-import java.util.function.Consumer;\n-import java.util.function.Function;\n-\n import org.apache.lucene.search.BooleanQuery;\n import org.elasticsearch.common.NamedRegistry;\n import org.elasticsearch.common.ParseField;\n@@ -283,6 +276,13 @@\n import org.elasticsearch.search.suggest.phrase.StupidBackoff;\n import org.elasticsearch.search.suggest.term.TermSuggester;\n \n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n import static java.util.Collections.unmodifiableMap;\n import static java.util.Objects.requireNonNull;\n \n@@ -361,7 +361,7 @@ public ParseFieldRegistry<SignificanceHeuristicParser> getSignificanceHeuristicP\n     /**\n      * The registry of {@link MovAvgModel}s.\n      */\n-    public ParseFieldRegistry<MovAvgModel.AbstractModelParser> getMovingAverageMdelParserRegistry() {\n+    public ParseFieldRegistry<MovAvgModel.AbstractModelParser> getMovingAverageModelParserRegistry() {\n         return movingAverageModelParserRegistry;\n     }\n ",
    "output": "Fix typo getMovingAverageMdelParserRegistry->getMovingAverageModelParserRegistry in SearchModule"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java b/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java\n--- a/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java\n@@ -32,7 +32,6 @@\n \n public class CompletionSuggestionTests extends ESTestCase {\n \n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/19896\")\n     public void testToReduce() throws Exception {\n         List<Suggest.Suggestion<CompletionSuggestion.Entry>> shardSuggestions = new ArrayList<>();\n         int nShards = randomIntBetween(1, 10);\n@@ -47,8 +46,11 @@ public void testToReduce() throws Exception {\n         float maxScore = randomIntBetween(totalResults, totalResults*2);\n         for (int i = 0; i < totalResults; i++) {\n             Suggest.Suggestion<CompletionSuggestion.Entry> suggestion = randomFrom(shardSuggestions);\n-            suggestion.getEntries().get(0).addOption(new CompletionSuggestion.Entry.Option(i, new Text(\"\"),\n-                maxScore - i, Collections.emptyMap()));\n+            CompletionSuggestion.Entry entry = suggestion.getEntries().get(0);\n+            if (entry.getOptions().size() < size) {\n+                entry.addOption(new CompletionSuggestion.Entry.Option(i, new Text(\"\"),\n+                    maxScore - i, Collections.emptyMap()));\n+            }\n         }\n         CompletionSuggestion reducedSuggestion = CompletionSuggestion.reduceTo(shardSuggestions);\n         assertNotNull(reducedSuggestion);",
    "output": "Fix CompletionSuggestion test failed caused by shard is 1"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java b/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java\n--- a/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionTests.java\n@@ -32,7 +32,6 @@\n \n public class CompletionSuggestionTests extends ESTestCase {\n \n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/19896\")\n     public void testToReduce() throws Exception {\n         List<Suggest.Suggestion<CompletionSuggestion.Entry>> shardSuggestions = new ArrayList<>();\n         int nShards = randomIntBetween(1, 10);\n@@ -47,8 +46,11 @@ public void testToReduce() throws Exception {\n         float maxScore = randomIntBetween(totalResults, totalResults*2);\n         for (int i = 0; i < totalResults; i++) {\n             Suggest.Suggestion<CompletionSuggestion.Entry> suggestion = randomFrom(shardSuggestions);\n-            suggestion.getEntries().get(0).addOption(new CompletionSuggestion.Entry.Option(i, new Text(\"\"),\n-                maxScore - i, Collections.emptyMap()));\n+            CompletionSuggestion.Entry entry = suggestion.getEntries().get(0);\n+            if (entry.getOptions().size() < size) {\n+                entry.addOption(new CompletionSuggestion.Entry.Option(i, new Text(\"\"),\n+                    maxScore - i, Collections.emptyMap()));\n+            }\n         }\n         CompletionSuggestion reducedSuggestion = CompletionSuggestion.reduceTo(shardSuggestions);\n         assertNotNull(reducedSuggestion);",
    "output": "Fix CompletionSuggestion test failed caused by shard is 1"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/fieldstats/FieldStatsRequest.java b/core/src/main/java/org/elasticsearch/action/fieldstats/FieldStatsRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/fieldstats/FieldStatsRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/fieldstats/FieldStatsRequest.java\n@@ -90,7 +90,7 @@ public void source(BytesReference content) throws IOException {\n                         break;\n                     case START_OBJECT:\n                         if (\"index_constraints\".equals(fieldName)) {\n-                            parseIndexContraints(indexConstraints, parser);\n+                            parseIndexConstraints(indexConstraints, parser);\n                         } else {\n                             throw new IllegalArgumentException(\"unknown field [\" + fieldName + \"]\");\n                         }\n@@ -117,8 +117,8 @@ public void source(BytesReference content) throws IOException {\n         this.indexConstraints = indexConstraints.toArray(new IndexConstraint[indexConstraints.size()]);\n     }\n \n-    private void parseIndexContraints(List<IndexConstraint> indexConstraints,\n-                                      XContentParser parser) throws IOException {\n+    private static void parseIndexConstraints(List<IndexConstraint> indexConstraints,\n+                                       XContentParser parser) throws IOException {\n         Token token = parser.currentToken();\n         assert token == Token.START_OBJECT;\n         String field = null;\n@@ -213,5 +213,4 @@ public void writeTo(StreamOutput out) throws IOException {\n         out.writeString(level);\n         out.writeBoolean(useCache);\n     }\n-\n }",
    "output": "Fix typo and make parseIndexConstraints method static in FieldStatsRequest"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java b/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java\n--- a/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java\n+++ b/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java\n@@ -585,7 +585,6 @@ public void testIndexWithShadowReplicasCleansUp() throws Exception {\n         assertAcked(client().admin().indices().prepareDelete(IDX));\n         assertAllIndicesRemovedAndDeletionCompleted(internalCluster().getInstances(IndicesService.class));\n         assertPathHasBeenCleared(dataPath);\n-        //norelease\n         //TODO: uncomment the test below when https://github.com/elastic/elasticsearch/issues/17695 is resolved.\n         //assertIndicesDirsDeleted(nodes);\n     }\n@@ -646,7 +645,6 @@ public void run() {\n         assertAcked(client().admin().indices().prepareDelete(IDX));\n         assertAllIndicesRemovedAndDeletionCompleted(internalCluster().getInstances(IndicesService.class));\n         assertPathHasBeenCleared(dataPath);\n-        //norelease\n         //TODO: uncomment the test below when https://github.com/elastic/elasticsearch/issues/17695 is resolved.\n         //assertIndicesDirsDeleted(nodes);\n     }",
    "output": "Remove //norelease from IndexWithShadowReplicasIT test that checks asserts the indices directory is deleted on index deletion, as we are no longer considering it a blocker for releasing. Relates"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java b/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java\n@@ -958,20 +958,6 @@ public void testNoDocumentSent() throws Exception {\n         }\n     }\n \n-    public void testHazardousFieldNames() throws Exception {\n-        IndexService indexService = createIndex(\"test\");\n-        DocumentMapperParser mapperParser = indexService.mapperService().documentMapperParser();\n-        String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\")\n-            .startObject(\"foo.bar\").field(\"type\", \"text\").endObject()\n-            .endObject().endObject().endObject().string();\n-        try {\n-            mapperParser.parse(\"type\", new CompressedXContent(mapping));\n-            fail(\"Mapping parse should have failed\");\n-        } catch (MapperParsingException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"cannot contain '.'\"));\n-        }\n-    }\n-\n     public void testNoLevel() throws Exception {\n         String defaultMapping = XContentFactory.jsonBuilder().startObject().startObject(\"type\").endObject().endObject().string();\n ",
    "output": "Remove dots in field names tests for mapping api"
  },
  {
    "input": "diff --git a/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java b/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java\n--- a/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java\n+++ b/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpServerTransport.java\n@@ -548,12 +548,12 @@ protected void initChannel(Channel ch) throws Exception {\n             decoder.setCumulator(ByteToMessageDecoder.COMPOSITE_CUMULATOR);\n             ch.pipeline().addLast(\"decoder\", decoder);\n             ch.pipeline().addLast(\"decoder_compress\", new HttpContentDecompressor());\n+            ch.pipeline().addLast(\"encoder\", new HttpResponseEncoder());\n             final HttpObjectAggregator aggregator = new HttpObjectAggregator(Math.toIntExact(transport.maxContentLength.bytes()));\n             if (transport.maxCompositeBufferComponents != -1) {\n                 aggregator.setMaxCumulationBufferComponents(transport.maxCompositeBufferComponents);\n             }\n             ch.pipeline().addLast(\"aggregator\", aggregator);\n-            ch.pipeline().addLast(\"encoder\", new HttpResponseEncoder());\n             if (transport.compression) {\n                 ch.pipeline().addLast(\"encoder_compress\", new HttpContentCompressor(transport.compressionLevel));\n             }",
    "output": "Fix expect 100 continue header handling Due to a misordering of the HTTP handlers, the Netty 4 HTTP server mishandles Expect: 100-continue headers from clients. This commit fixes this issue by ordering the handlers correctly. Relates"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/phrase/DirectCandidateGeneratorBuilder.java b/core/src/main/java/org/elasticsearch/search/suggest/phrase/DirectCandidateGeneratorBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/phrase/DirectCandidateGeneratorBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/phrase/DirectCandidateGeneratorBuilder.java\n@@ -374,7 +374,7 @@ public static DirectCandidateGeneratorBuilder fromXContent(QueryParseContext par\n         DirectCandidateGeneratorBuilder tempGenerator = new DirectCandidateGeneratorBuilder(\"_na_\");\n         // bucket for the field name, needed as constructor arg later\n         Set<String> tmpFieldName = new HashSet<>(1);\n-        PARSER.parse(parseContext.parser(), new Tuple<Set<String>, DirectCandidateGeneratorBuilder>(tmpFieldName, tempGenerator),\n+        PARSER.parse(parseContext.parser(), new Tuple<>(tmpFieldName, tempGenerator),\n                 parseContext);\n         if (tmpFieldName.size() != 1) {\n             throw new IllegalArgumentException(\"[\" + TYPE + \"] expects exactly one field parameter, but found \" + tmpFieldName);",
    "output": "Remove redundant generics type declaration"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java\n@@ -862,8 +862,7 @@ public void testGeoHashSearchWithPrefix() throws Exception {\n         final int numHashes = hashes.size();\n         for(int i=0; i<numHashes; ++i) {\n             String hash = \"dr5regy6rc6y\".substring(0, numHashes-i);\n-            Object expected = version.before(Version.V_5_0_0_alpha1) ? hash : new BytesRef(hash);\n-            assertEquals(expected, hashes.get(i));\n+            assertEquals(hash, hashes.get(i));\n         }\n     }\n ",
    "output": "Fix expectations of GeoPointFieldMapperTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n@@ -51,7 +51,7 @@ public class ListTasksResponse extends BaseTasksResponse implements ToXContent {\n \n     private List<TaskGroup> groups;\n \n-    private DiscoveryNodes discoveryNodes;\n+    private final DiscoveryNodes discoveryNodes;\n \n     public ListTasksResponse() {\n         this(null, null, null, null);",
    "output": "Fix after review"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n@@ -199,6 +199,6 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n \n     @Override\n     public String toString() {\n-        return Strings.toString(this);\n+        return Strings.toString(this, true);\n     }\n }",
    "output": "Fix toString method #issuecomment-238564524 Was introduced with"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java\n@@ -131,7 +131,6 @@ public List<TaskInfo> getTasks() {\n \n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n-        builder.startObject();\n         if (getTaskFailures() != null && getTaskFailures().size() > 0) {\n             builder.startArray(\"task_failures\");\n             for (TaskOperationFailure ex : getTaskFailures()){\n@@ -195,7 +194,6 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n             }\n             builder.endObject();\n         }\n-        builder.endObject();\n         return builder;\n     }\n ",
    "output": "Fix after merge"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ExceptionsHelper.java b/core/src/main/java/org/elasticsearch/ExceptionsHelper.java\n--- a/core/src/main/java/org/elasticsearch/ExceptionsHelper.java\n+++ b/core/src/main/java/org/elasticsearch/ExceptionsHelper.java\n@@ -179,19 +179,6 @@ public static Throwable unwrap(Throwable t, Class<?>... clazzes) {\n         return null;\n     }\n \n-    /**\n-     * Returns <code>true</code> iff the given throwable is and OutOfMemoryException, otherwise <code>false</code>\n-     */\n-    public static boolean isOOM(Throwable t) {\n-        return t != null\n-                && (t instanceof OutOfMemoryError\n-                    || (t instanceof IllegalStateException\n-                        && t.getMessage() != null\n-                        && t.getMessage().contains(\"OutOfMemoryError\")\n-                        )\n-                    );\n-    }\n-\n     /**\n      * Throws the specified exception. If null if specified then <code>true</code> is returned.\n      */\n\ndiff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java\n@@ -705,9 +705,6 @@ protected boolean maybeFailEngine(String source, Exception e) {\n         if (Lucene.isCorruptionException(e)) {\n             failEngine(\"corrupt file (source: [\" + source + \"])\", e);\n             return true;\n-        } else if (ExceptionsHelper.isOOM(e)) {\n-            failEngine(\"out of memory (source: [\" + source + \"])\", e);\n-            return true;\n         }\n         return false;\n     }",
    "output": "Remove dead OOM handling in engine Previously, the engine would catch an out of memory error and would try to handle the error (it would try to fail the engine, and then it would swallow the out of memory error). Catching the out of memory errors was removed in 3343ceeae44f3d28e3c1ba7861886848df74e390 so this code path is not effectively dead. This commit removes this dead code from the engine. Relates"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java\n--- a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java\n+++ b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java\n@@ -338,10 +338,7 @@ public Collection<Object> createComponents(InternalClient client, ThreadPool thr\n \n     public Settings additionalSettings() {\n         if (enabled == false) {\n-            return Settings.builder()\n-                    .put(NetworkModule.HTTP_TYPE_KEY, \"netty4\")\n-                    .put(NetworkModule.TRANSPORT_TYPE_KEY, \"netty4\")\n-                    .build();\n+            return Settings.EMPTY;\n         }\n \n         return additionalSettings(settings);",
    "output": "Remove network settings when security is disabled When security is disabled, we currently set the transport and HTTP type to Netty 4. However, this is unnecessary as these are the default settings so this commit removes these explicit settings. Relates elastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java\n@@ -119,7 +119,6 @@ private void assertGeoPointQuery(GeoPolygonQueryBuilder queryBuilder, Query quer\n      * explicitly mapped\n      */\n     @Override\n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/16399\")\n     public void testToQuery() throws IOException {\n         assumeTrue(\"test runs only when at least a type is registered\", getCurrentTypes().length > 0);\n         super.testToQuery();",
    "output": "Remove AwaitsFix that was fixed with"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilJNANativesTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilJNANativesTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilJNANativesTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilJNANativesTests.java\n@@ -40,7 +40,7 @@ public void testSetMaximumNumberOfThreads() throws IOException {\n                 for (String line : lines) {\n                     if (line != null && line.startsWith(\"Max processes\")) {\n                         final String[] fields = line.split(\"\\\\s+\");\n-                        final long limit = Long.parseLong(fields[2]);\n+                        final long limit = \"unlimited\".equals(fields[2]) ? JNACLibrary.RLIM_INFINITY : Long.parseLong(fields[2]);\n                         assertThat(JNANatives.MAX_NUMBER_OF_THREADS, equalTo(limit));\n                         return;\n                     }",
    "output": "Fix parsing in test set max number of threads This commit fixes a test bug in EvilJNANativesTests#testSetMaximumNumberOfThreads. Namely, the test was not checking whether or not the value from /proc/self/limits was equal to \"unlimited\" before attempting to parse as a long. This commit fixes that error"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/PutMappingResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/PutMappingResponse.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/PutMappingResponse.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/PutMappingResponse.java\n@@ -30,11 +30,11 @@\n  */\n public class PutMappingResponse extends AcknowledgedResponse {\n \n-    PutMappingResponse() {\n+    protected PutMappingResponse() {\n \n     }\n \n-    PutMappingResponse(boolean acknowledged) {\n+    protected PutMappingResponse(boolean acknowledged) {\n         super(acknowledged);\n     }\n \n\ndiff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateResponse.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateResponse.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateResponse.java\n@@ -29,10 +29,10 @@\n  */\n public class PutIndexTemplateResponse extends AcknowledgedResponse {\n \n-    PutIndexTemplateResponse() {\n+    protected PutIndexTemplateResponse() {\n     }\n \n-    PutIndexTemplateResponse(boolean acknowledged) {\n+    protected PutIndexTemplateResponse(boolean acknowledged) {\n         super(acknowledged);\n     }\n ",
    "output": "Make ctors protected This is useful if we need an acknowledged instance in a test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n@@ -124,6 +124,9 @@ private static ClientTemplate buildTemplate(Settings providedSettings, Settings\n             List<NamedWriteableRegistry.Entry> entries = new ArrayList<>();\n             entries.addAll(networkModule.getNamedWriteables());\n             entries.addAll(searchModule.getNamedWriteables());\n+            entries.addAll(pluginsService.filterPlugins(Plugin.class).stream()\n+                                         .flatMap(p -> p.getNamedWriteables().stream())\n+                                         .collect(Collectors.toList()));\n             NamedWriteableRegistry namedWriteableRegistry = new NamedWriteableRegistry(entries);\n \n             ModulesBuilder modules = new ModulesBuilder();",
    "output": "Add NamedWriteables from plugins to TransportClient Plugins provide NamedWriteables that are added to the NamedWriteableRegistry. Those are added on Nodes already, the same mechanism is added to the setup for TransportClient"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java\n@@ -303,7 +303,8 @@ public static Optional<FuzzyQueryBuilder> fromXContent(QueryParseContext parseCo\n                         } else if (parseContext.getParseFieldMatcher().match(currentFieldName, AbstractQueryBuilder.NAME_FIELD)) {\n                             queryName = parser.text();\n                         } else {\n-                            throw new ParsingException(parser.getTokenLocation(), \"[fuzzy] query does not support [\" + currentFieldName + \"]\");\n+                            throw new ParsingException(parser.getTokenLocation(),\n+                                    \"[fuzzy] query does not support [\" + currentFieldName + \"]\");\n                         }\n                     }\n                 }",
    "output": "Fix line length in FuzzyQueryBuilder"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n--- a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n@@ -115,10 +115,11 @@ public Optional<QueryBuilder> parseInnerQueryBuilder() throws IOException {\n         @SuppressWarnings(\"unchecked\")\n         Optional<QueryBuilder> result = (Optional<QueryBuilder>) indicesQueriesRegistry.lookup(queryName, parseFieldMatcher,\n                 parser.getTokenLocation()).fromXContent(this);\n-        if (parser.currentToken() == XContentParser.Token.END_OBJECT) {\n-            // if we are at END_OBJECT, move to the next one...\n-            parser.nextToken();\n+        if (parser.currentToken() != XContentParser.Token.END_OBJECT) {\n+            throw new ParsingException(parser.getTokenLocation(),\n+                    \"[\" + queryName + \"] malformed query, expected [END_OBJECT] but found [\" + parser.currentToken() + \"]\");\n         }\n+        parser.nextToken();\n         return result;\n     }\n ",
    "output": "Make query parsing stricter by requiring each parser to stop at END_OBJECT token Instead of being lenient in QueryParseContext#parseInnerQueryBuilder we check that the token where the parser stopped reading was END_OBJECT, and throw error otherwise. This is a best effort to verify that the parsers read a whole object rather than stepping out in the middle of it due to malformed queries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchResponse.java b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchResponse.java\n--- a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchResponse.java\n+++ b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchResponse.java\n@@ -136,14 +136,8 @@ public void readFrom(StreamInput in) throws IOException {\n             suggest = Suggest.readSuggest(in);\n         }\n         timedOut = in.readBoolean();\n-\n         terminatedEarly = in.readOptionalBoolean();\n-\n-        if (in.getVersion().onOrAfter(Version.V_2_2_0) && in.readBoolean()) {\n-            profileResults = new SearchProfileShardResults(in);\n-        } else {\n-            profileResults = null;\n-        }\n+        profileResults = in.readOptionalWriteable(SearchProfileShardResults::new);\n     }\n \n     @Override\n@@ -162,16 +156,7 @@ public void writeTo(StreamOutput out) throws IOException {\n             suggest.writeTo(out);\n         }\n         out.writeBoolean(timedOut);\n-\n         out.writeOptionalBoolean(terminatedEarly);\n-\n-        if (out.getVersion().onOrAfter(Version.V_2_2_0)) {\n-            if (profileResults == null) {\n-                out.writeBoolean(false);\n-            } else {\n-                out.writeBoolean(true);\n-                profileResults.writeTo(out);\n-            }\n-        }\n+        out.writeOptionalWriteable(profileResults);\n     }\n }",
    "output": "Remove BWC serialization logic for pre 2.2 nodes This change removes all pre 2.2 logic from InternalSearchResponse serialization. It's unneeded in 5.0 since we require full cluster restart"
  },
  {
    "input": "diff --git a/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java b/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java\n--- a/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java\n+++ b/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java\n@@ -32,8 +32,8 @@\n \n import java.util.Arrays;\n \n-import static org.junit.Assert.*;\n import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.fail;\n \n public class PreBuiltTransportClientTests extends RandomizedTest {",
    "output": "Fix import statements"
  },
  {
    "input": "diff --git a/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java b/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java\n--- a/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java\n+++ b/client/transport/src/test/java/org/elasticsearch/transport/client/PreBuiltTransportClientTests.java\n@@ -56,7 +56,8 @@ public void testInstallPluginTwice() {\n                 new PreBuiltTransportClient(Settings.EMPTY, plugin);\n                 fail(\"exception expected\");\n             } catch (IllegalArgumentException ex) {\n-                assertTrue(ex.getMessage().startsWith(\"plugin already exists: \"));\n+                assertTrue(\"Expected message to start with [plugin already exists: ] but was instead [\" + ex.getMessage() + \"]\",\n+                        ex.getMessage().startsWith(\"plugin already exists: \"));\n             }\n         }\n     }",
    "output": "Add failure message to test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java b/core/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java\n--- a/core/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/support/replication/TransportReplicationActionTests.java\n@@ -534,7 +534,7 @@ public void testReplicaProxy() throws InterruptedException, ExecutionException {\n         AtomicReference<Throwable> failure = new AtomicReference<>();\n         AtomicReference<Throwable> ignoredFailure = new AtomicReference<>();\n         AtomicBoolean success = new AtomicBoolean();\n-        proxy.failShard(replica, randomIntBetween(0, 10), \"test\", new ElasticsearchException(\"simulated\"),\n+        proxy.failShard(replica, randomIntBetween(1, 10), \"test\", new ElasticsearchException(\"simulated\"),\n             () -> success.set(true), failure::set, ignoredFailure::set\n         );\n         CapturingTransport.CapturedRequest[] shardFailedRequests = transport.getCapturedRequestsAndClear();",
    "output": "Fix primary term in TransportReplicationActionTests#testReplicaProxy"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n--- a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n+++ b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n@@ -48,6 +48,7 @@\n import org.elasticsearch.plugins.ScriptPlugin;\n import org.elasticsearch.rest.RestHandler;\n import org.elasticsearch.script.ScriptContext;\n+import org.elasticsearch.script.ScriptService;\n import org.elasticsearch.threadpool.ExecutorBuilder;\n import org.elasticsearch.threadpool.ThreadPool;\n import org.elasticsearch.watcher.ResourceWatcherService;\n@@ -188,7 +189,7 @@ public Collection<Module> createGuiceModules() {\n \n     @Override\n     public Collection<Object> createComponents(Client client, ClusterService clusterService, ThreadPool threadPool,\n-                                               ResourceWatcherService resourceWatcherService) {\n+                                               ResourceWatcherService resourceWatcherService, ScriptService scriptService) {\n         List<Object> components = new ArrayList<>();\n         final InternalClient internalClient = new InternalClient(settings, threadPool, client, security.getCryptoService());\n         components.add(internalClient);",
    "output": "Fix signature of createComponents after addition of script service in core"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java b/core/src/test/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java\n--- a/core/src/test/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/index/replication/ESIndexLevelReplicationTestCase.java\n@@ -316,7 +316,7 @@ private Store.MetadataSnapshot getMetadataSnapshotOrEmpty(IndexShard replica) th\n                 // OK!\n                 result = Store.MetadataSnapshot.EMPTY;\n             } catch (IOException e) {\n-                logger.warn(\"{} failed read store, treating as empty\", e);\n+                logger.warn(\"failed read store, treating as empty\", e);\n                 result = Store.MetadataSnapshot.EMPTY;\n             }\n             return result;",
    "output": "Fix log statement in ESIndexLevelReplicationTestCase"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java b/core/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java\n--- a/core/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java\n+++ b/core/src/main/java/org/elasticsearch/action/support/ActiveShardCount.java\n@@ -160,12 +160,15 @@ public boolean enoughShardsActive(final ClusterState clusterState, final String\n      * to meet the required shard count represented by this instance.\n      */\n     public boolean enoughShardsActive(final IndexShardRoutingTable shardRoutingTable) {\n+        final int activeShardCount = shardRoutingTable.activeShards().size();\n         if (this == ActiveShardCount.ALL) {\n-            return shardRoutingTable.allShardsStarted();\n+            // adding 1 for the primary in addition to the total number of replicas,\n+            // which gives us the total number of shard copies\n+            return activeShardCount == shardRoutingTable.replicaShards().size() + 1;\n         } else if (this == ActiveShardCount.DEFAULT) {\n-            return shardRoutingTable.primaryShard().started();\n+            return activeShardCount >= 1;\n         } else {\n-            return shardRoutingTable.activeShards().size() >= value;\n+            return activeShardCount >= value;\n         }\n     }\n ",
    "output": "Fix the active shard count check in the case of ActiveShardCount.ALL by checking for active shards, not just started shards, as a shard could be active but in the relocating state (i.e. not in the started state)"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java\n--- a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java\n+++ b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/Security.java\n@@ -350,7 +350,6 @@ static Settings additionalSettings(Settings settings) {\n         settingsBuilder.put(NetworkModule.TRANSPORT_TYPE_KEY, Security.NAME + \"4\");\n         settingsBuilder.put(NetworkModule.TRANSPORT_SERVICE_TYPE_KEY, Security.NAME);\n         settingsBuilder.put(NetworkModule.HTTP_TYPE_SETTING.getKey(), Security.NAME + \"4\");\n-        // nocommit\n         SecurityNetty4HttpServerTransport.overrideSettings(settingsBuilder, settings);\n         addUserSettings(settings, settingsBuilder);\n         addTribeSettings(settings, settingsBuilder);",
    "output": "Remove nocommit from Security This commit removes a nocommit from Security so that work can continue"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java\n--- a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java\n+++ b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java\n@@ -91,8 +91,10 @@ from all the nodes are attached with a user (either a serialize user\n                 } else if (((TcpTransportChannel) unwrappedChannel).getChannel() instanceof io.netty.channel.Channel) {\n                     io.netty.channel.Channel channel = (io.netty.channel.Channel) ((TcpTransportChannel) unwrappedChannel).getChannel();\n                     io.netty.handler.ssl.SslHandler sslHandler = channel.pipeline().get(io.netty.handler.ssl.SslHandler.class);\n-                    assert sslHandler != null : \"channel [\" + channel + \"] did not have a ssl handler. pipeline \" + channel.pipeline();\n-                    extactClientCertificates(sslHandler.engine(), channel);\n+                    if (channel.isOpen()) {\n+                        assert sslHandler != null : \"channel [\" + channel + \"] did not have a ssl handler. pipeline \" + channel.pipeline();\n+                        extactClientCertificates(sslHandler.engine(), channel);\n+                    }\n                 }\n             }\n ",
    "output": "Add channel is closed check"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java\n--- a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java\n+++ b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/transport/ServerTransportFilter.java\n@@ -91,7 +91,7 @@ from all the nodes are attached with a user (either a serialize user\n                 } else if (((TcpTransportChannel) unwrappedChannel).getChannel() instanceof io.netty.channel.Channel) {\n                     io.netty.channel.Channel channel = (io.netty.channel.Channel) ((TcpTransportChannel) unwrappedChannel).getChannel();\n                     io.netty.handler.ssl.SslHandler sslHandler = channel.pipeline().get(io.netty.handler.ssl.SslHandler.class);\n-                    assert sslHandler != null;\n+                    assert sslHandler != null : \"channel [\" + channel + \"] did not have a ssl handler. pipeline \" + channel.pipeline();\n                     extactClientCertificates(sslHandler.engine(), channel);\n                 }\n             }",
    "output": "Add some debugging info to assert"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestTasksAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestTasksAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestTasksAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestTasksAction.java\n@@ -98,7 +98,7 @@ protected Table getTableWithHeader(final RestRequest request) {\n \n         // Task detailed info\n         if (detailed) {\n-            table.addCell(\"description\", \"default:false;alias:desc;desc:task action\");\n+            table.addCell(\"description\", \"default:true;alias:desc;desc:task action\");\n         }\n         table.endHeaders();\n         return table;\n@@ -142,7 +142,7 @@ private void buildRow(Table table, boolean fullId, boolean detailed, DiscoveryNo\n         table.endRow();\n     }\n \n-    private void buildGroups(Table table, boolean detailed, boolean fullId, List<TaskGroup> taskGroups) {\n+    private void buildGroups(Table table, boolean fullId, boolean detailed, List<TaskGroup> taskGroups) {\n         DiscoveryNodes discoveryNodes = clusterService.state().nodes();\n         List<TaskGroup> sortedGroups = new ArrayList<>(taskGroups);\n         sortedGroups.sort((o1, o2) -> Long.compare(o1.getTaskInfo().getStartTime(), o2.getTaskInfo().getStartTime()));",
    "output": "Fix cat tasks operation in detailed mode Currently the cat tasks operation fails in the detailed mode"
  },
  {
    "input": "diff --git a/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpRequest.java b/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpRequest.java\n--- a/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpRequest.java\n+++ b/modules/transport-netty4/src/main/java/org/elasticsearch/http/netty4/Netty4HttpRequest.java\n@@ -34,7 +34,7 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-class Netty4HttpRequest extends RestRequest {\n+public class Netty4HttpRequest extends RestRequest {\n \n     private final FullHttpRequest request;\n     private final Channel channel;",
    "output": "Make netty4 http request public"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n@@ -48,8 +48,8 @@ public Object compile(String name, String script, Map<String, String> params) {\n         if (script.contains(\"{{\") && script.contains(\"}}\")) {\n             throw new IllegalArgumentException(\"Fix your test to not rely on mustache\");\n         }\n-\n-        return super.compile(name, script, params);\n+        // We always return the script's source as it is\n+        return new MockCompiledScript(name, params, script, null);\n     }\n \n     @Override",
    "output": "Make MockMustacheScriptEngine less strict Since elastic/elasticsearch#19621 MockScriptEngine is stricter and expects scripts to be defined before being used in tests. Because watcher makes heavy use of scripts without really need of custom logic, this commit changed the MockMustacheScriptEngine implementation so that it always returns the script's source as a result"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java b/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java\n@@ -187,7 +187,7 @@ public static ShardPath selectNewPathForShard(NodeEnvironment env, ShardId shard\n             // TODO - do we need something more extensible? Yet, this does the job for now...\n             final NodeEnvironment.NodePath[] paths = env.nodePaths();\n             NodeEnvironment.NodePath bestPath = null;\n-            BigInteger maxUsableBytes = BigInteger.valueOf(-1);\n+            BigInteger maxUsableBytes = BigInteger.valueOf(Long.MIN_VALUE);\n             for (NodeEnvironment.NodePath nodePath : paths) {\n                 FileStore fileStore = nodePath.fileStore;\n \n@@ -199,7 +199,7 @@ public static ShardPath selectNewPathForShard(NodeEnvironment env, ShardId shard\n                 if (count != null) {\n                     usableBytes = usableBytes.subtract(estShardSizeInBytes.multiply(BigInteger.valueOf(count)));\n                 }\n-                if (usableBytes.compareTo(maxUsableBytes) > 0) {\n+                if (bestPath == null || usableBytes.compareTo(maxUsableBytes) > 0) {\n                     maxUsableBytes = usableBytes;\n                     bestPath = nodePath;\n                 }",
    "output": "Add defense to selectNewPathForShard"
  },
  {
    "input": "diff --git a/modules/lang-mustache/src/main/java/org/elasticsearch/script/mustache/TemplateQueryBuilder.java b/modules/lang-mustache/src/main/java/org/elasticsearch/script/mustache/TemplateQueryBuilder.java\n--- a/modules/lang-mustache/src/main/java/org/elasticsearch/script/mustache/TemplateQueryBuilder.java\n+++ b/modules/lang-mustache/src/main/java/org/elasticsearch/script/mustache/TemplateQueryBuilder.java\n@@ -60,14 +60,13 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil\n     private final Script template;\n \n     public TemplateQueryBuilder(String template, ScriptService.ScriptType scriptType, Map<String, Object> params) {\n-        this.template = new Script(template, scriptType, \"mustache\", params);\n+        this(new Script(template, scriptType, \"mustache\", params));\n     }\n \n     public TemplateQueryBuilder(String template, ScriptService.ScriptType scriptType, Map<String, Object> params, XContentType ct) {\n-        this.template = new Script(template, scriptType, \"mustache\", params, ct);\n+        this(new Script(template, scriptType, \"mustache\", params, ct));\n     }\n \n-    // for tests, so that mock script can be used:\n     TemplateQueryBuilder(Script template) {\n         DEPRECATION_LOGGER.deprecated(\"[{}] query is deprecated, use search template api instead\", NAME);\n         if (template == null) {",
    "output": "Remove useless comment and make sure all public constructors delegate to the package protected constructor"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n@@ -202,8 +202,10 @@ public void createIndex(final CreateIndexClusterStateUpdateRequest request,\n             if (response.isAcknowledged()) {\n                 activeShardsObserver.waitForActiveShards(request.index(), request.waitForActiveShards(), request.ackTimeout(),\n                     shardsAcked -> {\n-                        logger.debug(\"[{}] index created, but the operation timed out while waiting for \" +\n-                                         \"enough shards to be started.\", request.index());\n+                        if (shardsAcked == false) {\n+                            logger.debug(\"[{}] index created, but the operation timed out while waiting for \" +\n+                                             \"enough shards to be started.\", request.index());\n+                        }\n                         listener.onResponse(new CreateIndexClusterStateUpdateResponse(response.isAcknowledged(), shardsAcked));\n                     }, listener::onFailure);\n             } else {",
    "output": "Fix debug logging on index creation waiting for shards to be started"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java b/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java\n--- a/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java\n+++ b/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java\n@@ -43,7 +43,6 @@\n import java.io.Closeable;\n import java.io.IOException;\n import java.io.OutputStream;\n-import java.io.UncheckedIOException;\n import java.net.InetSocketAddress;\n import java.net.ServerSocket;\n import java.net.Socket;\n@@ -210,7 +209,6 @@ protected NodeChannels connectToChannels(DiscoveryNode node) throws IOException\n \n     private void configureSocket(Socket socket) throws SocketException {\n         socket.setTcpNoDelay(TCP_NO_DELAY.get(settings));\n-        socket.setSoTimeout(15000);\n         ByteSizeValue tcpSendBufferSize = TCP_SEND_BUFFER_SIZE.get(settings);\n         if (tcpSendBufferSize.bytes() > 0) {\n             socket.setSendBufferSize(tcpSendBufferSize.bytesAsInt());",
    "output": "Remove socket timeout from MockTcpTransport added in b208a7dbaeeb269e6d1e121f46a29cb6b0f8004f"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java b/core/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java\n--- a/core/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java\n+++ b/core/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java\n@@ -58,6 +58,9 @@ public static boolean isCloseConnectionException(Throwable e) {\n             if (e.getMessage().equals(\"Socket is closed\")) {\n                 return true;\n             }\n+            if (e.getMessage().equals(\"Socket closed\")) {\n+                return true;\n+            }\n         }\n         return false;\n     }",
    "output": "Add `Socket closed` variant to NetworkExceptionHelper.isCloseConnectionException"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/DocWriteResponseTests.java b/core/src/test/java/org/elasticsearch/action/DocWriteResponseTests.java\n--- a/core/src/test/java/org/elasticsearch/action/DocWriteResponseTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/DocWriteResponseTests.java\n@@ -19,12 +19,13 @@\n \n package org.elasticsearch.action;\n \n+import org.elasticsearch.action.DocWriteResponse.Operation;\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.test.ESTestCase;\n \n public class DocWriteResponseTests extends ESTestCase {\n     public void testGetLocation() {\n-        DocWriteResponse response = new DocWriteResponse(new ShardId(\"index\", \"uuid\", 0), \"type\", \"id\", 0) {\n+        DocWriteResponse response = new DocWriteResponse(new ShardId(\"index\", \"uuid\", 0), \"type\", \"id\", 0, Operation.CREATE) {\n             // DocWriteResponse is abstract so we have to sneak a subclass in here to test it.\n         };\n         assertEquals(\"/index/type/id\", response.getLocation(null));",
    "output": "Fix unit test build failure We didn't catch the failure because we tested against the fork instead of master. I think"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java b/test/framework/src/main/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java\n@@ -488,7 +488,6 @@ public void onNodeDisconnected(DiscoveryNode node) {\n         assertThat(latch.await(5, TimeUnit.SECONDS), equalTo(true));\n     }\n \n-    @TestLogging(\"transport:DEBUG\")\n     public void testConcurrentSendRespondAndDisconnect() throws BrokenBarrierException, InterruptedException {\n         Set<Exception> sendingErrors = ConcurrentCollections.newConcurrentSet();\n         Set<Exception> responseErrors = ConcurrentCollections.newConcurrentSet();\n\ndiff --git a/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java b/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java\n--- a/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java\n+++ b/test/framework/src/main/java/org/elasticsearch/transport/MockTcpTransport.java\n@@ -210,6 +210,7 @@ protected NodeChannels connectToChannels(DiscoveryNode node) throws IOException\n \n     private void configureSocket(Socket socket) throws SocketException {\n         socket.setTcpNoDelay(TCP_NO_DELAY.get(settings));\n+        socket.setSoTimeout(15000);\n         ByteSizeValue tcpSendBufferSize = TCP_SEND_BUFFER_SIZE.get(settings);\n         if (tcpSendBufferSize.bytes() > 0) {\n             socket.setSendBufferSize(tcpSendBufferSize.bytesAsInt());",
    "output": "Add socket timeout in MockTcpTransport With this commit we set an explicit socket timeout in MockTcpTransport to avoid hanging tests in case of disconnections"
  },
  {
    "input": "diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java\n--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java\n+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java\n@@ -114,7 +114,7 @@ public long delayBeforeNextRetry(AmazonWebServiceRequest originalRequest,\n \n         AWSCredentialsProvider credentials;\n \n-        if (key == null && secret == null) {\n+        if (key.isEmpty() && secret.isEmpty()) {\n             credentials = new AWSCredentialsProviderChain(\n                     new EnvironmentVariableCredentialsProvider(),\n                     new SystemPropertiesCredentialsProvider(),",
    "output": "Fix EC2 discovery setting"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java\n--- a/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java\n+++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java\n@@ -85,10 +85,7 @@ public Map<String, BlobMetaData> listBlobsByPrefix(String blobNamePrefix) throws\n     @Override\n     public void deleteBlob(String blobName) throws IOException {\n         Path blobPath = path.resolve(blobName);\n-        if (!Files.deleteIfExists(blobPath)) {\n-            // blobPath does not exist\n-            throw new IOException(\"File [\" + blobPath.toString() + \"] does not exist\");\n-        }\n+        Files.delete(blobPath);\n     }\n \n     @Override",
    "output": "Change Files.deleteIfExists to Files.delete in FsBlobContainer"
  },
  {
    "input": "diff --git a/client/rest/src/main/java/org/elasticsearch/client/Response.java b/client/rest/src/main/java/org/elasticsearch/client/Response.java\n--- a/client/rest/src/main/java/org/elasticsearch/client/Response.java\n+++ b/client/rest/src/main/java/org/elasticsearch/client/Response.java\n@@ -32,7 +32,7 @@\n  * Holds an elasticsearch response. It wraps the {@link HttpResponse} returned and associates it with\n  * its corresponding {@link RequestLine} and {@link HttpHost}.\n  */\n-public class Response {\n+public final class Response {\n \n     private final RequestLine requestLine;\n     private final HttpHost host;",
    "output": "Make Response class final"
  },
  {
    "input": "diff --git a/client/rest/src/test/java/org/elasticsearch/client/RestClientMultipleHostsTests.java b/client/rest/src/test/java/org/elasticsearch/client/RestClientMultipleHostsTests.java\n--- a/client/rest/src/test/java/org/elasticsearch/client/RestClientMultipleHostsTests.java\n+++ b/client/rest/src/test/java/org/elasticsearch/client/RestClientMultipleHostsTests.java\n@@ -79,7 +79,6 @@ public Future<HttpResponse> answer(InvocationOnMock invocationOnMock) throws Thr\n                 HttpAsyncRequestProducer requestProducer = (HttpAsyncRequestProducer) invocationOnMock.getArguments()[0];\n                 HttpUriRequest request = (HttpUriRequest)requestProducer.generateRequest();\n                 HttpHost httpHost = requestProducer.getTarget();\n-                @SuppressWarnings(\"unchecked\")\n                 FutureCallback<HttpResponse> futureCallback = (FutureCallback<HttpResponse>) invocationOnMock.getArguments()[2];\n                 //return the desired status code or exception depending on the path\n                 if (request.getURI().getPath().equals(\"/soe\")) {\n\ndiff --git a/client/rest/src/test/java/org/elasticsearch/client/RestClientSingleHostTests.java b/client/rest/src/test/java/org/elasticsearch/client/RestClientSingleHostTests.java\n--- a/client/rest/src/test/java/org/elasticsearch/client/RestClientSingleHostTests.java\n+++ b/client/rest/src/test/java/org/elasticsearch/client/RestClientSingleHostTests.java\n@@ -102,7 +102,6 @@ public void createRestClient() throws IOException {\n                     @Override\n                     public Future<HttpResponse> answer(InvocationOnMock invocationOnMock) throws Throwable {\n                         HttpAsyncRequestProducer requestProducer = (HttpAsyncRequestProducer) invocationOnMock.getArguments()[0];\n-                        @SuppressWarnings(\"unchecked\")\n                         FutureCallback<HttpResponse> futureCallback = (FutureCallback<HttpResponse>) invocationOnMock.getArguments()[2];\n                         HttpUriRequest request = (HttpUriRequest)requestProducer.generateRequest();\n                         //return the desired status code or exception depending on the path",
    "output": "Remove one too many SuppressWarnings"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/SecurityLicensee.java b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/SecurityLicensee.java\n--- a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/SecurityLicensee.java\n+++ b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/SecurityLicensee.java\n@@ -15,13 +15,11 @@\n  */\n public class SecurityLicensee extends AbstractLicenseeComponent {\n \n-    private final boolean isTribeNode;\n     private final SecurityLicenseState securityLicenseState;\n \n     public SecurityLicensee(Settings settings, SecurityLicenseState securityLicenseState) {\n         super(settings, Security.NAME);\n         this.securityLicenseState = securityLicenseState;\n-        this.isTribeNode = settings.getGroups(\"tribe\", true).isEmpty() == false;\n     }\n \n     @Override",
    "output": "Remove unused var"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java b/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n@@ -34,7 +34,8 @@\n  */\n public final class Features {\n \n-    private static final List<String> SUPPORTED = Arrays.asList(\"stash_in_path\", \"groovy_scripting\", \"headers\", \"embedded_stash_key\", \"yaml\");\n+    private static final List<String> SUPPORTED =\n+            Arrays.asList(\"stash_in_path\", \"groovy_scripting\", \"headers\", \"embedded_stash_key\", \"yaml\");\n \n     private Features() {\n ",
    "output": "Fix line-length in o/e/t/r/s/Features.java This commit fixes a line-length checkstyle violation in o/e/t/r/s/Features.java"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bwcompat/RepositoryUpgradabilityIT.java b/core/src/test/java/org/elasticsearch/bwcompat/RepositoryUpgradabilityIT.java\n--- a/core/src/test/java/org/elasticsearch/bwcompat/RepositoryUpgradabilityIT.java\n+++ b/core/src/test/java/org/elasticsearch/bwcompat/RepositoryUpgradabilityIT.java\n@@ -26,6 +26,7 @@\n import org.elasticsearch.snapshots.SnapshotId;\n import org.elasticsearch.snapshots.SnapshotInfo;\n import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n \n import java.nio.file.DirectoryStream;\n import java.nio.file.Files;\n@@ -45,6 +46,8 @@\n  * as blob names and repository blob formats have changed between the snapshot versions.\n  */\n @ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST)\n+// this test sometimes fails in recovery when the recovery is reset, increasing the logging level to help debug \n+@TestLogging(\"indices.recovery:DEBUG\")\n public class RepositoryUpgradabilityIT extends AbstractSnapshotIntegTestCase {\n \n     /**",
    "output": "Add debug logging to RepositoryUpgradabilityIT test to help figure out failures in recovery reset/retry"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java b/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n@@ -34,7 +34,7 @@\n  */\n public final class Features {\n \n-    private static final List<String> SUPPORTED = Arrays.asList(\"stash_in_path\", \"groovy_scripting\", \"headers\", \"embedded_stash_key\");\n+    private static final List<String> SUPPORTED = Arrays.asList(\"stash_in_path\", \"groovy_scripting\", \"headers\", \"embedded_stash_key\", \"yaml\");\n \n     private Features() {\n ",
    "output": "Add 'yaml' feature for the test runner Also renamed 30_yaml.yaml to 30_json.yaml since it tests json, not yaml"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/LicensingTests.java b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/LicensingTests.java\n--- a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/LicensingTests.java\n+++ b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/LicensingTests.java\n@@ -266,7 +266,8 @@ public Collection<Object> createComponents(ClusterService clusterService, Clock\n             GraphLicensee graphLicensee = new GraphLicensee(settings);\n             TestLicensesService licensesService = new TestLicensesService(settings,\n                 Arrays.asList(securityLicensee, watcherLicensee, monitoringLicensee, graphLicensee));\n-            return Arrays.asList(securityLicensee, licensesService, watcherLicensee, monitoringLicensee, graphLicensee, securityLicenseState);\n+            return Arrays.asList(securityLicensee, licensesService, watcherLicensee, monitoringLicensee,\n+                graphLicensee, securityLicenseState);\n         }\n \n         public InternalLicensing() {",
    "output": "Fix line length"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n--- a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n+++ b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n@@ -40,6 +40,7 @@\n import org.elasticsearch.script.ScriptContext;\n import org.elasticsearch.threadpool.ExecutorBuilder;\n import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.watcher.ResourceWatcherService;\n import org.elasticsearch.xpack.action.TransportXPackInfoAction;\n import org.elasticsearch.xpack.action.TransportXPackUsageAction;\n import org.elasticsearch.xpack.action.XPackInfoAction;\n@@ -179,7 +180,8 @@ public Collection<Class<? extends LifecycleComponent>> getGuiceServiceClasses()\n     }\n \n     @Override\n-    public Collection<Object> createComponents(Client client, ClusterService clusterService, ThreadPool threadPool) {\n+    public Collection<Object> createComponents(Client client, ClusterService clusterService, ThreadPool threadPool,\n+            ResourceWatcherService resourceWatcherService) {\n         List<Object> components = new ArrayList<>();\n         if (transportClientMode == false) {\n             // watcher http stuff",
    "output": "Fix compilation error Core changed"
  },
  {
    "input": "diff --git a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n--- a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n+++ b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n@@ -80,7 +80,7 @@ public abstract class ESSmokeClientTestCase extends LuceneTestCase {\n     private static String clusterAddresses;\n     protected String index;\n \n-    private static final class BogusPlugin extends Plugin {\n+    public static final class BogusPlugin extends Plugin {\n         // se NettyUtils.... this runs without the permission from the netty module so it will fail since reindex can't set the property\n         // to make it still work we disable that check but need to register the setting first\n         private static final Setting<Boolean> ASSERT_NETTY_BUGLEVEL = Setting.boolSetting(\"netty.assert.buglevel\", true,",
    "output": "Fix test plugin visibility"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n@@ -157,13 +157,11 @@ public TransportClient build() {\n                 resourcesToClose.add(circuitBreakerService);\n                 BigArrays bigArrays = new BigArrays(settings, circuitBreakerService);\n                 resourcesToClose.add(bigArrays);\n-                Collection<Object> pluginComponents = pluginsService.createComponenents();\n                 modules.add(settingsModule);\n                 modules.add((b -> {\n                     b.bind(BigArrays.class).toInstance(bigArrays);\n                     b.bind(PluginsService.class).toInstance(pluginsService);\n                     b.bind(CircuitBreakerService.class).toInstance(circuitBreakerService);\n-                    pluginComponents.stream().forEach(p -> b.bind((Class)p.getClass()).toInstance(p));\n                 }));\n \n                 Injector injector = modules.createInjector();\n@@ -173,9 +171,7 @@ public TransportClient build() {\n                 final TransportProxyClient proxy = new TransportProxyClient(settings, transportService, nodesService,\n                     actionModule.getActions().values().stream().map(x -> x.getAction()).collect(Collectors.toList()));\n \n-                List<LifecycleComponent> pluginLifecycleComponents = pluginComponents.stream()\n-                    .filter(p -> p instanceof LifecycleComponent)\n-                    .map(p -> (LifecycleComponent)p).collect(Collectors.toList());\n+                List<LifecycleComponent> pluginLifecycleComponents = new ArrayList<>();\n                 pluginLifecycleComponents.addAll(pluginsService.getGuiceServiceClasses().stream()\n                     .map(injector::getInstance).collect(Collectors.toList()));\n                 resourcesToClose.addAll(pluginLifecycleComponents);",
    "output": "Remove createComponents from transport client"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java\n--- a/core/src/main/java/org/elasticsearch/node/Node.java\n+++ b/core/src/main/java/org/elasticsearch/node/Node.java\n@@ -195,7 +195,6 @@ public Node(Settings preparedSettings) {\n         this(InternalSettingsPreparer.prepareEnvironment(preparedSettings, null), Collections.<Class<? extends Plugin>>emptyList());\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n     protected Node(Environment tmpEnv, Collection<Class<? extends Plugin>> classpathPlugins) {\n         Settings tmpSettings = Settings.builder().put(tmpEnv.settings())\n                 .put(Client.CLIENT_TYPE_SETTING_S.getKey(), CLIENT_TYPE).build();",
    "output": "Remove unnecessary warning suppression"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/health/ClusterStateHealthTests.java b/core/src/test/java/org/elasticsearch/cluster/health/ClusterStateHealthTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/health/ClusterStateHealthTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/health/ClusterStateHealthTests.java\n@@ -165,8 +165,13 @@ public void testClusterHealth() throws IOException {\n             metaData.put(indexMetaData, true);\n             routingTable.add(indexRoutingTable);\n         }\n-        ClusterState clusterState = ClusterState.builder(ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable.build()).build();\n-        String[] concreteIndices = indexNameExpressionResolver.concreteIndexNames(clusterState, IndicesOptions.strictExpand(), (String[]) null);\n+        ClusterState clusterState = ClusterState.builder(ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY))\n+                                                .metaData(metaData)\n+                                                .routingTable(routingTable.build())\n+                                                .build();\n+        String[] concreteIndices = indexNameExpressionResolver.concreteIndexNames(\n+            clusterState, IndicesOptions.strictExpand(), (String[]) null\n+        );\n         ClusterStateHealth clusterStateHealth = new ClusterStateHealth(clusterState, concreteIndices);\n         logger.info(\"cluster status: {}, expected {}\", clusterStateHealth.getStatus(), counter.status());\n         clusterStateHealth = maybeSerialize(clusterStateHealth);",
    "output": "Fix line length formatting for ClusterStateHealthTests"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/integration/BasicWatcherTests.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/integration/BasicWatcherTests.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/integration/BasicWatcherTests.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/integration/BasicWatcherTests.java\n@@ -57,7 +57,7 @@\n \n /**\n  */\n-public class    BasicWatcherTests extends AbstractWatcherIntegrationTestCase {\n+public class BasicWatcherTests extends AbstractWatcherIntegrationTestCase {\n \n     @Override\n     protected boolean timeWarped() {",
    "output": "Fix spacing in watcher test class"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n@@ -671,7 +671,7 @@ public static String randomGeohash(int minPrecision, int maxPrecision) {\n     private static final GeohashGenerator geohashGenerator = new GeohashGenerator();\n \n     public static class GeohashGenerator extends CodepointSetGenerator {\n-        private final static char[] ASCII_SET = \"0123456789bcdefghjkmnpqrstuvwxyz\".toCharArray();\n+        private static final char[] ASCII_SET = \"0123456789bcdefghjkmnpqrstuvwxyz\".toCharArray();\n \n         public GeohashGenerator() {\n             super(ASCII_SET);",
    "output": "Fix modifier order checkstyle"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n@@ -271,6 +271,9 @@ public void testInputStreamSkip() throws IOException {\n                 final int offset = randomIntBetween(0, length-1);\n                 assertEquals(offset, input.skip(offset));\n                 assertEquals(pbr.get(offset), input.readByte());\n+                if (offset == length - 1) {\n+                    continue; // no more bytes to retrieve!\n+                }\n                 final int nextOffset = randomIntBetween(offset, length-2);\n                 assertEquals(nextOffset - offset, input.skip(nextOffset - offset));\n                 assertEquals(pbr.get(nextOffset+1), input.readByte()); // +1 for the one byte we read above",
    "output": "Fix test edge case for random bytes reference iter. Getting an offset to the last byte means we can only stream one byte and then we are done, we can't get another offset after it"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java\n@@ -314,7 +314,10 @@ protected Query doToQuery(QueryShardContext shardContext) throws IOException {\n         // if index created V_2_3 > use prefix encoded postings format\n         final GeoPointField.TermEncoding encoding = (indexVersionCreated.before(Version.V_2_3_0)) ?\n             GeoPointField.TermEncoding.NUMERIC : GeoPointField.TermEncoding.PREFIX;\n-        normDistance = GeoUtils.maxRadialDistance(center, normDistance);\n+        // Lucene 6.0 and earlier requires a radial restriction\n+        if (indexVersionCreated.before(Version.V_5_0_0_alpha4)) {\n+            normDistance = GeoUtils.maxRadialDistance(center, normDistance);\n+        }\n         return new GeoPointDistanceQuery(fieldType.name(), encoding, center.lat(), center.lon(), normDistance);\n     }\n ",
    "output": "Remove radial restriction for GeoDistanceQuery As of lucene 6.1 GeoDistanceQuery no longer requires restricting the radial distance in GeoPointDistanceQuery"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n@@ -1642,7 +1642,7 @@ public void testRecoverFromLocalShard() throws IOException {\n     }\n \n     /** A dummy repository for testing which just needs restore overridden */\n-    private static abstract class RestoreOnlyRepository extends AbstractLifecycleComponent implements Repository {\n+    private abstract static class RestoreOnlyRepository extends AbstractLifecycleComponent implements Repository {\n         public RestoreOnlyRepository() {\n             super(Settings.EMPTY);\n         }",
    "output": "Fix checkstyle in test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java\n--- a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java\n@@ -503,7 +503,7 @@ public void testWriteMapOfLists() throws IOException {\n         out.close();\n     }\n \n-    private static abstract class BaseNamedWriteable implements NamedWriteable {\n+    private abstract static class BaseNamedWriteable implements NamedWriteable {\n \n     }\n ",
    "output": "Fix modifier order in BytesStreamsTests This commit fixes an issue with the ordering of modifiers on a static nested class in BytesStreamsTests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java\n@@ -285,9 +285,6 @@ public void testDanglingIndicesWithAliasConflict() throws Exception {\n         listener.latch.await();\n         assertThat(clusterService.state(), not(originalState));\n         assertNotNull(clusterService.state().getMetaData().index(alias));\n-\n-        // cleanup\n-        indicesService.deleteIndex(test.index(), \"finished with test\");\n     }\n \n     /**",
    "output": "Fix test issue where index is explicitly deleted during cluster state update Calling indicesService.deleteIndex() can trip an assertion if there is an ongoing cluster state applied in IndicesClusterStateService. This means that the index is possibly deleted after the failMissingShards check and before we try creating new and updated shards, tripping an assertion that non-existing shards must have shard state initializing (started in this case)"
  },
  {
    "input": "diff --git a/modules/reindex/src/main/java/org/elasticsearch/index/reindex/TransportReindexAction.java b/modules/reindex/src/main/java/org/elasticsearch/index/reindex/TransportReindexAction.java\n--- a/modules/reindex/src/main/java/org/elasticsearch/index/reindex/TransportReindexAction.java\n+++ b/modules/reindex/src/main/java/org/elasticsearch/index/reindex/TransportReindexAction.java\n@@ -109,7 +109,7 @@ protected void doExecute(ReindexRequest request, ActionListener<BulkIndexByScrol\n \n     private void checkRemoteWhitelist(RemoteInfo remoteInfo) {\n         TransportAddress publishAddress = null;\n-        HttpInfo httpInfo = httpServer.info();\n+        HttpInfo httpInfo = httpServer == null ? null : httpServer.info();\n         if (httpInfo != null && httpInfo.getAddress() != null) {\n             publishAddress = httpInfo.getAddress().publishAddress();\n         }",
    "output": "Fix reindex NPE when http is disabled"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/ingest/TestProcessor.java b/test/framework/src/main/java/org/elasticsearch/ingest/TestProcessor.java\n--- a/test/framework/src/main/java/org/elasticsearch/ingest/TestProcessor.java\n+++ b/test/framework/src/main/java/org/elasticsearch/ingest/TestProcessor.java\n@@ -66,7 +66,8 @@ public int getInvokedCounter() {\n \n     public static final class Factory implements Processor.Factory {\n         @Override\n-        public TestProcessor create(Map<String, Processor.Factory> registry, String processorTag, Map<String, Object> config) throws Exception {\n+        public TestProcessor create(Map<String, Processor.Factory> registry, String processorTag,\n+                                    Map<String, Object> config) throws Exception {\n             return new TestProcessor(processorTag, \"test-processor\", ingestDocument -> {});\n         }\n     }",
    "output": "Fix checkstyle for TestProcessor"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n@@ -53,7 +53,7 @@ public void testGet() throws IOException {\n         for (int i = 0; i < probes; i++) {\n             int index = randomIntBetween(0, copy.length() - 1);\n             assertEquals(pbr.get(index), copy.get(index));\n-            index = randomIntBetween(sliceOffset, sliceOffset + sliceLength);\n+            index = randomIntBetween(sliceOffset, sliceOffset + sliceLength - 1);\n             assertEquals(pbr.get(index), slice.get(index - sliceOffset));\n         }\n     }",
    "output": "Fix rare OBOE in AbstractBytesReferenceTestCase"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n@@ -462,9 +462,16 @@ public void testSliceToBytesRef() throws IOException {\n         // get a BytesRef from a slice\n         int sliceOffset = randomIntBetween(0, pbr.length());\n         int sliceLength = randomIntBetween(0, pbr.length() - sliceOffset);\n+\n         BytesRef sliceRef = pbr.slice(sliceOffset, sliceLength).toBytesRef();\n-        // note that these are only true if we have <= than a page, otherwise offset/length are shifted\n-        assertEquals(sliceOffset, sliceRef.offset);\n+\n+        if (sliceLength == 0 && sliceOffset != sliceRef.offset) {\n+            // some impls optimize this to an empty instance then the offset will be 0\n+            assertEquals(0, sliceRef.offset);\n+        } else {\n+            // note that these are only true if we have <= than a page, otherwise offset/length are shifted\n+            assertEquals(sliceOffset, sliceRef.offset);\n+        }\n         assertEquals(sliceLength, sliceRef.length);\n     }\n ",
    "output": "Fix test to account for internal empyt reference optimization"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPingIT.java b/core/src/test/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPingIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPingIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPingIT.java\n@@ -30,6 +30,7 @@\n import org.elasticsearch.common.transport.TransportAddress;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.concurrent.ConcurrentCollections;\n import org.elasticsearch.discovery.zen.elect.ElectMasterService;\n import org.elasticsearch.discovery.zen.ping.PingContextProvider;\n import org.elasticsearch.discovery.zen.ping.ZenPing;\n@@ -42,7 +43,6 @@\n import org.elasticsearch.transport.TransportService;\n import org.elasticsearch.transport.TransportSettings;\n import org.elasticsearch.transport.netty.NettyTransport;\n-import org.jboss.netty.util.internal.ConcurrentHashMap;\n \n import java.net.InetSocketAddress;\n import java.util.concurrent.ConcurrentMap;\n@@ -208,7 +208,7 @@ protected Version getCurrentVersion() {\n         final TransportService transportService = new TransportService(settings, transport, threadPool);\n         transportService.start();\n         transportService.acceptIncomingRequests();\n-        ConcurrentMap<TransportAddress, AtomicInteger> counters = new ConcurrentHashMap<>();\n+        ConcurrentMap<TransportAddress, AtomicInteger> counters = ConcurrentCollections.newConcurrentMap();\n         transportService.addConnectionListener(new TransportConnectionListener() {\n             @Override\n             public void onNodeConnected(DiscoveryNode node) {",
    "output": "Upgrade to netty 3.10.6.Final"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java b/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java\n--- a/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java\n+++ b/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java\n@@ -858,7 +858,7 @@ public void testEmptyWithExtendedBounds() throws Exception {\n \n         // constructing the newly expected bucket list\n         int bucketsCount = (int) ((boundsMaxKey - boundsMinKey) / interval) + 1;\n-        long[] extendedValueCounts = new long[bucketsCount];\n+        long[] extendedValueCounts = new long[valueCounts.length + addedBucketsLeft + addedBucketsRight];\n         System.arraycopy(valueCounts, 0, extendedValueCounts, addedBucketsLeft, valueCounts.length);\n \n         SearchResponse response = null;",
    "output": "Fix histogram test when extended bounds overlaps data"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java b/core/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java\n--- a/core/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java\n+++ b/core/src/main/java/org/elasticsearch/common/bytes/CompositeBytesReference.java\n@@ -96,7 +96,7 @@ public BytesReference slice(int from, int length) {\n         return new CompositeBytesReference(inSlice);\n     }\n \n-    private final int getOffsetIndex(int offset) {\n+    private int getOffsetIndex(int offset) {\n         final int i = Arrays.binarySearch(offsets, offset);\n         return i < 0 ? (-(i + 1)) - 1 : i;\n     }",
    "output": "Remove redundant modifier"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n@@ -425,7 +425,8 @@ private PluginInfo verify(Terminal terminal, Path pluginRoot, boolean isBatch, E\n         // don't let luser install plugin as a module...\n         // they might be unavoidably in maven central and are packaged up the same way)\n         if (MODULES.contains(info.getName())) {\n-            throw new UserException(ExitCodes.USAGE, \"plugin '\" + info.getName() + \"' cannot be installed like this, it is a system module\");\n+            throw new UserException(\n+                    ExitCodes.USAGE, \"plugin '\" + info.getName() + \"' cannot be installed like this, it is a system module\");\n         }\n \n         // check for jar hell before any copying",
    "output": "Fix style violation in InstallPluginCommand.java This commit fixes a checkstyle violation in InstallPluginCommand.java added after renaming UserError to UserException in f9d55be1ed013e93cd732d01161ff2a34d49db13"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java\n@@ -207,15 +207,14 @@ private SnapshotsStatusResponse buildResponse(SnapshotsStatusRequest request, Li\n                 .filter(s -> requestedSnapshotNames.contains(s.getName()))\n                 .collect(Collectors.toMap(SnapshotId::getName, Function.identity()));\n             for (final String snapshotName : request.snapshots()) {\n+                if (currentSnapshotNames.contains(snapshotName)) {\n+                    // we've already found this snapshot in the current snapshot entries, so skip over\n+                    continue;\n+                }\n                 SnapshotId snapshotId = matchedSnapshotIds.get(snapshotName);\n                 if (snapshotId == null) {\n-                    if (currentSnapshotNames.contains(snapshotName)) {\n-                        // we've already found this snapshot in the current snapshot entries, so skip over\n-                        continue;\n-                    } else {\n-                        // neither in the current snapshot entries nor found in the repository\n-                        throw new SnapshotMissingException(repositoryName, snapshotName);\n-                    }\n+                    // neither in the current snapshot entries nor found in the repository\n+                    throw new SnapshotMissingException(repositoryName, snapshotName);\n                 }\n                 SnapshotInfo snapshotInfo = snapshotsService.snapshot(repositoryName, snapshotId);\n                 List<SnapshotIndexShardStatus> shardStatusBuilder = new ArrayList<>();",
    "output": "Fix getting snapshot status checks for preventing duplicate entries from both current snapshots (cluster state) and repository snapshots (on storage)"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/completion2x/CompletionTokenStream.java b/core/src/main/java/org/elasticsearch/search/suggest/completion2x/CompletionTokenStream.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/completion2x/CompletionTokenStream.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/completion2x/CompletionTokenStream.java\n@@ -108,8 +108,8 @@ public void close() throws IOException {\n         input.close();\n     }\n \n-    public static interface ToFiniteStrings {\n-        public Set<IntsRef> toFiniteStrings(TokenStream stream) throws IOException;\n+    public interface ToFiniteStrings {\n+        Set<IntsRef> toFiniteStrings(TokenStream stream) throws IOException;\n     }\n \n     @Override",
    "output": "Fix CompletionTokenStream modifier redundancy"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardOperationsLockTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardOperationsLockTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardOperationsLockTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardOperationsLockTests.java\n@@ -92,10 +92,12 @@ public void run() {\n             operationThreads.add(thread);\n         }\n \n+        CountDownLatch blockFinished = new CountDownLatch(1);\n         threadPool.generic().execute(() -> {\n             try {\n                 latch.await();\n                 blockAndWait().close();\n+                blockFinished.countDown();\n             } catch (InterruptedException e) {\n                 throw new RuntimeException(e);\n             }\n@@ -112,6 +114,8 @@ public void run() {\n         for (Thread thread : operationThreads) {\n             thread.join();\n         }\n+\n+        blockFinished.await();\n     }\n \n ",
    "output": "Make testAllOperationsInvoked properly clean up after itself"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/snapshots/RepositoriesIT.java b/core/src/test/java/org/elasticsearch/snapshots/RepositoriesIT.java\n--- a/core/src/test/java/org/elasticsearch/snapshots/RepositoriesIT.java\n+++ b/core/src/test/java/org/elasticsearch/snapshots/RepositoriesIT.java\n@@ -153,7 +153,8 @@ public void testMisconfiguredRepository() throws Exception {\n                     .get();\n             fail(\"Shouldn't be here\");\n         } catch (RepositoryException ex) {\n-            assertThat(ex.toString(), containsString(\"unsupported url protocol [netdoc]\"));\n+            assertThat(ex.toString(), containsString(\"Unable to parse URL repository setting\"));\n+            assertThat(ex.toString(), containsString(\"netdoc\"));\n         }\n \n         logger.info(\"--> trying creating url repository with location that is not registered in path.repo setting\");",
    "output": "Fix test assertion matching exception message Newer versions of the URL class in JDK 9 use a different exception message when throwing a MalformedURLException due to an unknown protocol"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/monitoring/src/test/java/org/elasticsearch/xpack/monitoring/agent/resolver/cluster/ClusterStatsResolverTests.java b/elasticsearch/x-pack/monitoring/src/test/java/org/elasticsearch/xpack/monitoring/agent/resolver/cluster/ClusterStatsResolverTests.java\n--- a/elasticsearch/x-pack/monitoring/src/test/java/org/elasticsearch/xpack/monitoring/agent/resolver/cluster/ClusterStatsResolverTests.java\n+++ b/elasticsearch/x-pack/monitoring/src/test/java/org/elasticsearch/xpack/monitoring/agent/resolver/cluster/ClusterStatsResolverTests.java\n@@ -109,7 +109,7 @@ private NodeInfo randomNodeInfo() {\n         BoundTransportAddress transportAddress = new BoundTransportAddress(new TransportAddress[]{DummyTransportAddress.INSTANCE},\n                 DummyTransportAddress.INSTANCE);\n         return new NodeInfo(Version.CURRENT, org.elasticsearch.Build.CURRENT,\n-                new DiscoveryNode(\"node_0\", DummyTransportAddress.INSTANCE, emptyMap(), emptySet(), Version.CURRENT), emptyMap(),\n+                new DiscoveryNode(\"node_0\", DummyTransportAddress.INSTANCE, emptyMap(), emptySet(), Version.CURRENT),\n                 Settings.EMPTY, DummyOsInfo.INSTANCE, new ProcessInfo(randomInt(), randomBoolean()), JvmInfo.jvmInfo(),\n                 new ThreadPoolInfo(Collections.singletonList(new ThreadPool.Info(\"test_threadpool\", ThreadPool.ThreadPoolType.FIXED, 5))),\n                 new TransportInfo(transportAddress, Collections.emptyMap()), new HttpInfo(transportAddress, randomLong()),",
    "output": "Fix xpack tests with node info ctor changes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/node/service/NodeService.java b/core/src/main/java/org/elasticsearch/node/service/NodeService.java\n--- a/core/src/main/java/org/elasticsearch/node/service/NodeService.java\n+++ b/core/src/main/java/org/elasticsearch/node/service/NodeService.java\n@@ -58,7 +58,6 @@ public class NodeService extends AbstractComponent implements Closeable {\n     private final CircuitBreakerService circuitBreakerService;\n     private final IngestService ingestService;\n     private final SettingsFilter settingsFilter;\n-    private ClusterService clusterService;\n     private ScriptService scriptService;\n \n     @Nullable\n@@ -80,7 +79,6 @@ public NodeService(Settings settings, ThreadPool threadPool, MonitorService moni\n         this.pluginService = pluginService;\n         this.circuitBreakerService = circuitBreakerService;\n         this.httpServer = httpServer;\n-        this.clusterService = clusterService;\n         this.ingestService = ingestService;\n         this.settingsFilter = settingsFilter;\n         this.scriptService = scriptService;",
    "output": "Remove unused ClusterService member of NodeService"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java\n@@ -202,16 +202,6 @@ public void readFrom(StreamInput in) throws IOException {\n         } else {\n             totalIndexingBuffer = null;\n         }\n-        if (version.onOrBefore(Version.V_5_0_0_alpha4)) {\n-            // service attributes were removed\n-            if (in.readBoolean()) {\n-                int size = in.readVInt();\n-                for (int i = 0; i < size; i++) {\n-                    in.readString(); // key\n-                    in.readString(); // value\n-                }\n-            }\n-        }\n         if (in.readBoolean()) {\n             settings = Settings.readSettingsFromStream(in);\n         }\n@@ -253,9 +243,6 @@ public void writeTo(StreamOutput out) throws IOException {\n             out.writeBoolean(true);\n             out.writeLong(totalIndexingBuffer.bytes());\n         }\n-        if (version.onOrBefore(Version.V_5_0_0_alpha4)) {\n-            out.writeBoolean(false); // service attributes removed\n-        }\n         if (settings == null) {\n             out.writeBoolean(false);\n         } else {",
    "output": "Remove unnecessary transport level bwc"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/node/service/NodeService.java b/core/src/main/java/org/elasticsearch/node/service/NodeService.java\n--- a/core/src/main/java/org/elasticsearch/node/service/NodeService.java\n+++ b/core/src/main/java/org/elasticsearch/node/service/NodeService.java\n@@ -74,7 +74,7 @@ public class NodeService extends AbstractComponent implements Closeable {\n     @Inject\n     public NodeService(Settings settings, ThreadPool threadPool, MonitorService monitorService,\n                        Discovery discovery, TransportService transportService, IndicesService indicesService,\n-                       PluginsService pluginService, CircuitBreakerService circuitBreakerService,\n+                       PluginsService pluginService, CircuitBreakerService circuitBreakerService, ScriptService scriptService,\n                        IngestService ingestService, ClusterService clusterService, SettingsFilter settingsFilter) {\n         super(settings);\n         this.threadPool = threadPool;\n@@ -87,17 +87,11 @@ public NodeService(Settings settings, ThreadPool threadPool, MonitorService moni\n         this.clusterService = clusterService;\n         this.ingestService = ingestService;\n         this.settingsFilter = settingsFilter;\n+        this.scriptService = scriptService;\n         clusterService.add(ingestService.getPipelineStore());\n         clusterService.add(ingestService.getPipelineExecutionService());\n     }\n \n-    // can not use constructor injection or there will be a circular dependency\n-    // nocommit: try removing this...\n-    @Inject(optional = true)\n-    public void setScriptService(ScriptService scriptService) {\n-        this.scriptService = scriptService;\n-    }\n-\n     public void setHttpServer(@Nullable HttpServer httpServer) {\n         this.httpServer = httpServer;\n     }",
    "output": "Remove unnecessary optional injection of ScriptService into NodeService"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java b/core/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java\n--- a/core/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/indices/cluster/AbstractIndicesClusterStateServiceTestCase.java\n@@ -181,7 +181,8 @@ public synchronized void removeIndex(Index index, String reason) {\n         }\n \n         @Override\n-        public @Nullable MockIndexService indexService(Index index) {\n+        @Nullable\n+        public MockIndexService indexService(Index index) {\n             return indices.get(index.getUUID());\n         }\n ",
    "output": "Fix checkstyle violations"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/ldap/AbstractAdLdapRealmTestCase.java b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/ldap/AbstractAdLdapRealmTestCase.java\n--- a/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/ldap/AbstractAdLdapRealmTestCase.java\n+++ b/elasticsearch/x-pack/security/src/test/java/org/elasticsearch/integration/ldap/AbstractAdLdapRealmTestCase.java\n@@ -55,9 +55,9 @@ public abstract  class AbstractAdLdapRealmTestCase extends SecurityIntegTestCase\n                     \"Gods: [ \\\"cn=Gods,ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com\\\" ] \\n\" +\n                     \"Philanthropists: [ \\\"cn=Philanthropists,ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com\\\" ] \\n\";\n \n-    static protected RealmConfig realmConfig;\n-    static protected boolean useGlobalSSL;\n-    static protected boolean sslEnabled;\n+    protected static RealmConfig realmConfig;\n+    protected static boolean useGlobalSSL;\n+    protected static boolean sslEnabled;\n \n     @BeforeClass\n     public static void setupRealm() {",
    "output": "Fix checkstyle violations"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java b/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java\n@@ -34,7 +34,7 @@\n  */\n public final class Features {\n \n-    private static final List<String> SUPPORTED = Arrays.asList(\"stash_in_path\", \"groovy_scripting\", \"headers\", \"yaml\");\n+    private static final List<String> SUPPORTED = Arrays.asList(\"stash_in_path\", \"groovy_scripting\", \"headers\");\n \n     private Features() {\n ",
    "output": "Remove feature yaml from REST tests The only runner that supported it was the java runner, we can use json format instead given that the default one with cat apis is text"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n@@ -394,7 +394,7 @@ public void testArrayOffset() throws IOException {\n     public void testSliceArrayOffset() throws IOException {\n         int length = randomInt(PAGE_SIZE * randomIntBetween(2, 5));\n         BytesReference pbr = newBytesReference(length);\n-        int sliceOffset = randomIntBetween(0, pbr.length() - 1);\n+        int sliceOffset = randomIntBetween(0, pbr.length() - 1); // an offset to the end would be len 0\n         int sliceLength = randomIntBetween(pbr.length() - sliceOffset, pbr.length() - sliceOffset);\n         BytesReference slice = pbr.slice(sliceOffset, sliceLength);\n         if (slice.hasArray()) {",
    "output": "Add comment explaining bytes reference edge case"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/bytes/AbstractBytesReferenceTestCase.java\n@@ -394,7 +394,7 @@ public void testArrayOffset() throws IOException {\n     public void testSliceArrayOffset() throws IOException {\n         int length = randomInt(PAGE_SIZE * randomIntBetween(2, 5));\n         BytesReference pbr = newBytesReference(length);\n-        int sliceOffset = randomIntBetween(0, pbr.length());\n+        int sliceOffset = randomIntBetween(0, pbr.length() - 1);\n         int sliceLength = randomIntBetween(pbr.length() - sliceOffset, pbr.length() - sliceOffset);\n         BytesReference slice = pbr.slice(sliceOffset, sliceLength);\n         if (slice.hasArray()) {",
    "output": "Fix test edge case for bytes reference"
  },
  {
    "input": "diff --git a/plugins/discovery-azure-classic/src/test/java/org/elasticsearch/discovery/azure/classic/AzureSimpleTests.java b/plugins/discovery-azure-classic/src/test/java/org/elasticsearch/discovery/azure/classic/AzureSimpleTests.java\n--- a/plugins/discovery-azure-classic/src/test/java/org/elasticsearch/discovery/azure/classic/AzureSimpleTests.java\n+++ b/plugins/discovery-azure-classic/src/test/java/org/elasticsearch/discovery/azure/classic/AzureSimpleTests.java\n@@ -38,7 +38,7 @@ public AzureSimpleTests() {\n         super(AzureComputeServiceSimpleMock.TestPlugin.class);\n     }\n \n-    public void testOneNodeDhouldRunUsingPrivateIp() {\n+    public void testOneNodeShouldRunUsingPrivateIp() {\n         Settings.Builder settings = Settings.builder()\n                 .put(Management.SERVICE_NAME_SETTING.getKey(), \"dummy\")\n                 .put(Discovery.HOST_TYPE_SETTING.getKey(), \"private_ip\");",
    "output": "Fix method name typo"
  },
  {
    "input": "diff --git a/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java b/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n--- a/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n+++ b/plugins/discovery-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n@@ -97,7 +97,8 @@ public InstanceList run() throws Exception {\n                     }\n                 });\n                 // assist type inference\n-                return instanceList.isEmpty()  || instanceList.getItems() == null ? Collections.<Instance>emptyList() : instanceList.getItems();\n+                return instanceList.isEmpty()  || instanceList.getItems() == null ?\n+                    Collections.<Instance>emptyList() : instanceList.getItems();\n             } catch (PrivilegedActionException e) {\n                 logger.warn(\"Problem fetching instance list for zone {}\", e, zoneId);\n                 logger.debug(\"Full exception:\", e);",
    "output": "Fix line width"
  },
  {
    "input": "diff --git a/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java b/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java\n--- a/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java\n+++ b/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java\n@@ -256,9 +256,11 @@ public void testIllegalSettingsMissingZone() {\n     }\n \n     /**\n-     * For issue https://github.com/elastic/elasticsearch/issues/16967\n+     * For issue https://github.com/elastic/elasticsearch/issues/16967:\n+     * When using multiple regions and one of them has no instance at all, this\n+     * was producing a NPE as a result.\n      */\n-    public void testEmptyRegion16967() {\n+    public void testNoRegionReturnsEmptyList() {\n         Settings nodeSettings = Settings.builder()\n             .put(GceComputeService.PROJECT_SETTING.getKey(), projectName)\n             .putArray(GceComputeService.ZONE_SETTING.getKey(), \"europe-west1-b\", \"us-central1-a\")",
    "output": "Add more javadoc and rename test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/ProgressInputStreamTests.java b/core/src/test/java/org/elasticsearch/plugins/ProgressInputStreamTests.java\n--- a/core/src/test/java/org/elasticsearch/plugins/ProgressInputStreamTests.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/ProgressInputStreamTests.java\n@@ -69,27 +69,27 @@ public void testOneByte() throws Exception {\n     }\n \n     public void testOddBytes() throws Exception {\n-        int odd = (randomIntBetween(100, 200) / 2) + 1;\n+        int odd = randomIntBetween(10, 100) * 2 + 1;\n         ProgressInputStream is = newProgressInputStream(odd);\n         for (int i = 0; i < odd; i++) {\n             is.checkProgress(1);\n         }\n         is.checkProgress(-1);\n \n-        assertThat(progresses, hasSize(odd+1));\n+        assertThat(progresses, hasSize(Math.min(odd + 1, 100)));\n         assertThat(progresses, hasItem(100));\n     }\n \n     public void testEvenBytes() throws Exception {\n-        int even = (randomIntBetween(100, 200) / 2);\n+        int even = randomIntBetween(10, 100) * 2;\n         ProgressInputStream is = newProgressInputStream(even);\n \n         for (int i = 0; i < even; i++) {\n             is.checkProgress(1);\n         }\n         is.checkProgress(-1);\n \n-        assertThat(progresses, hasSize(even+1));\n+        assertThat(progresses, hasSize(Math.min(even + 1, 100)));\n         assertThat(progresses, hasItem(100));\n     }\n ",
    "output": "Fix test bug in plugin cli progress tests"
  },
  {
    "input": "diff --git a/elasticsearch/qa/security-migrate-tests/src/test/java/org/elasticsearch/xpack/security/MigrateToolIT.java b/elasticsearch/qa/security-migrate-tests/src/test/java/org/elasticsearch/xpack/security/MigrateToolIT.java\n--- a/elasticsearch/qa/security-migrate-tests/src/test/java/org/elasticsearch/xpack/security/MigrateToolIT.java\n+++ b/elasticsearch/qa/security-migrate-tests/src/test/java/org/elasticsearch/xpack/security/MigrateToolIT.java\n@@ -73,6 +73,9 @@ public void testRunMigrateTool() throws Exception {\n \n         logger.info(\"--> output:\\n{}\", t.getOutput());\n \n+        Client client = getClient();\n+        SecurityClient c = new SecurityClient(client);\n+\n         // Check that the migrated user can be retrieved\n         GetUsersResponse resp = c.prepareGetUsers(\"bob\").get();\n         assertTrue(\"user 'bob' should exist\", resp.hasUsers());",
    "output": "Fix compilation for missing client"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java b/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/InternalTestCluster.java\n@@ -890,7 +890,7 @@ private void clearDataIfNeeded(RestartCallback callback) throws IOException {\n                 NodeEnvironment nodeEnv = node.getNodeEnvironment();\n                 if (nodeEnv.hasNodeFile()) {\n                     final Path[] locations = nodeEnv.nodeDataPaths();\n-                    logger.debug(\"removing node data paths: [{}]\", (Object[]) locations);\n+                    logger.debug(\"removing node data paths: [{}]\", Arrays.toString(locations));\n                     IOUtils.rm(locations);\n                 }\n             }\n@@ -1039,7 +1039,7 @@ private synchronized void reset(boolean wipeData) throws IOException {\n             ClusterHealthResponse response = client().admin().cluster().prepareHealth()\n                 .setWaitForNodes(Integer.toString(newSize)).get();\n             if (response.isTimedOut()) {\n-                logger.warn(\"failed to wait for a cluster of size [{}], got\", newSize, response);\n+                logger.warn(\"failed to wait for a cluster of size [{}], got [{}]\", newSize, response);\n                 throw new IllegalStateException(\"cluster failed to reach the expected size of [\" + newSize + \"]\");\n             }\n         }",
    "output": "Fix number of arguments provided to logger calls"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java b/core/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java\n--- a/core/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java\n+++ b/core/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java\n@@ -446,13 +446,6 @@ public void testRecoverBrokenIndexMetadata() throws Exception {\n         assertNotNull(ex.getCause());\n         assertEquals(IllegalArgumentException.class, ex.getCause().getClass());\n         assertEquals(ex.getCause().getMessage(), \"Unknown tokenfilter type [icu_collation] for [myCollator]\");\n-\n-        client().admin().indices().prepareUpdateSettings()\n-            .setSettings(Settings.builder().putNull(\"index.analysis.filter.myCollator.type\")).get();\n-        client().admin().indices().prepareOpen(\"test\").get();\n-        ensureYellow();\n-        logger.info(\"--> verify 1 doc in the index\");\n-        assertHitCount(client().prepareSearch().setQuery(matchAllQuery()).get(), 1L);\n     }\n \n     /**\n@@ -510,13 +503,6 @@ public void testRecoverMissingAnalyzer() throws Exception {\n         assertNotNull(ex.getCause());\n         assertEquals(MapperParsingException.class, ex.getCause().getClass());\n         assertEquals(ex.getCause().getMessage(), \"analyzer [test] not found for field [field1]\");\n-\n-        client().admin().indices().prepareUpdateSettings()\n-            .setSettings(Settings.builder().put(\"index.analysis.analyzer.test.tokenizer\", \"keyword\")).get();\n-        client().admin().indices().prepareOpen(\"test\").get();\n-        ensureYellow();\n-        logger.info(\"--> verify 1 doc in the index\");\n-        assertHitCount(client().prepareSearch().setQuery(matchQuery(\"field1\", \"value one\")).get(), 1L);\n     }\n \n     public void testArchiveBrokenClusterSettings() throws Exception {",
    "output": "Fix tests that assumed that broken settings can be updated"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java b/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java\n--- a/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java\n+++ b/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HistogramTests.java\n@@ -857,7 +857,7 @@ public void testEmptyWithExtendedBounds() throws Exception {\n         boolean invalidBoundsError = boundsMin > boundsMax;\n \n         // constructing the newly expected bucket list\n-        int bucketsCount = numValueBuckets + addedBucketsLeft + addedBucketsRight;\n+        int bucketsCount = (int) ((boundsMaxKey - boundsMinKey) / interval) + 1;\n         long[] extendedValueCounts = new long[bucketsCount];\n         System.arraycopy(valueCounts, 0, extendedValueCounts, addedBucketsLeft, valueCounts.length);\n \n@@ -893,7 +893,7 @@ public void testEmptyWithExtendedBounds() throws Exception {\n         List<? extends Bucket> buckets = histo.getBuckets();\n         assertThat(buckets.size(), equalTo(bucketsCount));\n \n-        long key = Math.min(boundsMinKey, 0);\n+        long key = boundsMinKey;\n         for (int i = 0; i < bucketsCount; i++) {\n             Histogram.Bucket bucket = buckets.get(i);\n             assertThat(bucket, notNullValue());",
    "output": "Fix bounds calculation for extended bounds in histogram agg empty buckets test"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/AbstractQueryTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/AbstractQueryTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/AbstractQueryTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/AbstractQueryTestCase.java\n@@ -92,6 +92,7 @@\n import org.elasticsearch.indices.mapper.MapperRegistry;\n import org.elasticsearch.indices.query.IndicesQueriesRegistry;\n import org.elasticsearch.node.internal.InternalSettingsPreparer;\n+import org.elasticsearch.plugins.MapperPlugin;\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.script.Script.ScriptParseException;\n@@ -895,7 +896,7 @@ protected void configureSearch() {\n                         b.bind(Environment.class).toInstance(new Environment(settings));\n                         b.bind(ThreadPool.class).toInstance(threadPool);\n                     },\n-                    settingsModule, new IndicesModule(namedWriteableRegistry, Collections.emptyList()) {\n+                    settingsModule, new IndicesModule(namedWriteableRegistry, pluginsService.filterPlugins(MapperPlugin.class)) {\n                         @Override\n                         public void configure() {\n                             // skip services",
    "output": "Fix percolator tests They need their plugin or they'll break!"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java\n--- a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java\n+++ b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java\n@@ -43,14 +43,16 @@ public class IndicesModuleTests extends ESTestCase {\n \n     private static class FakeMapperParser implements Mapper.TypeParser {\n         @Override\n-        public Mapper.Builder<?, ?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+        public Mapper.Builder<?, ?> parse(String name, Map<String, Object> node, ParserContext parserContext)\n+            throws MapperParsingException {\n             return null;\n         }\n     }\n \n     private static class FakeMetadataMapperParser implements MetadataFieldMapper.TypeParser {\n         @Override\n-        public MetadataFieldMapper.Builder<?, ?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+        public MetadataFieldMapper.Builder<?, ?> parse(String name, Map<String, Object> node, ParserContext parserContext)\n+            throws MapperParsingException {\n             return null;\n         }\n         @Override",
    "output": "Fix line length in new indices module tests"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java b/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java\n--- a/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java\n+++ b/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java\n@@ -8,7 +8,6 @@\n \n import com.carrotsearch.randomizedtesting.annotations.Name;\n import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n-import org.elasticsearch.client.ResponseException;\n import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n@@ -51,24 +50,6 @@ public static Iterable<Object[]> parameters() throws IOException, RestTestParseE\n         return ESRestTestCase.createParameters(0, 1);\n     }\n \n-    @Before\n-    public void startWatcher() throws Exception {\n-        try {\n-            getAdminExecutionContext().callApi(\"xpack.watcher.start\", emptyMap(), emptyList(), emptyMap());\n-        } catch(ResponseException e) {\n-            //TODO ignore for now, needs to be fixed though\n-        }\n-    }\n-\n-    @After\n-    public void stopWatcher() throws Exception {\n-        try {\n-            getAdminExecutionContext().callApi(\"xpack.watcher.stop\", emptyMap(), emptyList(), emptyMap());\n-        } catch(ResponseException e) {\n-            //TODO ignore for now, needs to be fixed though\n-        }\n-    }\n-\n     @Before\n     public void installLicense() throws Exception {\n         final XContentBuilder builder = XContentFactory.jsonBuilder();",
    "output": "Remove start and stop watcher from XPackRestTestCase"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java\n@@ -379,7 +379,8 @@ private ShapeBuilder fetch(Client client, GetRequest getRequest, String path) th\n             throw new IllegalArgumentException(\"Shape with ID [\" + getRequest.id() + \"] in type [\" + getRequest.type() + \"] not found\");\n         }\n         if (response.isSourceEmpty()) {\n-            throw new IllegalArgumentException(\"Shape with ID [\" + getRequest.id() + \"] in type [\" + getRequest.type() + \"] source disabled\");\n+            throw new IllegalArgumentException(\"Shape with ID [\" + getRequest.id() + \"] in type [\" + getRequest.type() +\n+                    \"] source disabled\");\n         }\n \n         String[] pathElements = path.split(\"\\\\.\");",
    "output": "Fix checkstyle issue"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/authz/RoleDescriptor.java b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/authz/RoleDescriptor.java\n--- a/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/authz/RoleDescriptor.java\n+++ b/elasticsearch/x-pack/security/src/main/java/org/elasticsearch/xpack/security/authz/RoleDescriptor.java\n@@ -235,10 +235,6 @@ private static RoleDescriptor.IndicesPrivileges parseIndex(String roleName, XCon\n                 }\n             } else if (ParseFieldMatcher.STRICT.match(currentFieldName, Fields.PRIVILEGES)) {\n                 privileges = readStringArray(roleName, parser, true);\n-                if (names.length == 0) {\n-                    throw new ElasticsearchParseException(\"failed to parse indices privileges for role [{}]. [{}] cannot be an empty \" +\n-                            \"array\", roleName, currentFieldName);\n-                }\n             } else if (ParseFieldMatcher.STRICT.match(currentFieldName, Fields.FIELDS)) {\n                 fields = readStringArray(roleName, parser, true);\n             } else {",
    "output": "Remove too-strict validation of role names When parsing the privileges, we now no longer throw an exception if there haven't been any names parsed out. This is not an issue though, because we validate that the `names` array is not empty when we parse it, and that it's not `null` before returning from the function. Adds a rest test that sends things out of order to test this still works. Resolves elastic/elasticsearch"
  },
  {
    "input": "diff --git a/plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRepository.java b/plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRepository.java\n--- a/plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRepository.java\n+++ b/plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRepository.java\n@@ -62,7 +62,7 @@ public class GoogleCloudStorageRepository extends BlobStoreRepository {\n     public static final Setting<String> APPLICATION_NAME =\n             new Setting<>(\"application_name\", GoogleCloudStoragePlugin.NAME, Function.identity(), Property.NodeScope, Property.Dynamic);\n     public static final Setting<String> SERVICE_ACCOUNT =\n-            simpleString(\"service_account\", Property.NodeScope, Property.Dynamic, Property.Filtered);\n+            simpleString(\"service_account\", Property.NodeScope, Property.Dynamic);\n     public static final Setting<TimeValue> HTTP_READ_TIMEOUT =\n             timeSetting(\"http.read_timeout\", NO_TIMEOUT, Property.NodeScope, Property.Dynamic);\n     public static final Setting<TimeValue> HTTP_CONNECT_TIMEOUT =",
    "output": "Remove settings filtering for service_account in GCS repository Related to #18945 and to this https://github.com/elastic/elasticsearch/commit/35d3bdab84fa05c71e8ae019aaf661759c8b1622#commitcomment-17914150 In GCS Repository plugin we defined a `service_account` setting which is defined as `Property.Filtered`. It's not needed as it's only a path to a file"
  },
  {
    "input": "diff --git a/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java b/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java\n--- a/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java\n+++ b/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java\n@@ -200,7 +200,9 @@ public void testSearchInlineTemplate() throws Exception {\n \n         assertNotNull(executedResult.executedRequest());\n         assertThat(executedResult.status(), is(Input.Result.Status.SUCCESS));\n-        assertEquals(executedResult.executedRequest().searchType(), request.searchType());\n+        if (getNumShards(\"test-search-index\").numPrimaries > 1) {\n+            assertEquals(executedResult.executedRequest().searchType(), request.searchType());\n+        }\n         assertArrayEquals(executedResult.executedRequest().indices(), request.indices());\n         assertEquals(executedResult.executedRequest().indicesOptions(), request.indicesOptions());\n ",
    "output": "Fix SearchInputIT.testSearchInlineTemplate The search type is overridden from default to query_and_fetch by the search action if the number of shards to request is equal to 1"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java\n@@ -18,6 +18,7 @@\n  */\n package org.elasticsearch.search.aggregations.bucket;\n \n+import org.elasticsearch.cluster.health.ClusterHealthStatus;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;\n import static org.hamcrest.Matchers.containsString;\n@@ -54,6 +55,7 @@ protected Collection<Class<? extends Plugin>> nodePlugins() {\n     public void setupSuiteScopeCluster() throws Exception {\n         assertAcked(prepareCreate(\"idx\")\n                 .addMapping(\"type\", \"ip\", \"type=ip\", \"ips\", \"type=ip\"));\n+        waitForRelocation(ClusterHealthStatus.GREEN);\n \n         indexRandom(true,\n                 client().prepareIndex(\"idx\", \"type\", \"1\").setSource(\n@@ -67,6 +69,8 @@ public void setupSuiteScopeCluster() throws Exception {\n                         \"ips\", Arrays.asList(\"2001:db8::ff00:42:8329\", \"2001:db8::ff00:42:8380\")));\n \n         assertAcked(prepareCreate(\"idx_unmapped\"));\n+        waitForRelocation(ClusterHealthStatus.GREEN);\n+        refresh();\n     }\n \n     public void testSingleValuedField() {",
    "output": "Add ensureGreen for IpRangeIT"
  },
  {
    "input": "diff --git a/client/test/src/main/java/org/elasticsearch/client/RestClientTestCase.java b/client/test/src/main/java/org/elasticsearch/client/RestClientTestCase.java\n--- a/client/test/src/main/java/org/elasticsearch/client/RestClientTestCase.java\n+++ b/client/test/src/main/java/org/elasticsearch/client/RestClientTestCase.java\n@@ -26,6 +26,7 @@\n import com.carrotsearch.randomizedtesting.annotations.TestMethodProviders;\n import com.carrotsearch.randomizedtesting.annotations.ThreadLeakAction;\n import com.carrotsearch.randomizedtesting.annotations.ThreadLeakGroup;\n+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakLingering;\n import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;\n import com.carrotsearch.randomizedtesting.annotations.ThreadLeakZombies;\n import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;\n@@ -38,7 +39,8 @@\n @ThreadLeakGroup(ThreadLeakGroup.Group.MAIN)\n @ThreadLeakAction({ThreadLeakAction.Action.WARN, ThreadLeakAction.Action.INTERRUPT})\n @ThreadLeakZombies(ThreadLeakZombies.Consequence.IGNORE_REMAINING_TESTS)\n+@ThreadLeakLingering(linger = 5000) // 5 sec lingering\n @TimeoutSuite(millis = 2 * 60 * 60 * 1000)\n public abstract class RestClientTestCase extends RandomizedTest {\n \n-}\n\\ No newline at end of file\n+}",
    "output": "Add ThreadLeakLingering option to Rest client tests Some Rest tests use the Sun HTTP server which has lingering threads after shutdown. Similar to ESTestCase, this adds an option to wait 5 seconds for these threads to terminate"
  },
  {
    "input": "diff --git a/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java b/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java\n--- a/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java\n+++ b/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/SearchInputIT.java\n@@ -313,7 +313,8 @@ public void testParserValid() throws Exception {\n                                 .from(\"{{ctx.trigger.scheduled_time}}||-30s\").to(\"{{ctx.trigger.triggered_time}}\"))));\n \n         TimeValue timeout = randomBoolean() ? TimeValue.timeValueSeconds(randomInt(10)) : null;\n-        XContentBuilder builder = jsonBuilder().value(new SearchInput(new WatcherSearchTemplateRequest(searchRequest), null, timeout, null));\n+        XContentBuilder builder = jsonBuilder().value(\n+                new SearchInput(new WatcherSearchTemplateRequest(searchRequest), null, timeout, null));\n         XContentParser parser = JsonXContent.jsonXContent.createParser(builder.bytes());\n         parser.nextToken();\n ",
    "output": "Fix checkstyle line length limit"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.common.transport.BoundTransportAddress;\n import org.elasticsearch.common.transport.DummyTransportAddress;\n import org.elasticsearch.common.transport.TransportAddress;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.xcontent.XContentType;\n import org.elasticsearch.http.HttpInfo;\n import org.elasticsearch.index.Index;\n@@ -112,7 +113,7 @@ private NodeInfo randomNodeInfo() {\n                 Settings.EMPTY, DummyOsInfo.INSTANCE, new ProcessInfo(randomInt(), randomBoolean()), JvmInfo.jvmInfo(),\n                 new ThreadPoolInfo(Collections.singletonList(new ThreadPool.Info(\"test_threadpool\", ThreadPool.ThreadPoolType.FIXED, 5))),\n                 new TransportInfo(transportAddress, Collections.emptyMap()), new HttpInfo(transportAddress, randomLong()),\n-                new PluginsAndModules(), new IngestInfo(Collections.emptyList()));\n+                new PluginsAndModules(), new IngestInfo(Collections.emptyList()), new ByteSizeValue(randomIntBetween(1, 1024)));\n \n     }\n ",
    "output": "Fix compilation issue Relates elastic/elasticsearchelastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java\n--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java\n+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java\n@@ -439,7 +439,7 @@ public Object readGenericValue() throws IOException {\n             case 5:\n                 return readBoolean();\n             case 6:\n-                return fastReadByteArray();\n+                return readByteArray();\n             case 7:\n                 return readArrayList();\n             case 8:\n@@ -477,13 +477,6 @@ public Object readGenericValue() throws IOException {\n         }\n     }\n \n-    private byte[] fastReadByteArray() throws IOException {\n-        int bytesSize = readVInt();\n-        byte[] value = new byte[bytesSize];\n-        readBytes(value, 0, bytesSize);\n-        return value;\n-    }\n-\n     @SuppressWarnings(\"unchecked\")\n     private List readArrayList() throws IOException {\n         int size = readVInt();\n@@ -609,12 +602,10 @@ public double[] readDoubleArray() throws IOException {\n     }\n \n     public byte[] readByteArray() throws IOException {\n-        int length = readVInt();\n-        byte[] values = new byte[length];\n-        for (int i = 0; i < length; i++) {\n-            values[i] = readByte();\n-        }\n-        return values;\n+        final int length = readVInt();\n+        final byte[] bytes = new byte[length];\n+        readBytes(bytes, 0, bytes.length);\n+        return bytes;\n     }\n \n     /**",
    "output": "Remove duplicated read byte array methods This commit removes duplicated methods for reading byte arrays in StreamInput. One method would read a byte array by repeatedly calling StreamInput#readByte in a loop, and the other would just call StreamInput#readBytes. In this commit, we remove the former. Relates"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java b/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java\n--- a/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java\n+++ b/elasticsearch/x-pack/src/test/java/org/elasticsearch/xpack/test/rest/XPackRestTestCase.java\n@@ -8,7 +8,6 @@\n \n import com.carrotsearch.randomizedtesting.annotations.Name;\n import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n-import org.elasticsearch.client.ResponseException;\n import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n@@ -51,24 +50,6 @@ public static Iterable<Object[]> parameters() throws IOException, RestTestParseE\n         return ESRestTestCase.createParameters(0, 1);\n     }\n \n-    @Before\n-    public void startWatcher() throws Exception {\n-        try {\n-            getAdminExecutionContext().callApi(\"xpack.watcher.start\", emptyMap(), emptyList(), emptyMap());\n-        } catch(ResponseException e) {\n-            //TODO ignore for now, needs to be fixed though\n-        }\n-    }\n-\n-    @After\n-    public void stopWatcher() throws Exception {\n-        try {\n-            getAdminExecutionContext().callApi(\"xpack.watcher.stop\", emptyMap(), emptyList(), emptyMap());\n-        } catch(ResponseException e) {\n-            //TODO ignore for now, needs to be fixed though\n-        }\n-    }\n-\n     @Before\n     public void installLicense() throws Exception {\n         final XContentBuilder builder = XContentFactory.jsonBuilder();",
    "output": "Remove start and stop watcher from XPackRestTestCase We were ignoring the response code which is always 401 because the license is not good to start watcher. Plus all tests run fine without these methods"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/tasks/PersistedTaskInfo.java b/core/src/main/java/org/elasticsearch/tasks/PersistedTaskInfo.java\n--- a/core/src/main/java/org/elasticsearch/tasks/PersistedTaskInfo.java\n+++ b/core/src/main/java/org/elasticsearch/tasks/PersistedTaskInfo.java\n@@ -160,6 +160,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n     }\n \n     public XContentBuilder innerToXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.field(\"completed\", completed);\n         builder.field(\"task\", task);\n         if (error != null) {\n             XContentHelper.writeRawField(\"error\", error, builder, params);\n@@ -171,8 +172,16 @@ public XContentBuilder innerToXContent(XContentBuilder builder, Params params) t\n     }\n \n     public static final ConstructingObjectParser<PersistedTaskInfo, ParseFieldMatcherSupplier> PARSER = new ConstructingObjectParser<>(\n-            \"persisted_task_info\", a -> new PersistedTaskInfo(true, (TaskInfo) a[0], (BytesReference) a[1], (BytesReference) a[2]));\n+            \"persisted_task_info\", a -> {\n+                int i = 0;\n+                boolean completed = (boolean) a[i++];\n+                TaskInfo task = (TaskInfo) a[i++];\n+                BytesReference error = (BytesReference) a[i++];\n+                BytesReference response = (BytesReference) a[i++];\n+                return new PersistedTaskInfo(completed, task, error, response);\n+            });\n     static {\n+        PARSER.declareBoolean(constructorArg(), new ParseField(\"completed\"));\n         PARSER.declareObject(constructorArg(), TaskInfo.PARSER, new ParseField(\"task\"));\n         PARSER.declareRawObject(optionalConstructorArg(), new ParseField(\"error\"));\n         PARSER.declareRawObject(optionalConstructorArg(), new ParseField(\"response\"));",
    "output": "Add missing field to PersistedTaskInfo"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n@@ -31,7 +31,7 @@\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.index.shard.ShardPath;\n import org.elasticsearch.indices.NodeIndicesStats;\n-import org.elasticsearch.ingest.core.IngestInfo;\n+import org.elasticsearch.ingest.IngestInfo;\n import org.elasticsearch.marvel.agent.collector.cluster.ClusterStatsMonitoringDoc;\n import org.elasticsearch.marvel.agent.exporter.MarvelTemplateUtils;\n import org.elasticsearch.marvel.agent.resolver.MonitoringIndexNameResolverTestCase;",
    "output": "Fix compile error caused by change in core"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/CastTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/CastTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/CastTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/CastTests.java\n@@ -162,6 +162,15 @@ public void testMethodCallDef() {\n         assertEquals(5, exec(\"def x = 5; return (int)x.longValue();\"));\n     }\n     \n+    /**\n+     * Currently these do not adopt the argument value, we issue a separate cast!\n+     */\n+    public void testArgumentsDef() {\n+        assertEquals(5, exec(\"def x = 5L; return (+(int)x);\"));\n+        assertEquals(6, exec(\"def x = 5; def y = 1L; return x + (int)y\"));\n+        assertEquals('b', exec(\"def x = 'abcdeg'; def y = 1L; x.charAt((int)y)\"));\n+    }\n+    \n     /**\n      * Unary operators adopt the return value\n      */",
    "output": "Add simple arguments test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/client/FilterClient.java b/core/src/main/java/org/elasticsearch/client/FilterClient.java\n--- a/core/src/main/java/org/elasticsearch/client/FilterClient.java\n+++ b/core/src/main/java/org/elasticsearch/client/FilterClient.java\n@@ -24,6 +24,8 @@\n import org.elasticsearch.action.ActionRequestBuilder;\n import org.elasticsearch.action.ActionResponse;\n import org.elasticsearch.client.support.AbstractClient;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.threadpool.ThreadPool;\n \n \n /**\n@@ -42,7 +44,15 @@ public abstract class FilterClient extends AbstractClient {\n      * @see #in()\n      */\n     public FilterClient(Client in) {\n-        super(in.settings(), in.threadPool());\n+        this(in.settings(), in.threadPool(), in);\n+    }\n+\n+    /**\n+     * A Constructor that allows to pass settings and threadpool separately. This is useful if the\n+     * client is a proxy and not yet fully constructed ie. both dependencies are not available yet.\n+     */\n+    protected FilterClient(Settings settings, ThreadPool threadPool, Client in) {\n+        super(settings, threadPool);\n         this.in = in;\n     }\n ",
    "output": "Add extra ctor to FilterClient to support Guice proxies just don't ask it's bad but some plugins are so involved they need this. Closes #the_issue_that_never_existed"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java\n@@ -161,6 +161,11 @@ public void testNestedCapture() {\n                              \"return Optional.empty().orElseGet(() -> x ? 5 : Optional.empty().orElseGet(() -> y));\"));\n     }\n     \n+    public void testNestedCaptureParams() {\n+        assertEquals(2, exec(\"int foo(Function f) { return f.apply(1) }\" +\n+                             \"return foo(x -> foo(y -> x + 1))\"));\n+    }\n+    \n     public void testWrongArity() {\n         IllegalArgumentException expected = expectScriptThrows(IllegalArgumentException.class, () -> {\n             exec(\"Optional.empty().orElseGet(x -> x);\");\n@@ -174,4 +179,12 @@ public void testWrongArityDef() {\n         });\n         assertTrue(expected.getMessage(), expected.getMessage().contains(\"Incorrect number of parameters\"));\n     }\n+    \n+    public void testLambdaInFunction() {\n+        assertEquals(5, exec(\"def foo() { Optional.empty().orElseGet(() -> 5) } return foo();\"));\n+    }\n+    \n+    public void testLambdaCaptureFunctionParam() {\n+        assertEquals(5, exec(\"def foo(int x) { Optional.empty().orElseGet(() -> x) } return foo(5);\"));\n+    }\n }",
    "output": "Add a few more tests"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefMath.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefMath.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefMath.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefMath.java\n@@ -25,7 +25,6 @@\n import java.lang.invoke.MethodHandles.Lookup;\n import java.util.Collections;\n import java.util.HashMap;\n-import java.util.IdentityHashMap;\n import java.util.Map;\n import java.util.function.Function;\n import java.util.stream.Collectors;",
    "output": "Remove unused import"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n@@ -64,10 +64,6 @@ public SearchScript search(CompiledScript compiledScript, SearchLookup lookup, @\n         return null;\n     }\n \n-    @Override\n-    public void scriptRemoved(@Nullable CompiledScript script) {\n-    }\n-\n     @Override\n     public void close() throws IOException {\n     }",
    "output": "Remove scriptRemoved() method Related to elastic/elasticsearch@18572"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/analysis/AnalysisModule.java b/core/src/main/java/org/elasticsearch/indices/analysis/AnalysisModule.java\n--- a/core/src/main/java/org/elasticsearch/indices/analysis/AnalysisModule.java\n+++ b/core/src/main/java/org/elasticsearch/indices/analysis/AnalysisModule.java\n@@ -54,16 +54,6 @@\n  * The {@link org.elasticsearch.indices.analysis.AnalysisModule.AnalysisProvider} is only a functional interface that allows to register factory constructors directly like the plugin example below:\n  * <pre>\n  *     public class MyAnalysisPlugin extends Plugin {\n- *       \\@Override\n- *       public String name() {\n- *         return \"analysis-my-plugin\";\n- *       }\n- *\n- *       \\@Override\n- *       public String description() {\n- *         return \"my very fast and efficient analyzer\";\n- *       }\n- *\n  *       public void onModule(AnalysisModule module) {\n  *         module.registerAnalyzer(\"my-analyzer-name\", MyAnalyzer::new);\n  *       }",
    "output": "Remove outtdated comment referring to name/description for Plugin class"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/LambdaTests.java\n@@ -81,4 +81,22 @@ public void testPrimitiveArgsTypedOddly() {\n     public void testMultipleStatements() {\n         assertEquals(2, exec(\"int applyOne(IntFunction arg) { arg.apply(1) } applyOne(x -> { x = x + 1; return x;})\"));\n     }\n+\n+    public void testTwoLambdas() {\n+        assertEquals(\"testingcdefg\", exec(\n+                \"org.elasticsearch.painless.FeatureTest test = new org.elasticsearch.painless.FeatureTest(2,3);\" +\n+                \"return test.twoFunctionsOfX(x -> 'testing'.concat(x), y -> 'abcdefg'.substring(y))\"));\n+    }\n+\n+    public void testNestedLambdas() {\n+        assertEquals(1, exec(\"Optional.empty().orElseGet(() -> Optional.empty().orElseGet(() -> 1));\"));\n+    }\n+\n+    public void testLambdaInLoop() {\n+        assertEquals(100, exec(\"int sum = 0; \" +\n+                               \"for (int i = 0; i < 100; i++) {\" +\n+                               \"  sum += Optional.empty().orElseGet(() -> 1);\" +\n+                               \"}\" +\n+                               \"return sum;\"));\n+    }\n }",
    "output": "Add more simple tests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java\n@@ -275,7 +275,7 @@ public NodesResponseRestListener(RestChannel channel) {\n \n         @Override\n         public RestResponse buildResponse(NodesResponse response, XContentBuilder builder) throws Exception {\n-            return RestActions.nodesResponse(builder, ToXContent.EMPTY_PARAMS, response);\n+            return RestActions.nodesResponse(builder, channel.request(), response);\n         }\n \n     }",
    "output": "Fix flat_settings REST parameter * Get XContent params from request in Nodes rest actions * Adding test for nodes info rest api"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java\n@@ -38,11 +38,4 @@ public interface QueryParser<QB extends QueryBuilder> {\n      * @return the new QueryBuilder\n      */\n     Optional<QB> fromXContent(QueryParseContext parseContext) throws IOException;\n-\n-    /**\n-     * @return an empty {@link QueryBuilder} instance for this parser that can be used for deserialization\n-     */\n-    default QB getBuilderPrototype() { // TODO remove this when nothing implements it\n-        throw new UnsupportedOperationException();\n-    }\n }",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/IngestAttachmentPlugin.java b/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/IngestAttachmentPlugin.java\n--- a/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/IngestAttachmentPlugin.java\n+++ b/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/IngestAttachmentPlugin.java\n@@ -38,6 +38,6 @@ public String description() {\n \n     public void onModule(NodeModule nodeModule) throws IOException {\n         nodeModule.registerProcessor(AttachmentProcessor.TYPE,\n-            (templateService, registry) -> new AttachmentProcessor.Factory());\n+            (registry) -> new AttachmentProcessor.Factory());\n     }\n }",
    "output": "Fix compile for ingest plugin lambda"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ResourceNotFoundException.java b/core/src/main/java/org/elasticsearch/ResourceNotFoundException.java\n--- a/core/src/main/java/org/elasticsearch/ResourceNotFoundException.java\n+++ b/core/src/main/java/org/elasticsearch/ResourceNotFoundException.java\n@@ -32,7 +32,7 @@ public ResourceNotFoundException(String msg, Object... args) {\n         super(msg, args);\n     }\n \n-    protected ResourceNotFoundException(String msg, Throwable cause, Object... args) {\n+    public ResourceNotFoundException(String msg, Throwable cause, Object... args) {\n         super(msg, cause, args);\n     }\n ",
    "output": "Fix exception on task not found Silly protected method"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java\n@@ -99,6 +99,9 @@ static final class PIC extends MutableCallSite {\n \n         PIC(Lookup lookup, String name, MethodType type, int flavor, Object[] args) {\n             super(type);\n+            if (type.parameterType(0) != Object.class) {\n+                throw new BootstrapMethodError(\"The receiver type (1st arg) of invokedynamic descriptor must be Object.\");\n+            }\n             this.lookup = lookup;\n             this.name = name;\n             this.flavor = flavor;\n@@ -178,8 +181,6 @@ protected MethodHandle computeValue(Class<?> receiverType) {\n             final MethodHandle target = lookup(flavor, name, receiver, callArgs).asType(type);\n \n             MethodHandle test = CHECK_CLASS.bindTo(receiver);\n-            test = test.asType(test.type().changeParameterType(0, type.parameterType(0)));\n-\n             MethodHandle guard = MethodHandles.guardWithTest(test, target, getTarget());\n             \n             depth++;",
    "output": "Remove unneeded type adaption and add error message on violation"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/DefBootstrap.java\n@@ -169,7 +169,7 @@ protected MethodHandle computeValue(Class<?> receiverType) {\n                 };\n                 MethodHandle cacheLookup = MEGAMORPHIC_LOOKUP.bindTo(megamorphicCache);\n                 cacheLookup = MethodHandles.dropArguments(cacheLookup,\n-                        0, type.parameterList().subList(1, type.parameterCount()));\n+                        1, type.parameterList().subList(1, type.parameterCount()));\n                 MethodHandle target = MethodHandles.foldArguments(MethodHandles.exactInvoker(type), cacheLookup);\n                 setTarget(target);\n                 return target.invokeWithArguments(callArgs);                    ",
    "output": "Fix bug with first param (receiver) on the cache lookup"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n@@ -134,9 +134,6 @@ class InstallPluginCommand extends SettingCommand {\n         }\n     }\n \n-    // protocols allowed for direct url installation\n-    private static final List<String> URL_PROTOCOLS = Arrays.asList(\"http\", \"https\", \"file\");\n-\n     private final OptionSpec<Void> batchOption;\n     private final OptionSpec<String> arguments;\n \n\ndiff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n@@ -307,6 +307,12 @@ public void testMalformedUrlNotMaven() throws Exception {\n         assertTrue(e.getMessage(), e.getMessage().contains(\"no protocol\"));\n     }\n \n+    public void testUnknownPlugin() throws Exception {\n+        Tuple<Path, Environment> env = createEnv(fs, temp);\n+        UserError e = expectThrows(UserError.class, () -> installPlugin(\"foo\", env.v1()));\n+        assertTrue(e.getMessage(), e.getMessage().contains(\"Unknown plugin foo\"));\n+    }\n+\n     public void testPluginsDirMissing() throws Exception {\n         Tuple<Path, Environment> env = createEnv(fs, temp);\n         Files.delete(env.v2().pluginsFile());",
    "output": "Add test for plugin install heuristic"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java\n@@ -229,4 +229,9 @@ public void testBadRegexPattern() {\n         assertThat(e.getMessage(), containsString(\"\\\\ujjjj\"));\n     }\n \n+    public void testBadBoxingCast() {\n+        expectScriptThrows(ClassCastException.class, () -> {\n+            exec(\"BitSet bs = new BitSet(); bs.and(2);\");\n+        });\n+    }\n }",
    "output": "Add a test"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n@@ -37,6 +37,6 @@ public void testCompatibility() {\n          *\n          */\n         assertThat(\"Remove workaround in LicenseService class when es core supports merging cluster level custom metadata\",\n-                   Version.CURRENT.equals(Version.V_5_0_0), is(true));\n+                   Version.CURRENT.equals(Version.V_5_0_0_alpha4), is(true));\n     }\n }",
    "output": "Fix test compile error"
  },
  {
    "input": "diff --git a/client/src/main/java/org/elasticsearch/client/RestClient.java b/client/src/main/java/org/elasticsearch/client/RestClient.java\n--- a/client/src/main/java/org/elasticsearch/client/RestClient.java\n+++ b/client/src/main/java/org/elasticsearch/client/RestClient.java\n@@ -244,7 +244,6 @@ public int compare(Map.Entry<HttpHost, DeadHostState> o1, Map.Entry<HttpHost, De\n         }\n \n         List<HttpHost> rotatedHosts = new ArrayList<>(filteredHosts);\n-        //TODO is it possible to make this O(1)? (rotate is O(n))\n         Collections.rotate(rotatedHosts, rotatedHosts.size() - lastHostIndex.getAndIncrement());\n         return rotatedHosts;\n     }",
    "output": "Remove TODO around copying hosts when rotating the collection, it's not a problem for now"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/ELambda.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/ELambda.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/ELambda.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/ELambda.java\n@@ -33,8 +33,6 @@ public class ELambda extends AExpression {\n     final List<String> paramNameStrs;\n     final List<AStatement> statements;\n \n-    Locals locals = null;\n-\n     public ELambda(FunctionReserved reserved, Location location,\n                    List<String> paramTypes, List<String> paramNames, List<AStatement> statements) {\n         super(location);",
    "output": "Remove unused field"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/SSource.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/SSource.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/SSource.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/SSource.java\n@@ -177,7 +177,9 @@ public void write() {\n                                            function.method.method.getDescriptor(), \n                                            false);\n                 clinit.push(handle);\n-                clinit.putStatic(CLASS_TYPE, \"handle$\" + function.name + \"$\" + function.parameters.size(), Type.getType(MethodHandle.class));\n+                clinit.putStatic(CLASS_TYPE, \n+                                 \"handle$\" + function.name + \"$\" + function.parameters.size(), \n+                                 Type.getType(MethodHandle.class));\n             }\n             clinit.returnValue();\n             clinit.endMethod();",
    "output": "Fix too long line"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/FunctionRefTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/FunctionRefTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/FunctionRefTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/FunctionRefTests.java\n@@ -112,13 +112,13 @@ public void testCapturingMethodReferenceMultipleLambdasDefEverywhere() {\n     public void testOwnStaticMethodReference() {\n         //System.out.println(Debugger.toString(\"int mycompare(int i, int j) { return j - i; } \" +\n         //                     \"List l = new ArrayList(); l.add(2); l.add(1); l.sort(this::mycompare); return l.get(0);\"));\n-        assertEquals(2, exec(\"int mycompare(int i, int j) { return j - i; } \" +\n+        assertEquals(2, exec(\"int mycompare(int i, int j) { j - i } \" +\n                              \"List l = new ArrayList(); l.add(2); l.add(1); l.sort(this::mycompare); return l.get(0);\"));\n     }\n     \n     @AwaitsFix(bugUrl = \"working on it\")\n     public void testOwnStaticMethodReferenceDef() {\n-        assertEquals(2, exec(\"int mycompare(int i, int j) { return j - i; } \" +\n+        assertEquals(2, exec(\"int mycompare(int i, int j) { j - i } \" +\n                              \"def l = new ArrayList(); l.add(2); l.add(1); l.sort(this::mycompare); return l.get(0);\"));\n     }\n ",
    "output": "Remove unnecessary semicolon and return"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n@@ -468,6 +468,16 @@ public Query rewrite(IndexReader reader) throws IOException {\n         public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n             return new CreateScorerOnceWeight(query.createWeight(searcher, needsScores));\n         }\n+\n+        @Override\n+        public boolean equals(Object obj) {\n+            return sameClassAs(obj) && query.equals(((CreateScorerOnceQuery) obj).query);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return 31 * classHash() + query.hashCode();\n+        }\n     }\n \n     public void doTestIndexSearcherWrapper(boolean sparse, boolean deletions) throws IOException {",
    "output": "Upgrade code for Lucene 6.1"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/rollover/TransportRolloverAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/rollover/TransportRolloverAction.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/rollover/TransportRolloverAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/rollover/TransportRolloverAction.java\n@@ -217,7 +217,6 @@ static CreateIndexClusterStateUpdateRequest prepareCreateIndexRequest(final Stri\n             .masterNodeTimeout(createIndexRequest.masterNodeTimeout())\n             .settings(createIndexRequest.settings())\n             .aliases(createIndexRequest.aliases())\n-            .customs(createIndexRequest.customs())\n             .mappings(createIndexRequest.mappings());\n     }\n ",
    "output": "Remove support for customs from create index request"
  },
  {
    "input": "diff --git a/client/src/main/java/org/elasticsearch/client/DeadHostState.java b/client/src/main/java/org/elasticsearch/client/DeadHostState.java\n--- a/client/src/main/java/org/elasticsearch/client/DeadHostState.java\n+++ b/client/src/main/java/org/elasticsearch/client/DeadHostState.java\n@@ -26,7 +26,7 @@\n  * when the host should be retried (based on number of previous failed attempts).\n  * Class is immutable, a new copy of it should be created each time the state has to be changed.\n  */\n-class DeadHostState {\n+final class DeadHostState {\n \n     private static final long MIN_CONNECTION_TIMEOUT_NANOS = TimeUnit.MINUTES.toNanos(1);\n     private static final long MAX_CONNECTION_TIMEOUT_NANOS = TimeUnit.MINUTES.toNanos(30);",
    "output": "Make DeadHostState final"
  },
  {
    "input": "diff --git a/client-sniffer/src/test/java/org/elasticsearch/client/sniff/SnifferBuilderTests.java b/client-sniffer/src/test/java/org/elasticsearch/client/sniff/SnifferBuilderTests.java\n--- a/client-sniffer/src/test/java/org/elasticsearch/client/sniff/SnifferBuilderTests.java\n+++ b/client-sniffer/src/test/java/org/elasticsearch/client/sniff/SnifferBuilderTests.java\n@@ -62,7 +62,8 @@ public void testBuild() throws Exception {\n             }\n \n             try {\n-                Sniffer.builder(client, hostsSniffer).setSniffAfterFailureDelayMillis(RandomInts.randomIntBetween(random(), Integer.MIN_VALUE, 0));\n+                Sniffer.builder(client, hostsSniffer)\n+                        .setSniffAfterFailureDelayMillis(RandomInts.randomIntBetween(random(), Integer.MIN_VALUE, 0));\n                 fail(\"should have failed\");\n             } catch(IllegalArgumentException e) {\n                 assertEquals(\"sniffAfterFailureDelayMillis must be greater than 0\", e.getMessage());",
    "output": "Fix line length"
  },
  {
    "input": "diff --git a/client/src/test/java/org/elasticsearch/client/RestClientBuilderTests.java b/client/src/test/java/org/elasticsearch/client/RestClientBuilderTests.java\n--- a/client/src/test/java/org/elasticsearch/client/RestClientBuilderTests.java\n+++ b/client/src/test/java/org/elasticsearch/client/RestClientBuilderTests.java\n@@ -53,7 +53,8 @@ public void testBuild() throws IOException {\n         }\n \n         try {\n-            RestClient.builder(new HttpHost(\"localhost\", 9200)).setMaxRetryTimeoutMillis(RandomInts.randomIntBetween(random(), Integer.MIN_VALUE, 0));\n+            RestClient.builder(new HttpHost(\"localhost\", 9200))\n+                    .setMaxRetryTimeoutMillis(RandomInts.randomIntBetween(random(), Integer.MIN_VALUE, 0));\n             fail(\"should have failed\");\n         } catch(IllegalArgumentException e) {\n             assertEquals(\"maxRetryTimeout must be greater than 0\", e.getMessage());",
    "output": "Fix line length"
  },
  {
    "input": "diff --git a/client/src/main/java/org/elasticsearch/client/RestClient.java b/client/src/main/java/org/elasticsearch/client/RestClient.java\n--- a/client/src/main/java/org/elasticsearch/client/RestClient.java\n+++ b/client/src/main/java/org/elasticsearch/client/RestClient.java\n@@ -138,19 +138,21 @@ public Response performRequest(String method, String endpoint, Map<String, Strin\n         HttpRequestBase request = createHttpRequest(method, uri, entity);\n         setHeaders(request, headers);\n         //we apply a soft margin so that e.g. if a request took 59 seconds and timeout is set to 60 we don't do another attempt\n-        long retryTimeout = Math.round(this.maxRetryTimeoutMillis / (float)100 * 98);\n+        long retryTimeoutMillis = Math.round(this.maxRetryTimeoutMillis / (float)100 * 98);\n         IOException lastSeenException = null;\n         long startTime = System.nanoTime();\n         for (HttpHost host : nextHost()) {\n             if (lastSeenException != null) {\n-                long timeElapsed = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime);\n-                long timeout = retryTimeout - timeElapsed;\n+                //in case we are retrying, check whether maxRetryTimeout has been reached, in which case an exception will be thrown\n+                long timeElapsedMillis = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime);\n+                long timeout = retryTimeoutMillis - timeElapsedMillis;\n                 if (timeout <= 0) {\n                     IOException retryTimeoutException = new IOException(\n-                            \"request retries exceeded max retry timeout [\" + retryTimeout + \"]\");\n+                            \"request retries exceeded max retry timeout [\" + retryTimeoutMillis + \"]\");\n                     retryTimeoutException.addSuppressed(lastSeenException);\n                     throw retryTimeoutException;\n                 }\n+                //also reset the request to make it reusable for the next attempt\n                 request.reset();\n             }\n ",
    "output": "Add comments on retries"
  },
  {
    "input": "diff --git a/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RethrottleTests.java b/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RethrottleTests.java\n--- a/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RethrottleTests.java\n+++ b/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RethrottleTests.java\n@@ -21,7 +21,6 @@\n \n import org.elasticsearch.action.ListenableActionFuture;\n import org.elasticsearch.action.admin.cluster.node.tasks.list.ListTasksResponse;\n-import org.elasticsearch.test.junit.annotations.TestLogging;\n \n import static org.hamcrest.Matchers.hasSize;\n \n@@ -30,9 +29,6 @@\n  * too but this is the only place that tests running against multiple nodes so it is the only integration tests that checks for\n  * serialization.\n  */\n-// Extra logging in case of failure. We couldn't explain the last failure:\n-// https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+g1gc/359/consoleFull\n-@TestLogging(\"_root:DEBUG\")\n public class RethrottleTests extends ReindexTestCase {\n \n     public void testReindex() throws Exception {",
    "output": "Remove extra logging The test shouldn't be failing any more"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java\n@@ -57,7 +57,7 @@ public class RestoreSnapshotRequest extends MasterNodeRequest<RestoreSnapshotReq\n     private String renamePattern;\n     private String renameReplacement;\n     private boolean waitForCompletion;\n-    private boolean includeGlobalState = true;\n+    private boolean includeGlobalState = false;\n     private boolean partial = false;\n     private boolean includeAliases = true;\n     private Settings settings = EMPTY_SETTINGS;",
    "output": "Change the default of `include_global_state` from true to false for restores This changes the default value to be false *only* for restore operations"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java\n--- a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java\n@@ -199,6 +199,19 @@ public void testVerifyingIndexOutput() throws IOException {\n         IOUtils.close(indexInput, verifyingOutput, dir);\n     }\n \n+    public void testVerifyingIndexOutputOnEmptyFile() throws IOException {\n+        Directory dir = newDirectory();\n+        IndexOutput verifyingOutput = new Store.LuceneVerifyingIndexOutput(new StoreFileMetaData(\"foo.bar\", 0, Store.digestToString(0)),\n+            dir.createOutput(\"foo1.bar\", IOContext.DEFAULT));\n+        try {\n+            Store.verify(verifyingOutput);\n+            fail(\"should be a corrupted index\");\n+        } catch (CorruptIndexException | IndexFormatTooOldException | IndexFormatTooNewException ex) {\n+            // ok\n+        }\n+        IOUtils.close(verifyingOutput, dir);\n+    }\n+\n     public void testChecksumCorrupted() throws IOException {\n         Directory dir = newDirectory();\n         IndexOutput output = dir.createOutput(\"foo.bar\", IOContext.DEFAULT);",
    "output": "Add a dedicated test for empty files"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java b/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java\n--- a/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java\n+++ b/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java\n@@ -61,16 +61,19 @@ public void testCheckpointsAdvance() throws Exception {\n                     XContentHelper.toString(shardStats.getSeqNoStats(),\n                         new ToXContent.MapParams(Collections.singletonMap(\"pretty\", \"false\"))));\n                 final Matcher<Long> localCheckpointRule;\n+                final Matcher<Long> globalCheckpointRule;\n                 if (shardStats.getShardRouting().primary()) {\n                     localCheckpointRule = equalTo(numDocs - 1L);\n+                    globalCheckpointRule = equalTo(numDocs - 1L);\n                 } else {\n-                    // nocommit:  recovery doesn't transfer local checkpoints yet (we don't persist them in lucene).\n+                    // nocommit: recovery doesn't transfer checkpoints yet (we don't persist them in lucene).\n                     localCheckpointRule = anyOf(equalTo(numDocs - 1L), equalTo(SequenceNumbersService.NO_OPS_PERFORMED));\n+                    globalCheckpointRule = anyOf(equalTo(numDocs - 1L), equalTo(SequenceNumbersService.UNASSIGNED_SEQ_NO));\n                 }\n                 assertThat(shardStats.getShardRouting() + \" local checkpoint mismatch\",\n                     shardStats.getSeqNoStats().getLocalCheckpoint(), localCheckpointRule);\n                 assertThat(shardStats.getShardRouting() + \" global checkpoint mismatch\",\n-                    shardStats.getSeqNoStats().getGlobalCheckpoint(), equalTo(numDocs - 1L));\n+                    shardStats.getSeqNoStats().getGlobalCheckpoint(), globalCheckpointRule);\n                 assertThat(shardStats.getShardRouting() + \" max seq no mismatch\",\n                     shardStats.getSeqNoStats().getMaxSeqNo(), equalTo(numDocs - 1L));\n             }",
    "output": "Fix global checkpoints test bug This commit fixes a test bug in a global checkpoints integration test. Namely, if the replica shard is slow to start and is peer recovered from the primary, it will not have the expected global checkpoint due to these not being persisted and transferred on recovery. Relates"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/slice/SliceBuilderTests.java b/core/src/test/java/org/elasticsearch/search/slice/SliceBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/search/slice/SliceBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/slice/SliceBuilderTests.java\n@@ -90,7 +90,6 @@ public static void afterClass() throws Exception {\n \n     private final SliceBuilder randomSliceBuilder() throws IOException {\n         int max = randomIntBetween(2, MAX_SLICE);\n-        if (max == 0) max++;\n         int id = randomInt(max - 1);\n         String field = randomAsciiOfLengthBetween(5, 20);\n         return new SliceBuilder(field, id, max);\n@@ -279,8 +278,8 @@ public Query termQuery(Object value, @Nullable QueryShardContext context) {\n             assertThat(total, equalTo(numSlices));\n \n             // numShards > numSlices\n-            numShards = randomIntBetween(3, 100);\n-            numSlices = randomInt(numShards-1);\n+            numShards = randomIntBetween(4, 100);\n+            numSlices = randomIntBetween(2, numShards-1);\n             List<Integer> targetShards = new ArrayList<>();\n             for (int i = 0; i < numSlices; i++) {\n                 for (int j = 0; j < numShards; j++) {",
    "output": "Fix ut: make sure that the number of slices is bigger than 1 in the SliceBuilder tests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/restore/RestoreSnapshotRequest.java\n@@ -57,7 +57,7 @@ public class RestoreSnapshotRequest extends MasterNodeRequest<RestoreSnapshotReq\n     private String renamePattern;\n     private String renameReplacement;\n     private boolean waitForCompletion;\n-    private boolean includeGlobalState = true;\n+    private boolean includeGlobalState = false;\n     private boolean partial = false;\n     private boolean includeAliases = true;\n     private Settings settings = EMPTY_SETTINGS;",
    "output": "Change the default of `include_global_state` from true to false"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java\n@@ -489,20 +489,22 @@ private void runMightForkTest(\n         final Runnable enableMightFork,\n         final Consumer<RuntimeException> consumer) {\n \n+        final String methodName = Thread.currentThread().getStackTrace()[2].getMethodName();\n+\n         // if seccomp is disabled, nothing should happen\n         isSeccompInstalled.set(false);\n         if (randomBoolean()) {\n             disableMightFork.run();\n         } else {\n             enableMightFork.run();\n         }\n-        BootstrapCheck.check(true, randomBoolean(), Collections.singletonList(check), \"testMightFork\");\n+        BootstrapCheck.check(true, randomBoolean(), Collections.singletonList(check), methodName);\n \n         // if seccomp is enabled, but we will not fork, nothing should\n         // happen\n         isSeccompInstalled.set(true);\n         disableMightFork.run();\n-        BootstrapCheck.check(true, randomBoolean(), Collections.singletonList(check), \"testMightFork\");\n+        BootstrapCheck.check(true, randomBoolean(), Collections.singletonList(check), methodName);\n \n         // if seccomp is enabled, and we might fork, the check should\n         // be enforced, regardless of bootstrap checks being enabled or\n@@ -512,7 +514,7 @@ private void runMightForkTest(\n \n         final RuntimeException e = expectThrows(\n             RuntimeException.class,\n-            () -> BootstrapCheck.check(randomBoolean(), randomBoolean(), Collections.singletonList(check), \"testMightFork\"));\n+            () -> BootstrapCheck.check(randomBoolean(), randomBoolean(), Collections.singletonList(check), methodName));\n         consumer.accept(e);\n     }\n ",
    "output": "Use method name in bootstrap check might fork test This commit modifies the bootstrap check invocations in the might fork tests to use the underlying test name when setting up the logging prefix when invoking the bootstrap checks. This is done to give clear logs in case of failure"
  },
  {
    "input": "diff --git a/modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorFieldMapperTests.java b/modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorFieldMapperTests.java\n--- a/modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorFieldMapperTests.java\n+++ b/modules/percolator/src/test/java/org/elasticsearch/percolator/PercolatorFieldMapperTests.java\n@@ -209,7 +209,7 @@ public void testMultiplePercolatorFields() throws Exception {\n                         .field(\"query_field2\", queryBuilder)\n                         .endObject().bytes()\n         );\n-        assertThat(doc.rootDoc().getFields().size(), equalTo(22)); // also includes all other meta fields\n+        assertThat(doc.rootDoc().getFields().size(), equalTo(24)); // also includes all other meta fields\n         BytesRef queryBuilderAsBytes = doc.rootDoc().getField(\"query_field1.query_builder_field\").binaryValue();\n         assertQueryBuilder(queryBuilderAsBytes, queryBuilder);\n ",
    "output": "Fix testMultiplePercolatorFields to account for seq_no fields"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/RefreshListenersTests.java b/core/src/test/java/org/elasticsearch/index/shard/RefreshListenersTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/RefreshListenersTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/RefreshListenersTests.java\n@@ -54,6 +54,7 @@\n import org.elasticsearch.test.DummyShardLock;\n import org.elasticsearch.test.ESTestCase;\n import org.elasticsearch.test.IndexSettingsModule;\n+import org.elasticsearch.threadpool.TestThreadPool;\n import org.elasticsearch.threadpool.ThreadPool;\n import org.junit.After;\n import org.junit.Before;\n@@ -93,7 +94,7 @@ public void setupListeners() throws Exception {\n                 );\n \n         // Now setup the InternalEngine which is much more complicated because we aren't mocking anything\n-        threadPool = new ThreadPool(getTestName());\n+        threadPool = new TestThreadPool(getTestName());\n         IndexSettings indexSettings = IndexSettingsModule.newIndexSettings(\"index\", Settings.EMPTY);\n         ShardId shardId = new ShardId(new Index(\"index\", \"_na_\"), 1);\n         Directory directory = newDirectory();",
    "output": "Fix compilation issue in RefreshListenersTests This commit fixes a compilation issue in RefreshListenersTests that arose from code being integrated into master, and then a large pull request refactoring the handling of thread pools was later merged into master"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n@@ -487,7 +487,6 @@ static MethodHandle lookupIterator(Class<?> receiverClass) {\n         } else if (receiverClass.isArray()) {\n             return ArrayIteratorHelper.newIterator(receiverClass);\n         } else {\n-            // TODO: arrays\n             throw new IllegalArgumentException(\"Cannot iterate over [\" + receiverClass.getCanonicalName() + \"]\");\n         }\n     }",
    "output": "Remove outdated TODO"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/RestRolloverIndexAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/RestRolloverIndexAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/RestRolloverIndexAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/RestRolloverIndexAction.java\n@@ -37,7 +37,6 @@ public class RestRolloverIndexAction extends BaseRestHandler {\n     @Inject\n     public RestRolloverIndexAction(Settings settings, RestController controller, Client client) {\n         super(settings, client);\n-        controller.registerHandler(RestRequest.Method.PUT, \"/{alias}/_rollover\", this);\n         controller.registerHandler(RestRequest.Method.POST, \"/{alias}/_rollover\", this);\n         controller.registerHandler(RestRequest.Method.GET, \"/{alias}/_rollover\", this);\n     }",
    "output": "Remove put method"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n@@ -238,14 +238,9 @@ private static MethodHandle lookupReference(Class<?> clazz, String signature) {\n          } catch (LambdaConversionException e) {\n              throw new RuntimeException(e);\n          }\n-         try {\n-             // create an implementation of the interface (instance)\n-             Object instance = callSite.dynamicInvoker().asType(MethodType.methodType(clazz)).invoke();\n-             // bind this instance as a constant replacement for the parameter\n-             return MethodHandles.dropArguments(MethodHandles.constant(clazz, instance), 0, Object.class);\n-         } catch (Throwable e) {\n-             throw new RuntimeException(e);\n-         }\n+         // we could actually invoke and cache here (in non-capturing cases), but this is not a speedup.\n+         MethodHandle factory = callSite.dynamicInvoker().asType(MethodType.methodType(clazz));\n+         return MethodHandles.dropArguments(factory, 0, Object.class);\n      }\n      \n ",
    "output": "Remove unnecessary caching"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n@@ -256,7 +256,7 @@ private void validate(PutRequest request) {\n             validationErrors.add(\"template must not start with '_'\");\n         }\n         if (!Strings.validFileNameExcludingAstrix(request.template)) {\n-            validationErrors.add(\"template must not container the following characters \" + Strings.INVALID_FILENAME_CHARS);\n+            validationErrors.add(\"template must not contain the following characters \" + Strings.INVALID_FILENAME_CHARS);\n         }\n \n         List<String> indexSettingsValidation = metaDataCreateIndexService.getIndexSettingsValidationErrors(request.settings);",
    "output": "Fix typo in template validation message This commit addresses a typo in a template validation message in MetaDataIndexTemplateService.java. Relates"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java\n@@ -207,7 +207,7 @@ public void testPendingTasks() throws Exception {\n             // shard lock released... we can now delete\n             indicesService.processPendingDeletes(test.index(), test.getIndexSettings(), new TimeValue(0, TimeUnit.MILLISECONDS));\n             assertEquals(indicesService.numPendingDeletes(test.index()), 0);\n-            assertFalse(indicesService.hasUncompletedPendingDeletes());\n+            assertTrue(indicesService.hasUncompletedPendingDeletes()); // \"bogus\" index has not been removed\n         }\n         assertAcked(client().admin().indices().prepareOpen(\"test\"));\n ",
    "output": "Fix assertion that index was fully deleted"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/ESRestTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/rest/ESRestTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/ESRestTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/ESRestTestCase.java\n@@ -340,11 +340,6 @@ protected Settings restAdminSettings() {\n         return restClientSettings(); // default to the same client settings\n     }\n \n-    /** Returns the addresses the client uses to connect to the test cluster. */\n-    protected URL[] getClusterUrls() {\n-        return clusterUrls;\n-    }\n-\n     @Before\n     public void reset() throws IOException {\n         // admin context must be available for @After always, regardless of whether the test was blacklisted",
    "output": "Remove unused method"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/rest/action/RestAuthenticateActionTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/rest/action/RestAuthenticateActionTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/rest/action/RestAuthenticateActionTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/rest/action/RestAuthenticateActionTests.java\n@@ -51,8 +51,9 @@ protected Settings nodeSettings(int nodeOrdinal) {\n     }\n \n     public void testAuthenticateApi() throws Exception {\n-        try (ElasticsearchResponse response = getRestClient().performRequest(\"GET\", \"/_xpack/security/_authenticate\", Collections.emptyMap(),\n-                null, new BasicHeader(\"Authorization\", basicAuthHeaderValue(ShieldSettingsSource.DEFAULT_USER_NAME,\n+        try (ElasticsearchResponse response = getRestClient().performRequest(\n+                \"GET\", \"/_xpack/security/_authenticate\", Collections.emptyMap(), null,\n+                new BasicHeader(\"Authorization\", basicAuthHeaderValue(ShieldSettingsSource.DEFAULT_USER_NAME,\n                         new SecuredString(ShieldSettingsSource.DEFAULT_PASSWORD.toCharArray()))))) {\n             assertThat(response.getStatusLine().getStatusCode(), is(200));\n             JsonPath jsonPath = new JsonPath(EntityUtils.toString(response.getEntity()));",
    "output": "Fix line length issue"
  },
  {
    "input": "diff --git a/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/AzureTestUtils.java b/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/AzureTestUtils.java\n--- a/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/AzureTestUtils.java\n+++ b/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/AzureTestUtils.java\n@@ -24,6 +24,8 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.settings.SettingsException;\n \n+import java.io.IOException;\n+\n public class AzureTestUtils {\n     /**\n      * Read settings from file when running integration tests with ThirdParty annotation.\n@@ -36,7 +38,11 @@ public static Settings readSettingsFromFile() {\n         // if explicit, just load it and don't load from env\n         try {\n             if (Strings.hasText(System.getProperty(\"tests.config\"))) {\n-                settings.loadFromPath(PathUtils.get((System.getProperty(\"tests.config\"))));\n+                try {\n+                    settings.loadFromPath(PathUtils.get((System.getProperty(\"tests.config\"))));\n+                } catch (IOException e) {\n+                    throw new IllegalArgumentException(\"could not load azure tests config\", e);\n+                }\n             } else {\n                 throw new IllegalStateException(\"to run integration tests, you need to set -Dtests.thirdparty=true and \" +\n                     \"-Dtests.config=/path/to/elasticsearch.yml\");",
    "output": "Fix uncaught checked exception in AzureTestUtils This commit fixes an uncaught checked IOException now thrown in AzureTestUtils after 3adaf096758a6015ca4f733e2e49ee5528ac3cd5"
  },
  {
    "input": "diff --git a/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceMockUtils.java b/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceMockUtils.java\n--- a/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceMockUtils.java\n+++ b/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceMockUtils.java\n@@ -78,7 +78,7 @@ private static String readJsonResponse(String url, String urlRoot) throws IOExce\n         // We extract from the url the mock file path we want to use\n         String mockFileName = Strings.replace(url, urlRoot, \"\");\n \n-        URL resource = GceInstancesServiceMock.class.getResource(mockFileName);\n+        URL resource = GceMockUtils.class.getResource(mockFileName);\n         if (resource == null) {\n             throw new IOException(\"can't read [\" + url + \"] in src/test/resources/org/elasticsearch/discovery/gce\");\n         }",
    "output": "Fix getResource to call it from the current class"
  },
  {
    "input": "diff --git a/client/src/test/java/org/elasticsearch/client/RestClientTests.java b/client/src/test/java/org/elasticsearch/client/RestClientTests.java\n--- a/client/src/test/java/org/elasticsearch/client/RestClientTests.java\n+++ b/client/src/test/java/org/elasticsearch/client/RestClientTests.java\n@@ -31,7 +31,7 @@\n import java.util.Collection;\n import java.util.Collections;\n \n-public class RestClientBuilderTests extends LuceneTestCase {\n+public class RestClientTests extends LuceneTestCase {\n \n     public void testBuild() throws IOException {\n         try {\n@@ -105,4 +105,33 @@ public void testBuild() throws IOException {\n             assertNotNull(restClient);\n         }\n     }\n+\n+    public void testSetNodes() throws IOException {\n+        try (RestClient restClient = RestClient.builder().setHosts(new HttpHost(\"localhost\", 9200)).build()) {\n+            try {\n+                restClient.setHosts((HttpHost[]) null);\n+                fail(\"setHosts should have failed\");\n+            } catch (IllegalArgumentException e) {\n+                assertEquals(\"hosts must not be null nor empty\", e.getMessage());\n+            }\n+            try {\n+                restClient.setHosts();\n+                fail(\"setHosts should have failed\");\n+            } catch (IllegalArgumentException e) {\n+                assertEquals(\"hosts must not be null nor empty\", e.getMessage());\n+            }\n+            try {\n+                restClient.setHosts((HttpHost) null);\n+                fail(\"setHosts should have failed\");\n+            } catch (NullPointerException e) {\n+                assertEquals(\"host cannot be null\", e.getMessage());\n+            }\n+            try {\n+                restClient.setHosts(new HttpHost(\"localhost\", 9200), null, new HttpHost(\"localhost\", 9201));\n+                fail(\"setHosts should have failed\");\n+            } catch (NullPointerException e) {\n+                assertEquals(\"host cannot be null\", e.getMessage());\n+            }\n+        }\n+    }\n }",
    "output": "Add setHosts test and rename RestClientBuilderTests to RestClientTests"
  },
  {
    "input": "diff --git a/client/src/main/java/org/elasticsearch/client/DeadHostState.java b/client/src/main/java/org/elasticsearch/client/DeadHostState.java\n--- a/client/src/main/java/org/elasticsearch/client/DeadHostState.java\n+++ b/client/src/main/java/org/elasticsearch/client/DeadHostState.java\n@@ -55,4 +55,12 @@ private DeadHostState() {\n     long getDeadUntil() {\n         return deadUntil;\n     }\n+\n+    @Override\n+    public String toString() {\n+        return \"DeadHostState{\" +\n+                \"failedAttempts=\" + failedAttempts +\n+                \", deadUntil=\" + deadUntil +\n+                '}';\n+    }\n }",
    "output": "Add toString to DeadHostState class"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/client/RestTestClient.java b/test/framework/src/main/java/org/elasticsearch/test/rest/client/RestTestClient.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/client/RestTestClient.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/client/RestTestClient.java\n@@ -27,12 +27,12 @@\n import org.apache.http.conn.socket.ConnectionSocketFactory;\n import org.apache.http.conn.socket.PlainConnectionSocketFactory;\n import org.apache.http.conn.ssl.SSLConnectionSocketFactory;\n-import org.apache.http.conn.ssl.SSLContexts;\n import org.apache.http.entity.StringEntity;\n import org.apache.http.impl.client.CloseableHttpClient;\n import org.apache.http.impl.client.HttpClientBuilder;\n import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;\n import org.apache.http.message.BasicHeader;\n+import org.apache.http.ssl.SSLContexts;\n import org.apache.lucene.util.IOUtils;\n import org.elasticsearch.Version;\n import org.elasticsearch.client.ElasticsearchResponse;",
    "output": "Remove usage of deprecated api"
  },
  {
    "input": "diff --git a/client/src/main/java/org/elasticsearch/client/ElasticsearchResponse.java b/client/src/main/java/org/elasticsearch/client/ElasticsearchResponse.java\n--- a/client/src/main/java/org/elasticsearch/client/ElasticsearchResponse.java\n+++ b/client/src/main/java/org/elasticsearch/client/ElasticsearchResponse.java\n@@ -77,6 +77,19 @@ public Header[] getHeaders() {\n         return response.getAllHeaders();\n     }\n \n+    /**\n+     * Returns the value of the first header with a specified name of this message.\n+     * If there is more than one matching header in the message the first element is returned.\n+     * If there is no matching header in the message <code>null</code> is returned.\n+     */\n+    public String getFirstHeader(String name) {\n+        Header header = response.getFirstHeader(name);\n+        if (header == null) {\n+            return null;\n+        }\n+        return header.getValue();\n+    }\n+\n     /**\n      * Returns the response body available, null otherwise\n      * @see HttpEntity",
    "output": "Add getFirstHeader method to ElasticsearchResponse"
  },
  {
    "input": "diff --git a/client/src/main/java/org/elasticsearch/client/RestClient.java b/client/src/main/java/org/elasticsearch/client/RestClient.java\n--- a/client/src/main/java/org/elasticsearch/client/RestClient.java\n+++ b/client/src/main/java/org/elasticsearch/client/RestClient.java\n@@ -107,7 +107,7 @@ private ElasticsearchResponse performRequest(HttpRequestBase request, Iterator<C\n             }\n             int statusCode = response.getStatusLine().getStatusCode();\n             //TODO make ignore status code configurable. rest-spec and tests support that parameter (ignore_missing)\n-            if (statusCode < 300 || request.getMethod().equals(HttpHead.METHOD_NAME) && statusCode == 404) {\n+            if (statusCode < 300 || (request.getMethod().equals(HttpHead.METHOD_NAME) && statusCode == 404) ) {\n                 RequestLogger.log(logger, \"request succeeded\", request.getRequestLine(), connection.getHost(), response.getStatusLine());\n                 connectionPool.onSuccess(connection);\n                 return new ElasticsearchResponse(request.getRequestLine(), connection.getHost(), response);",
    "output": "Add missing parentheses"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n@@ -412,13 +412,13 @@ private Table buildTable(RestRequest request, String[] indices, ClusterHealthRes\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getIndexing().getTotal().getIndexFailedCount());\n \n             table.addCell(indexStats == null ? null : indexStats.getTotal().getMerge().getCurrent());\n-            table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getCurrentSize());\n+            table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getCurrent());\n \n             table.addCell(indexStats == null ? null : indexStats.getTotal().getMerge().getCurrentNumDocs());\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getCurrentNumDocs());\n \n             table.addCell(indexStats == null ? null : indexStats.getTotal().getMerge().getCurrentSize());\n-            table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getCurrent());\n+            table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getCurrentSize());\n \n             table.addCell(indexStats == null ? null : indexStats.getTotal().getMerge().getTotal());\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getTotal());",
    "output": "Fix merge stats rendering in RestIndicesAction give the table description: ``` table.addCell(\"merges.total\", \"sibling:pri;alias:mt,mergesTotal;default:false;text-align:right;desc:number of completed merge ops\"); table.addCell(\"pri.merges.total\", \"default:false;text-align:right;desc:number of completed merge ops\"); table.addCell(\"merges.total_docs\", \"sibling:pri;alias:mtd,mergesTotalDocs;default:false;text-align:right;desc:docs merged\"); table.addCell(\"pri.merges.total_docs\", \"default:false;text-align:right;desc:docs merged\"); table.addCell(\"merges.total_size\", \"sibling:pri;alias:mts,mergesTotalSize;default:false;text-align:right;desc:size merged\"); table.addCell(\"pri.merges.total_size\", \"default:false;text-align:right;desc:size merged\"); ``` this is how it should be"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EChain.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EChain.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EChain.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EChain.java\n@@ -301,7 +301,7 @@ void write(MethodWriter writer) {\n \n                     if (!(expression instanceof EBinary) ||\n                         ((EBinary)expression).operation != Operation.ADD || expression.actual.sort != Sort.STRING) {\n-                        writer.writeAppendStrings(expression.actual); // append the expression's value unless its also a concatenation\n+                        writer.writeAppendStrings(expression.actual); // append the expression's value unless it's also a concatenation\n                     }\n \n                     writer.writeToStrings(); // put the value of the StringBuilder on the stack",
    "output": "Fix a grammar mistake in a comment"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -86,11 +86,7 @@ public static void initializeNatives(Path tmpFile, boolean mlockAll, boolean sec\n \n         // check if the user is running as root, and bail\n         if (Natives.definitelyRunningAsRoot()) {\n-            if (Boolean.parseBoolean(System.getProperty(\"es.insecure.allow.root\"))) {\n-                logger.warn(\"running as ROOT user. this is a bad idea!\");\n-            } else {\n-                throw new RuntimeException(\"don't run elasticsearch as root.\");\n-            }\n+            throw new RuntimeException(\"can not run elasticsearch as root\");\n         }\n \n         // enable secure computing mode",
    "output": "Remove allow running as root This commit removes the escape hatch for running Elasticsearch as root. Relates"
  },
  {
    "input": "diff --git a/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/MatrixStatsResults.java b/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/MatrixStatsResults.java\n--- a/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/MatrixStatsResults.java\n+++ b/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/MatrixStatsResults.java\n@@ -31,8 +31,6 @@\n /**\n  * Descriptive stats gathered per shard. Coordinating node computes final pearson product coefficient\n  * based on these descriptive stats\n- *\n- * @internal\n  */\n class MatrixStatsResults implements Writeable {\n     /** object holding results - computes results in place */\n\ndiff --git a/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/RunningStats.java b/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/RunningStats.java\n--- a/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/RunningStats.java\n+++ b/modules/aggs-matrix-stats/src/main/java/org/elasticsearch/search/aggregations/matrix/stats/RunningStats.java\n@@ -34,8 +34,6 @@\n  * based on these descriptive stats. This single pass, parallel approach is based on:\n  *\n  * http://prod.sandia.gov/techlib/access-control.cgi/2008/086212.pdf\n- *\n- * @internal\n  */\n public class RunningStats implements Writeable, Cloneable {\n     /** count of observations (same number of observations per field) */",
    "output": "Remove unrecognized javadoc tag from matrix aggregation module"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/StoreRecoveryTests.java b/core/src/test/java/org/elasticsearch/index/shard/StoreRecoveryTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/StoreRecoveryTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/StoreRecoveryTests.java\n@@ -74,7 +74,7 @@ public void testAddIndices() throws IOException {\n         assertEquals(numFiles, targetNumFiles);\n         assertEquals(indexStats.totalFileCount(), targetNumFiles);\n         if (hardLinksSupported(createTempDir())) {\n-            assertEquals(\"upgrade to HardlinkCopyDirectoryWrapper in Lucene 6.1\", Version.LATEST, Version.LUCENE_6_0_0);\n+            assertEquals(\"upgrade to HardlinkCopyDirectoryWrapper in Lucene 6.1\", Version.LATEST, Version.LUCENE_6_0_1);\n             // assertEquals(indexStats.reusedFileCount(), targetNumFiles); -- uncomment this once upgraded to Lucene 6.1\n             assertEquals(indexStats.reusedFileCount(), 0);\n         } else {",
    "output": "Fix StoreRecoveryTests after 6.0.1 upgrade"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -77,7 +77,7 @@ public class Version {\n     public static final int V_5_0_0_alpha3_ID = 5000003;\n     public static final Version V_5_0_0_alpha3 = new Version(V_5_0_0_alpha3_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n     public static final int V_5_0_0_ID = 5000099;\n-    public static final Version V_5_0_0 = new Version(V_5_0_0_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n+    public static final Version V_5_0_0 = new Version(V_5_0_0_ID, org.apache.lucene.util.Version.LUCENE_6_0_1);\n     public static final Version CURRENT = V_5_0_0;\n \n     static {",
    "output": "Upgrade to Lucene 6.0.1"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n@@ -37,6 +37,6 @@ public void testCompatibility() {\n          *\n          */\n         assertThat(\"Remove workaround in LicenseService class when es core supports merging cluster level custom metadata\",\n-                   Version.CURRENT.equals(Version.V_5_0_0_alpha3), is(true));\n+                   Version.CURRENT.equals(Version.V_5_0_0), is(true));\n     }\n }",
    "output": "Fix version compatability test This commit fixes the version compatability test by updating the version to reflect the current version in core"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/blobstore/BlobContainer.java b/core/src/main/java/org/elasticsearch/common/blobstore/BlobContainer.java\n--- a/core/src/main/java/org/elasticsearch/common/blobstore/BlobContainer.java\n+++ b/core/src/main/java/org/elasticsearch/common/blobstore/BlobContainer.java\n@@ -44,7 +44,6 @@ public interface BlobContainer {\n      * @param   blobName\n      *          The name of the blob whose existence is to be determined.\n      * @return  {@code true} if a blob exists in the {@link BlobContainer} with the given name, and {@code false} otherwise.\n-     * @throws  IOException if any error occurred while attempting to ascertain if the blob exists\n      */\n     boolean blobExists(String blobName);\n ",
    "output": "Fix javadoc that stated a throws clause that didn't exist"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -76,7 +76,9 @@ public class Version {\n     public static final Version V_5_0_0_alpha2 = new Version(V_5_0_0_alpha2_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n     public static final int V_5_0_0_alpha3_ID = 5000003;\n     public static final Version V_5_0_0_alpha3 = new Version(V_5_0_0_alpha3_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n-    public static final Version CURRENT = V_5_0_0_alpha3;\n+    public static final int V_5_0_0_ID = 5000099;\n+    public static final Version V_5_0_0 = new Version(V_5_0_0_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n+    public static final Version CURRENT = V_5_0_0;\n \n     static {\n         assert CURRENT.luceneVersion.equals(org.apache.lucene.util.Version.LATEST) : \"Version must be upgraded to [\"\n@@ -89,6 +91,8 @@ public static Version readVersion(StreamInput in) throws IOException {\n \n     public static Version fromId(int id) {\n         switch (id) {\n+            case V_5_0_0_ID:\n+                return V_5_0_0;\n             case V_5_0_0_alpha3_ID:\n                 return V_5_0_0_alpha3;\n             case V_5_0_0_alpha2_ID:",
    "output": "Change version back to 5.0.0"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/license/plugin/LicensesTransportTests.java b/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/license/plugin/LicensesTransportTests.java\n--- a/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/license/plugin/LicensesTransportTests.java\n+++ b/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/license/plugin/LicensesTransportTests.java\n@@ -58,11 +58,19 @@ protected Settings nodeSettings() {\n     }\n \n     public void testEmptyGetLicense() throws Exception {\n-        final ActionFuture<GetLicenseResponse> getLicenseFuture =\n-                new GetLicenseRequestBuilder(client().admin().cluster(), GetLicenseAction.INSTANCE).execute();\n-        final GetLicenseResponse getLicenseResponse = getLicenseFuture.get();\n-        assertNotNull(getLicenseResponse.license());\n-        assertThat(getLicenseResponse.license().operationMode(), equalTo(License.OperationMode.TRIAL));\n+        // trail license is added async, we should wait for it\n+        assertBusy(() -> {\n+            try {\n+                final ActionFuture<GetLicenseResponse> getLicenseFuture =\n+                        new GetLicenseRequestBuilder(client().admin().cluster(), GetLicenseAction.INSTANCE).execute();\n+                final GetLicenseResponse getLicenseResponse;\n+                getLicenseResponse = getLicenseFuture.get();\n+                assertNotNull(getLicenseResponse.license());\n+                assertThat(getLicenseResponse.license().operationMode(), equalTo(License.OperationMode.TRIAL));\n+            } catch (Exception e) {\n+                throw new RuntimeException(\"unexpected exception\", e);\n+            }\n+        });\n     }\n \n     public void testPutLicense() throws Exception {",
    "output": "Add assertBusy to testEmptyGetLicense as trial license is added async"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java\n@@ -43,6 +43,11 @@ public final class Definition {\n                       \"java.lang.txt\",\n                       \"java.math.txt\",\n                       \"java.text.txt\",\n+                      \"java.time.txt\",\n+                      \"java.time.chrono.txt\",\n+                      \"java.time.format.txt\",\n+                      \"java.time.temporal.txt\",\n+                      \"java.time.zone.txt\",\n                       \"java.util.txt\",\n                       \"java.util.function.txt\",\n                       \"java.util.stream.txt\"));",
    "output": "Add java.time packages to painless whitelist"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Definition.java\n@@ -43,6 +43,11 @@ public final class Definition {\n                       \"java.lang.txt\",\n                       \"java.math.txt\",\n                       \"java.text.txt\",\n+                      \"java.time.txt\",\n+                      \"java.time.chrono.txt\",\n+                      \"java.time.format.txt\",\n+                      \"java.time.temporal.txt\",\n+                      \"java.time.zone.txt\",\n                       \"java.util.txt\",\n                       \"java.util.function.txt\",\n                       \"java.util.stream.txt\"));",
    "output": "Add java.time packages to painless whitelist"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java b/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n--- a/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n+++ b/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n@@ -44,12 +44,6 @@ public class GroovySecurityTests extends ESTestCase {\n \n     private GroovyScriptEngineService se;\n \n-    static {\n-        // ensure we load all the timezones in the parent classloader with all permissions\n-        // relates to https://github.com/elastic/elasticsearch/issues/14524\n-        org.joda.time.DateTimeZone.getDefault();\n-    }\n-\n     @Override\n     public void setUp() throws Exception {\n         super.setUp();",
    "output": "Upgrade joda-time to 2.9.4 This commit upgrades joda-time to version 2.9.4 to integrate a bug fix there into Elasticsearch. Relates"
  },
  {
    "input": "diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n--- a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n@@ -289,7 +289,7 @@ public S3Repository(RepositoryName name, RepositorySettings repositorySettings,\n         String cannedACL = getValue(repositorySettings, Repository.CANNED_ACL_SETTING, Repositories.CANNED_ACL_SETTING);\n \n         logger.debug(\"using bucket [{}], region [{}], endpoint [{}], protocol [{}], chunk_size [{}], server_side_encryption [{}], \" +\n-            \"buffer_size [{}], max_retries [{}], throttle_retries [{}], cannedACL [{}], storageClass [{}]\",\n+            \"buffer_size [{}], max_retries [{}], use_throttle_retries [{}], cannedACL [{}], storageClass [{}]\",\n             bucket, region, endpoint, protocol, chunkSize, serverSideEncryption, bufferSize, maxRetries, useThrottleRetries, cannedACL,\n             storageClass);\n ",
    "output": "Fix log use_throttle_retries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n@@ -304,7 +304,9 @@ private Path unzip(Path zip, Path pluginsDir) throws IOException, UserError {\n \n                 // be on the safe side: do not rely on that directories are always extracted\n                 // before their children (although this makes sense, but is it guaranteed?)\n-                Files.createDirectories(targetFile.getParent());\n+                if (!Files.isSymbolicLink(targetFile.getParent())) {\n+                    Files.createDirectories(targetFile.getParent());\n+                }\n                 if (entry.isDirectory() == false) {\n                     try (OutputStream out = Files.newOutputStream(targetFile)) {\n                         int len;",
    "output": "Fix when plugins directory is symlink This commit fixes an issue with the plugins directory being a symbolic link. Namely, the install plugins command attempts to always create the plugins directory just in case it does not exist. The JDK method used here guarantees that the directory is created, and an exception is not thrown if the directory could not be created because it already exists. The problem is that this JDK method does not respect symlinks so its internal existence checks fails, it proceeds to attempt to create the directory, but the directory creation fails because the symlink exists. This is documented as being not an issue. We work around this by checking if there is a symlink where we expect the plugins directory to be, and only attempt to create if not. We add a unit test that plugin installation to a symlinked plugins directory works as expected"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java b/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java\n--- a/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java\n+++ b/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java\n@@ -291,12 +291,14 @@ private RoutingAllocation onePrimaryOnNode1And1Replica(AllocationDeciders decide\n         // mark shard as delayed if reason is NODE_LEFT\n         boolean delayed = reason == UnassignedInfo.Reason.NODE_LEFT &&\n             UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.get(settings).nanos() > 0;\n+        int failedAllocations = reason == UnassignedInfo.Reason.ALLOCATION_FAILED ? 1 : 0;\n         RoutingTable routingTable = RoutingTable.builder()\n                 .add(IndexRoutingTable.builder(shardId.getIndex())\n                                 .addIndexShard(new IndexShardRoutingTable.Builder(shardId)\n                                         .addShard(primaryShard)\n                                         .addShard(ShardRouting.newUnassigned(shardId, null, false,\n-                                            new UnassignedInfo(reason, null, null, 0, System.nanoTime(), System.currentTimeMillis(), delayed)))\n+                                            new UnassignedInfo(reason, null, null, failedAllocations, System.nanoTime(),\n+                                                System.currentTimeMillis(), delayed)))\n                                         .build())\n                 )\n                 .build();",
    "output": "Fix ReplicaShardAllocatorTests when unassigned reason is ALLOCATION_FAILED When mocking unassigned shards which have failed with reason ALLOCATION_FAILED we have to ensure that the failed allocation counter is strictly positive"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/RemovePluginCommand.java\n@@ -71,7 +71,7 @@ void execute(Terminal terminal, String pluginName, Map<String, String> settings)\n \n         Path pluginDir = env.pluginsFile().resolve(pluginName);\n         if (Files.exists(pluginDir) == false) {\n-            throw new UserError(ExitCodes.USAGE, \"Plugin \" + pluginName + \" not found. Run 'plugin list' to get list of installed plugins.\");\n+            throw new UserError(ExitCodes.USAGE, \"plugin \" + pluginName + \" not found; run 'elasticsearch-plugin list' to get list of installed plugins\");\n         }\n \n         List<Path> pluginPaths = new ArrayList<>();\n\ndiff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/RemovePluginCommandTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/RemovePluginCommandTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/RemovePluginCommandTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/RemovePluginCommandTests.java\n@@ -73,7 +73,7 @@ static void assertRemoveCleaned(Environment env) throws IOException {\n \n     public void testMissing() throws Exception {\n         UserError e = expectThrows(UserError.class, () -> removePlugin(\"dne\", home));\n-        assertTrue(e.getMessage(), e.getMessage().contains(\"Plugin dne not found\"));\n+        assertTrue(e.getMessage(), e.getMessage().contains(\"plugin dne not found\"));\n         assertRemoveCleaned(env);\n     }\n ",
    "output": "Fix plugin command name in remove plugin command This commit fixes the name of the plugin command that is output when a user attempts to remove a plugin that does not exist"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n@@ -554,7 +554,6 @@ public void testOfficialPluginsHelpSorted() throws Exception {\n                 line = reader.readLine();\n             }\n         }\n-        terminal.getOutput();\n     }\n \n     public void testOfficialPluginsIncludesXpack() throws Exception {",
    "output": "Remove unused line in official plugins test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n@@ -135,7 +135,6 @@ class InstallPluginCommand extends SettingCommand {\n         } catch (IOException e) {\n             throw new RuntimeException(e);\n         }\n-\n     }\n \n     private final OptionSpec<Void> batchOption;\n\ndiff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n@@ -557,6 +557,12 @@ public void testOfficialPluginsHelpSorted() throws Exception {\n         terminal.getOutput();\n     }\n \n+    public void testOfficialPluginsIncludesXpack() throws Exception {\n+        MockTerminal terminal = new MockTerminal();\n+        new InstallPluginCommand().main(new String[] { \"--help\" }, terminal);\n+        assertTrue(terminal.getOutput(), terminal.getOutput().contains(\"x-pack\"));\n+    }\n+\n     // TODO: test batch flag?\n     // TODO: test checksum (need maven/official below)\n     // TODO: test maven, official, and staging install...need tests with fixtures...",
    "output": "Add test that x-pack is in official plugins list"
  },
  {
    "input": "diff --git a/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RetryTests.java b/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RetryTests.java\n--- a/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RetryTests.java\n+++ b/modules/reindex/src/test/java/org/elasticsearch/index/reindex/RetryTests.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.index.reindex;\n \n-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;\n import org.elasticsearch.action.ListenableActionFuture;\n import org.elasticsearch.action.admin.cluster.node.tasks.list.ListTasksResponse;\n import org.elasticsearch.action.bulk.BackoffPolicy;\n@@ -103,8 +102,13 @@ public void testUpdateByQuery() throws Exception {\n                 matcher().updated(DOC_COUNT));\n     }\n \n-    private void testCase(String action, AbstractBulkIndexByScrollRequestBuilder<?, ?> request, BulkIndexByScrollResponseMatcher matcher)\n-            throws Exception {\n+    public void testDeleteByQuery() throws Exception {\n+        testCase(DeleteByQueryAction.NAME, DeleteByQueryAction.INSTANCE.newRequestBuilder(client()).source(\"source\"),\n+                matcher().deleted(DOC_COUNT));\n+    }\n+\n+    private void testCase(String action, AbstractBulkByScrollRequestBuilder<?, BulkIndexByScrollResponse, ?> request,\n+            BulkIndexByScrollResponseMatcher matcher) throws Exception {\n         logger.info(\"Blocking search\");\n         CyclicBarrier initialSearchBlock = blockExecutor(ThreadPool.Names.SEARCH);\n ",
    "output": "Add retry test case for delete-by-query Tests that we retry failed searches, scrolls, and bulks"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/unit/TimeValueTests.java b/core/src/test/java/org/elasticsearch/common/unit/TimeValueTests.java\n--- a/core/src/test/java/org/elasticsearch/common/unit/TimeValueTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/unit/TimeValueTests.java\n@@ -83,6 +83,9 @@ public void testParseTimeValue() {\n         assertEquals(new TimeValue(10, TimeUnit.SECONDS),\n                      TimeValue.parseTimeValue(\"10S\", null, \"test\"));\n \n+        assertEquals(new TimeValue(100, TimeUnit.MILLISECONDS),\n+                    TimeValue.parseTimeValue(\"0.1s\", null, \"test\"));\n+\n         assertEquals(new TimeValue(10, TimeUnit.MINUTES),\n                      TimeValue.parseTimeValue(\"10 m\", null, \"test\"));\n         assertEquals(new TimeValue(10, TimeUnit.MINUTES),",
    "output": "Add test for parsing fractional seconds This commit adds a test that ensures that strings containing a fractional number of seconds are correctly parsed into milliseconds. Relates"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n@@ -161,7 +161,7 @@ public void waitForNoBlocksOnNodes() throws Exception {\n             public void run() {\n                 for (String nodeId : internalCluster().getNodeNames()) {\n                     try {\n-                        assertTrue(waitForNoBlocksOnNode(nodeId));\n+                        waitForNoBlocksOnNode(nodeId);\n                     } catch (Exception e) {\n                         fail(\"failed to wait for no blocks on node [\" + nodeId + \"]: \" + e.getMessage());\n                     }\n@@ -170,13 +170,12 @@ public void run() {\n         });\n     }\n \n-    public boolean waitForNoBlocksOnNode(final String nodeId) throws Exception {\n-        return assertBusy(() -> {\n+    public void waitForNoBlocksOnNode(final String nodeId) throws Exception {\n+        assertBusy(() -> {\n             ClusterBlocks clusterBlocks =\n                     client(nodeId).admin().cluster().prepareState().setLocal(true).execute().actionGet().getState().blocks();\n             assertTrue(clusterBlocks.global().isEmpty());\n             assertTrue(clusterBlocks.indices().values().isEmpty());\n-            return true;\n         }, 30L, TimeUnit.SECONDS);\n     }\n ",
    "output": "Remove unnecessary use of return value for assertBusy"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/OpenLdapTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/OpenLdapTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/OpenLdapTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/OpenLdapTests.java\n@@ -97,7 +97,6 @@ public void testGroupSearchScopeBase() throws Exception {\n         }\n     }\n \n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/x-plugins/issues/2313\")\n     public void testUsageStats() throws Exception {\n         String groupSearchBase = \"ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com\";\n         String userTemplate = \"uid={0},ou=people,dc=oldap,dc=test,dc=elasticsearch,dc=com\";\n@@ -120,7 +119,7 @@ public void testUsageStats() throws Exception {\n \n         Map<String, Object> stats = realm.usageStats();\n         assertThat(stats, is(notNullValue()));\n-        assertThat(stats, hasEntry(\"size\", \"small\"));\n+        assertThat(stats, hasEntry(\"size\", \"tiny\"));\n         assertThat(stats, hasEntry(\"ssl\", true));\n         assertThat(stats, hasEntry(\"user_search\", userSearch));\n         assertThat(stats, hasEntry(\"load_balance_type\", loadBalanceType));",
    "output": "Fix test Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java b/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n--- a/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n+++ b/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n@@ -59,7 +59,7 @@ public void testScalingThreadPoolConfiguration() throws InterruptedException {\n \n         final int expectedSize;\n         if (sizeBasedOnNumberOfProcessors < min || randomBoolean()) {\n-            expectedSize = randomIntBetween(min, 16);\n+            expectedSize = randomIntBetween(Math.max(1, min), 16);\n             builder.put(\"threadpool.\" + threadPoolName + \".size\", expectedSize);\n         }  else {\n             expectedSize = sizeBasedOnNumberOfProcessors;",
    "output": "Fix scaling thread pool test bug This commit fixes a test bug in the scaling thread pool configuration test. In particular, the test randomization could select min and max for a thread pool configuration where both are equal to zero. This is a violation of the requirements of the ThreadPoolExecutor. With this commit, we now ensure that the max is bounded below by one"
  },
  {
    "input": "diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/cloud/aws/RepositoryS3SettingsTests.java b/plugins/repository-s3/src/test/java/org/elasticsearch/cloud/aws/RepositoryS3SettingsTests.java\n--- a/plugins/repository-s3/src/test/java/org/elasticsearch/cloud/aws/RepositoryS3SettingsTests.java\n+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/cloud/aws/RepositoryS3SettingsTests.java\n@@ -316,7 +316,7 @@ public void testInvalidChunkBufferSizeRepositorySettings() throws IOException {\n             \"Failed to parse value [4mb] for setting [buffer_size] must be >= 5mb\");\n         // chunk > 5tb should fail\n         internalTestInvalidChunkBufferSizeSettings(new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(6, ByteSizeUnit.TB),\n-            \"Failed to parse value [6tb] for setting [chunk_size] must be =< 5tb\");\n+            \"Failed to parse value [6tb] for setting [chunk_size] must be <= 5tb\");\n     }\n \n     private Settings buildSettings(Settings... global) {",
    "output": "Fix inequality symbol in test assertion This commit fixes the inequality symbol used in a test assertion in RepositoryS3SettingsTests#testInvalidChunkBufferSizeRepositorySettings. The inequality symbol was previously backwards but fixed in commit cad0608cdb28e2b8485e5c01c26579a35cb84356 but fixing the inequality symbol here was missed in that commit"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java b/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n--- a/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n@@ -396,12 +396,14 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n                     builder.endObject();\n                 }\n                 builder.endArray();\n+\n                 builder.startObject(\"total\");\n                 builder.field(OPERATIONS, totalOperations);\n                 builder.field(READ_OPERATIONS, totalReadOperations);\n                 builder.field(WRITE_OPERATIONS, totalWriteOperations);\n                 builder.field(READ_KILOBYTES, totalReadKilobytes);\n                 builder.field(WRITE_KILOBYTES, totalWriteKilobytes);\n+                builder.endObject();\n             }\n             return builder;\n         }",
    "output": "Add missing builder.endObject() in FsInfo"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java b/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n--- a/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/fs/FsInfo.java\n@@ -396,12 +396,14 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n                     builder.endObject();\n                 }\n                 builder.endArray();\n+\n                 builder.startObject(\"total\");\n                 builder.field(OPERATIONS, totalOperations);\n                 builder.field(READ_OPERATIONS, totalReadOperations);\n                 builder.field(WRITE_OPERATIONS, totalWriteOperations);\n                 builder.field(READ_KILOBYTES, totalReadKilobytes);\n                 builder.field(WRITE_KILOBYTES, totalWriteKilobytes);\n+                builder.endObject();\n             }\n             return builder;\n         }",
    "output": "Add missing builder.endObject() in FsInfo"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n@@ -88,15 +88,13 @@ boolean isUpgraded(IndexMetaData indexMetaData) {\n     }\n \n     /**\n-     * Elasticsearch 3.0 no longer supports indices with pre Lucene v5.0 (Elasticsearch v2.0.0.beta1) segments. All indices\n-     * that were created before Elasticsearch v2.0.0.beta1 should be upgraded using upgrade API before they can\n-     * be open by this version of elasticsearch.\n-     */\n+     * Elasticsearch 5.0 no longer supports indices with pre Lucene v5.0 (Elasticsearch v2.0.0.beta1) segments. All indices\n+     * that were created before Elasticsearch v2.0.0.beta1 should be reindexed in Elasticsearch 2.x\n+     * before they can be opened by this version of elasticsearch.     */\n     private void checkSupportedVersion(IndexMetaData indexMetaData) {\n         if (indexMetaData.getState() == IndexMetaData.State.OPEN && isSupportedVersion(indexMetaData) == false) {\n-            throw new IllegalStateException(\"The index [\" + indexMetaData.getIndex() + \"] was created before v2.0.0.beta1 and wasn't upgraded.\"\n-                    + \" This index should be opened using a version before \" + Version.CURRENT.minimumCompatibilityVersion()\n-                    + \" and upgraded using the upgrade API.\");\n+            throw new IllegalStateException(\"The index [\" + indexMetaData.getIndex() + \"] was created before v2.0.0.beta1.\"\n+                    + \" It should be reindexed in Elasticsearch 2.x before upgrading to \" + Version.CURRENT + \".\");\n         }\n     }\n ",
    "output": "Make the index-too-old exception more explicit"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n@@ -169,6 +169,7 @@ public BulkRequest add(DeleteRequest request) {\n     }\n \n     public BulkRequest add(DeleteRequest request, @Nullable Object payload) {\n+        Objects.requireNonNull(request, \"'request' must not be null\");\n         requests.add(request);\n         addPayload(payload);\n         sizeInBytes += REQUEST_OVERHEAD;\n\ndiff --git a/core/src/test/java/org/elasticsearch/action/bulk/BulkRequestTests.java b/core/src/test/java/org/elasticsearch/action/bulk/BulkRequestTests.java\n--- a/core/src/test/java/org/elasticsearch/action/bulk/BulkRequestTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/bulk/BulkRequestTests.java\n@@ -210,4 +210,11 @@ public void testBulkNoSource() throws Exception {\n                 \"script or doc is missing\",\n                 \"source is missing\"));\n     }\n+\n+    public void testCannotAddNullRequests() throws Exception {\n+        BulkRequest bulkRequest = new BulkRequest();\n+        expectThrows(NullPointerException.class, () -> bulkRequest.add((IndexRequest) null));\n+        expectThrows(NullPointerException.class, () -> bulkRequest.add((UpdateRequest) null));\n+        expectThrows(NullPointerException.class, () -> bulkRequest.add((DeleteRequest) null));\n+    }\n }",
    "output": "Add tests for null precondition check in BulkRequest Relates Checked with @javanna"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ingest/processor/SortProcessorTests.java b/core/src/test/java/org/elasticsearch/ingest/processor/SortProcessorTests.java\n--- a/core/src/test/java/org/elasticsearch/ingest/processor/SortProcessorTests.java\n+++ b/core/src/test/java/org/elasticsearch/ingest/processor/SortProcessorTests.java\n@@ -30,6 +30,7 @@\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n+import java.util.Random;\n import java.util.stream.Collectors;\n \n import static org.hamcrest.Matchers.containsString;\n@@ -66,7 +67,7 @@ public void testSortIntegersNonRandom() throws Exception {\n         Integer[] expectedResult = new Integer[]{1,2,3,4,5,10,20,21,22,50,100};\n         List<Integer> fieldValue = new ArrayList<>(expectedResult.length);\n         fieldValue.addAll(Arrays.asList(expectedResult).subList(0, expectedResult.length));\n-        Collections.shuffle(fieldValue);\n+        Collections.shuffle(fieldValue, random());\n \n         String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);\n         Processor processor = new SortProcessor(randomAsciiOfLength(10), fieldName, SortOrder.ASCENDING);",
    "output": "Use a reproducible source of randomness in shuffle"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n@@ -43,6 +43,7 @@\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.List;\n+import java.util.Objects;\n \n import static org.elasticsearch.action.ValidateActions.addValidationError;\n \n@@ -125,6 +126,7 @@ public BulkRequest add(IndexRequest request, @Nullable Object payload) {\n     }\n \n     BulkRequest internalAdd(IndexRequest request, @Nullable Object payload) {\n+        Objects.requireNonNull(request, \"'request' must not be null\");\n         requests.add(request);\n         addPayload(payload);\n         // lack of source is validated in validate() method\n@@ -144,6 +146,7 @@ public BulkRequest add(UpdateRequest request, @Nullable Object payload) {\n     }\n \n     BulkRequest internalAdd(UpdateRequest request, @Nullable Object payload) {\n+        Objects.requireNonNull(request, \"'request' must not be null\");\n         requests.add(request);\n         addPayload(payload);\n         if (request.doc() != null) {",
    "output": "Add not-null precondition check in BulkRequest"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n@@ -43,6 +43,7 @@\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.List;\n+import java.util.Objects;\n \n import static org.elasticsearch.action.ValidateActions.addValidationError;\n \n@@ -125,6 +126,7 @@ public BulkRequest add(IndexRequest request, @Nullable Object payload) {\n     }\n \n     BulkRequest internalAdd(IndexRequest request, @Nullable Object payload) {\n+        Objects.requireNonNull(request, \"'request' must not be null\");\n         requests.add(request);\n         addPayload(payload);\n         // lack of source is validated in validate() method\n@@ -144,6 +146,7 @@ public BulkRequest add(UpdateRequest request, @Nullable Object payload) {\n     }\n \n     BulkRequest internalAdd(UpdateRequest request, @Nullable Object payload) {\n+        Objects.requireNonNull(request, \"'request' must not be null\");\n         requests.add(request);\n         addPayload(payload);\n         if (request.doc() != null) {",
    "output": "Add not-null precondition check in BulkRequest With this commit we add a precondition check to BulkRequest so we fail early if users pass `null` for the request object. For a more detailed discussion, . This supersedes #12038. Relates #12038"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/WhenThingsGoWrongTests.java\n@@ -175,9 +175,15 @@ public void testDynamicNPE() {\n         });\n     }\n \n-    public void testDynamicWrongArgs() {\n+    public void testDynamicArrayWrongIndex() {\n         expectThrows(WrongMethodTypeException.class, () -> {\n-            exec(\"def x = new ArrayList(); return x.get('bogus');\");\n+            exec(\"def x = new long[1]; x[0]=1; return x['bogus'];\");\n+        });\n+    }\n+\n+    public void testDynamicListWrongIndex() {\n+        expectThrows(WrongMethodTypeException.class, () -> {\n+            exec(\"def x = new ArrayList(); x.add('foo'); return x['bogus'];\");\n         });\n     }\n }",
    "output": "Add test for wrong array index"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n@@ -46,12 +46,11 @@ public String getExtension() {\n     }\n \n     @Override\n-    public Object compile(String script, Map<String, String> params) {\n+    public Object compile(String name, String script, Map<String, String> params) {\n         if (script.contains(\"{{\") && script.contains(\"}}\")) {\n             throw new IllegalArgumentException(\"Fix your test to not rely on mustache\");\n         }\n \n-        return script;\n+        return super.compile(name, script, params);\n     }\n-\n }\n\ndiff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n@@ -55,8 +55,8 @@ public String getExtension() {\n     }\n \n     @Override\n-    public Object compile(String script, Map<String, String> params) {\n-        return script;\n+    public Object compile(String scriptName, String scriptSource, Map<String, String> params) {\n+        return scriptSource;\n     }\n \n     @Override",
    "output": "Upgrade mock script engines to take name parameter"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n@@ -41,8 +41,8 @@ public String getType() {\n     }\n \n     @Override\n-    public List<String> getExtensions() {\n-        return Collections.singletonList(NAME);\n+    public String getExtension() {\n+        return NAME;\n     }\n \n     @Override\n\ndiff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n@@ -22,8 +22,6 @@ public class SleepScriptEngine implements ScriptEngineService {\n \n     public static final String NAME = \"sleep\";\n \n-    public static final List<String> TYPES = Collections.singletonList(NAME);\n-\n     public static class TestPlugin extends Plugin {\n \n         public TestPlugin() {\n@@ -52,8 +50,8 @@ public String getType() {\n     }\n \n     @Override\n-    public List<String> getExtensions() {\n-        return TYPES;\n+    public String getExtension() {\n+        return NAME;\n     }\n \n     @Override",
    "output": "Fix compilation for only one script language extension"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/MockMustacheScriptEngine.java\n@@ -41,8 +41,8 @@ public String getType() {\n     }\n \n     @Override\n-    public List<String> getExtensions() {\n-        return Collections.singletonList(NAME);\n+    public String getExtension() {\n+        return NAME;\n     }\n \n     @Override\n\ndiff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n@@ -22,8 +22,6 @@ public class SleepScriptEngine implements ScriptEngineService {\n \n     public static final String NAME = \"sleep\";\n \n-    public static final List<String> TYPES = Collections.singletonList(NAME);\n-\n     public static class TestPlugin extends Plugin {\n \n         public TestPlugin() {\n@@ -52,8 +50,8 @@ public String getType() {\n     }\n \n     @Override\n-    public List<String> getExtensions() {\n-        return TYPES;\n+    public String getExtension() {\n+        return NAME;\n     }\n \n     @Override",
    "output": "Fix compilation for only one script language extension Relates to https://github.com/elastic/elasticsearch/pull/18332"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/IpRangeIT.java\n@@ -256,13 +256,4 @@ public Object run() {\n         }\n     }\n \n-    public static void main(String[] args) {\n-        AggregatorBuilder<?> aggregation =\n-                AggregationBuilders\n-                        .ipRange(\"agg\")\n-                        .field(\"ip\")\n-                        .addUnboundedTo(\"192.168.1.0\")             // from -infinity to 192.168.1.0 (excluded)\n-                        .addRange(\"192.168.1.0\", \"192.168.2.0\")    // from 192.168.1.0 to 192.168.2.0 (excluded)\n-                        .addUnboundedFrom(\"192.168.2.0\");          // from 192.168.2.0 to +infinity\n-    }\n }",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/script/SleepScriptEngine.java\n@@ -54,11 +54,6 @@ public List<String> getExtensions() {\n         return TYPES;\n     }\n \n-    @Override\n-    public boolean isSandboxed() {\n-        return true;\n-    }\n-\n     @Override\n     public Object compile(String script, Map<String, String> params) {\n         return script;\n\ndiff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/AbstractWatcherIntegrationTestCase.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/AbstractWatcherIntegrationTestCase.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/AbstractWatcherIntegrationTestCase.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/xpack/watcher/test/AbstractWatcherIntegrationTestCase.java\n@@ -136,6 +136,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 .put(\"xpack.watcher.watch.scroll.size\", randomIntBetween(1, 100))\n                 .put(ShieldSettings.settings(shieldEnabled))\n                 .put(\"xpack.watcher.trigger.schedule.engine\", scheduleImplName)\n+                .put(\"script.inline\", \"true\")\n                 .build();\n     }\n ",
    "output": "Fix Watcher tests for 'sandbox' option removal Relates to https://github.com/elastic/elasticsearch/pull/18226"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n@@ -95,7 +95,7 @@ boolean isUpgraded(IndexMetaData indexMetaData) {\n     private void checkSupportedVersion(IndexMetaData indexMetaData) {\n         if (indexMetaData.getState() == IndexMetaData.State.OPEN && isSupportedVersion(indexMetaData) == false) {\n             throw new IllegalStateException(\"The index [\" + indexMetaData.getIndex() + \"] was created before v2.0.0.beta1 and wasn't upgraded.\"\n-                    + \" This index should be open using a version before \" + Version.CURRENT.minimumCompatibilityVersion()\n+                    + \" This index should be opened using a version before \" + Version.CURRENT.minimumCompatibilityVersion()\n                     + \" and upgraded using the upgrade API.\");\n         }\n     }",
    "output": "Fix grammar in index-too-old exception"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/IndexAlreadyExistsException.java b/core/src/main/java/org/elasticsearch/indices/IndexAlreadyExistsException.java\n--- a/core/src/main/java/org/elasticsearch/indices/IndexAlreadyExistsException.java\n+++ b/core/src/main/java/org/elasticsearch/indices/IndexAlreadyExistsException.java\n@@ -32,7 +32,7 @@\n public class IndexAlreadyExistsException extends ElasticsearchException {\n \n     public IndexAlreadyExistsException(Index index) {\n-        this(index, \"already exists\");\n+        this(index, \"index \" + index.toString() + \" already exists\");\n     }\n \n     public IndexAlreadyExistsException(Index index, String message) {\n@@ -48,4 +48,4 @@ public IndexAlreadyExistsException(StreamInput in) throws IOException{\n     public RestStatus status() {\n         return RestStatus.BAD_REQUEST;\n     }\n-}\n\\ No newline at end of file\n+}",
    "output": "Add index name and uuid in IndexAlreadyExistsException default message Relates"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n@@ -335,7 +335,7 @@ public boolean check() {\n         @Override\n         public String errorMessage() {\n             return \"please set [\" + ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey() +\n-                \"] to a majority of the number of master eligible nodes in your cluster.\";\n+                \"] to a majority of the number of master eligible nodes in your cluster\";\n         }\n \n         @Override",
    "output": "Remove period in min master node check log message As most of our log messages are not sentences and do not end with periods, this commit removes a period from the end of the min master node bootstrap check log message"
  },
  {
    "input": "diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java\n--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java\n+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java\n@@ -134,6 +134,7 @@ public void onModule(SettingsModule settingsModule) {\n         settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.GROUPS_SETTING);\n         settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.AVAILABILITY_ZONES_SETTING);\n         settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.NODE_CACHE_TIME_SETTING);\n+        settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.TAG_SETTING);\n     }\n \n     /**",
    "output": "Add TAG_SETTING to list of allowed tags for the ec2 discovery plugin"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/test/java/org/elasticsearch/painless/ReservedWordTests.java b/modules/lang-painless/src/test/java/org/elasticsearch/painless/ReservedWordTests.java\n--- a/modules/lang-painless/src/test/java/org/elasticsearch/painless/ReservedWordTests.java\n+++ b/modules/lang-painless/src/test/java/org/elasticsearch/painless/ReservedWordTests.java\n@@ -37,4 +37,20 @@ public void testScoreStore() {\n         });\n         assertTrue(expected.getMessage().contains(\"Variable [_score] is read-only\"));\n     }\n+    \n+    /** check that we can't declare a variable of doc, its really reserved! */\n+    public void testDocVar() {\n+        IllegalArgumentException expected = expectThrows(IllegalArgumentException.class, () -> {\n+            exec(\"int doc = 5; return doc;\");\n+        });\n+        assertTrue(expected.getMessage().contains(\"Variable name [doc] already defined\"));\n+    }\n+    \n+    /** check that we can't write to _score, its read-only! */\n+    public void testDocStore() {\n+        IllegalArgumentException expected = expectThrows(IllegalArgumentException.class, () -> {\n+            exec(\"doc = 5; return doc;\");\n+        });\n+        assertTrue(expected.getMessage().contains(\"Variable [doc] is read-only\"));\n+    }\n }",
    "output": "Add reserved word tests for 'doc', too"
  },
  {
    "input": "diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java\n--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java\n+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java\n@@ -134,6 +134,7 @@ public void onModule(SettingsModule settingsModule) {\n         settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.GROUPS_SETTING);\n         settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.AVAILABILITY_ZONES_SETTING);\n         settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.NODE_CACHE_TIME_SETTING);\n+        settingsModule.registerSetting(AwsEc2Service.DISCOVERY_EC2.TAG_SETTING);\n     }\n \n     /**",
    "output": "Add TAG_SETTING to list of allowed tags for the ec2 discovery plugin. I am unable to set ec2 discovery tags because this setting was accidentally omitted from the register settings list in Ec2DiscoveryPlugin.java. I get this: java.lang.IllegalArgumentException: unknown setting [discovery.ec2.tag.project]"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java\n--- a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java\n@@ -395,6 +395,6 @@ public void testEmptySimpleQueryStringWithAnalysis() throws Exception {\n         SearchResponse searchResponse = client().prepareSearch()\n                 .setQuery(simpleQueryStringQuery(\"the*\").analyzeWildcard(true).field(\"body\")).get();\n         assertNoFailures(searchResponse);\n-        assertHitCount(searchResponse, 0l);\n+        assertHitCount(searchResponse, 0L);\n     }\n }",
    "output": "Use uppercase 'L' for long literal"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java\n--- a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java\n@@ -370,4 +370,31 @@ public void testSimpleQueryStringOnIndexMetaField() throws Exception {\n         assertHitCount(searchResponse, 2L);\n         assertSearchHits(searchResponse, \"1\", \"2\");\n     }\n+\n+    public void testEmptySimpleQueryStringWithAnalysis() throws Exception {\n+        // https://github.com/elastic/elasticsearch/issues/18202\n+        String mapping = XContentFactory.jsonBuilder()\n+                .startObject()\n+                .startObject(\"type1\")\n+                .startObject(\"properties\")\n+                .startObject(\"body\")\n+                .field(\"type\", \"string\")\n+                .field(\"analyzer\", \"stop\")\n+                .endObject()\n+                .endObject()\n+                .endObject()\n+                .endObject().string();\n+\n+        CreateIndexRequestBuilder mappingRequest = client().admin().indices()\n+                .prepareCreate(\"test1\")\n+                .addMapping(\"type1\", mapping);\n+        mappingRequest.execute().actionGet();\n+        indexRandom(true, client().prepareIndex(\"test1\", \"type1\", \"1\").setSource(\"body\", \"Some Text\"));\n+        refresh();\n+\n+        SearchResponse searchResponse = client().prepareSearch()\n+                .setQuery(simpleQueryStringQuery(\"the*\").analyzeWildcard(true).field(\"body\")).get();\n+        assertNoFailures(searchResponse);\n+        assertHitCount(searchResponse, 0l);\n+    }\n }",
    "output": "Add test for NullPointerException in SQS when analyzing text produces null query"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/watch/Watch.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/watch/Watch.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/watch/Watch.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/watch/Watch.java\n@@ -73,7 +73,7 @@ public class Watch implements TriggerEngine.Job, ToXContent {\n \n     private final transient AtomicLong nonceCounter = new AtomicLong();\n \n-    private transient long version = Versions.NOT_SET;\n+    private transient long version = Versions.MATCH_ANY;\n \n     public Watch(String id, Trigger trigger, ExecutableInput input, ExecutableCondition condition, @Nullable ExecutableTransform transform,\n                  @Nullable TimeValue throttlePeriod, ExecutableActions actions, @Nullable Map<String, Object> metadata,",
    "output": "Use Versions.MATCH_ANY rather than NOT_SET now that NOT_SET is gone"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/rest/section/DoSection.java b/test/framework/src/main/java/org/elasticsearch/test/rest/section/DoSection.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/rest/section/DoSection.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/rest/section/DoSection.java\n@@ -129,7 +129,11 @@ private void assertStatusCode(RestResponse restResponse) {\n     }\n \n     private String formatStatusCodeMessage(RestResponse restResponse, String expected) {\n-        return \"expected [\" + expected + \"] status code but api [\" + apiCallSection.getApi() + \"] returned [\"\n+        String api = apiCallSection.getApi();\n+        if (\"raw\".equals(api)) {\n+            api += \"[method=\" + apiCallSection.getParams().get(\"method\") + \" path=\" + apiCallSection.getParams().get(\"path\") + \"]\";\n+        }\n+        return \"expected [\" + expected + \"] status code but api [\" + api + \"] returned [\"\n                 + restResponse.getStatusCode() + \" \" + restResponse.getReasonPhrase() + \"] [\" + restResponse.getBodyAsString() + \"]\";\n     }\n ",
    "output": "Improve logging of raw rest actions on failure Log the method and the path"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n@@ -37,6 +37,6 @@ public void testCompatibility() {\n          *\n          */\n         assertThat(\"Remove workaround in LicenseService class when es core supports merging cluster level custom metadata\",\n-                Version.CURRENT.onOrBefore(Version.V_5_0_0_alpha2), is(true));\n+                   Version.CURRENT.equals(Version.V_5_0_0), is(true));\n     }\n }",
    "output": "Use Strict version check for VersionCompatibilityTests This changes the loose usage of onOrBefore to equals so that when we add beta1, this test fails again"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -73,7 +73,9 @@ public class Version {\n     public static final Version V_5_0_0_alpha1 = new Version(V_5_0_0_alpha1_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n     public static final int V_5_0_0_alpha2_ID = 5000002;\n     public static final Version V_5_0_0_alpha2 = new Version(V_5_0_0_alpha2_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n-    public static final Version CURRENT = V_5_0_0_alpha2;\n+    public static final int V_5_0_0_ID = 5000099;\n+    public static final Version V_5_0_0 = new Version(V_5_0_0_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n+    public static final Version CURRENT = V_5_0_0;\n \n     static {\n         assert CURRENT.luceneVersion.equals(org.apache.lucene.util.Version.LATEST) : \"Version must be upgraded to [\"\n@@ -86,6 +88,8 @@ public static Version readVersion(StreamInput in) throws IOException {\n \n     public static Version fromId(int id) {\n         switch (id) {\n+            case V_5_0_0_ID:\n+                return V_5_0_0;\n             case V_5_0_0_alpha2_ID:\n                 return V_5_0_0_alpha2;\n             case V_5_0_0_alpha1_ID:",
    "output": "Add back Version.V_5_0_0. This was lost whene releasing alpha2 since the version constant got renamed"
  },
  {
    "input": "diff --git a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n--- a/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n+++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/Def.java\n@@ -241,7 +241,8 @@ public static Object arrayLoad(final Object array, Object index,\n         }\n     }\n \n-    public static Method getMethod(final Object owner, final String name, final Definition definition) {\n+    /** Method lookup for owner.name(), returns null if no matching method was found */ \n+    private static Method getMethod(final Object owner, final String name, final Definition definition) {\n         Class<?> clazz = owner.getClass();\n \n         while (clazz != null) {\n@@ -273,7 +274,8 @@ public static Method getMethod(final Object owner, final String name, final Defi\n         return null;\n     }\n \n-    public static Field getField(final Object owner, final String name, final Definition definition) {\n+    /** Field lookup for owner.name, returns null if no matching field was found */ \n+    private static Field getField(final Object owner, final String name, final Definition definition) {\n         Class<?> clazz = owner.getClass();\n \n         while (clazz != null) {",
    "output": "Make internal Def methods private and add basic javadocs"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/http/HttpExporterTemplateTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/http/HttpExporterTemplateTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/http/HttpExporterTemplateTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/http/HttpExporterTemplateTests.java\n@@ -133,8 +133,8 @@ public MockResponse dispatch(RecordedRequest request) throws InterruptedExceptio\n                     String[] paths = request.getPath().split(\"/\");\n \n                     // Templates\n-                    if ((paths != null) && (paths.length > 0) && (\"_template\".equals(paths[0]))) {\n-                        String templateName = paths[1];\n+                    if ((paths != null) && (paths.length > 1) && (\"_template\".equals(paths[1]))) {\n+                        String templateName = paths[2];\n                         boolean templateExist = templates.containsKey(templateName);\n \n                         if (\"GET\".equals(request.getMethod())) {",
    "output": "Fix HttpExporterTemplateTests from string split This commit fixes an issue in HttpExporterTemplateTests caused by the migration from Strings#splitStringToArray to String#split. Namely, the previous would split a string like \"/x/y/z/\" into { \"x\", \"y\", \"z\" } but the former will split this into { \"\", \"x\", \"y\", \"z\" }. This commit modifies the test logic to respond to this change"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/support/xcontent/ObjectPath.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/support/xcontent/ObjectPath.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/support/xcontent/ObjectPath.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/xpack/watcher/support/xcontent/ObjectPath.java\n@@ -5,6 +5,8 @@\n  */\n package org.elasticsearch.xpack.watcher.support.xcontent;\n \n+import org.elasticsearch.common.Strings;\n+\n import java.lang.reflect.Array;\n import java.util.List;\n import java.util.Map;\n@@ -22,7 +24,9 @@ public static <T> T eval(String path, Object object) {\n     }\n \n     private static Object evalContext(String path, Object ctx) {\n-        String[] parts = path.split(\"\\\\.\");\n+        final String[] parts;\n+        if (path == null || path.isEmpty()) parts = Strings.EMPTY_ARRAY;\n+        else parts = path.split(\"\\\\.\");\n         StringBuilder resolved = new StringBuilder();\n         for (String part : parts) {\n             if (ctx == null) {",
    "output": "Fix ObjectPath#evalContext edge cases This commit fixes an issue that was introduced in ObjectPath#evalContext when refactoring from Strings#splitStringToArray to String#split. Namely, the former would return an empty array when receiving a null or empty string as input but the latter will NPE on a null string and return an array containing the empty string on an empty string input"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n@@ -638,31 +638,6 @@ public static Version parse(String toParse, Version defaultValue) {\n         }\n     }\n \n-    /**\n-     * Return a Scorer that throws an ElasticsearchIllegalStateException\n-     * on all operations with the given message.\n-     */\n-     public static Scorer illegalScorer(final String message) {\n-         return new Scorer(null) {\n-             @Override\n-             public float score() throws IOException {\n-                 throw new IllegalStateException(message);\n-             }\n-             @Override\n-             public int freq() throws IOException {\n-                 throw new IllegalStateException(message);\n-             }\n-             @Override\n-             public int docID() {\n-                 throw new IllegalStateException(message);\n-             }\n-             @Override\n-             public DocIdSetIterator iterator() {\n-                 throw new IllegalStateException(message);\n-             }\n-         };\n-    }\n-\n     /**\n      * Return a Scorer that throws an ElasticsearchIllegalStateException\n      * on all operations with the given message.",
    "output": "Fix build: restore illegalScorer still in use in ExpressionSearchScript (2)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java b/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n--- a/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n+++ b/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n@@ -27,7 +27,6 @@\n import java.util.Map;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.Executor;\n-import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n import java.util.function.BiConsumer;\n ",
    "output": "Remove unused import from ScalingThreadPoolTests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java b/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n--- a/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n+++ b/core/src/test/java/org/elasticsearch/threadpool/ScalingThreadPoolTests.java\n@@ -27,6 +27,7 @@\n import java.util.Map;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.Executor;\n+import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n import java.util.function.BiConsumer;\n \n@@ -193,7 +194,6 @@ public void testScalingThreadPoolThreadsAreTerminatedAfterKeepAlive() throws Int\n             } catch (InterruptedException e) {\n                 throw new RuntimeException(e);\n             }\n-            assertThat(stats(threadPool, threadPoolName).getCompleted(), equalTo(128L));\n         }));\n     }\n ",
    "output": "Remove racy but unnecessary assertion This commit removes a racy but unnecessary assertion in scaling thread pool idle test. Namely, the main test thread can reach the removed assertion before the last few threads in the thread pool have completed their tasks and caused the completed tasks count on the underlying executor to be updated. But this assertion is unnecessary. The main test thread already waits on a latch that is only decremented immediately before a task completes. This ensures that it was in fact the case that every submitted task was executed"
  },
  {
    "input": "diff --git a/plugins/mapper-attachments/src/test/java/org/elasticsearch/mapper/attachments/MultifieldAttachmentMapperTests.java b/plugins/mapper-attachments/src/test/java/org/elasticsearch/mapper/attachments/MultifieldAttachmentMapperTests.java\n--- a/plugins/mapper-attachments/src/test/java/org/elasticsearch/mapper/attachments/MultifieldAttachmentMapperTests.java\n+++ b/plugins/mapper-attachments/src/test/java/org/elasticsearch/mapper/attachments/MultifieldAttachmentMapperTests.java\n@@ -151,7 +151,6 @@ public void testAllExternalValues() throws Exception {\n         String forcedContentType = randomAsciiOfLength(20);\n \n         String bytes = Base64.encodeBytes(originalText.getBytes(StandardCharsets.ISO_8859_1));\n-        threadPool = new ThreadPool(\"testing-only\");\n \n         MapperService mapperService = MapperTestUtils.newMapperService(createTempDir(),\n             Settings.builder().put(AttachmentMapper.INDEX_ATTACHMENT_DETECT_LANGUAGE_SETTING.getKey(), true).build(),",
    "output": "Fix test in mapper attachments plugin"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ingest/processor/SetProcessor.java b/core/src/main/java/org/elasticsearch/ingest/processor/SetProcessor.java\n--- a/core/src/main/java/org/elasticsearch/ingest/processor/SetProcessor.java\n+++ b/core/src/main/java/org/elasticsearch/ingest/processor/SetProcessor.java\n@@ -88,7 +88,11 @@ public SetProcessor doCreate(String processorTag, Map<String, Object> config) th\n             String field = ConfigurationUtils.readStringProperty(TYPE, processorTag, config, \"field\");\n             Object value = ConfigurationUtils.readObject(TYPE, processorTag, config, \"value\");\n             boolean overrideEnabled = ConfigurationUtils.readBooleanProperty(TYPE, processorTag, config, \"override\", true);\n-            return new SetProcessor(processorTag, templateService.compile(field), ValueSource.wrap(value, templateService), overrideEnabled);\n+            return new SetProcessor(\n+                    processorTag,\n+                    templateService.compile(field),\n+                    ValueSource.wrap(value, templateService),\n+                    overrideEnabled);\n         }\n     }\n }",
    "output": "Fix line-length violation in SetProcessor This commit addresses a checkstyle line-length violation in SetProcessor.java"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/script/ScriptMetaData.java b/core/src/main/java/org/elasticsearch/script/ScriptMetaData.java\n--- a/core/src/main/java/org/elasticsearch/script/ScriptMetaData.java\n+++ b/core/src/main/java/org/elasticsearch/script/ScriptMetaData.java\n@@ -82,12 +82,6 @@ public String getScript(String language, String id) {\n             parser.nextToken();\n             switch (parser.currentName()) {\n                 case \"script\":\n-                    if (parser.nextToken() == Token.VALUE_STRING) {\n-                        return parser.text();\n-                    } else {\n-                        builder.copyCurrentStructure(parser);\n-                    }\n-                    break;\n                 case \"template\":\n                     if (parser.nextToken() == Token.VALUE_STRING) {\n                         return parser.text();",
    "output": "Remove duplicated code"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java b/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java\n--- a/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java\n+++ b/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java\n@@ -50,7 +50,6 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         //Have very low pool and queue sizes to overwhelm internal pools easily\n         return Settings.builder()\n                 .put(super.nodeSettings(nodeOrdinal))\n-                .put(\"threadpool.generic.max\", 4)\n                 // don't mess with this one! It's quite sensitive to a low queue size\n                 // (see also ThreadedActionListener which is happily spawning threads even when we already got rejected)\n                 //.put(\"threadpool.listener.queue_size\", 1)",
    "output": "Remove BulkProcessorRetryIT's generic threadpool setting It wasn't required to excercise the retries and it caused stability issues"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java\n@@ -114,7 +114,7 @@ public UnassignedInfo getUnassignedInfo() {\n         return this.unassignedInfo;\n     }\n \n-    /** Return the remaining allocation delay for this shard in nanoseconds */\n+    /** Return the remaining allocation delay for this shard in millisocends */\n     public long getRemainingDelayMillis() {\n         return this.remainingDelayMillis;\n     }\n@@ -142,8 +142,8 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n             if (unassignedInfo != null) {\n                 unassignedInfo.toXContent(builder, params);\n                 long delay = unassignedInfo.getLastComputedLeftDelayNanos();\n-                builder.timeValueField(\"allocation_delay_ms\", \"allocation_delay\", TimeValue.timeValueNanos(delay));\n-                builder.timeValueField(\"remaining_delay_ms\", \"remaining_delay\", TimeValue.timeValueMillis(remainingDelayMillis));\n+                builder.timeValueField(\"allocation_delay_in_millis\", \"allocation_delay\", TimeValue.timeValueNanos(delay));\n+                builder.timeValueField(\"remaining_delay_in_millis\", \"remaining_delay\", TimeValue.timeValueMillis(remainingDelayMillis));\n             }\n             builder.startObject(\"nodes\");\n             for (NodeExplanation explanation : nodeExplanations.values()) {",
    "output": "Use \"_in_millis\" for the suffix of delay times Also change the javadoc to say \"milliseconds\" instead of \"nanoseconds\""
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java\n--- a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java\n+++ b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java\n@@ -286,8 +286,6 @@ protected final Query termQuery(MappedFieldType fieldType, Object value, boolean\n     }\n \n     protected Query zeroTermsQuery() {\n-        // TODO This is weird: DEFAULT_ZERO_TERMS_QUERY is a public static final field, so this can have only one value.\n-        // why are we then having this if clause in here?\n         return zeroTermsQuery == DEFAULT_ZERO_TERMS_QUERY ? Queries.newMatchNoDocsQuery() : Queries.newMatchAllQuery();\n     }\n ",
    "output": "Remove question concerning default no docs query"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/allocation/ClusterAllocationExplanation.java\n@@ -19,12 +19,8 @@\n \n package org.elasticsearch.action.admin.cluster.allocation;\n \n-import org.apache.lucene.index.CorruptIndexException;\n-import org.elasticsearch.ExceptionsHelper;\n-import org.elasticsearch.action.admin.indices.shards.IndicesShardStoresResponse;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n import org.elasticsearch.cluster.routing.UnassignedInfo;\n-import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n@@ -33,16 +29,10 @@\n import org.elasticsearch.common.xcontent.ToXContent;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.index.shard.ShardId;\n-import org.elasticsearch.index.shard.ShardStateMetaData;\n \n import java.io.IOException;\n-import java.util.ArrayList;\n-import java.util.Collections;\n import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Set;\n \n /**\n  * A {@code ClusterAllocationExplanation} is an explanation of why a shard may or may not be allocated to nodes. It also includes weights",
    "output": "Remove unneeded imports"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n@@ -37,6 +37,6 @@ public void testCompatibility() {\n          *\n          */\n         assertThat(\"Remove workaround in LicenseService class when es core supports merging cluster level custom metadata\",\n-                Version.CURRENT.onOrBefore(Version.V_5_0_0), is(true));\n+                Version.CURRENT.onOrBefore(Version.V_5_0_0_alpha2), is(true));\n     }\n }",
    "output": "Fix compilation issue"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java\n@@ -397,7 +397,7 @@ public List<ShardRouting> shardsWithState(String index, ShardRoutingState... sta\n         for (ShardRoutingState s : state) {\n             if (s == ShardRoutingState.UNASSIGNED) {\n                 for (ShardRouting unassignedShard : unassignedShards) {\n-                    if (unassignedShard.index().equals(index)) {\n+                    if (unassignedShard.index().getName().equals(index)) {\n                         shards.add(unassignedShard);\n                     }\n                 }",
    "output": "Fix index name equality check in RoutingNodes This commit fixes an index name equality check in RoutingNodes. Namely, the check was comparing an instance of Index to an instance of String. Instead, the index name should be obtained from the Index instance to be compared to the instance of String"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/action/MonitoringBulkResponse.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/action/MonitoringBulkResponse.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/action/MonitoringBulkResponse.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/action/MonitoringBulkResponse.java\n@@ -87,6 +87,11 @@ public Error(Throwable t) {\n             this(in.<Throwable>readThrowable());\n         }\n \n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            out.writeThrowable(getCause());\n+        }\n+\n         /**\n          * The failure message.\n          */\n@@ -108,16 +113,6 @@ public Throwable getCause() {\n             return cause;\n         }\n \n-        @Override\n-        public Error readFrom(StreamInput in) throws IOException {\n-            return new Error(in);\n-        }\n-\n-        @Override\n-        public void writeTo(StreamOutput out) throws IOException {\n-            out.writeThrowable(getCause());\n-        }\n-\n         @Override\n         public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n             builder.startObject();",
    "output": "Remove the last readFrom from xpack This the last Writeable#readFrom in xpack!"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java\n@@ -59,7 +59,6 @@\n import java.util.Collections;\n import java.util.Map;\n \n-import static java.lang.Math.abs;\n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;\n import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;\n@@ -201,13 +200,13 @@ private static DecayFunctionBuilder<?> createRandomDecayFunction() {\n             break;\n         case DATE_FIELD_NAME:\n             origin = new DateTime(System.currentTimeMillis() - randomIntBetween(0, 1000000), DateTimeZone.UTC).toString();\n-            scale = randomTimeValue();\n-            offset = randomTimeValue();\n+            scale = randomPositiveTimeValue();\n+            offset = randomPositiveTimeValue();\n             break;\n         default:\n             origin = randomBoolean() ? randomInt() : randomFloat();\n-            scale = randomBoolean() ? abs(randomInt()) : abs(randomFloat());\n-            offset = randomBoolean() ? abs(randomInt()) : abs(randomFloat());\n+            scale = randomBoolean() ? between(1, Integer.MAX_VALUE) : randomFloat() + Float.MIN_NORMAL;\n+            offset = randomBoolean() ? between(1, Integer.MAX_VALUE) : randomFloat() + Float.MIN_NORMAL;\n             break;\n         }\n         offset = randomBoolean() ? null : offset;",
    "output": "Fix random bounds 0 is invalid so we don't generate it any more"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/actions/pagerduty/PagerDutyActionTests.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/actions/pagerduty/PagerDutyActionTests.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/actions/pagerduty/PagerDutyActionTests.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/actions/pagerduty/PagerDutyActionTests.java\n@@ -158,7 +158,7 @@ public void testParser() throws Exception {\n         TextTemplate eventType = null;\n         if (randomBoolean()) {\n             eventType = TextTemplate.inline(randomFrom(\"trigger\", \"resolve\", \"acknowledge\")).build();\n-            builder.field(\"eventType\", eventType);\n+            builder.field(\"event_type\", eventType);\n         }\n \n         Boolean attachPayload = randomBoolean() ? null : randomBoolean();",
    "output": "Use underscore notation for field names Relates elastic/elasticsearchelastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java b/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/DocumentParserTests.java\n@@ -90,6 +90,7 @@ public void testDotsWithExistingMapper() throws Exception {\n             .endObject()\n             .endObject().bytes();\n         ParsedDocument doc = mapper.parse(\"test\", \"type\", \"1\", bytes);\n+        assertNull(doc.dynamicMappingsUpdate()); // no update!\n         String[] values = doc.rootDoc().getValues(\"foo.bar.baz\");\n         assertEquals(3, values.length);\n         assertEquals(\"123\", values[0]);",
    "output": "Add check that no dynamic update was done with existing mappings and dots"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java b/core/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n--- a/core/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n+++ b/core/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n@@ -276,7 +276,7 @@ public void testNegativeShardInactiveTime() {\n \n     }\n \n-    public void testNegative() {\n+    public void testNegativeMaxIndexBufferSize() {\n         Exception e = expectThrows(IllegalArgumentException.class,\n                                    () -> new MockController(Settings.builder()\n                                                             .put(\"indices.memory.max_index_buffer_size\", \"-6mb\").build()));",
    "output": "Fix test method name"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregatorBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregatorBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregatorBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregatorBuilder.java\n@@ -186,7 +186,7 @@ protected XContentBuilder internalXContent(XContentBuilder builder, Params param\n             builder.field(GAP_POLICY_FIELD.getPreferredName(), gapPolicy.getName());\n         }\n         if (units != null) {\n-            builder.field(FORMAT_FIELD.getPreferredName(), units);\n+            builder.field(UNIT_FIELD.getPreferredName(), units);\n         }\n         return builder;\n     }",
    "output": "Fix bad toXContent for derivative aggregation I busted it in the last commit"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherDateTimeUtils.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherDateTimeUtils.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherDateTimeUtils.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherDateTimeUtils.java\n@@ -25,7 +25,7 @@\n  */\n public class WatcherDateTimeUtils {\n \n-    public static final FormatDateTimeFormatter dateTimeFormatter = DateFieldMapper.Defaults.DATE_TIME_FORMATTER;\n+    public static final FormatDateTimeFormatter dateTimeFormatter = DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER;\n     public static final DateMathParser dateMathParser = new DateMathParser(dateTimeFormatter);\n \n     private WatcherDateTimeUtils() {",
    "output": "Fix compile error due to change in DateFieldMapper"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamableReader.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamableReader.java\n--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamableReader.java\n+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamableReader.java\n@@ -1,33 +0,0 @@\n-/*\n- * Licensed to Elasticsearch under one or more contributor\n- * license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright\n- * ownership. Elasticsearch licenses this file to you under\n- * the Apache License, Version 2.0 (the \"License\"); you may\n- * not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-package org.elasticsearch.common.io.stream;\n-\n-import java.io.IOException;\n-\n-/**\n- * Implementers can be read from {@linkplain StreamInput} by calling their {@link #readFrom(StreamInput)} method.\n- *\n- * Implementers of this interface that also implement {@link Writeable} should see advice there on how to do so.\n- */\n-public interface StreamableReader<T> {\n-    /**\n-     * Reads an object of this type from the provided {@linkplain StreamInput}. The receiving instance remains unchanged.\n-     */\n-    T readFrom(StreamInput in) throws IOException;\n-}",
    "output": "Remove StreamableReader It's use tempted the creation of PROTOTYPEs. The only classes that legitimately implement a readFrom method are those extending from Diffable - such behavior is part of cluster state management and out of scope for the PROTOTYPE cleanup"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/monitor/jvm/JvmInfoTests.java b/core/src/test/java/org/elasticsearch/monitor/jvm/JvmInfoTests.java\n--- a/core/src/test/java/org/elasticsearch/monitor/jvm/JvmInfoTests.java\n+++ b/core/src/test/java/org/elasticsearch/monitor/jvm/JvmInfoTests.java\n@@ -29,7 +29,7 @@ public void testUseG1GC() {\n         // if we are running on HotSpot, and the test JVM was started\n         // with UseG1GC, then JvmInfo should successfully report that\n         // G1GC is enabled\n-        if (Constants.JVM_NAME.contains(\"HotSpot\")) {\n+        if (Constants.JVM_NAME.contains(\"HotSpot\") || Constants.JVM_NAME.contains(\"OpenJDK\")) {\n             assertEquals(Boolean.toString(isG1GCEnabled()), JvmInfo.jvmInfo().useG1GC());\n         } else {\n             assertEquals(\"unknown\", JvmInfo.jvmInfo().useG1GC());",
    "output": "Fix JvmInfoTests#testUseG1GC to include OpenJDK VMs Since OpenJDK virtual machines have G1 GC but do not have a java.vm.name that contains HotSpot, this test fails on OpenJDK. Instead, the java.vm.name condition should be expanded to include OpenJDK virtual machines"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/esnative/ReservedRealmTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/esnative/ReservedRealmTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/esnative/ReservedRealmTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/esnative/ReservedRealmTests.java\n@@ -129,6 +129,6 @@ public void testHelperMethods() {\n         assertThat(ReservedRealm.isReserved(notExpected), is(false));\n         assertThat(ReservedRealm.getUser(notExpected), nullValue());\n \n-        assertThat(ReservedRealm.users(), containsInAnyOrder(XPackUser.INSTANCE, KibanaUser.INSTANCE));\n+        assertThat(ReservedRealm.users(), containsInAnyOrder((User) XPackUser.INSTANCE, KibanaUser.INSTANCE));\n     }\n }",
    "output": "Fix Eclipse Compile error in ReservedRealmTests The eclipse compiler errors on this class because \"the method containsInAnyOrder(T...) of type Matchers is not applicable as the formal varargs element type T is not accessible here\". This is because the first common superclass of `XPackUser` and `KibanaUser` is `ReservedUser` which is package protected and not available to this test class. This change casts to `User` so the error does not occur in Eclipse"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java b/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java\n@@ -90,11 +90,13 @@ public class ZenDiscoveryIT extends ESIntegTestCase {\n     @Before\n     public void computePrevMajorVersion() {\n         Version previousMajor;\n-        // find a GA build whose major version is N-1\n+        // find a GA build whose major version is <N\n         do {\n             previousMajor = VersionUtils.randomVersion(random());\n-        } while (previousMajor.major != Version.CURRENT.major - 1\n-                && (previousMajor.isAlpha() || previousMajor.isBeta() || previousMajor.isRC()));\n+        } while (previousMajor.onOrAfter(Version.CURRENT.minimumCompatibilityVersion())\n+                || previousMajor.isAlpha()\n+                || previousMajor.isBeta()\n+                || previousMajor.isRC());\n         previousMajorVersion = previousMajor;\n     }\n ",
    "output": "Fix test bug in ZenDiscoveryIT"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorBuilder.java\n@@ -71,7 +71,7 @@ protected AggregatorBuilder(StreamInput in, Type type) throws IOException {\n         metaData = in.readMap();\n     }\n \n-    protected boolean usesNewStyleSerialization() {\n+    protected boolean usesNewStyleSerialization() { // NORELEASE remove this before 5.0.0GA, when all the aggregations have been migrated\n         return false;\n     }\n ",
    "output": "Add NORELEASE while we migrate aggregations"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n@@ -113,7 +113,7 @@ public static SearchRequest readSearchRequest(XContentParser parser, SearchType\n             if (token == XContentParser.Token.FIELD_NAME) {\n                 currentFieldName = parser.currentName();\n                 if (ParseFieldMatcher.STRICT.match(currentFieldName, BODY_FIELD)) {\n-                    searchRequest.source(SearchSourceBuilder.parseSearchSource(parser, context, aggParsers, suggesters));\n+                    searchRequest.source(SearchSourceBuilder.fromXContent(parser, context, aggParsers, suggesters));\n                 }\n             } else if (token == XContentParser.Token.START_ARRAY) {\n                 if (ParseFieldMatcher.STRICT.match(currentFieldName, INDICES_FIELD)) {",
    "output": "Fix compilation error from core change Relates https://github.com/elastic/elasticsearch/commit/2c487110b2508ea50f311894fa8ed88240e3eef5"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/sort/SortBuilder.java b/core/src/main/java/org/elasticsearch/search/sort/SortBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/sort/SortBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/sort/SortBuilder.java\n@@ -34,7 +34,6 @@\n import org.elasticsearch.index.query.QueryParseContext;\n import org.elasticsearch.index.query.QueryShardContext;\n import org.elasticsearch.index.query.QueryShardException;\n-import org.elasticsearch.search.internal.SearchContext;\n \n import java.io.IOException;\n import java.util.ArrayList;\n@@ -143,15 +142,6 @@ private static void parseCompoundSortField(XContentParser parser, QueryParseCont\n         }\n     }\n \n-    public static void parseSort(XContentParser parser, SearchContext context) throws IOException {\n-        QueryParseContext parseContext = context.getQueryShardContext().parseContext();\n-        parseContext.reset(parser);\n-        Optional<Sort> sortOptional = buildSort(SortBuilder.fromXContent(parseContext), context.getQueryShardContext());\n-        if (sortOptional.isPresent()) {\n-            context.sort(sortOptional.get());\n-        }\n-    }\n-\n     public static Optional<Sort> buildSort(List<SortBuilder<?>> sortBuilders, QueryShardContext context) throws IOException {\n         List<SortField> sortFields = new ArrayList<>(sortBuilders.size());\n         for (SortBuilder<?> builder : sortBuilders) {",
    "output": "Remove unused parse method from SortBuilder"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/Security.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/Security.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/Security.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/Security.java\n@@ -258,12 +258,11 @@ public void onIndexModule(IndexModule module) {\n                     shieldLicenseState));\n         }\n         if (transportClientMode == false) {\n-            module.registerQueryCache(Security.OPT_OUT_QUERY_CACHE, OptOutQueryCache::new);\n             /*  We need to forcefully overwrite the query cache implementation to use Shield's opt out query cache implementation.\n              *  This impl. disabled the query cache if field level security is used for a particular request. If we wouldn't do\n              *  forcefully overwrite the query cache implementation then we leave the system vulnerable to leakages of data to\n              *  unauthorized users. */\n-            module.forceQueryCacheType(Security.OPT_OUT_QUERY_CACHE);\n+            module.forceQueryCacheProvider(OptOutQueryCache::new);\n         }\n     }\n ",
    "output": "Fix compilation as a result of elastic/elasticsearchelastic/elasticsearch#16268"
  },
  {
    "input": "diff --git a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n--- a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n+++ b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n@@ -73,7 +73,7 @@ public abstract class ESSmokeClientTestCase extends LuceneTestCase {\n     protected String index;\n \n     private static Client startClient(Path tempDir, TransportAddress... transportAddresses) {\n-        Settings clientSettings = Settings.settingsBuilder()\n+        Settings clientSettings = Settings.builder()\n                 .put(\"node.name\", \"qa_smoke_client_\" + counter.getAndIncrement())\n                 .put(InternalSettingsPreparer.IGNORE_SYSTEM_PROPERTIES_SETTING.getKey(), true) // prevents any settings to be replaced by system properties.\n                 .put(\"client.transport.ignore_cluster_name\", true)",
    "output": "Use Settings.builder instead of settingsBuilder in ESSmokeClientTestCase"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -36,7 +36,6 @@\n import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n import org.elasticsearch.cluster.service.ClusterService;\n import org.elasticsearch.common.Priority;\n-import org.elasticsearch.common.SuppressForbidden;\n import org.elasticsearch.common.component.AbstractLifecycleComponent;\n import org.elasticsearch.common.component.Lifecycle;\n import org.elasticsearch.common.inject.Inject;\n@@ -774,7 +773,6 @@ public void clusterStateProcessed(String source, ClusterState oldState, ClusterS\n      * If the first condition fails we reject the cluster state and throw an error.\n      * If the second condition fails we ignore the cluster state.\n      */\n-    @SuppressForbidden(reason = \"debug\")\n     public static boolean shouldIgnoreOrRejectNewClusterState(ESLogger logger, ClusterState currentState, ClusterState newClusterState) {\n         validateStateIsFromCurrentMaster(logger, currentState.nodes(), newClusterState);\n ",
    "output": "Remove leftover forbidden suppression in ZD"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -296,7 +296,7 @@ private ClusterState applyRequest(ClusterState currentState, PutMappingClusterSt\n             }\n             assert mappingType != null;\n \n-            if (!MapperService.DEFAULT_MAPPING.equals(mappingType) && !PercolatorFieldMapper.TYPE_NAME.equals(mappingType) && mappingType.charAt(0) == '_') {\n+            if (!MapperService.DEFAULT_MAPPING.equals(mappingType) && mappingType.charAt(0) == '_') {\n                 throw new InvalidTypeNameException(\"Document mapping type name can't start with '_'\");\n             }\n             MetaData.Builder builder = MetaData.builder(metaData);\n\ndiff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n@@ -806,9 +806,6 @@ public void close(String reason, boolean flushEngine) throws IOException {\n     }\n \n     public IndexShard postRecovery(String reason) throws IndexShardStartedException, IndexShardRelocatedException, IndexShardClosedException {\n-        if (mapperService.hasMapping(PercolatorFieldMapper.TYPE_NAME)) {\n-            refresh(\"percolator_load_queries\");\n-        }\n         synchronized (mutex) {\n             if (state == IndexShardState.CLOSED) {\n                 throw new IndexShardClosedException(shardId);",
    "output": "Remove unneeded refresh during post recovery. and removed an obsolete exception, `_percolator` type is now `.percolator` since version 1.0"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n@@ -419,20 +419,6 @@ void validateIncomingState(ClusterState incomingState, ClusterState lastSeenClus\n             throw new IllegalStateException(message);\n         }\n \n-        if (lastSeenClusterState != null && lastSeenClusterState.supersedes(incomingState)) {\n-            final String message = String.format(\n-                    Locale.ROOT,\n-                    \"received cluster state from current master superseded by last seen cluster state; \" +\n-                            \"received version [%d] with uuid [%s], last seen version [%d] with uuid [%s]\",\n-                    incomingState.version(),\n-                    incomingState.stateUUID(),\n-                    lastSeenClusterState.version(),\n-                    lastSeenClusterState.stateUUID()\n-            );\n-            logger.warn(message);\n-            throw new IllegalStateException(message);\n-        }\n-\n     }\n \n     protected void handleCommitRequest(CommitClusterStateRequest request, final TransportChannel channel) {",
    "output": "Remove superfluous validation of incoming states This commit removes a superfluous check when validing incoming cluster states. The check in question prevents out-of-order cluster states from the same master from entering the queue. However, such out-of-order cluster states will be cleaned from the queue when a commit message for that cluster state arrives or a commit message for any higher-versioned cluster state arrives"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n@@ -532,7 +532,7 @@ public void waitForCommit(TimeValue commitTimeout) {\n             }\n \n             if (timedout) {\n-                markAsFailed(\"timed out waiting for commit (commit timeout [\" + commitTimeout + \"]\");\n+                markAsFailed(\"timed out waiting for commit (commit timeout [\" + commitTimeout + \"])\");\n             }\n             if (isCommitted() == false) {\n                 throw new Discovery.FailedToCommitClusterStateException(\"{} enough masters to ack sent cluster state. [{}] left\",",
    "output": "Fix missing parenthesis in commit timeout message"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/VersionType.java b/core/src/main/java/org/elasticsearch/index/VersionType.java\n--- a/core/src/main/java/org/elasticsearch/index/VersionType.java\n+++ b/core/src/main/java/org/elasticsearch/index/VersionType.java\n@@ -266,8 +266,6 @@ public boolean validateVersionForReads(long version) {\n \n     private final byte value;\n \n-    private static final VersionType PROTOTYPE = INTERNAL;\n-\n     VersionType(byte value) {\n         this.value = value;\n     }\n@@ -383,17 +381,12 @@ public static VersionType fromValue(byte value) {\n         throw new IllegalArgumentException(\"No version type match [\" + value + \"]\");\n     }\n \n-    @Override\n-    public VersionType readFrom(StreamInput in) throws IOException {\n+    public static VersionType readVersionTypeFrom(StreamInput in) throws IOException {\n         int ordinal = in.readVInt();\n         assert (ordinal == 0 || ordinal == 1 || ordinal == 2 || ordinal == 3);\n         return VersionType.values()[ordinal];\n     }\n \n-    public static VersionType readVersionTypeFrom(StreamInput in) throws IOException {\n-        return PROTOTYPE.readFrom(in);\n-    }\n-\n     @Override\n     public void writeTo(StreamOutput out) throws IOException {\n         out.writeVInt(ordinal());",
    "output": "Remove PROTOTYPE from VersionType"
  },
  {
    "input": "diff --git a/elasticsearch/license/base/src/test/java/org/elasticsearch/license/core/LicenseOperationModeTests.java b/elasticsearch/license/base/src/test/java/org/elasticsearch/license/core/LicenseOperationModeTests.java\n--- a/elasticsearch/license/base/src/test/java/org/elasticsearch/license/core/LicenseOperationModeTests.java\n+++ b/elasticsearch/license/base/src/test/java/org/elasticsearch/license/core/LicenseOperationModeTests.java\n@@ -7,6 +7,8 @@\n \n import org.elasticsearch.test.ESTestCase;\n \n+import java.util.Locale;\n+\n import static org.elasticsearch.license.core.License.OperationMode;\n import static org.hamcrest.Matchers.equalTo;\n \n@@ -52,7 +54,7 @@ public void testResolveUnknown() {\n             try {\n                 OperationMode.resolve(type);\n \n-                fail(String.format(\"[%s] should not be recognized as an operation mode\", type));\n+                fail(String.format(Locale.ROOT, \"[%s] should not be recognized as an operation mode\", type));\n             }\n             catch (IllegalArgumentException e) {\n                 assertThat(e.getMessage(), equalTo(\"unknown type [\" + type + \"]\"));",
    "output": "Add Locale.ROOT to String.format for forbidden API usage"
  },
  {
    "input": "diff --git a/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java b/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java\n--- a/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java\n+++ b/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java\n@@ -14,7 +14,6 @@\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.shield.transport.netty.ShieldNettyTransport;\n import org.elasticsearch.test.ESIntegTestCase;\n-import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.elasticsearch.xpack.XPackPlugin;\n import org.junit.After;\n import org.junit.AfterClass;\n@@ -43,7 +42,6 @@\n  * then uses a transport client to check that the data have been correctly received and\n  * indexed in the cluster.\n  */\n-@TestLogging(\"org.elasticsearch.action.admin.cluster.settings:DEBUG\")\n public class SmokeTestMonitoringWithShieldIT extends ESIntegTestCase {\n \n     private static final String USER = \"test_user\";",
    "output": "Remove test logger now that fix is in"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n@@ -918,9 +918,9 @@ public void testSycnedFlushSurvivesEngineRestart() throws IOException {\n         } else {\n             engine.flushAndClose();\n         }\n-        engine = new InternalEngine(copy(config, EngineConfig.OpenMode.OPEN_INDEX_AND_TRANSLOG));\n+        engine = new InternalEngine(copy(config, randomFrom(EngineConfig.OpenMode.OPEN_INDEX_AND_TRANSLOG, EngineConfig.OpenMode.OPEN_INDEX_CREATE_TRANSLOG)));\n \n-        if (randomBoolean()) {\n+        if (engine.config().getOpenMode() == EngineConfig.OpenMode.OPEN_INDEX_AND_TRANSLOG && randomBoolean()) {\n             engine.recoverFromTranslog();\n         }\n         assertEquals(engine.getLastCommittedSegmentInfos().getUserData().get(Engine.SYNC_COMMIT_ID), syncId);",
    "output": "Add back opem mode randomization"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/sort/ScoreSortBuilder.java b/core/src/main/java/org/elasticsearch/search/sort/ScoreSortBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/sort/ScoreSortBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/sort/ScoreSortBuilder.java\n@@ -39,9 +39,7 @@\n public class ScoreSortBuilder extends SortBuilder<ScoreSortBuilder> {\n \n     public static final String NAME = \"_score\";\n-    public static final ParseField REVERSE_FIELD = new ParseField(\"reverse\");\n     public static final ParseField ORDER_FIELD = new ParseField(\"order\");\n-    private static final ParseField REVERSE_FORBIDDEN = new ParseField(\"reverse\");\n     private static final SortField SORT_SCORE = new SortField(null, SortField.Type.SCORE);\n     private static final SortField SORT_SCORE_REVERSE = new SortField(null, SortField.Type.SCORE, true);\n ",
    "output": "Remove unused 'reverse' parse field from ScoreSortBuilder"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -62,6 +62,8 @@ public class Version {\n     public static final Version V_2_2_0 = new Version(V_2_2_0_ID, org.apache.lucene.util.Version.LUCENE_5_4_1);\n     public static final int V_2_2_1_ID = 2020199;\n     public static final Version V_2_2_1 = new Version(V_2_2_1_ID, org.apache.lucene.util.Version.LUCENE_5_4_1);\n+    public static final int V_2_2_2_ID = 2020299;\n+    public static final Version V_2_2_2 = new Version(V_2_2_2_ID, org.apache.lucene.util.Version.LUCENE_5_4_1);\n     public static final int V_2_3_0_ID = 2030099;\n     public static final Version V_2_3_0 = new Version(V_2_3_0_ID, org.apache.lucene.util.Version.LUCENE_5_5_0);\n     public static final int V_5_0_0_alpha1_ID = 5000001;\n@@ -83,6 +85,8 @@ public static Version fromId(int id) {\n                 return V_5_0_0_alpha1;\n             case V_2_3_0_ID:\n                 return V_2_3_0;\n+            case V_2_2_2_ID:\n+                return V_2_2_2;\n             case V_2_2_1_ID:\n                 return V_2_2_1;\n             case V_2_2_0_ID:",
    "output": "Add bwc indices for 2.2.2 and 2.3.0"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/support/InnerHitBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/support/InnerHitBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/support/InnerHitBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/support/InnerHitBuilderTests.java\n@@ -236,10 +236,12 @@ static InnerHitBuilder mutate(InnerHitBuilder innerHits) throws IOException {\n                 }));\n                 break;\n             case 9:\n-                copy.setSorts(randomValueOtherThan(copy.getSorts(), () -> {\n-                    return randomListStuff(16,\n-                            () -> SortBuilders.fieldSort(randomAsciiOfLengthBetween(5, 20)).order(randomFrom(SortOrder.values())));\n-                }));\n+                final List<SortBuilder<?>> sortBuilders = randomValueOtherThan(copy.getSorts(), () -> {\n+                    List<SortBuilder<?>> builders = randomListStuff(16,\n+                        () -> SortBuilders.fieldSort(randomAsciiOfLengthBetween(5, 20)).order(randomFrom(SortOrder.values())));\n+                    return builders;\n+                });\n+                copy.setSorts(sortBuilders);\n                 break;\n             case 10:\n                 copy.setHighlightBuilder(randomValueOtherThan(copy.getHighlightBuilder(),",
    "output": "Make type inference simpler"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java\n@@ -100,7 +100,8 @@ public void testNoNodesIndexing() throws Exception {\n         logger.debug(\"--> ensure that the 'nodes' attributes of the cluster state document is not indexed\");\n         assertHitCount(client().prepareSearch().setSize(0)\n                 .setTypes(ClusterStateResolver.TYPE)\n-                .setQuery(matchQuery(\"cluster_state.nodes.\" + nodes.getMasterNodeId() + \".name\", nodes.getMasterNode().getName())).get(), 0L);\n+                .setQuery(matchQuery(\"cluster_state.nodes.\" + nodes.getMasterNodeId() + \".name\",\n+                        nodes.getMasterNode().getName())).get(), 0L);\n     }\n \n     public void testClusterStateNodes() throws Exception {",
    "output": "Fix checkstyle line lenght issue"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java b/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n@@ -565,7 +565,8 @@ public void writeTo(StreamOutput out) throws IOException {\n     }\n \n     private PingResponse createPingResponse(DiscoveryNodes discoNodes) {\n-        return new PingResponse(discoNodes.getLocalNode(), discoNodes.getMasterNode(), clusterName, contextProvider.nodeHasJoinedClusterOnce());\n+        return new PingResponse(discoNodes.getLocalNode(), discoNodes.getMasterNode(), clusterName,\n+                contextProvider.nodeHasJoinedClusterOnce());\n     }\n \n     static class UnicastPingResponse extends TransportResponse {",
    "output": "Fix checkstyle line lenght issue"
  },
  {
    "input": "diff --git a/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/NoMasterNodeIT.java b/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/NoMasterNodeIT.java\n--- a/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/NoMasterNodeIT.java\n+++ b/elasticsearch/qa/messy-test-xpack-with-mustache/src/test/java/org/elasticsearch/messy/tests/NoMasterNodeIT.java\n@@ -271,7 +271,7 @@ private void stopElectedMasterNodeAndWait() throws Exception {\n             public void run () {\n                 for (Client client : clients()) {\n                     ClusterState state = client.admin().cluster().prepareState().setLocal(true).get().getState();\n-                    assertThat(\"Node [\" + state.nodes().localNode() + \"] should have a NO_MASTER_BLOCK\",\n+                    assertThat(\"Node [\" + state.nodes().getLocalNode() + \"] should have a NO_MASTER_BLOCK\",\n                             state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), is(true));\n                 }\n             }",
    "output": "Remove DiscoveryNodes#localNode in favour of existing DiscoveryNodes#getLocalNode"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStateTests.java\n@@ -100,7 +100,7 @@ public void testNoNodesIndexing() throws Exception {\n         logger.debug(\"--> ensure that the 'nodes' attributes of the cluster state document is not indexed\");\n         assertHitCount(client().prepareSearch().setSize(0)\n                 .setTypes(ClusterStateResolver.TYPE)\n-                .setQuery(matchQuery(\"cluster_state.nodes.\" + nodes.masterNodeId() + \".name\", nodes.masterNode().getName())).get(), 0L);\n+                .setQuery(matchQuery(\"cluster_state.nodes.\" + nodes.getMasterNodeId() + \".name\", nodes.masterNode().getName())).get(), 0L);\n     }\n \n     public void testClusterStateNodes() throws Exception {",
    "output": "Remove DiscoveryNodes#masterNodeId in favour of existing DiscoveryNodes#getMasterNodeId"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java\n--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java\n@@ -77,14 +77,6 @@ public Iterator<DiscoveryNode> iterator() {\n         return nodes.valuesIt();\n     }\n \n-    /**\n-     * Is this a valid nodes that has the minimal information set. The minimal set is defined\n-     * by the localNodeId being set.\n-     */\n-    public boolean valid() {\n-        return localNodeId != null;\n-    }\n-\n     /**\n      * Returns <tt>true</tt> if the local node is the elected master node.\n      */",
    "output": "Remove unused DiscoveryNodes#valid method"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n@@ -35,7 +35,6 @@\n import java.util.Collections;\n import java.util.EnumSet;\n import java.util.HashMap;\n-import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import java.util.function.Predicate;\n@@ -80,8 +79,6 @@ public static boolean isIngestNode(Settings settings) {\n         return Node.NODE_INGEST_SETTING.get(settings);\n     }\n \n-    public static final List<DiscoveryNode> EMPTY_LIST = Collections.emptyList();\n-\n     private final String nodeName;\n     private final String nodeId;\n     private final String hostName;\n\ndiff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java\n--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java\n@@ -480,10 +480,6 @@ public String prettyPrint() {\n         return sb.toString();\n     }\n \n-    public Delta emptyDelta() {\n-        return new Delta(null, null, localNodeId, DiscoveryNode.EMPTY_LIST, DiscoveryNode.EMPTY_LIST);\n-    }\n-\n     public static class Delta {\n \n         private final String localNodeId;",
    "output": "Remove unused emptyDelta method from DiscoveryNodes and related EMPTY_LIST from DiscoveryNode"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java\n--- a/core/src/main/java/org/elasticsearch/node/Node.java\n+++ b/core/src/main/java/org/elasticsearch/node/Node.java\n@@ -131,8 +131,6 @@ public class Node implements Closeable {\n \n     public static final Setting<Boolean> WRITE_PORTS_FIELD_SETTING =\n         Setting.boolSetting(\"node.portsfile\", false, Property.NodeScope);\n-    public static final Setting<Boolean> NODE_CLIENT_SETTING =\n-        Setting.boolSetting(\"node.client\", false, Property.NodeScope);\n     public static final Setting<Boolean> NODE_DATA_SETTING = Setting.boolSetting(\"node.data\", true, Property.NodeScope);\n     public static final Setting<Boolean> NODE_MASTER_SETTING =\n         Setting.boolSetting(\"node.master\", true, Property.NodeScope);",
    "output": "Remove unused 'node.client' setting"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java\n@@ -53,7 +53,7 @@ public void testNodeStatsCollector() throws Exception {\n             assertThat(nodeStatsMarvelDoc.getSourceNode(), notNullValue());\n \n             assertThat(nodeStatsMarvelDoc.getNodeId(),\n-                    equalTo(internalCluster().getInstance(ClusterService.class, node).localNode().id()));\n+                    equalTo(internalCluster().getInstance(ClusterService.class, node).localNode().getId()));\n             assertThat(nodeStatsMarvelDoc.isNodeMaster(), equalTo(node.equals(internalCluster().getMasterName())));\n             assertThat(nodeStatsMarvelDoc.isMlockall(), equalTo(BootstrapInfo.isMemoryLocked()));\n             assertNotNull(nodeStatsMarvelDoc.isDiskThresholdDeciderEnabled());",
    "output": "Remove DiscoveryNode#id in favour of existing DiscoveryNode#getId"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java\n--- a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java\n@@ -654,7 +654,7 @@ public static List<String> fill(List<String> list, String value, int times) {\n \n     public List<String> fillRandom(List<String> list, int times) {\n         for (int i = 0; i < times; i++) {\n-            list.add(randomRealisticUnicodeOfCodepointLengthBetween(1, 5));\n+            list.add(randomAsciiOfLengthBetween(1, 5));\n         }\n         return list;\n     }",
    "output": "Use random ascii instead of random unicode Otherwise fields might not have values after analysis and the docCount and hence the score will be unpredictable"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n@@ -741,7 +741,7 @@ public void postDelete(Engine.Delete delete, Throwable ex) {\n         assertEquals(0, postDeleteException.get());\n \n         shard.index(index);\n-        assertEquals(1, preIndex.get());\n+        assertEquals(2, preIndex.get());\n         assertEquals(1, postIndexCreate.get());\n         assertEquals(1, postIndexUpdate.get());\n         assertEquals(0, postIndexException.get());",
    "output": "Fix test bug"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ingest/processor/GsubProcessorFactoryTests.java b/core/src/test/java/org/elasticsearch/ingest/processor/GsubProcessorFactoryTests.java\n--- a/core/src/test/java/org/elasticsearch/ingest/processor/GsubProcessorFactoryTests.java\n+++ b/core/src/test/java/org/elasticsearch/ingest/processor/GsubProcessorFactoryTests.java\n@@ -21,13 +21,13 @@\n \n import org.elasticsearch.ElasticsearchParseException;\n import org.elasticsearch.ingest.core.AbstractProcessorFactory;\n-import org.elasticsearch.ingest.core.Processor;\n import org.elasticsearch.test.ESTestCase;\n \n import java.util.HashMap;\n import java.util.Map;\n \n import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.Matchers.containsString;\n \n public class GsubProcessorFactoryTests extends ESTestCase {\n \n@@ -95,7 +95,7 @@ public void testCreateInvalidPattern() throws Exception {\n             factory.create(config);\n             fail(\"factory create should have failed\");\n         } catch(ElasticsearchParseException e) {\n-            assertThat(e.getMessage(), equalTo(\"[pattern] Invalid regex pattern. Unclosed character class near index 0\\n[\\n^\"));\n+            assertThat(e.getMessage(), containsString(\"[pattern] Invalid regex pattern. Unclosed character class\"));\n         }\n     }\n }",
    "output": "Make GsubProcessorFactoryTests.testCreateInvalidPattern windows friendly"
  },
  {
    "input": "diff --git a/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java b/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java\n--- a/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java\n+++ b/elasticsearch/qa/smoke-test-plugins-ssl/src/test/java/org/elasticsearch/smoketest/SmokeTestMonitoringWithShieldIT.java\n@@ -14,6 +14,7 @@\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.shield.transport.netty.ShieldNettyTransport;\n import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.elasticsearch.xpack.XPackPlugin;\n import org.junit.After;\n import org.junit.AfterClass;\n@@ -41,6 +42,7 @@\n  * then uses a transport client to check that the data have been correctly received and\n  * indexed in the cluster.\n  */\n+@TestLogging(\"org.elasticsearch.action.admin.cluster.settings:DEBUG\")\n public class SmokeTestMonitoringWithShieldIT extends ESIntegTestCase {\n \n     private static final String USER = \"test_user\";",
    "output": "Add logger to catch test failure. See elastic/elasticsearch"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/IndicesAccessControlTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/IndicesAccessControlTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/IndicesAccessControlTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/IndicesAccessControlTests.java\n@@ -135,7 +135,7 @@ public void testMergeNotGrantedAndGranted() {\n     public void testMergeNotGranted() {\n         final Set<String> notGrantedFields = randomFrom(null, Collections.<String>emptySet(), Collections.singleton(\"baz\"));\n         final Set<BytesReference> notGrantedQueries = randomFrom(null, Collections.<BytesReference>emptySet(),\n-                Collections.singleton(new BytesArray(new byte[] { randomByte() })));\n+                Collections.<BytesReference>singleton(new BytesArray(new byte[] { randomByte() })));\n         final IndexAccessControl indexAccessControl = new IndexAccessControl(false, notGrantedFields, notGrantedQueries);\n \n         final BytesReference query1 = new BytesArray(new byte[] { 0x1 });",
    "output": "Add type to generic call"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n@@ -113,7 +113,7 @@ public DiscoveryNode(StreamInput in) throws IOException {\n             if (ordinal < 0 || ordinal >= Role.values().length) {\n                 throw new IOException(\"Unknown Role ordinal [\" + ordinal + \"]\");\n             }\n-            this.roles.add(Role.values()[in.readVInt()]);\n+            this.roles.add(Role.values()[ordinal]);\n         }\n         this.version = Version.readVersion(in);\n     }",
    "output": "Fix silly serialization mistake in DiscoveryNode"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.index.query;\n \n+import org.apache.lucene.search.MatchNoDocsQuery;\n import org.apache.lucene.search.Query;\n import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.index.mapper.internal.TypeFieldMapper;\n@@ -34,7 +35,11 @@ protected TypeQueryBuilder doCreateTestQueryBuilder() {\n \n     @Override\n     protected void doAssertLuceneQuery(TypeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {\n-        assertEquals(new TypeFieldMapper.TypeQuery(new BytesRef(queryBuilder.type())), query);\n+        if (queryShardContext().getMapperService().documentMapper(queryBuilder.type()) == null) {\n+            assertEquals(new MatchNoDocsQuery(), query);\n+        } else {\n+            assertEquals(new TypeFieldMapper.TypeQuery(new BytesRef(queryBuilder.type())), query);\n+        }\n     }\n \n     public void testIllegalArgument() {",
    "output": "Fix test bug in TypeQueryBuilderTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java\n@@ -64,7 +64,7 @@ public class ClusterStatsNodes implements ToXContent, Writeable<ClusterStatsNode\n \n         int size = in.readVInt();\n         this.versions = new HashSet<>(size);\n-        for (; size > 0; size--) {\n+        for (int i = 0; i < size; i++) {\n             this.versions.add(Version.readVersion(in));\n         }\n \n@@ -75,7 +75,7 @@ public class ClusterStatsNodes implements ToXContent, Writeable<ClusterStatsNode\n \n         size = in.readVInt();\n         this.plugins = new HashSet<>(size);\n-        for (; size > 0; size--) {\n+        for (int i = 0; i < size; i++) {\n             this.plugins.add(PluginInfo.readFromStream(in));\n         }\n     }\n@@ -477,7 +477,7 @@ public static class JvmStats implements Writeable<JvmStats>, ToXContent {\n         private JvmStats(StreamInput in) throws IOException {\n             int size = in.readVInt();\n             this.versions = new ObjectIntHashMap<>(size);\n-            for (; size > 0; size--) {\n+            for (int i = 0; i < size; i++) {\n                 this.versions.addTo(JvmVersion.readJvmVersion(in), in.readVInt());\n             }\n             this.threads = in.readVLong();\n@@ -664,6 +664,4 @@ public void writeTo(StreamOutput out) throws IOException {\n             out.writeString(vmVendor);\n         }\n     }\n-\n-\n }",
    "output": "Use ordinary incrementing loops in ClusterStatsNodes"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -893,10 +893,10 @@ public void testClusterJoinDespiteOfPublishingIssues() throws Exception {\n         assertNoMaster(nonMasterNode);\n \n         logger.info(\"blocking cluster state publishing from master [{}] to non master [{}]\", masterNode, nonMasterNode);\n-        MockTransportService masterTransportService = (MockTransportService) internalCluster().getInstance(TransportService.class,\n-                masterNode);\n-        TransportService localTransportService = internalCluster().getInstance(TransportService.class, discoveryNodes.localNode().getName\n-                ());\n+        MockTransportService masterTransportService =\n+            (MockTransportService) internalCluster().getInstance(TransportService.class, masterNode);\n+        TransportService localTransportService =\n+            internalCluster().getInstance(TransportService.class, discoveryNodes.localNode().getName());\n         if (randomBoolean()) {\n             masterTransportService.addFailToSendNoConnectRule(localTransportService, PublishClusterStateAction.SEND_ACTION_NAME);\n         } else {",
    "output": "Fix formatting in DWSDIT#TCJDOPI"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -448,6 +448,9 @@ public void testIsolateMasterAndVerifyClusterStateConsensus() throws Exception {\n             + \"indices.recovery:TRACE,indices.cluster:TRACE\")\n     @AwaitsFix(bugUrl = \"needs primary terms\")\n     public void testAckedIndexing() throws Exception {\n+\n+        final String timeout = !(TEST_NIGHTLY && rarely()) ? \"1s\" : \"5s\";\n+\n         // TODO: add node count randomizaion\n         final List<String> nodes = startCluster(3);\n \n@@ -490,7 +493,8 @@ public void testAckedIndexing() throws Exception {\n                                 id = Integer.toString(idGenerator.incrementAndGet());\n                                 int shard = MathUtils.mod(Murmur3HashFunction.hash(id), numPrimaries);\n                                 logger.trace(\"[{}] indexing id [{}] through node [{}] targeting shard [{}]\", name, id, node, shard);\n-                                IndexResponse response = client.prepareIndex(\"test\", \"type\", id).setSource(\"{}\").setTimeout(\"1s\").get(\"1s\");\n+                                IndexResponse response =\n+                                    client.prepareIndex(\"test\", \"type\", id).setSource(\"{}\").setTimeout(timeout).get(timeout);\n                                 assertThat(response.getVersion(), equalTo(1L));\n                                 ackedDocs.put(id, node);\n                                 logger.trace(\"[{}] indexed id [{}] through node [{}]\", name, id, node);",
    "output": "Use longer timeout on nightly tests, but rarely This commit increases the timeout while indexing during the acked indexing test when running nightly tests, but only rarely"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java\n@@ -111,6 +111,10 @@ public DiscoveryNode(StreamInput in) throws IOException {\n         int rolesSize = in.readVInt();\n         this.roles = new HashSet<>(rolesSize);\n         for (int i = 0; i < rolesSize; i++) {\n+            int ordinal = in.readVInt();\n+            if (ordinal < 0 || ordinal >= Role.values().length) {\n+                throw new IOException(\"Unknown Role ordinal [\" + ordinal + \"]\");\n+            }\n             roles.add(Role.values()[in.readVInt()]);\n         }\n         this.version = Version.readVersion(in);",
    "output": "Add explicit check for Role enum ordinal when reading from StreamInput"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java\n@@ -391,7 +391,8 @@ protected void assertContains(String field, Map<String, Object> values, String p\n                 assertFalse(value instanceof Map);\n             }\n         } else {\n-            assertTrue(\"expecting field [\" + rebuildName(parent, field) + \"] to be present in monitoring document\", values.containsKey(field));\n+            assertTrue(\"expecting field [\" + rebuildName(parent, field) + \"] to be present in monitoring document\",\n+                       values.containsKey(field));\n         }\n     }\n ",
    "output": "Fix checkstyle overrun"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java b/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/zen/ZenDiscoveryIT.java\n@@ -303,7 +303,7 @@ public void testJoinElectedMaster_incompatibleMinVersion() {\n         ElectMasterService electMasterService = new ElectMasterService(Settings.EMPTY, Version.V_5_0_0_alpha1);\n \n         DiscoveryNode node = new DiscoveryNode(\"_node_id\", new LocalTransportAddress(\"_id\"), emptyMap(),\n-                emptySet(), Version.V_5_0_0_alpha1);\n+                Collections.singleton(DiscoveryNode.Role.MASTER), Version.V_5_0_0_alpha1);\n         assertThat(electMasterService.electMaster(Collections.singletonList(node)), sameInstance(node));\n         node = new DiscoveryNode(\"_node_id\", new LocalTransportAddress(\"_id\"), emptyMap(), emptySet(), Version.V_2_0_0);\n         assertThat(\"Can't join master because version 2.0.0 is lower than the minimum compatable version 5.0.0 can support\", electMasterService.electMaster(Collections.singletonList(node)), nullValue());",
    "output": "Fix failing ZenDiscoveryIT"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/recovery/IndexPrimaryRelocationIT.java b/core/src/test/java/org/elasticsearch/indices/recovery/IndexPrimaryRelocationIT.java\n--- a/core/src/test/java/org/elasticsearch/indices/recovery/IndexPrimaryRelocationIT.java\n+++ b/core/src/test/java/org/elasticsearch/indices/recovery/IndexPrimaryRelocationIT.java\n@@ -40,6 +40,7 @@ public class IndexPrimaryRelocationIT extends ESIntegTestCase {\n \n     private static final int RELOCATION_COUNT = 25;\n \n+    @TestLogging(\"_root:DEBUG,action.delete:TRACE,action.index:TRACE,index.shard:TRACE,cluster.service:TRACE\")\n     public void testPrimaryRelocationWhileIndexing() throws Exception {\n         internalCluster().ensureAtLeastNumDataNodes(randomIntBetween(2, 3));\n         client().admin().indices().prepareCreate(\"test\")",
    "output": "Add some debug logging to testPrimaryRelocationWhileIndexing"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n@@ -345,12 +345,7 @@ public void testOperationLocksOnPrimaryShards() throws InterruptedException, Exe\n         }\n         Releasable operation1 = indexShard.acquirePrimaryOperationLock();\n         assertEquals(1, indexShard.getActiveOperationsCount());\n-        Releasable operation2;\n-        if (randomBoolean()) {\n-            operation2 = indexShard.acquirePrimaryOperationLock();\n-        } else {\n-            operation2 = indexShard.acquireReplicaOperationLock(primaryTerm);\n-        }\n+        Releasable operation2 = indexShard.acquirePrimaryOperationLock();\n         assertEquals(2, indexShard.getActiveOperationsCount());\n \n         Releasables.close(operation1, operation2);",
    "output": "Fix missing change when merged from master"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java\n@@ -43,7 +43,6 @@\n import org.elasticsearch.common.transport.TransportAddress;\n import org.elasticsearch.indices.breaker.CircuitBreakerModule;\n import org.elasticsearch.monitor.MonitorService;\n-import org.elasticsearch.node.Node;\n import org.elasticsearch.node.internal.InternalSettingsPreparer;\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.plugins.PluginsModule;\n@@ -112,10 +111,6 @@ private PluginsService newPluginService(final Settings settings) {\n                     .put(NettyTransport.PING_SCHEDULE.getKey(), \"5s\") // enable by default the transport schedule ping interval\n                     .put(InternalSettingsPreparer.prepareSettings(settings))\n                     .put(NetworkService.NETWORK_SERVER.getKey(), false)\n-                    //nocommit not too sure if these settings are needed here...\n-                    .put(Node.NODE_MASTER_SETTING.getKey(), false)\n-                    .put(Node.NODE_DATA_SETTING.getKey(), false)\n-                    .put(Node.NODE_INGEST_SETTING.getKey(), false)\n                     .put(CLIENT_TYPE_SETTING_S.getKey(), CLIENT_TYPE);\n             return new PluginsService(settingsBuilder.build(), null, null, pluginClasses);\n         }",
    "output": "Remove needless settings from transport client"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java\n--- a/core/src/main/java/org/elasticsearch/index/IndexService.java\n+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java\n@@ -780,7 +780,7 @@ protected String getThreadPool() {\n         }\n \n         @Override\n-        public void close() {\n+        public synchronized void close() {\n             if (closed.compareAndSet(false, true)) {\n                 FutureUtils.cancel(scheduledFuture);\n                 scheduledFuture = null;\n\ndiff --git a/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java b/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java\n@@ -187,12 +187,13 @@ protected String getThreadPool() {\n                 return ThreadPool.Names.GENERIC;\n             }\n         };\n+\n         latch.get().await();\n         latch.set(new CountDownLatch(1));\n         assertEquals(1, count.get());\n-        latch2.get().countDown();\n-        latch2.set(new CountDownLatch(1));\n-\n+        // here we need to swap first before we let it go otherwise threads might be very fast and run that task twice due to\n+        // random exception and the schedule interval is 1ms\n+        latch2.getAndSet(new CountDownLatch(1)).countDown();\n         latch.get().await();\n         assertEquals(2, count.get());\n         task.close();",
    "output": "Improve test to not rely on thread slowness We have to swap the second latch before we count it down otherwise threads might be faster than the test. This has happend on a recent CI failure: https://elasticsearch-ci.elastic.co/job/elastic+elasticsearch+master+multijob-os-compatibility/os=ubuntu/121/console This commit also adds a synchronized on the close method since it's canceling and modifying a member varialbe that is assigned under lock"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelSettings.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelSettings.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelSettings.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelSettings.java\n@@ -238,8 +238,6 @@ private void setIndices(List<String> indices) {\n \n     /**\n      * Prefix the {@code key} with the Monitoring prefix.\n-     * <p>\n-     * The {@code key} is prefixed by {@link XPackPlugin#featureSettingPrefix(String)}, {@link Marvel#NAME}, and {@code \".\"}.\n      *\n      * @param key The key to prefix\n      * @return The key prefixed by the product prefixes.",
    "output": "Remove unnecessary JavaDoc"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n@@ -281,8 +281,8 @@ private Table buildTable(RestRequest req, ClusterStateResponse state, NodesInfoR\n             table.addCell(!hasLoadAverage || osStats.getCpu().getLoadAverage()[2] == -1 ? null : String.format(Locale.ROOT, \"%.2f\", osStats.getCpu().getLoadAverage()[2]));\n             table.addCell(jvmStats == null ? null : jvmStats.getUptime());\n \n-            String roles;\n-            if (node.getRoles().size() == 0) {\n+            final String roles;\n+            if (node.getRoles().isEmpty()) {\n                 roles = \"-\";\n             } else {\n                 roles = node.getRoles().stream().map(DiscoveryNode.Role::getAbbreviation).collect(Collectors.joining());",
    "output": "Make roles final"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java b/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java\n--- a/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java\n@@ -49,22 +49,16 @@ public void testSimpleJsonSettings() throws Exception {\n     }\n \n     public void testDuplicateKeysThrowsException() {\n-        String json = \"{\\\"foo\\\":\\\"bar\\\",\\\"foo\\\":\\\"baz\\\"}\";\n-        try {\n-            settingsBuilder()\n-                    .loadFromSource(json)\n-                    .build();\n-            fail(\"expected exception\");\n-        } catch (SettingsException e) {\n-            assertEquals(e.getCause().getClass(), ElasticsearchParseException.class);\n-            assertThat(\n-                    e.toString(),\n-                    containsString(\"duplicate settings key [foo] \" +\n-                            \"found at line number [1], \" +\n-                            \"column number [20], \" +\n-                            \"previous value [bar], \" +\n-                            \"current value [baz]\"));\n-        }\n+        final String json = \"{\\\"foo\\\":\\\"bar\\\",\\\"foo\\\":\\\"baz\\\"}\";\n+        final SettingsException e = expectThrows(SettingsException.class, () -> settingsBuilder().loadFromSource(json).build());\n+        assertEquals(e.getCause().getClass(), ElasticsearchParseException.class);\n+        assertThat(\n+                e.toString(),\n+                containsString(\"duplicate settings key [foo] \" +\n+                        \"found at line number [1], \" +\n+                        \"column number [20], \" +\n+                        \"previous value [bar], \" +\n+                        \"current value [baz]\"));\n     }\n \n     public void testNullValuedSettingThrowsException() {",
    "output": "Use expectThrows in JsonSettingsLoaderTests This commit refactors the unit tests in JsonSettingsLoaderTests to use exceptThrows for simplification"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/loader/PropertiesSettingsLoader.java b/core/src/main/java/org/elasticsearch/common/settings/loader/PropertiesSettingsLoader.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/loader/PropertiesSettingsLoader.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/loader/PropertiesSettingsLoader.java\n@@ -75,7 +75,12 @@ class NoDuplicatesProperties extends Properties {\n         public synchronized Object put(Object key, Object value) {\n             Object previousValue = super.put(key, value);\n             if (previousValue != null) {\n-                throw new ElasticsearchParseException(\"duplicate settings key [{}] found, previous value [{}], current value [{}]\", key, previousValue, value);\n+                throw new ElasticsearchParseException(\n+                        \"duplicate settings key [{}] found, previous value [{}], current value [{}]\",\n+                        key,\n+                        previousValue,\n+                        value\n+                );\n             }\n             return previousValue;\n         }",
    "output": "Fix line-length issue in PropertiesSettingsLoader This commit fixes a line-length checkstyle violation in PropertiesSettingsLoader.java and removes this file from the checkstyle line-length suppressions"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java b/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java\n@@ -265,7 +265,7 @@ && parseNorms(builder, propName, propNode, parserContext)) {\n                 iterator.remove();\n             } else if (propName.equals(\"fielddata\")\n                     && propNode instanceof Map\n-                    && parserContext.indexVersionCreated().before(Version.V_5_0_0)) {\n+                    && parserContext.indexVersionCreated().before(Version.V_5_0_0_alpha1)) {\n                 // ignore for bw compat\n                 iterator.remove();\n             } else if (propName.equals(\"copy_to\")) {",
    "output": "Fix compilation error"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java b/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java\n--- a/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java\n@@ -896,9 +896,6 @@ public void testThatIndexingInvalidFieldsInCompletionFieldResultsInException() t\n     }\n \n     public void assertSuggestions(String suggestionName, SuggestionBuilder suggestBuilder, String... suggestions) {\n-        final SearchRequest searchRequest = Requests.searchRequest(INDEX);\n-        searchRequest.source(new SearchSourceBuilder());\n-        searchRequest.source().suggest();\n         SearchResponse searchResponse = client().prepareSearch(INDEX).suggest(new SuggestBuilder().addSuggestion(suggestionName, suggestBuilder)).execute().actionGet();\n         assertSuggestions(searchResponse, suggestionName, suggestions);\n     }",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/ElasticsearchCliTests.java b/core/src/test/java/org/elasticsearch/bootstrap/ElasticsearchCliTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/ElasticsearchCliTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/ElasticsearchCliTests.java\n@@ -80,17 +80,24 @@ public void testPositionalArgs() throws Exception {\n         runTest(\n             ExitCodes.USAGE,\n             false,\n-            output -> assertThat(output, containsString(\"Positional args not allowed, found [foo]\")),\n+            output -> assertThat(output, containsString(\"Positional arguments not allowed, found [foo]\")),\n             (foreground, pidFile, esSettings) -> {},\n             \"foo\"\n         );\n         runTest(\n             ExitCodes.USAGE,\n             false,\n-            output -> assertThat(output, containsString(\"Positional args not allowed, found [foo, bar]\")),\n+            output -> assertThat(output, containsString(\"Positional arguments not allowed, found [foo, bar]\")),\n             (foreground, pidFile, esSettings) -> {},\n             \"foo\", \"bar\"\n         );\n+        runTest(\n+            ExitCodes.USAGE,\n+            false,\n+            output -> assertThat(output, containsString(\"Positional arguments not allowed, found [foo]\")),\n+            (foreground, pidFile, esSettings) -> {},\n+            \"-E\", \"something\", \"foo\", \"-E\", \"somethingelse\"\n+        );\n     }\n \n     public void testThatPidFileCanBeConfigured() throws Exception {",
    "output": "Add elasticsearch cli test for options plus illegal args"
  },
  {
    "input": "diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n--- a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n@@ -266,7 +266,7 @@ public S3Repository(RepositoryName name, RepositorySettings repositorySettings,\n         this.compress = getValue(repositorySettings, Repository.COMPRESS_SETTING, Repositories.COMPRESS_SETTING);\n \n         // We make sure that chunkSize is bigger or equal than/to bufferSize\n-        if (this.chunkSize.getMb() < bufferSize.getMb()) {\n+        if (this.chunkSize.getBytes() < bufferSize.getBytes()) {\n             throw new RepositoryException(name.name(), Repository.CHUNK_SIZE_SETTING.getKey() + \" (\" + this.chunkSize +\n                 \") can't be lower than \" + Repository.BUFFER_SIZE_SETTING.getKey() + \" (\" + bufferSize + \").\");\n         }",
    "output": "Upgrade after review"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/sort/SortBuilderTests.java b/core/src/test/java/org/elasticsearch/search/sort/SortBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/search/sort/SortBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/sort/SortBuilderTests.java\n@@ -82,6 +82,13 @@ public void testSingleFieldSort() throws IOException {\n         sortBuilder = result.get(0);\n         assertEquals(new FieldSortBuilder(\"field1\"), sortBuilder);\n \n+        // one element array, see https://github.com/elastic/elasticsearch/issues/17257\n+        json = \"{ \\\"sort\\\" : [\\\"field1\\\"] }\";\n+        result = parseSort(json);\n+        assertEquals(1, result.size());\n+        sortBuilder = result.get(0);\n+        assertEquals(new FieldSortBuilder(\"field1\"), sortBuilder);\n+\n         json = \"{ \\\"sort\\\" : { \\\"_doc\\\" : \\\"\" + order + \"\\\" }}\";\n         result = parseSort(json);\n         assertEquals(1, result.size());",
    "output": "Add test for parsing sort on single fields as list"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/core/StringMappingUpgradeTests.java b/core/src/test/java/org/elasticsearch/index/mapper/core/StringMappingUpgradeTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/core/StringMappingUpgradeTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/core/StringMappingUpgradeTests.java\n@@ -126,7 +126,7 @@ public void testUpgradeFielddataSettings() throws IOException {\n                         .field(\"type\", \"string\")\n                         .field(\"index\", keyword ? \"not_analyzed\" : \"analyzed\")\n                         .startObject(\"fielddata\")\n-                            .field(\"forwat\", format)\n+                            .field(\"format\", format)\n                             .field(\"loading\", loading)\n                             .startObject(\"filter\")\n                                 .startObject(\"frequency\")",
    "output": "Fix test bug"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n@@ -40,7 +40,6 @@\n import org.elasticsearch.index.shard.IndexSearcherWrapper;\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.index.shard.ShardUtils;\n-import org.elasticsearch.percolator.PercolatorService;\n import org.elasticsearch.shield.authz.InternalAuthorizationService;\n import org.elasticsearch.shield.authz.accesscontrol.DocumentSubsetReader.DocumentSubsetDirectoryReader;\n import org.elasticsearch.shield.license.ShieldLicenseState;\n@@ -229,9 +228,10 @@ private void resolveParentChildJoinFields(Set<String> allowedFields) {\n     }\n \n     private void resolvePercolatorFields(Set<String> allowedFields) {\n-        if (mapperService.hasMapping(PercolatorService.TYPE_NAME)) {\n+        if (mapperService.hasMapping(PercolatorFieldMapper.TYPE_NAME)) {\n             allowedFields.add(PercolatorFieldMapper.EXTRACTED_TERMS_FULL_FIELD_NAME);\n             allowedFields.add(PercolatorFieldMapper.UNKNOWN_QUERY_FULL_FIELD_NAME);\n+            allowedFields.add(PercolatorFieldMapper.EXTRACTED_TERMS_FULL_FIELD_NAME);\n         }\n     }\n ",
    "output": "Fix for upstream percolator changes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java b/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java\n@@ -102,7 +102,7 @@ public String toString() {\n         return \"version [\" + legacyVersion + \"], primary [\" + primary + \"], allocation [\" + allocationId + \"]\";\n     }\n \n-    public static final MetaDataStateFormat<ShardStateMetaData> FORMAT = new MetaDataStateFormat<ShardStateMetaData>(XContentType.JSON, SHARD_STATE_FILE_PREFIX) {\n+    public static final MetaDataStateFormat<ShardStateMetaData> FORMAT = new MetaDataStateFormat<ShardStateMetaData>(XContentType.SMILE, SHARD_STATE_FILE_PREFIX) {\n \n         @Override\n         protected XContentBuilder newXContentBuilder(XContentType type, OutputStream stream) throws IOException {",
    "output": "Change shard state format to smile"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n--- a/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/InstallPluginCommand.java\n@@ -97,8 +97,11 @@ class InstallPluginCommand extends Command {\n \n     // TODO: make this a resource file generated by gradle\n     static final Set<String> MODULES = unmodifiableSet(newHashSet(\n+        \"ingest-grok\",\n         \"lang-expression\",\n-        \"lang-groovy\"));\n+        \"lang-groovy\",\n+        \"lang-painless\",\n+        \"reindex\"));\n \n     // TODO: make this a resource file generated by gradle\n     static final Set<String> OFFICIAL_PLUGINS = unmodifiableSet(new LinkedHashSet<>(Arrays.asList(\n@@ -111,8 +114,9 @@ class InstallPluginCommand extends Command {\n         \"discovery-azure\",\n         \"discovery-ec2\",\n         \"discovery-gce\",\n+        \"ingest-attachment\",\n+        \"ingest-geoip\",\n         \"lang-javascript\",\n-        \"lang-painless\",\n         \"lang-python\",\n         \"mapper-attachments\",\n         \"mapper-murmur3\",",
    "output": "Fix list of modules and official plugins"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/profile/QueryProfilerIT.java b/core/src/test/java/org/elasticsearch/search/profile/QueryProfilerIT.java\n--- a/core/src/test/java/org/elasticsearch/search/profile/QueryProfilerIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/profile/QueryProfilerIT.java\n@@ -131,15 +131,13 @@ public void testProfileMatchesRegular() throws Exception {\n             SearchRequestBuilder vanilla = client().prepareSearch(\"test\")\n                     .setQuery(q)\n                     .setProfile(false)\n-                    .addSort(\"_score\", SortOrder.DESC)\n                     .addSort(\"_uid\", SortOrder.ASC)\n                     .setPreference(\"_primary\")\n                     .setSearchType(SearchType.QUERY_THEN_FETCH);\n \n             SearchRequestBuilder profile = client().prepareSearch(\"test\")\n                     .setQuery(q)\n                     .setProfile(true)\n-                    .addSort(\"_score\", SortOrder.DESC)\n                     .addSort(\"_uid\", SortOrder.ASC)\n                     .setPreference(\"_primary\")\n                     .setSearchType(SearchType.QUERY_THEN_FETCH);",
    "output": "Make test less fragile by sorting only on _uid The previous method sorted first by _score, then _uid. In certain situations, this allowed floating point errors to slightly alter the sort order, causing test failure. We only sort on _uid now, which should be deterministic and allow comparison of ten documents. Not quite as useful, but less fragile and we still check to make sure num hits and max score are identical"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -64,6 +64,8 @@ public class Version {\n     public static final Version V_2_2_1 = new Version(V_2_2_1_ID, org.apache.lucene.util.Version.LUCENE_5_4_1);\n     public static final int V_2_3_0_ID = 2030099;\n     public static final Version V_2_3_0 = new Version(V_2_3_0_ID, org.apache.lucene.util.Version.LUCENE_5_5_0);\n+    public static final int V_2_4_0_ID = 2040099;\n+    public static final Version V_2_4_0 = new Version(V_2_4_0_ID, org.apache.lucene.util.Version.LUCENE_5_5_0);\n     public static final int V_5_0_0_ID = 5000099;\n     public static final Version V_5_0_0 = new Version(V_5_0_0_ID, org.apache.lucene.util.Version.LUCENE_6_0_0);\n     public static final Version CURRENT = V_5_0_0;\n@@ -81,6 +83,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_5_0_0_ID:\n                 return V_5_0_0;\n+            case V_2_4_0_ID:\n+                return V_2_4_0;\n             case V_2_3_0_ID:\n                 return V_2_3_0;\n             case V_2_2_1_ID:",
    "output": "Add version 2.4.0 to Version"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java\n@@ -18,6 +18,7 @@\n import static org.hamcrest.Matchers.containsString;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.startsWith;\n \n /**\n  */\n@@ -64,7 +65,7 @@ public void testLockingStopTimeout(){\n             lockService.stop();\n             fail(\"Expected ElasticsearchTimeoutException\");\n         } catch (ElasticsearchTimeoutException e) {\n-            assertThat(e.getMessage(), is(\"timed out waiting for watches to complete, after waiting for [2s]\"));\n+            assertThat(e.getMessage(), startsWith(\"timed out waiting for watches to complete, after waiting for\"));\n         }\n     }\n ",
    "output": "Fix timeout test so it checks message but not the reported time waiting The reported time waiting for watches can be slightly different from the actual timeout (e.g. 2.1 seconds instead of 2 seconds) so checking the time waited in the message makes the test sometimes fail"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java b/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java\n@@ -154,8 +154,6 @@ public Collection<String> simpleMatchToFullName(String pattern) {\n         for (MappedFieldType fieldType : this) {\n             if (Regex.simpleMatch(pattern, fieldType.name())) {\n                 fields.add(fieldType.name());\n-            } else if (Regex.simpleMatch(pattern, fieldType.name())) {\n-                fields.add(fieldType.name());\n             }\n         }\n         return fields;",
    "output": "Remove dead code in FTL#simpleMatchToFullName This commit removes some dead code that resulted from removing the ability for a field to have different names (after enforcing that fields have the same full and index name)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/VersionTests.java b/core/src/test/java/org/elasticsearch/VersionTests.java\n--- a/core/src/test/java/org/elasticsearch/VersionTests.java\n+++ b/core/src/test/java/org/elasticsearch/VersionTests.java\n@@ -260,4 +260,20 @@ public void testAllVersionsMatchId() throws Exception {\n         }\n     }\n \n+    // this test ensures we never bump the lucene version in a bugfix release\n+    public void testLuceneVersionIsSameOnMinorRelease() {\n+        for (Version version : VersionUtils.allVersions()) {\n+            for (Version other : VersionUtils.allVersions()) {\n+                if (other.onOrAfter(version)) {\n+                    assertTrue(\"lucene versions must be \"  + other + \" >= \" + version,\n+                        other.luceneVersion.onOrAfter(version.luceneVersion));\n+                }\n+                if (other.major == version.major && other.minor == version.minor) {\n+                    assertEquals(other.luceneVersion.major, version.luceneVersion.major);\n+                    assertEquals(other.luceneVersion.minor, version.luceneVersion.minor);\n+                    // should we also assert the lucene bugfix version?\n+                }\n+            }\n+        }\n+    }\n }",
    "output": "Add test that ensures we never bump the minor version of lucene in a bugfix release"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -83,6 +83,8 @@ public static Version fromId(int id) {\n                 return V_5_0_0;\n             case V_2_3_0_ID:\n                 return V_2_3_0;\n+            case V_2_2_1_ID:\n+                return V_2_2_1;\n             case V_2_2_0_ID:\n                 return V_2_2_0;\n             case V_2_1_2_ID:",
    "output": "Add 2.2.1 to the version lookup table"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -60,6 +60,8 @@ public class Version {\n     public static final Version V_2_1_2 = new Version(V_2_1_2_ID, org.apache.lucene.util.Version.LUCENE_5_3_1);\n     public static final int V_2_2_0_ID = 2020099;\n     public static final Version V_2_2_0 = new Version(V_2_2_0_ID, org.apache.lucene.util.Version.LUCENE_5_4_1);\n+    public static final int V_2_2_1_ID = 2020199;\n+    public static final Version V_2_2_1 = new Version(V_2_2_1_ID, org.apache.lucene.util.Version.LUCENE_5_4_1);\n     public static final int V_2_3_0_ID = 2030099;\n     public static final Version V_2_3_0 = new Version(V_2_3_0_ID, org.apache.lucene.util.Version.LUCENE_5_5_0);\n     public static final int V_5_0_0_ID = 5000099;",
    "output": "Add version 2.2.1 and bwc indices for 2.2.1"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/sort/AbstractSortTestCase.java b/core/src/test/java/org/elasticsearch/search/sort/AbstractSortTestCase.java\n--- a/core/src/test/java/org/elasticsearch/search/sort/AbstractSortTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/search/sort/AbstractSortTestCase.java\n@@ -86,8 +86,6 @@ public void testFromXContent() throws IOException {\n             builder.endObject();\n \n             XContentParser itemParser = XContentHelper.createParser(builder.bytes());\n-            ParsingException except = new ParsingException(itemParser.getTokenLocation(), \"mytext\", itemParser.getTokenLocation());\n-            System.out.println(except.getMessage());\n             itemParser.nextToken();\n \n             /*",
    "output": "Fix compile error that's what you get for a \"let me quickly try something out here\""
  },
  {
    "input": "diff --git a/modules/lang-expression/src/test/java/org/elasticsearch/script/expression/MoreExpressionTests.java b/modules/lang-expression/src/test/java/org/elasticsearch/script/expression/MoreExpressionTests.java\n--- a/modules/lang-expression/src/test/java/org/elasticsearch/script/expression/MoreExpressionTests.java\n+++ b/modules/lang-expression/src/test/java/org/elasticsearch/script/expression/MoreExpressionTests.java\n@@ -385,7 +385,7 @@ public void testSpecialValueVariable() throws Exception {\n                         AggregationBuilders.stats(\"double_agg\").field(\"y\")\n                                 .script(new Script(\"_value - 1.1\", ScriptType.INLINE, ExpressionScriptEngineService.NAME, null)))\n                 .addAggregation(\n-                        AggregationBuilders.stats(\"const_agg\").field(\"x\")\n+                        AggregationBuilders.stats(\"const_agg\").field(\"x\") // specifically to test a script w/o _value\n                                 .script(new Script(\"3.0\", ScriptType.INLINE, ExpressionScriptEngineService.NAME, null))\n                 );\n ",
    "output": "Add one minor comment for expressions tests"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java\n@@ -5,7 +5,6 @@\n  */\n package org.elasticsearch.shield.authz.indicesresolver;\n \n-import org.apache.lucene.util.ArrayUtil;\n import org.elasticsearch.action.AliasesRequest;\n import org.elasticsearch.action.CompositeIndicesRequest;\n import org.elasticsearch.action.IndicesRequest;",
    "output": "Remove unused imports"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesAndAliasesResolver.java\n@@ -5,6 +5,7 @@\n  */\n package org.elasticsearch.shield.authz.indicesresolver;\n \n+import org.apache.lucene.util.ArrayUtil;\n import org.elasticsearch.action.AliasesRequest;\n import org.elasticsearch.action.CompositeIndicesRequest;\n import org.elasticsearch.action.IndicesRequest;\n@@ -78,6 +79,8 @@ private Set<String> resolveIndicesAndAliases(User user, String action, IndicesRe\n              * the list of indices in there, if we do so it will result in an invalid request and the update will fail.\n              */\n             indices = Collections.singleton(((PutMappingRequest) indicesRequest).getConcreteIndex().getName());\n+            assert indicesRequest.indices() == null || indicesRequest.indices().length == 0\n+                    : \"indices are: \" + Arrays.toString(indicesRequest.indices()); // Arrays.toString() can handle null values - all good\n         } else {\n             if (indicesRequest.indicesOptions().expandWildcardsOpen() || indicesRequest.indicesOptions().expandWildcardsClosed()) {\n                 if (indicesRequest instanceof IndicesRequest.Replaceable) {",
    "output": "Add assertion DefaultIndicesAndAliasesResolver that PutMapping special case holds"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java\n@@ -223,7 +223,7 @@ public void testSimpleAllMappersWithReparseWithStore() throws Exception {\n     }\n \n     public void testRandom() throws Exception {\n-        boolean norms = false;\n+        boolean norms = true;\n         boolean stored = false;\n         boolean enabled = true;\n         boolean tv_stored = false;",
    "output": "Fix test bug: norms are on by default on _all"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionBuilder.java b/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionBuilder.java\n@@ -346,10 +346,12 @@ public Template collateQuery() {\n     }\n \n     /**\n-     * Sets additional params for collate script\n+     * Adds additional parameters for collate scripts. Previously added parameters on the\n+     * same builder will be overwritten.\n      */\n     public PhraseSuggestionBuilder collateParams(Map<String, Object> collateParams) {\n-        this.collateParams = collateParams;\n+        Objects.requireNonNull(collateParams, \"collate parameters cannot be null.\");\n+        this.collateParams = new HashMap<>(collateParams);\n         return this;\n     }\n \n\ndiff --git a/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionContext.java b/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionContext.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionContext.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggestionContext.java\n@@ -201,7 +201,7 @@ Map<String, Object> getCollateScriptParams() {\n     }\n \n     void setCollateScriptParams(Map<String, Object> collateScriptParams) {\n-        this.collateScriptParams = collateScriptParams;\n+        this.collateScriptParams = new HashMap<>(collateScriptParams);\n     }\n \n     void setCollatePrune(boolean prune) {",
    "output": "Make Copy of collate parameter map Test failures showed problems with passing down the same collate parameter map reference from the phrase suggestion builder to the context where. This changes the collate parameter setters to make a shallow copy of the map passed in"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java\n@@ -316,7 +316,8 @@ private static int expandCommonMappers(List<ObjectMapper> parentMappers, String[\n         while (i < nameParts.length - 1 && last.getMapper(nameParts[i]) != null) {\n             Mapper newLast = last.getMapper(nameParts[i]);\n             assert newLast instanceof ObjectMapper;\n-            parentMappers.add((ObjectMapper)newLast);\n+            last = (ObjectMapper) newLast;\n+            parentMappers.add(last);\n             ++i;\n         }\n         return i;",
    "output": "Fix dynamic mapper bug with deeply nested fields"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/DerivativeIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/DerivativeIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/DerivativeIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/DerivativeIT.java\n@@ -44,7 +44,11 @@\n \n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;\n-import static org.elasticsearch.search.aggregations.AggregationBuilders.*;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.filters;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.stats;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.sum;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.avg;\n import static org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorBuilders.derivative;\n import static org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorBuilders.movingAvg;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;",
    "output": "Fix import formatting - do not use wildcard"
  },
  {
    "input": "diff --git a/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/TikaImpl.java b/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/TikaImpl.java\n--- a/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/TikaImpl.java\n+++ b/plugins/ingest-attachment/src/main/java/org/elasticsearch/ingest/attachment/TikaImpl.java\n@@ -137,6 +137,8 @@ static PermissionCollection getRestrictedPermissions() {\n         perms.add(new SecurityPermission(\"putProviderProperty.BC\"));\n         perms.add(new SecurityPermission(\"insertProvider\"));\n         perms.add(new ReflectPermission(\"suppressAccessChecks\"));\n+        // xmlbeans, use by POI, needs to get the context classloader\n+        perms.add(new RuntimePermission(\"getClassLoader\"));\n         perms.setReadOnly();\n         return perms;\n     }",
    "output": "Add getClassLoader perm for tika in ingest"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n@@ -370,7 +370,6 @@ public void finalizeRecovery() {\n              * target are failed (see {@link IndexShard#updateRoutingEntry}).\n              */\n             try {\n-                // nocommit: awful hack to work around delay replications being rejected by the primary term check. proper fix coming.\n                 shard.relocated(\"to \" + request.targetNode());\n             } catch (IllegalIndexShardStateException e) {\n                 // we can ignore this exception since, on the other node, when it moved to phase3\n@@ -550,4 +549,4 @@ void sendFiles(Store store, StoreFileMetaData[] files, Function<StoreFileMetaDat\n     protected void failEngine(IOException cause) {\n         shard.failShard(\"recovery\", cause);\n     }\n-}\n+}\n\\ No newline at end of file",
    "output": "Remove unneeded nocommit"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java\n@@ -502,7 +502,6 @@ private static void parseArray(ParseContext context, ObjectMapper parentMapper,\n             } else if (dynamic == ObjectMapper.Dynamic.TRUE) {\n                 Mapper.Builder builder = context.root().findTemplateBuilder(context, arrayFieldName, \"object\");\n                 if (builder == null) {\n-                    // TODO: shouldn't this create a default object mapper builder?\n                     parseNonDynamicArray(context, parentMapper, lastFieldName, arrayFieldName);\n                     return;\n                 }",
    "output": "Remove unnecessary comment"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/OptOutQueryCache.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/OptOutQueryCache.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/OptOutQueryCache.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/OptOutQueryCache.java\n@@ -55,7 +55,7 @@ public Weight doCache(Weight weight, QueryCachingPolicy policy) {\n         // At this level only IndicesRequest\n         final String indexName;\n         if (context.getRequest() instanceof ShardSearchRequest) {\n-            indexName = ((ShardSearchRequest) context.getRequest()).index();\n+            indexName = ((ShardSearchRequest) context.getRequest()).shardId().getIndexName();\n         } else if (context.getRequest() instanceof BroadcastShardRequest) {\n             indexName = ((BroadcastShardRequest) context.getRequest()).shardId().getIndexName();\n         } else {",
    "output": "Use ShardId#getIndexName() since index name has been removed from ShardSearchRequest"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java\n--- a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java\n@@ -567,7 +567,7 @@ public void testCrossFieldMode() throws ExecutionException, InterruptedException\n \n         // test if boosts work\n         searchResponse = client().prepareSearch(\"test\")\n-                .setQuery(randomizeType(multiMatchQuery(\"the ultimate\", \"full_name\", \"first_name\", \"last_name\", \"category\").field(\"last_name\", 2)\n+                .setQuery(randomizeType(multiMatchQuery(\"the ultimate\", \"full_name\", \"first_name\", \"last_name\", \"category\").field(\"last_name\", 10)\n                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)\n                         .operator(Operator.AND))).get();\n         assertFirstHit(searchResponse, hasId(\"ultimate1\"));   // has ultimate in the last_name and that is boosted",
    "output": "Make boost more prominent in test since with new default similarity it might score lower without the boost"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n@@ -235,11 +235,7 @@ public static void checkSegmentInfoIntegrity(final Directory directory) throws I\n             @Override\n             protected Object doBody(String segmentFileName) throws IOException {\n                 try (IndexInput input = directory.openInput(segmentFileName, IOContext.READ)) {\n-                    final int format = input.readInt();\n-                    if (format == CodecUtil.CODEC_MAGIC) {\n-                        CodecUtil.checksumEntireFile(input);\n-                    }\n-                    // legacy....\n+                    CodecUtil.checksumEntireFile(input);\n                 }\n                 return null;\n             }",
    "output": "Remove leniency from segments info integrity checks"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/IndexingSlowLog.java b/core/src/main/java/org/elasticsearch/index/IndexingSlowLog.java\n--- a/core/src/main/java/org/elasticsearch/index/IndexingSlowLog.java\n+++ b/core/src/main/java/org/elasticsearch/index/IndexingSlowLog.java\n@@ -75,14 +75,7 @@ public final class IndexingSlowLog implements IndexingOperationListener {\n     }, true, Setting.Scope.INDEX);\n \n     IndexingSlowLog(IndexSettings indexSettings) {\n-        this(indexSettings, Loggers.getLogger(INDEX_INDEXING_SLOWLOG_PREFIX + \".index\", indexSettings.getSettings()));\n-    }\n-\n-    /**\n-     * Build with the specified loggers. Only used to testing.\n-     */\n-    IndexingSlowLog(IndexSettings indexSettings, ESLogger indexLogger) {\n-        this.indexLogger = indexLogger;\n+        this.indexLogger = Loggers.getLogger(INDEX_INDEXING_SLOWLOG_PREFIX + \".index\", indexSettings.getSettings());\n         this.index = indexSettings.getIndex();\n \n         indexSettings.getScopedSettings().addSettingsUpdateConsumer(INDEX_INDEXING_SLOWLOG_REFORMAT_SETTING, this::setReformat);",
    "output": "Remove unused test-only constructor from IndexingSlowLog"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/tribe/TribeIT.java b/core/src/test/java/org/elasticsearch/tribe/TribeIT.java\n--- a/core/src/test/java/org/elasticsearch/tribe/TribeIT.java\n+++ b/core/src/test/java/org/elasticsearch/tribe/TribeIT.java\n@@ -132,6 +132,9 @@ private void setupTribeNode(Settings settings) {\n         Settings.Builder tribe1Defaults = Settings.builder();\n         Settings.Builder tribe2Defaults = Settings.builder();\n         for (Map.Entry<String, String> entry : asMap.entrySet()) {\n+            if (entry.getKey().startsWith(\"path.\")) {\n+                continue;\n+            }\n             tribe1Defaults.put(\"tribe.t1.\" + entry.getKey(), entry.getValue());\n             tribe2Defaults.put(\"tribe.t2.\" + entry.getKey(), entry.getValue());\n         }",
    "output": "Fix tribe integ test to not try to pass through path settings"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCliParser.java b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCliParser.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCliParser.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCliParser.java\n@@ -51,7 +51,7 @@ final class BootstrapCliParser extends Command {\n         pidfileOption = parser.acceptsAll(Arrays.asList(\"p\", \"pidfile\"),\n             \"Creates a pid file in the specified path on start\")\n             .withRequiredArg();\n-        propertyOption = parser.accepts(\"E\", \"Configures an Elasticsearch setting\")\n+        propertyOption = parser.accepts(\"D\", \"Configures an Elasticsearch setting\")\n             .withRequiredArg();\n     }\n \n@@ -80,7 +80,11 @@ protected void execute(Terminal terminal, OptionSet options) throws Exception {\n             if (keyValue.length != 2) {\n                 throw new UserError(ExitCodes.USAGE, \"Malformed elasticsearch setting, must be of the form key=value\");\n             }\n-            System.setProperty(\"es.\" + keyValue[0], keyValue[1]);\n+            String key = keyValue[0];\n+            if (key.startsWith(\"es.\") == false) {\n+                key = \"es.\" + key;\n+            }\n+            System.setProperty(key, keyValue[1]);\n         }\n         shouldRun = true;\n     }",
    "output": "Fix more licenses"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/admin/cluster/node/tasks/TasksIT.java b/core/src/test/java/org/elasticsearch/action/admin/cluster/node/tasks/TasksIT.java\n--- a/core/src/test/java/org/elasticsearch/action/admin/cluster/node/tasks/TasksIT.java\n+++ b/core/src/test/java/org/elasticsearch/action/admin/cluster/node/tasks/TasksIT.java\n@@ -42,6 +42,7 @@\n import org.elasticsearch.test.tasks.MockTaskManager;\n import org.elasticsearch.test.tasks.MockTaskManagerListener;\n import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.transport.ReceiveTimeoutTransportException;\n \n import java.io.IOException;\n import java.util.ArrayList;\n@@ -57,6 +58,7 @@\n import java.util.function.Function;\n \n import static org.elasticsearch.common.unit.TimeValue.timeValueMillis;\n+import static org.hamcrest.Matchers.either;\n import static org.hamcrest.Matchers.emptyCollectionOf;\n import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n import static org.hamcrest.Matchers.instanceOf;\n@@ -383,7 +385,8 @@ public void testTasksListWaitForTimeout() throws Exception {\n                 if (timeoutException.getCause() != null) {\n                     timeoutException = timeoutException.getCause();\n                 }\n-                assertThat(failure.getCause().getCause(), instanceOf(ElasticsearchTimeoutException.class));\n+                assertThat(timeoutException,\n+                        either(instanceOf(ElasticsearchTimeoutException.class)).or(instanceOf(ReceiveTimeoutTransportException.class)));\n             }\n         } finally {\n             // Now we can unblock those requests",
    "output": "Fix uncommon tests failure in TasksIT"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/recovery/RecoverySourceHandlerTests.java b/core/src/test/java/org/elasticsearch/indices/recovery/RecoverySourceHandlerTests.java\n--- a/core/src/test/java/org/elasticsearch/indices/recovery/RecoverySourceHandlerTests.java\n+++ b/core/src/test/java/org/elasticsearch/indices/recovery/RecoverySourceHandlerTests.java\n@@ -94,7 +94,7 @@ public void testSendFiles() throws Throwable {\n                     @Override\n                     public void close() throws IOException {\n                         super.close();\n-                        store.directory().sync(Collections.singleton(md.name())); // sync otherwise MDW will mess with it\n+                        targetStore.directory().sync(Collections.singleton(md.name())); // sync otherwise MDW will mess with it\n                     }\n                 };\n             } catch (IOException e) {",
    "output": "Use actual target directory to fsync copied files in test Apparently lucene6 is way more picky with respect to corrupting files that are not fsynced that's why this test sometimes failed after the lucene6 upgrade"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/Setting.java b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n@@ -20,6 +20,7 @@\n \n import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.ElasticsearchParseException;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.support.ToXContentToBytes;\n import org.elasticsearch.common.Booleans;\n import org.elasticsearch.common.Strings;\n@@ -30,6 +31,7 @@\n import org.elasticsearch.common.unit.MemorySizeValue;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n import org.elasticsearch.common.xcontent.XContentParser;\n import org.elasticsearch.common.xcontent.XContentType;\n \n@@ -519,7 +521,16 @@ public boolean isGroupSetting() {\n \n             @Override\n             public String getRaw(Settings settings) {\n-                throw new UnsupportedOperationException(\"group settings don't support raw values\");\n+                Settings subSettings = get(settings);\n+                try {\n+                    XContentBuilder builder = XContentFactory.jsonBuilder();\n+                    builder.startObject();\n+                    subSettings.toXContent(builder, EMPTY_PARAMS);\n+                    builder.endObject();\n+                    return builder.string();\n+                } catch (IOException e) {\n+                    throw new RuntimeException(e);\n+                }\n             }\n \n             @Override",
    "output": "Add Json representation to raw group settings for better logging represetation"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/common/cli/CliToolTestCase.java b/test/framework/src/main/java/org/elasticsearch/common/cli/CliToolTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/common/cli/CliToolTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/common/cli/CliToolTestCase.java\n@@ -28,6 +28,10 @@\n import org.junit.After;\n import org.junit.Before;\n \n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.isEmptyString;\n+import static org.hamcrest.Matchers.not;\n+\n public abstract class CliToolTestCase extends ESTestCase {\n \n     @Before\n@@ -51,8 +55,10 @@ public static String[] args(String command) {\n \n     public static void assertTerminalOutputContainsHelpFile(MockTerminal terminal, String classPath) throws IOException {\n         String output = terminal.getOutput();\n-        assertFalse(output, output.isEmpty());\n+        assertThat(output, not(isEmptyString()));\n         String expectedDocs = StreamsUtils.copyToStringFromClasspath(classPath);\n-        assertTrue(output, output.contains(expectedDocs));\n+        // convert to *nix newlines as MockTerminal used for tests also uses *nix newlines\n+        expectedDocs = expectedDocs.replace(\"\\r\\n\", \"\\n\");\n+        assertThat(output, containsString(expectedDocs));\n     }\n }",
    "output": "Fix newline issue in PluginCliTests on Windows"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeActionTests.java b/core/src/test/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeActionTests.java\n--- a/core/src/test/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeActionTests.java\n@@ -26,7 +26,9 @@\n import org.elasticsearch.common.xcontent.XContentFactory;\n import org.elasticsearch.test.ESTestCase;\n \n-import static org.hamcrest.Matchers.*;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.Matchers.startsWith;\n \n public class RestAnalyzeActionTests extends ESTestCase {\n ",
    "output": "Fix checkstyle error"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/resolver/cluster/ClusterStatsResolverTests.java\n@@ -31,6 +31,7 @@\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.index.shard.ShardPath;\n import org.elasticsearch.indices.NodeIndicesStats;\n+import org.elasticsearch.ingest.core.IngestInfo;\n import org.elasticsearch.marvel.agent.collector.cluster.ClusterStatsMonitoringDoc;\n import org.elasticsearch.marvel.agent.exporter.MarvelTemplateUtils;\n import org.elasticsearch.marvel.agent.resolver.MonitoringIndexNameResolverTestCase;\n@@ -112,7 +113,7 @@ private NodeInfo randomNodeInfo() {\n                 Settings.EMPTY, DummyOsInfo.INSTANCE, new ProcessInfo(randomInt(), randomBoolean()), JvmInfo.jvmInfo(),\n                 new ThreadPoolInfo(Collections.singletonList(new ThreadPool.Info(\"test_threadpool\", ThreadPool.ThreadPoolType.FIXED, 5))),\n                 new TransportInfo(transportAddress, Collections.emptyMap()), new HttpInfo(transportAddress, randomLong()),\n-                new PluginsAndModules());\n+                new PluginsAndModules(), new IngestInfo());\n \n     }\n ",
    "output": "Fix compile due to core change in NodeInfo"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n@@ -235,11 +235,7 @@ public static void checkSegmentInfoIntegrity(final Directory directory) throws I\n             @Override\n             protected Object doBody(String segmentFileName) throws IOException {\n                 try (IndexInput input = directory.openInput(segmentFileName, IOContext.READ)) {\n-                    final int format = input.readInt();\n-                    if (format == CodecUtil.CODEC_MAGIC) {\n-                        CodecUtil.checksumEntireFile(input);\n-                    }\n-                    // legacy....\n+                    CodecUtil.checksumEntireFile(input);\n                 }\n                 return null;\n             }",
    "output": "Remove leniency from segments info integrity checks"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/get/GetActionIT.java b/core/src/test/java/org/elasticsearch/get/GetActionIT.java\n--- a/core/src/test/java/org/elasticsearch/get/GetActionIT.java\n+++ b/core/src/test/java/org/elasticsearch/get/GetActionIT.java\n@@ -875,7 +875,7 @@ public void testGeneratedStringFieldsStored() throws IOException {\n \n     void indexSingleDocumentWithStringFieldsGeneratedFromText(boolean stored, boolean sourceEnabled) {\n \n-        String storedString = stored ? \"yes\" : \"no\";\n+        String storedString = stored ? \"true\" : \"false\";\n         String createIndexSource = \"{\\n\" +\n                 \"  \\\"settings\\\": {\\n\" +\n                 \"    \\\"index.translog.flush_threshold_size\\\": \\\"1pb\\\",\\n\" +\n@@ -926,7 +926,7 @@ public void testGeneratedNumberFieldsStored() throws IOException {\n     }\n \n     void indexSingleDocumentWithNumericFieldsGeneratedFromText(boolean stored, boolean sourceEnabled) {\n-        String storedString = stored ? \"yes\" : \"no\";\n+        String storedString = stored ? \"true\" : \"false\";\n         String createIndexSource = \"{\\n\" +\n                 \"  \\\"settings\\\": {\\n\" +\n                 \"    \\\"index.translog.flush_threshold_size\\\": \\\"1pb\\\",\\n\" +",
    "output": "Use true/false rather than yes/no in tests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/cli/TerminalTests.java b/core/src/test/java/org/elasticsearch/common/cli/TerminalTests.java\n--- a/core/src/test/java/org/elasticsearch/common/cli/TerminalTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/cli/TerminalTests.java\n@@ -46,7 +46,8 @@ public void testEscaping() throws Exception {\n \n     private void assertPrinted(MockTerminal logTerminal, Terminal.Verbosity verbosity, String text) throws Exception {\n         logTerminal.println(verbosity, text);\n-        assertTrue(logTerminal.getOutput().contains(text));\n+        String output = logTerminal.getOutput();\n+        assertTrue(output, output.contains(text));\n         logTerminal.resetOutput();\n     }\n \n\ndiff --git a/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java\n@@ -233,7 +233,6 @@ public void testHelpWorks() throws Exception {\n             BootstrapCLIParser parser = new BootstrapCLIParser(terminal);\n             ExitStatus status = parser.execute(args(tuple.v1()));\n             assertStatus(status, OK_AND_EXIT);\n-            // nocommit\n             assertTerminalOutputContainsHelpFile(terminal, \"/org/elasticsearch/bootstrap/\" + tuple.v2());\n         }\n     }",
    "output": "Remove outdated nocommit and tweak assert to output bad exception message on failure"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n@@ -928,12 +928,6 @@ private IndexWriter createWriter(boolean create) throws IOException {\n             iwc.setSimilarity(engineConfig.getSimilarity());\n             iwc.setRAMBufferSizeMB(engineConfig.getIndexingBufferSize().mbFrac());\n             iwc.setCodec(engineConfig.getCodec());\n-            /* We set this timeout to a highish value to work around\n-             * the default poll interval in the Lucene lock that is\n-             * 1000ms by default. We might need to poll multiple times\n-             * here but with 1s poll this is only executed twice at most\n-             * in combination with the default writelock timeout*/\n-            iwc.setWriteLockTimeout(5000);\n             iwc.setUseCompoundFile(true); // always use compound on flush - reduces # of file-handles on refresh\n             // Warm-up hook for newly-merged segments. Warming up segments here is better since it will be performed at the end\n             // of the merge operation and won't slow down _refresh",
    "output": "Remove writeLockTimeout from InternalEngine"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n@@ -928,12 +928,6 @@ private IndexWriter createWriter(boolean create) throws IOException {\n             iwc.setSimilarity(engineConfig.getSimilarity());\n             iwc.setRAMBufferSizeMB(engineConfig.getIndexingBufferSize().mbFrac());\n             iwc.setCodec(engineConfig.getCodec());\n-            /* We set this timeout to a highish value to work around\n-             * the default poll interval in the Lucene lock that is\n-             * 1000ms by default. We might need to poll multiple times\n-             * here but with 1s poll this is only executed twice at most\n-             * in combination with the default writelock timeout*/\n-            iwc.setWriteLockTimeout(5000);\n             iwc.setUseCompoundFile(true); // always use compound on flush - reduces # of file-handles on refresh\n             // Warm-up hook for newly-merged segments. Warming up segments here is better since it will be performed at the end\n             // of the merge operation and won't slow down _refresh",
    "output": "Remove writeLockTimeout from InternalEngine `writeLockTimeout` has been removed in Lucene 6 completely and since we have the shard locking mechanism now for quite a while we don't need this anymore. Shards should only be allocated once all resources are released such that there can't be any other shard holding the lock to that index in any sane situation"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n@@ -196,22 +196,19 @@ protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query,\n             assertTrue(numericRangeQuery.includesMax());\n \n             double value;\n-            double width = 0;\n-            try {\n+            double width;\n+            if (queryBuilder.fieldName().equals(DATE_FIELD_NAME) == false) {\n                 value = Double.parseDouble(queryBuilder.value().toString());\n-            } catch (NumberFormatException e) {\n-                // Maybe its a date\n-                value = ISODateTimeFormat.dateTimeParser().parseMillis(queryBuilder.value().toString());\n-                width = queryBuilder.fuzziness().asTimeValue().getMillis();\n-            }\n-\n-            if (width == 0) {\n                 if (queryBuilder.fuzziness().equals(Fuzziness.AUTO)) {\n                     width = 1;\n                 } else {\n                     width = queryBuilder.fuzziness().asDouble();\n                 }\n+            } else {\n+                value = ISODateTimeFormat.dateTimeParser().parseMillis(queryBuilder.value().toString());\n+                width = queryBuilder.fuzziness().asTimeValue().getMillis();\n             }\n+\n             assertEquals(value - width, numericRangeQuery.getMin().doubleValue(), width * .1);\n             assertEquals(value + width, numericRangeQuery.getMax().doubleValue(), width * .1);\n         }",
    "output": "Fix sporadic error on match query test when a fuzziness of 0s is used"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n@@ -196,7 +196,7 @@ protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query,\n             assertTrue(numericRangeQuery.includesMax());\n \n             double value;\n-            double width = 0;\n+            double width = -1;\n             try {\n                 value = Double.parseDouble(queryBuilder.value().toString());\n             } catch (NumberFormatException e) {\n@@ -205,7 +205,7 @@ protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query,\n                 width = queryBuilder.fuzziness().asTimeValue().getMillis();\n             }\n \n-            if (width == 0) {\n+            if (width == -1) {\n                 if (queryBuilder.fuzziness().equals(Fuzziness.AUTO)) {\n                     width = 1;\n                 } else {",
    "output": "Fix sporadic error on match query test when a fuzziness of 0s is used on a date field"
  },
  {
    "input": "diff --git a/modules/reindex/src/test/java/org/elasticsearch/index/reindex/UpdateByQueryBasicTests.java b/modules/reindex/src/test/java/org/elasticsearch/index/reindex/UpdateByQueryBasicTests.java\n--- a/modules/reindex/src/test/java/org/elasticsearch/index/reindex/UpdateByQueryBasicTests.java\n+++ b/modules/reindex/src/test/java/org/elasticsearch/index/reindex/UpdateByQueryBasicTests.java\n@@ -94,7 +94,7 @@ private void refreshTestCase(Boolean refresh, boolean visible) throws Exception\n \n         // Now make foo searchable\n         assertAcked(client().admin().indices().preparePutMapping(\"test\").setType(\"test\")\n-                .setSource(\"{\\\"test\\\": {\\\"properties\\\":{\\\"foo\\\": {\\\"type\\\": \\\"string\\\"}}}}\"));\n+                .setSource(\"{\\\"test\\\": {\\\"properties\\\":{\\\"foo\\\": {\\\"type\\\": \\\"text\\\"}}}}\"));\n         UpdateByQueryRequestBuilder update = request().source(\"test\");\n         if (refresh != null) {\n             update.refresh(refresh);",
    "output": "Fix modules/reindex to not use the string field anymore"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCheckTests.java\n@@ -121,7 +121,7 @@ boolean isMemoryLocked() {\n                 } catch (final RuntimeException e) {\n                     assertThat(\n                             e.getMessage(),\n-                            containsString(\"Memory locking requested for elasticsearch process but memory is not locked\"));\n+                            containsString(\"memory locking requested for elasticsearch process but memory is not locked\"));\n                 }\n             } else {\n                 // nothing should happen",
    "output": "Fix case in mlockall check error message"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n@@ -210,7 +210,7 @@ public boolean check() {\n \n         @Override\n         public String errorMessage() {\n-            return \"Memory locking requested for elasticsearch process but memory is not locked\";\n+            return \"memory locking requested for elasticsearch process but memory is not locked\";\n         }\n \n         // visible for testing",
    "output": "Fix case in mlockall check error message"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapCheck.java\n@@ -72,7 +72,7 @@ public static void check(final Settings settings) {\n     static void check(final boolean enforceLimits, final List<Check> checks) {\n         final ESLogger logger = Loggers.getLogger(BootstrapCheck.class);\n \n-        for (Check check : checks) {\n+        for (final Check check : checks) {\n             final boolean fail = check.check();\n             if (fail) {\n                 if (enforceLimits) {\n@@ -115,8 +115,8 @@ static boolean enforceLimits(final Settings settings) {\n \n     // the list of checks to execute\n     private static List<Check> checks(final Settings settings) {\n-        List<Check> checks = new ArrayList<>();\n-        FileDescriptorCheck fileDescriptorCheck\n+        final List<Check> checks = new ArrayList<>();\n+        final FileDescriptorCheck fileDescriptorCheck\n                 = Constants.MAC_OS_X ? new OsXFileDescriptorCheck() : new FileDescriptorCheck();\n         checks.add(fileDescriptorCheck);\n         checks.add(new MlockallCheck(BootstrapSettings.MLOCKALL_SETTING.get(settings)));",
    "output": "Add more missed final keywords in BootstrapChecks"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/Setting.java b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.common.Booleans;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.logging.DeprecationLogger;\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.common.regex.Regex;\n@@ -110,6 +111,8 @@ public enum SettingsProperty {\n     }\n \n     private static final ESLogger logger = Loggers.getLogger(Setting.class);\n+    private static final DeprecationLogger deprecationLogger = new DeprecationLogger(logger);\n+\n     private final String key;\n     protected final Function<Settings, String> defaultValue;\n     private final Function<String, T> parser;\n@@ -292,7 +295,7 @@ public String getRaw(Settings settings) {\n         // They're using the setting, so we need to tell them to stop\n         if (this.isDeprecated() && this.exists(settings)) {\n             // It would be convenient to show its replacement key, but replacement is often not so simple\n-            logger.warn(\"[{}] setting was deprecated in Elasticsearch and it will be removed in a future release! \" +\n+            deprecationLogger.deprecated(\"[{}] setting was deprecated in Elasticsearch and it will be removed in a future release! \" +\n                     \"See the breaking changes lists in the documentation for details\", getKey());\n         }\n         return settings.get(key, defaultValue.apply(settings));",
    "output": "Use deprecation Logger"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/agent/exporter/local/LocalBulk.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/agent/exporter/local/LocalBulk.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/agent/exporter/local/LocalBulk.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/agent/exporter/local/LocalBulk.java\n@@ -39,7 +39,8 @@ public class LocalBulk extends ExportBulk {\n \n     AtomicReference<State> state = new AtomicReference<>();\n \n-    public LocalBulk(String name, ESLogger logger, Client client, MonitoringIndexNameResolver indexNameResolver, RendererRegistry renderers) {\n+    public LocalBulk(String name, ESLogger logger, Client client, MonitoringIndexNameResolver indexNameResolver,\n+                     RendererRegistry renderers) {\n         super(name);\n         this.logger = logger;\n         this.client = client;",
    "output": "Fix checkstyle violation"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java b/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java\n@@ -48,6 +48,12 @@ public void testEnvironmentSettings() {\n         assertEquals(\"conf/path\", clientSettings.get(\"path.conf\"));\n         assertEquals(\"plugins/path\", clientSettings.get(\"path.plugins\"));\n         assertEquals(\"logs/path\", clientSettings.get(\"path.logs\"));\n+\n+        // TODO: this should be an error, not just ignored!\n+        Settings tribeSettings = Settings.builder()\n+            .put(\"path.home\", \"alternate/path\").build();\n+        clientSettings = TribeService.buildClientSettings(\"tribe1\", globalSettings, tribeSettings);\n+        assertEquals(\"some/path\", clientSettings.get(\"path.home\"));\n     }\n \n     public void testPassthroughSettings() {",
    "output": "Add test for ignoring path settings in tribe client"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java b/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/tribe/TribeServiceTests.java\n@@ -61,5 +61,15 @@ public void testPassthroughSettings() {\n         assertEquals(\"0.0.0.0\", clientSettings.get(\"network.host\"));\n         assertEquals(\"1.1.1.1\", clientSettings.get(\"network.bind_host\"));\n         assertEquals(\"2.2.2.2\", clientSettings.get(\"network.publish_host\"));\n+\n+        // per tribe client overrides still work\n+        Settings tribeSettings = Settings.builder()\n+            .put(\"network.host\", \"3.3.3.3\")\n+            .put(\"network.bind_host\", \"4.4.4.4\")\n+            .put(\"network.publish_host\", \"5.5.5.5\").build();\n+        clientSettings = TribeService.buildClientSettings(\"tribe1\", globalSettings, tribeSettings);\n+        assertEquals(\"3.3.3.3\", clientSettings.get(\"network.host\"));\n+        assertEquals(\"4.4.4.4\", clientSettings.get(\"network.bind_host\"));\n+        assertEquals(\"5.5.5.5\", clientSettings.get(\"network.publish_host\"));\n     }\n }",
    "output": "Add test for per tribe client overrides"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -1075,6 +1075,7 @@ public boolean clearData(String nodeName) {\n      * Tests that indices are properly deleted even if there is a master transition in between.\n      * Test for https://github.com/elastic/elasticsearch/issues/11665\n      */\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/16890\")\n     public void testIndicesDeleted() throws Exception {\n         configureUnicastCluster(3, null, 2);\n         InternalTestCluster.Async<List<String>> masterNodes = internalCluster().startMasterOnlyNodesAsync(2);",
    "output": "Add AwaitsFix annotation to the sporadically failing test DiscoveryWithServiceDisruptionIT.testIndicesDeleted pending a fix for that test (see issue #16890)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java b/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java\n--- a/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java\n+++ b/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java\n@@ -19,7 +19,6 @@\n package org.elasticsearch.gateway;\n \n import org.apache.lucene.codecs.CodecUtil;\n-import org.apache.lucene.index.CorruptIndexException;\n import org.apache.lucene.store.ChecksumIndexInput;\n import org.apache.lucene.store.Directory;\n import org.apache.lucene.store.IOContext;\n@@ -378,7 +377,7 @@ public void testLoadState() throws IOException {\n                 format.loadLatestState(logger, dirList.toArray(new Path[0]));\n                 fail(\"latest version can not be read\");\n             } catch (ElasticsearchException ex) {\n-                assertThat(ExceptionsHelper.unwrap(ex, CorruptIndexException.class), notNullValue());\n+                assertThat(ExceptionsHelper.unwrap(ex, CorruptStateException.class), notNullValue());\n             }\n         }\n ",
    "output": "Fix exception assertions in MetaDataStateFormatTests.testLoadState (again)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java b/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java\n--- a/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java\n+++ b/core/src/test/java/org/elasticsearch/gateway/MetaDataStateFormatTests.java\n@@ -19,6 +19,7 @@\n package org.elasticsearch.gateway;\n \n import org.apache.lucene.codecs.CodecUtil;\n+import org.apache.lucene.index.CorruptIndexException;\n import org.apache.lucene.store.ChecksumIndexInput;\n import org.apache.lucene.store.Directory;\n import org.apache.lucene.store.IOContext;\n@@ -27,6 +28,7 @@\n import org.apache.lucene.store.SimpleFSDirectory;\n import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.Version;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n import org.elasticsearch.cluster.metadata.MetaData;\n@@ -59,7 +61,6 @@\n import java.util.stream.StreamSupport;\n \n import static org.hamcrest.Matchers.equalTo;\n-import static org.hamcrest.Matchers.instanceOf;\n import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.not;\n import static org.hamcrest.Matchers.notNullValue;\n@@ -377,7 +378,7 @@ public void testLoadState() throws IOException {\n                 format.loadLatestState(logger, dirList.toArray(new Path[0]));\n                 fail(\"latest version can not be read\");\n             } catch (ElasticsearchException ex) {\n-                assertThat(ex.getCause(), instanceOf(CorruptStateException.class));\n+                assertThat(ExceptionsHelper.unwrap(ex, CorruptIndexException.class), notNullValue());\n             }\n         }\n ",
    "output": "Fix exception assertions in MetaDataStateFormatTests.testLoadState Got broken with the change in"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java b/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java\n--- a/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java\n+++ b/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java\n@@ -313,7 +313,7 @@ public  T loadLatestState(ESLogger logger, Path... dataLocations) throws IOExcep\n                 }\n                 return state;\n             } catch (Throwable e) {\n-                exceptions.add(e);\n+                exceptions.add(new IOException(\"failed to read \" + pathAndStateId.toString(), e));\n                 logger.debug(\"{}: failed to read [{}], ignoring...\", e, pathAndStateId.file.toAbsolutePath(), prefix);\n             }\n         }",
    "output": "Add file name to exceptions when failing to read index state"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/settings/SettingTests.java b/core/src/test/java/org/elasticsearch/common/settings/SettingTests.java\n--- a/core/src/test/java/org/elasticsearch/common/settings/SettingTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/settings/SettingTests.java\n@@ -40,7 +40,7 @@ public void testGet() {\n         Setting<Boolean> booleanSetting = Setting.boolSetting(\"foo.bar\", false, SettingsProperty.Dynamic, SettingsProperty.ClusterScope);\n         assertFalse(booleanSetting.get(Settings.EMPTY));\n         assertFalse(booleanSetting.get(Settings.builder().put(\"foo.bar\", false).build()));\n-        assertTrue(booleanSetting.get(Settings.builder().put(\"foo.bar\", SettingsProperty.Dynamic).build()));\n+        assertTrue(booleanSetting.get(Settings.builder().put(\"foo.bar\", true).build()));\n     }\n \n     public void testByteSize() {",
    "output": "Fix regression in test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/routing/SimpleRoutingIT.java b/core/src/test/java/org/elasticsearch/routing/SimpleRoutingIT.java\n--- a/core/src/test/java/org/elasticsearch/routing/SimpleRoutingIT.java\n+++ b/core/src/test/java/org/elasticsearch/routing/SimpleRoutingIT.java\n@@ -200,10 +200,6 @@ public void testRequiredRoutingCrudApis() throws Exception {\n             assertThat(client().prepareGet(indexOrAlias(), \"type1\", \"1\").setRouting(\"0\").execute().actionGet().isExists(), equalTo(true));\n         }\n \n-        logger.info(\"--> indexing with id [1], and routing [0]\");\n-        client().prepareIndex(indexOrAlias(), \"type1\", \"1\").setRouting(\"0\").setSource(\"field\", \"value1\").setRefresh(true).execute().actionGet();\n-        logger.info(\"--> verifying get with no routing, should not find anything\");\n-\n         try {\n             client().prepareUpdate(indexOrAlias(), \"type1\", \"1\").setDoc(\"field\", \"value2\").execute().actionGet();\n             fail(\"update with missing routing when routing is required should fail\");",
    "output": "Remove needless index operation in SimpleRoutingIT"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/shield/authz/AuthorizationUtilsTests.java b/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/shield/authz/AuthorizationUtilsTests.java\n--- a/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/shield/authz/AuthorizationUtilsTests.java\n+++ b/elasticsearch/x-pack/license-plugin/src/test/java/org/elasticsearch/shield/authz/AuthorizationUtilsTests.java\n@@ -18,7 +18,7 @@\n /**\n  * Unit tests for the AuthorizationUtils class\n  */\n-public class AuthorizationUtilsTest extends ESTestCase {\n+public class AuthorizationUtilsTests extends ESTestCase {\n \n     private ThreadContext threadContext;\n \n\ndiff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n@@ -42,7 +42,7 @@\n import static org.elasticsearch.common.unit.TimeValue.timeValueMinutes;\n \n @ClusterScope(scope = ESIntegTestCase.Scope.SUITE, randomDynamicTemplates = false, transportClientRatio = 0.0)\n-public class AbstractCollectorTestCase extends MarvelIntegTestCase {\n+public abstract class AbstractCollectorTestCase extends MarvelIntegTestCase {\n \n     @Override\n     protected Collection<Class<? extends Plugin>> nodePlugins() {",
    "output": "Make tests follow naming conventions One test wasn't running because it didn't match!"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/RoleDescriptor.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/RoleDescriptor.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/RoleDescriptor.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/RoleDescriptor.java\n@@ -169,7 +169,8 @@ public static RoleDescriptor source(String name, BytesReference source) throws E\n                         } else if (roleName.equals(parser.text()) == false) {\n                             // if the given role name is not the same as the parsed role name, we have inconstency and we need to\n                             // throw an error\n-                            throw new ElasticsearchParseException(\"expected role name [{}] but found [{}] instead\", roleName, parser.text());\n+                            throw new ElasticsearchParseException(\"expected role name [{}] but found [{}] instead\",\n+                                    roleName, parser.text());\n                         }\n                     } else {\n                         throw new ElasticsearchParseException(\"unexpected field in add role request [{}]\", currentFieldName);",
    "output": "Fix checkstyle error"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java b/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java\n--- a/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/settings/loader/JsonSettingsLoaderTests.java\n@@ -58,7 +58,7 @@ public void testDuplicateKeysThrowsException() {\n             fail(\"expected exception\");\n         } catch (SettingsException e) {\n             assertEquals(e.getCause().getClass(), ElasticsearchParseException.class);\n-            assertTrue(e.toString().contains(\"duplicate settings key [foo] found at line number [1], column number [13], previous value [bar], current value [baz]\"));\n+            assertTrue(e.toString().contains(\"duplicate settings key [foo] found at line number [1], column number [20], previous value [bar], current value [baz]\"));\n         }\n     }\n }",
    "output": "Upgrade to Jackson 2.7.0"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java b/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java\n--- a/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java\n+++ b/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java\n@@ -36,8 +36,6 @@\n  */\n public abstract class ConcurrentCollections {\n \n-    private final static boolean useLinkedTransferQueue = Boolean.parseBoolean(System.getProperty(\"es.useLinkedTransferQueue\", \"false\"));\n-\n     static final int aggressiveConcurrencyLevel;\n \n     static {\n@@ -71,9 +69,6 @@ public static <V> Set<V> newConcurrentSet() {\n     }\n \n     public static <T> Queue<T> newQueue() {\n-        if (useLinkedTransferQueue) {\n-            return new LinkedTransferQueue<>();\n-        }\n         return new ConcurrentLinkedQueue<>();\n     }\n ",
    "output": "Remove es.useLinkedTransferQueue This commit removes the system property \"es.useLinkedTransferQueue\" that defaulted to false and was used to control the queue implementation used in a few places"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/netty/NettyUtils.java b/core/src/main/java/org/elasticsearch/common/netty/NettyUtils.java\n--- a/core/src/main/java/org/elasticsearch/common/netty/NettyUtils.java\n+++ b/core/src/main/java/org/elasticsearch/common/netty/NettyUtils.java\n@@ -18,8 +18,6 @@\n  */\n package org.elasticsearch.common.netty;\n \n-import org.elasticsearch.common.Booleans;\n-import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.transport.netty.NettyInternalESLoggerFactory;\n import org.jboss.netty.logging.InternalLogger;\n import org.jboss.netty.logging.InternalLoggerFactory;\n@@ -74,7 +72,7 @@ public class NettyUtils {\n      * sized pages, and if its a single one, makes sure that it gets sliced and wrapped in a composite\n      * buffer.\n      */\n-    public static final boolean DEFAULT_GATHERING;\n+    public static final boolean DEFAULT_GATHERING = true;\n \n     private static EsThreadNameDeterminer ES_THREAD_NAME_DETERMINER = new EsThreadNameDeterminer();\n \n@@ -95,13 +93,6 @@ public InternalLogger newInstance(String name) {\n         });\n \n         ThreadRenamingRunnable.setThreadNameDeterminer(ES_THREAD_NAME_DETERMINER);\n-\n-        /**\n-         * This is here just to give us an option to rollback the change, if its stable, we should remove\n-         * the option to even set it.\n-         */\n-        DEFAULT_GATHERING = Booleans.parseBoolean(System.getProperty(\"es.netty.gathering\"), true);\n-        Loggers.getLogger(NettyUtils.class).debug(\"using gathering [{}]\", DEFAULT_GATHERING);\n     }\n \n     public static void setup() {",
    "output": "Remove ability to disable Netty gathering writes Java NIO has the notion of gathering writes. These are writes that gather data from multiple buffers into a single channel. These gathering writes in Netty have been enabled by default with the possibility to disable them using \"es.netty.gathering\". This flag was added in case having gathering writes on by default did not work out. We have not published this ability and sufficient time has passed to render judgement that using gathering writes is okay"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/Marvel.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/Marvel.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/Marvel.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/Marvel.java\n@@ -10,13 +10,11 @@\n import org.elasticsearch.common.inject.Module;\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.logging.Loggers;\n-import org.elasticsearch.common.settings.Setting;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.settings.SettingsModule;\n import org.elasticsearch.marvel.agent.AgentService;\n import org.elasticsearch.marvel.agent.collector.CollectorModule;\n import org.elasticsearch.marvel.agent.exporter.ExporterModule;\n-import org.elasticsearch.marvel.agent.exporter.Exporters;\n import org.elasticsearch.marvel.agent.renderer.RendererModule;\n import org.elasticsearch.marvel.cleaner.CleanerService;\n import org.elasticsearch.marvel.license.LicenseModule;\n@@ -28,7 +26,6 @@\n import java.util.Collection;\n import java.util.Collections;\n import java.util.List;\n-import java.util.function.Function;\n \n public class Marvel {\n ",
    "output": "Remove unused imports"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/cleaner/CleanerService.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/cleaner/CleanerService.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/cleaner/CleanerService.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/cleaner/CleanerService.java\n@@ -8,7 +8,6 @@\n import org.elasticsearch.common.component.AbstractLifecycleComponent;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.ClusterSettings;\n-import org.elasticsearch.common.settings.Setting;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.util.concurrent.AbstractRunnable;",
    "output": "Remove duplicated import"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapSettingsTests.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapSettingsTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapSettingsTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapSettingsTests.java\n@@ -43,7 +43,7 @@ public void testEnforceMaxFileDescriptorLimits() {\n         long maxFileDescriptorCount = ProcessProbe.getInstance().getMaxFileDescriptorCount();\n         try {\n             Bootstrap.enforceOrLogLimits(build);\n-            if (maxFileDescriptorCount != -1 || maxFileDescriptorCount < (1 << 16)) {\n+            if (maxFileDescriptorCount != -1 && maxFileDescriptorCount < (1 << 16)) {\n                 fail(\"must have enforced limits: \" + maxFileDescriptorCount);\n             }\n         } catch (IllegalStateException ex) {",
    "output": "Fix test to only enforce settings if it's not negative AND less than the limit"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -256,11 +256,6 @@ static void init(String[] args) throws Throwable {\n             PidFile.create(environment.pidFile(), true);\n         }\n \n-        if (System.getProperty(\"es.max-open-files\", \"false\").equals(\"true\")) {\n-            ESLogger logger = Loggers.getLogger(Bootstrap.class);\n-            logger.info(\"max_open_files [{}]\", ProcessProbe.getInstance().getMaxFileDescriptorCount());\n-        }\n-\n         // warn if running using the client VM\n         if (JvmInfo.jvmInfo().getVmName().toLowerCase(Locale.ROOT).contains(\"client\")) {\n             ESLogger logger = Loggers.getLogger(Bootstrap.class);",
    "output": "Remove es.max-open-files flag This commit removes the es.max-open-files flag as the same information can be obtained from the cluster nodes info API, and is warn logged on startup if it's set too low anyway"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java\n@@ -55,7 +55,8 @@ public CommonStats getPrimaries() {\n                         CommonStats stats = new CommonStats();\n                         stats.docs = new DocsStats(345678L, randomLong());\n                         stats.store = new StoreStats(randomLong(), randomLong());\n-                        stats.indexing = new IndexingStats(new IndexingStats.Stats(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, true, randomLong()), null);\n+                        stats.indexing = new IndexingStats(new IndexingStats.Stats(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, true,\n+                                randomLong()), null);\n                         stats.search = new SearchStats(new SearchStats.Stats(1L, 7L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), 0L, null);\n                         stats.merge = new MergeStats();\n                         stats.merge.add(0L, 0L, 0L, 42L, 0L, 0L, 0L, 0L, 0L, 0L);",
    "output": "Fix line length"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n@@ -115,7 +115,6 @@ protected Table getTableWithHeader(final RestRequest request) {\n         table.startHeaders();\n         table.addCell(\"id\", \"default:false;alias:id,nodeId;desc:unique node id\");\n         table.addCell(\"pid\", \"default:false;alias:p;desc:process id\");\n-        table.addCell(\"host\", \"alias:h;desc:host name\");\n         table.addCell(\"ip\", \"alias:i;desc:ip address\");\n         table.addCell(\"port\", \"default:false;alias:po;desc:bound transport port\");\n \n@@ -242,7 +241,6 @@ private Table buildTable(RestRequest req, ClusterStateResponse state, NodesInfoR\n \n             table.addCell(fullId ? node.id() : Strings.substring(node.getId(), 0, 4));\n             table.addCell(info == null ? null : info.getProcess().getId());\n-            table.addCell(node.getHostName());\n             table.addCell(node.getHostAddress());\n             if (node.address() instanceof InetSocketTransportAddress) {\n                 table.addCell(((InetSocketTransportAddress) node.address()).address().getPort());",
    "output": "Remove host from cat nodes API As the host and ip fields are always equal by design, the host field in the cat nodes API is redundant and should be removed"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java\n--- a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java\n@@ -501,7 +501,7 @@ private QueryBuilder<?> parseQuery(XContentParser parser, ParseFieldMatcher matc\n         context.reset(parser);\n         context.parseFieldMatcher(matcher);\n         QueryBuilder<?> parseInnerQueryBuilder = context.parseInnerQueryBuilder();\n-        assertTrue(parser.nextToken() == null);\n+        assertNull(parser.nextToken());\n         return parseInnerQueryBuilder;\n     }\n \n\ndiff --git a/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java b/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java\n@@ -368,7 +368,7 @@ private void assertParseSearchSource(SearchSourceBuilder testBuilder, BytesRefer\n             parser.nextToken(); // sometimes we move it on the START_OBJECT to test the embedded case\n         }\n         SearchSourceBuilder newBuilder = SearchSourceBuilder.parseSearchSource(parser, parseContext);\n-        assertTrue(parser.nextToken() == null);\n+        assertNull(parser.nextToken());\n         assertEquals(testBuilder, newBuilder);\n         assertEquals(testBuilder.hashCode(), newBuilder.hashCode());\n     }",
    "output": "Use assertNull rather than assertTrue(object == null)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java b/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/builder/SearchSourceBuilderTests.java\n@@ -368,7 +368,7 @@ private void assertParseSearchSource(SearchSourceBuilder testBuilder, BytesRefer\n             parser.nextToken(); // sometimes we move it on the START_OBJECT to test the embedded case\n         }\n         SearchSourceBuilder newBuilder = SearchSourceBuilder.parseSearchSource(parser, parseContext);\n-        assertNotSame(testBuilder, newBuilder);\n+        assertTrue(parser.nextToken() == null);\n         assertEquals(testBuilder, newBuilder);\n         assertEquals(testBuilder.hashCode(), newBuilder.hashCode());\n     }",
    "output": "Make SearchSourceBuilderTests pickier, check that the search source has been read completely Same check is already performed in AbstractQueryTestCase, makes sense to have it here too"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/MetaDataIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/MetaDataIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/MetaDataIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/MetaDataIT.java\n@@ -31,7 +31,8 @@\n import java.util.Map;\n \n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n-import static org.elasticsearch.search.aggregations.AggregationBuilders.*;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.sum;\n+import static org.elasticsearch.search.aggregations.AggregationBuilders.terms;\n import static org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorBuilders.maxBucket;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;\n ",
    "output": "Fix failing stylecheck"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/InstallPluginCommandTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.plugins;\n \n import java.io.IOException;\n+import java.io.InputStream;\n import java.net.MalformedURLException;\n import java.net.URL;\n import java.nio.charset.StandardCharsets;\n@@ -203,7 +204,9 @@ public void testSpaceInUrl() throws Exception {\n         Path pluginDir = createTempDir();\n         String pluginZip = createPlugin(\"fake\", pluginDir);\n         Path pluginZipWithSpaces = createTempFile(\"foo bar\", \".zip\");\n-        Files.copy(new URL(pluginZip).openStream(), pluginZipWithSpaces, StandardCopyOption.REPLACE_EXISTING);\n+        try (InputStream in = new URL(pluginZip).openStream()) {\n+            Files.copy(in, pluginZipWithSpaces, StandardCopyOption.REPLACE_EXISTING);\n+        }\n         installPlugin(pluginZipWithSpaces.toUri().toURL().toString(), env);\n         assertPlugin(\"fake\", pluginDir, env);\n     }",
    "output": "Add missing try with resources in InstallPluginCommandTest, this should fix the build on windows"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/SuggestBuilder.java b/core/src/main/java/org/elasticsearch/search/suggest/SuggestBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/SuggestBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/SuggestBuilder.java\n@@ -72,7 +72,7 @@ public SuggestBuilder setText(@Nullable String globalText) {\n      * Gets the global suggest text\n      */\n     public String getText() {\n-        return null;\n+        return this.globalText;\n     }\n \n     /**",
    "output": "Fix small issue in SuggestBuilder#getText"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -254,10 +254,6 @@ static void init(String[] args) throws Throwable {\n         INSTANCE = new Bootstrap();\n \n         boolean foreground = !\"false\".equals(System.getProperty(\"es.foreground\", System.getProperty(\"es-foreground\")));\n-        // handle the wrapper system property, if its a service, don't run as a service\n-        if (System.getProperty(\"wrapper.service\", \"XXX\").equalsIgnoreCase(\"true\")) {\n-            foreground = false;\n-        }\n \n         Environment environment = initialSettings(foreground);\n         Settings settings = environment.settings();",
    "output": "Remove dead support for Java Service Wrapper This commit removes bootstrap support for Java Service Wrapper. The implementation of this has been moved to its own repository where it was deprecated, does not work with Elasticsearch 2.x, and is untested and therefore unmaintained"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TopHitsTests.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TopHitsTests.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TopHitsTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TopHitsTests.java\n@@ -125,8 +125,8 @@ protected final TopHitsAggregator.TopHitsAggregatorBuilder createTestAggregatorB\n                     factory.sort(SortBuilders.fieldSort(randomAsciiOfLengthBetween(5, 20)).order(randomFrom(SortOrder.values())));\n                     break;\n                 case 1:\n-                    factory.sort(SortBuilders.geoDistanceSort(randomAsciiOfLengthBetween(5, 20))\n-                            .geohashes(AbstractQueryTestCase.randomGeohash(1, 12)).order(randomFrom(SortOrder.values())));\n+                    factory.sort(SortBuilders.geoDistanceSort(randomAsciiOfLengthBetween(5, 20), AbstractQueryTestCase.randomGeohash(1, 12))\n+                            .order(randomFrom(SortOrder.values())));\n                     break;\n                 case 2:\n                     factory.sort(SortBuilders.scoreSort().order(randomFrom(SortOrder.values())));",
    "output": "Fix merge error"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java\n@@ -396,7 +396,7 @@ public void testMinimumShouldMatch() throws IOException {\n             assertThat(query, instanceOf(BooleanQuery.class));\n             BooleanQuery boolQuery = (BooleanQuery) query;\n             int expectedMinimumShouldMatch = numberOfTerms * percent / 100;\n-            if (simpleQueryStringBuilder.defaultOperator().equals(Operator.AND) && numberOfTerms > 1) {\n+            if (numberOfTerms == 1 || simpleQueryStringBuilder.defaultOperator().equals(Operator.AND)) {\n                 expectedMinimumShouldMatch = 0;\n             }\n             assertEquals(expectedMinimumShouldMatch, boolQuery.getMinimumNumberShouldMatch());",
    "output": "Fix sporadic SimpleQueryStringBuilderTests failures"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggestionBuilder.java b/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggestionBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggestionBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggestionBuilder.java\n@@ -19,12 +19,6 @@\n \n package org.elasticsearch.search.suggest.term;\n \n-import org.apache.lucene.search.spell.DirectSpellChecker;\n-import org.apache.lucene.search.spell.JaroWinklerDistance;\n-import org.apache.lucene.search.spell.LevensteinDistance;\n-import org.apache.lucene.search.spell.LuceneLevenshteinDistance;\n-import org.apache.lucene.search.spell.NGramDistance;\n-import org.apache.lucene.search.spell.StringDistance;\n import org.elasticsearch.common.ParseFieldMatcher;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n@@ -545,6 +539,8 @@ public static StringDistanceImpl resolve(final String str) {\n                     return LEVENSTEIN;\n                 case \"ngram\":\n                     return NGRAM;\n+                case \"jarowinkler\":\n+                    return JAROWINKLER;\n                 default: throw new IllegalArgumentException(\"Illegal distance option \" + str);\n             }\n         }",
    "output": "Fix test failures in TermSuggestionBuilderTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/env/Environment.java b/core/src/main/java/org/elasticsearch/env/Environment.java\n--- a/core/src/main/java/org/elasticsearch/env/Environment.java\n+++ b/core/src/main/java/org/elasticsearch/env/Environment.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.env;\n \n-import org.apache.lucene.util.Constants;\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.common.SuppressForbidden;\n import org.elasticsearch.common.io.PathUtils;",
    "output": "Remove unused import from o.e.e.Environment"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java b/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java\n--- a/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java\n+++ b/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java\n@@ -19,8 +19,6 @@\n \n package org.elasticsearch.common.hash;\n \n-import org.elasticsearch.ElasticsearchException;\n-\n import java.security.MessageDigest;\n import java.security.NoSuchAlgorithmException;\n import java.util.Objects;",
    "output": "Remove unused import from o.e.c.h.MessageDigests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/similarity/SimilarityTests.java b/core/src/test/java/org/elasticsearch/index/similarity/SimilarityTests.java\n--- a/core/src/test/java/org/elasticsearch/index/similarity/SimilarityTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/similarity/SimilarityTests.java\n@@ -228,7 +228,7 @@ public void testResolveSimilaritiesFromMapping_Unknown() throws IOException {\n             indexService.mapperService().documentMapperParser().parse(\"type\", new CompressedXContent(mapping));\n             fail(\"Expected MappingParsingException\");\n         } catch (MapperParsingException e) {\n-            assertThat(e.getMessage(), equalTo(\"Unknown Similarity type [unknown_similarity] for [field1]\"));\n+            assertThat(e.getMessage(), equalTo(\"Unknown Similarity type [unknown_similarity] for field [field1]\"));\n         }\n     }\n \n@@ -255,7 +255,7 @@ public void testSimilarityDefaultBackCompat() throws IOException {\n             parser.parse(\"type\", new CompressedXContent(mapping));\n             fail(\"Expected MappingParsingException\");\n         } catch (MapperParsingException e) {\n-            assertThat(e.getMessage(), equalTo(\"Unknown Similarity type [default] for [field1]\"));\n+            assertThat(e.getMessage(), equalTo(\"Unknown Similarity type [default] for field [field1]\"));\n         }\n     }\n }",
    "output": "Fix similarity tests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactory.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactory.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactory.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactory.java\n@@ -67,6 +67,7 @@ public AggregatorFactory(String name, Type type, AggregationContext context, Agg\n         this.type = type;\n         this.context = context;\n         this.factories = subFactoriesBuilder.build(context, this);\n+        this.metaData = metaData;\n     }\n \n     public String name() {",
    "output": "Fix where metadata wasn't being passed through to the AggregatorFactory"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java\n@@ -210,7 +210,7 @@ public void onIndexModule(IndexModule module) {\n         assert shieldLicenseState != null;\n         if (flsDlsEnabled(settings)) {\n             module.setSearcherWrapper((indexService) -> new ShieldIndexSearcherWrapper(indexService.getIndexSettings(),\n-                    indexService.getQueryShardContext(), indexService.mapperService(),\n+                    indexService.newQueryShardContext(), indexService.mapperService(),\n                     indexService.cache().bitsetFilterCache(), indexService.getIndexServices().getThreadPool().getThreadContext(),\n                     shieldLicenseState));\n         }",
    "output": "Fix compile error after core change"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -910,7 +910,7 @@ private DiscoveryNode findMaster() {\n             activeNodes.add(localNode);\n             long joinsCounter = clusterJoinsCounter.get();\n             if (joinsCounter > 0) {\n-                logger.trace(\"adding local node to the list of active nodes who has previously joined the cluster (joins counter is [{}})\", joinsCounter);\n+                logger.trace(\"adding local node to the list of active nodes that have previously joined the cluster (joins counter is [{}])\", joinsCounter);\n                 joinedOnceActiveNodes.add(localNode);\n             }\n         }",
    "output": "Fix trace logging statement in ZenDiscovery"
  },
  {
    "input": "diff --git a/modules/lang-mustache/src/test/java/org/elasticsearch/messy/tests/TemplateQueryParserTests.java b/modules/lang-mustache/src/test/java/org/elasticsearch/messy/tests/TemplateQueryParserTests.java\n--- a/modules/lang-mustache/src/test/java/org/elasticsearch/messy/tests/TemplateQueryParserTests.java\n+++ b/modules/lang-mustache/src/test/java/org/elasticsearch/messy/tests/TemplateQueryParserTests.java\n@@ -43,6 +43,7 @@\n import org.elasticsearch.index.analysis.AnalysisRegistry;\n import org.elasticsearch.index.analysis.AnalysisService;\n import org.elasticsearch.index.cache.bitset.BitsetFilterCache;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n import org.elasticsearch.index.fielddata.IndexFieldDataService;\n import org.elasticsearch.index.mapper.MapperService;\n import org.elasticsearch.index.query.QueryShardContext;\n@@ -138,7 +139,8 @@ protected void configure() {\n         SimilarityService similarityService = new SimilarityService(idxSettings, Collections.emptyMap());\n         MapperRegistry mapperRegistry = new IndicesModule().getMapperRegistry();\n         MapperService mapperService = new MapperService(idxSettings, analysisService, similarityService, mapperRegistry, () -> context);\n-        IndexFieldDataService indexFieldDataService =new IndexFieldDataService(idxSettings, injector.getInstance(IndicesFieldDataCache.class), injector.getInstance(CircuitBreakerService.class), mapperService);\n+        IndicesFieldDataCache cache = new IndicesFieldDataCache(settings, new IndexFieldDataCache.Listener() {});\n+        IndexFieldDataService indexFieldDataService =new IndexFieldDataService(idxSettings, cache, injector.getInstance(CircuitBreakerService.class), mapperService);\n         BitsetFilterCache bitsetFilterCache = new BitsetFilterCache(idxSettings, new IndicesWarmer(idxSettings.getNodeSettings(), null), new BitsetFilterCache.Listener() {\n             @Override\n             public void onCache(ShardId shardId, Accountable accountable) {",
    "output": "Fix another test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java b/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java\n--- a/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java\n+++ b/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java\n@@ -37,6 +37,7 @@\n import org.elasticsearch.common.xcontent.XContentFactory;\n import org.elasticsearch.index.MockEngineFactoryPlugin;\n import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.indices.IndicesService;\n import org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache;\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.search.sort.SortOrder;\n@@ -176,7 +177,7 @@ public void testBreakerWithRandomExceptions() throws IOException, InterruptedExc\n \n                 // Since .cleanUp() is no longer called on cache clear, we need to call it on each node manually\n                 for (String node : internalCluster().getNodeNames()) {\n-                    final IndicesFieldDataCache fdCache = internalCluster().getInstance(IndicesFieldDataCache.class, node);\n+                    final IndicesFieldDataCache fdCache = internalCluster().getInstance(IndicesService.class, node).getIndicesFieldDataCache();\n                     // Clean up the cache, ensuring that entries' listeners have been called\n                     fdCache.getCache().refresh();\n                 }",
    "output": "Fix more tests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/SettingsModule.java b/core/src/main/java/org/elasticsearch/common/settings/SettingsModule.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/SettingsModule.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/SettingsModule.java\n@@ -31,8 +31,6 @@\n \n /**\n  * A module that binds the provided settings to the {@link Settings} interface.\n- *\n- *\n  */\n public class SettingsModule extends AbstractModule {\n \n@@ -42,7 +40,6 @@ public class SettingsModule extends AbstractModule {\n     private final Map<String, Setting<?>> indexSettings = new HashMap<>();\n     private static final Predicate<String> TRIBE_CLIENT_NODE_SETTINGS_PREDICATE =  (s) -> s.startsWith(\"tribe.\") && TribeService.TRIBE_SETTING_KEYS.contains(s) == false;\n \n-\n     public SettingsModule(Settings settings) {\n         this.settings = settings;\n         for (Setting<?> setting : ClusterSettings.BUILT_IN_CLUSTER_SETTINGS) {\n@@ -112,7 +109,7 @@ public void registerSettingsFilterIfMissing(String filter) {\n     }\n \n \n-    public void validateTribeSettings(Settings settings, ClusterSettings clusterSettings) {\n+    private void validateTribeSettings(Settings settings, ClusterSettings clusterSettings) {\n         Map<String, Settings> groups = settings.filter(TRIBE_CLIENT_NODE_SETTINGS_PREDICATE).getGroups(\"tribe.\", true);\n         for (Map.Entry<String, Settings>  tribeSettings : groups.entrySet()) {\n             Settings thisTribesSettings = tribeSettings.getValue();",
    "output": "Fix method visibility in SettingsModule.java"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/SuggestUtils.java b/core/src/main/java/org/elasticsearch/search/suggest/SuggestUtils.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/SuggestUtils.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/SuggestUtils.java\n@@ -171,6 +171,7 @@ public static SuggestMode resolveSuggestMode(String suggestMode) {\n     }\n \n     public static Suggest.Suggestion.Sort resolveSort(String sortVal) {\n+        sortVal = sortVal.toLowerCase(Locale.US);\n         if (\"score\".equals(sortVal)) {\n             return Suggest.Suggestion.Sort.SCORE;\n         } else if (\"frequency\".equals(sortVal)) {\n@@ -181,6 +182,7 @@ public static Suggest.Suggestion.Sort resolveSort(String sortVal) {\n     }\n \n     public static StringDistance resolveDistance(String distanceVal) {\n+        distanceVal = distanceVal.toLowerCase(Locale.US);\n         if (\"internal\".equals(distanceVal)) {\n             return DirectSpellChecker.INTERNAL_LEVENSHTEIN;\n         } else if (\"damerau_levenshtein\".equals(distanceVal) || \"damerauLevenshtein\".equals(distanceVal)) {",
    "output": "Fix JSON parsing for the Term Suggester Ensures that the clients' serialization of the sort and string edit distance enumeration values as upper case are correctly normalized when parsing the incoming JSON"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n@@ -67,9 +67,6 @@ public final class EngineConfig {\n     private final QueryCache queryCache;\n     private final QueryCachingPolicy queryCachingPolicy;\n \n-    static {\n-\n-    }\n     /**\n      * Index setting to change the low level lucene codec used for writing new segments.\n      * This setting is <b>not</b> realtime updateable.",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelPlugin.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelPlugin.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelPlugin.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/MarvelPlugin.java\n@@ -139,6 +139,7 @@ public void onModule(SettingsModule module) {\n         module.registerSetting(INDEX_MARVEL_TEMPLATE_VERSION_SETTING);\n         // TODO convert these settings to where they belong\n         module.registerSetting(Setting.simpleString(\"marvel.agent.exporter.es.ssl.truststore.password\", false, Setting.Scope.CLUSTER));\n+        module.registerSetting(Setting.simpleString(\"marvel.agent.exporter.es.ssl.truststore.path\", false, Setting.Scope.CLUSTER));\n         module.registerSetting(Setting.boolSetting(\"marvel.enabled\", false, false, Setting.Scope.CLUSTER));\n     }\n }",
    "output": "Add missing setting"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java b/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java\n@@ -147,8 +147,6 @@ public void apply(Settings value, Settings current, Settings previous) {\n         }\n     }\n \n-    ;\n-\n     public static Set<Setting<?>> BUILT_IN_CLUSTER_SETTINGS = Collections.unmodifiableSet(new HashSet<>(\n         Arrays.asList(AwarenessAllocationDecider.CLUSTER_ROUTING_ALLOCATION_AWARENESS_ATTRIBUTE_SETTING,\n             TransportClientNodesService.CLIENT_TRANSPORT_NODES_SAMPLER_INTERVAL, // TODO these transport client settings are kind of odd here and should only be valid if we are a transport client",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java b/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java\n--- a/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java\n@@ -556,7 +556,7 @@ public void messageReceived(StringMessageRequest request, TransportChannel chann\n         });\n         final CountDownLatch latch = new CountDownLatch(1);\n         TransportFuture<StringMessageResponse> res = serviceB.submitRequest(nodeA, \"sayHelloTimeoutDelayedResponse\",\n-                new StringMessageRequest(\"300ms\"), TransportRequestOptions.builder().withTimeout(100).build(), new BaseTransportResponseHandler<StringMessageResponse>() {\n+                new StringMessageRequest(\"2m\"), TransportRequestOptions.builder().withTimeout(100).build(), new BaseTransportResponseHandler<StringMessageResponse>() {\n                     @Override\n                     public StringMessageResponse newInstance() {\n                         return new StringMessageResponse();",
    "output": "Make testTimeoutSendExceptionWithDelayedResponse less timing sensitive"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java b/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n--- a/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n+++ b/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.ingest;\n \n import org.elasticsearch.ElasticsearchParseException;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.bulk.BulkItemResponse;\n import org.elasticsearch.action.bulk.BulkRequest;\n import org.elasticsearch.action.bulk.BulkResponse;\n@@ -219,7 +220,9 @@ public void testPutWithPipelineFactoryError() throws Exception {\n         try {\n             client().admin().cluster().putPipeline(putPipelineRequest).get();\n         } catch (ExecutionException e) {\n-            assertThat(e.getCause().getCause().getMessage(), equalTo(\"processor [test] doesn't support one or more provided configuration parameters [unused]\"));\n+            ElasticsearchParseException ex = (ElasticsearchParseException) ExceptionsHelper.unwrap(e, ElasticsearchParseException.class);\n+            assertNotNull(ex);\n+            assertThat(ex.getMessage(), equalTo(\"processor [test] doesn't support one or more provided configuration parameters [unused]\"));\n         }\n     }\n ",
    "output": "Fix ingest client put error test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java b/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n--- a/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n+++ b/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.ingest;\n \n import org.elasticsearch.ElasticsearchParseException;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.bulk.BulkItemResponse;\n import org.elasticsearch.action.bulk.BulkRequest;\n import org.elasticsearch.action.bulk.BulkResponse;\n@@ -219,7 +220,9 @@ public void testPutWithPipelineFactoryError() throws Exception {\n         try {\n             client().admin().cluster().putPipeline(putPipelineRequest).get();\n         } catch (ExecutionException e) {\n-            assertThat(e.getCause().getCause().getMessage(), equalTo(\"processor [test] doesn't support one or more provided configuration parameters [unused]\"));\n+            ElasticsearchParseException ex = (ElasticsearchParseException) ExceptionsHelper.unwrap(e, ElasticsearchParseException.class);\n+            assertNotNull(ex);\n+            assertThat(ex.getMessage(), equalTo(\"processor [test] doesn't support one or more provided configuration parameters [unused]\"));\n         }\n     }\n ",
    "output": "Fix ingest client put error test"
  },
  {
    "input": "diff --git a/plugins/lang-painless/src/test/java/org/elasticsearch/painless/NoSemiColonTests.java b/plugins/lang-painless/src/test/java/org/elasticsearch/painless/NoSemiColonTests.java\n--- a/plugins/lang-painless/src/test/java/org/elasticsearch/painless/NoSemiColonTests.java\n+++ b/plugins/lang-painless/src/test/java/org/elasticsearch/painless/NoSemiColonTests.java\n@@ -22,7 +22,7 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-public class NoSemiColonTest extends ScriptTestCase {\n+public class NoSemiColonTests extends ScriptTestCase {\n \n     public void testIfStatement() {\n         assertEquals(1, exec(\"int x = 5 if (x == 5) return 1 return 0\"));",
    "output": "Fix test file name"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/monitor/jvm/JvmGcMonitorServiceSettingsTests.java b/core/src/test/java/org/elasticsearch/monitor/jvm/JvmGcMonitorServiceSettingsTests.java\n--- a/core/src/test/java/org/elasticsearch/monitor/jvm/JvmGcMonitorServiceSettingsTests.java\n+++ b/core/src/test/java/org/elasticsearch/monitor/jvm/JvmGcMonitorServiceSettingsTests.java\n@@ -62,9 +62,9 @@ public void testNegativeSetting() throws InterruptedException {\n     public void testMissingSetting() throws InterruptedException {\n         String collector = randomAsciiOfLength(5);\n         Set<AbstractMap.SimpleEntry<String, String>> entries = new HashSet<>();\n-        entries.add(new AbstractMap.SimpleEntry<>(\"monitor.jvm.gc.collector.\" + collector + \".warn\", randomTimeValue()));\n-        entries.add(new AbstractMap.SimpleEntry<>(\"monitor.jvm.gc.collector.\" + collector + \".info\", randomTimeValue()));\n-        entries.add(new AbstractMap.SimpleEntry<>(\"monitor.jvm.gc.collector.\" + collector + \".debug\", randomTimeValue()));\n+        entries.add(new AbstractMap.SimpleEntry<>(\"monitor.jvm.gc.collector.\" + collector + \".warn\", randomPositiveTimeValue()));\n+        entries.add(new AbstractMap.SimpleEntry<>(\"monitor.jvm.gc.collector.\" + collector + \".info\", randomPositiveTimeValue()));\n+        entries.add(new AbstractMap.SimpleEntry<>(\"monitor.jvm.gc.collector.\" + collector + \".debug\", randomPositiveTimeValue()));\n         Settings.Builder builder = Settings.builder();\n \n         // drop a random setting or two",
    "output": "Fix JVM GC monitor missing settings test This commit fixes a test bug in JvmGcMonitorServiceSettingsTests#testMissingSetting. The purpose of the test is to test that if settings are provided for a collector for at least one of warn, info, and debug then it is provided for all of warn, info, and debug. However, for a collector setting to be valid it must be a positive time value but the randomization in the test construction could produce zero time values"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n@@ -382,9 +382,18 @@ public static String[] generateRandomStringArray(int maxArraySize, int maxString\n         return generateRandomStringArray(maxArraySize, maxStringSize, allowNull, true);\n     }\n \n+    private static String[] TIME_SUFFIXES = new String[]{\"d\", \"H\", \"ms\", \"s\", \"S\", \"w\"};\n+\n+    private static String randomTimeValue(int lower, int upper) {\n+        return randomIntBetween(lower, upper) + randomFrom(TIME_SUFFIXES);\n+    }\n+\n     public static String randomTimeValue() {\n-        final String[] values = new String[]{\"d\", \"H\", \"ms\", \"s\", \"S\", \"w\"};\n-        return randomIntBetween(0, 1000) + randomFrom(values);\n+        return randomTimeValue(0, 1000);\n+    }\n+\n+    public static String randomPositiveTimeValue() {\n+        return randomTimeValue(1, 1000);\n     }\n \n     /**",
    "output": "Add random positive time value convenience method This commit adds a convenience method for producing random positive time values which can be useful for places where non-negative and non-zero time values are expected"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n@@ -165,7 +165,6 @@ public GeoPoint[] points() {\n      * \n      * Deprecated - please use points(GeoPoint... points) instead.\n      */\n-    @Deprecated\n     public GeoDistanceSortBuilder geohashes(String... geohashes) {\n         for (String geohash : geohashes) {\n             this.points.add(GeoPoint.fromGeohash(geohash));",
    "output": "Remove deprecation for geohash setter This removes the deprecation for the geohash based setter to quickly fix the failure here: http://build-us-00.elastic.co/job/es_core_master_suse/3312 Reintroducing postponed until related test in groovy module is fixed. Need to figure out what went wrong when I ran the build locally w/o failure before"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DiversifiedSamplerIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DiversifiedSamplerIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DiversifiedSamplerIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DiversifiedSamplerIT.java\n@@ -215,7 +215,7 @@ public void testPartiallyUnmappedDiversifyField() throws Exception {\n                 .execute().actionGet();\n         assertSearchResponse(response);\n         Sampler sample = response.getAggregations().get(\"sample\");\n-        assertThat(sample.getDocCount(), greaterThan(0l));\n+        assertThat(sample.getDocCount(), greaterThan(0L));\n         Terms authors = sample.getAggregations().get(\"authors\");\n         assertThat(authors.getBuckets().size(), greaterThan(0));\n     }\n@@ -230,7 +230,7 @@ public void testWhollyUnmappedDiversifyField() throws Exception {\n                 .setQuery(new TermQueryBuilder(\"genre\", \"fantasy\")).setFrom(0).setSize(60).addAggregation(sampleAgg).execute().actionGet();\n         assertSearchResponse(response);\n         Sampler sample = response.getAggregations().get(\"sample\");\n-        assertThat(sample.getDocCount(), equalTo(0l));\n+        assertThat(sample.getDocCount(), equalTo(0L));\n         Terms authors = sample.getAggregations().get(\"authors\");\n         assertNull(authors);\n     }",
    "output": "Fix issue from merge"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapUserSearchSessionFactoryTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapUserSearchSessionFactoryTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapUserSearchSessionFactoryTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/authc/ldap/LdapUserSearchSessionFactoryTests.java\n@@ -35,6 +35,7 @@\n import org.elasticsearch.xpack.XPackPlugin;\n import org.junit.Before;\n \n+import java.io.IOException;\n import java.nio.file.Path;\n import java.text.MessageFormat;\n import java.util.Collections;\n@@ -495,7 +496,7 @@ public void testThatBindRequestReturnsSimpleBindRequest() {\n     }\n \n     @Network\n-    public void testThatLDAPServerConnectErrorDoesNotPreventNodeFromStarting() {\n+    public void testThatLDAPServerConnectErrorDoesNotPreventNodeFromStarting() throws IOException {\n         String groupSearchBase = \"DC=ad,DC=test,DC=elasticsearch,DC=com\";\n         String userSearchBase = \"CN=Users,DC=ad,DC=test,DC=elasticsearch,DC=com\";\n         Settings ldapSettings = settingsBuilder()",
    "output": "Fix test compilation failures"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/transport/ServerTransportFilterIntegrationTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/transport/ServerTransportFilterIntegrationTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/transport/ServerTransportFilterIntegrationTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/shield/transport/ServerTransportFilterIntegrationTests.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.xpack.XPackPlugin;\n import org.junit.BeforeClass;\n \n+import java.io.IOException;\n import java.net.InetSocketAddress;\n import java.nio.file.Files;\n import java.nio.file.Path;\n@@ -77,7 +78,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 .build();\n     }\n \n-    public void testThatConnectionToServerTypeConnectionWorks() {\n+    public void testThatConnectionToServerTypeConnectionWorks() throws IOException {\n         Settings dataNodeSettings = internalCluster().getDataNodeInstance(Settings.class);\n         String systemKeyFile = dataNodeSettings.get(InternalCryptoService.FILE_SETTING);\n \n@@ -109,7 +110,7 @@ public void testThatConnectionToServerTypeConnectionWorks() {\n         }\n     }\n \n-    public void testThatConnectionToClientTypeConnectionIsRejected() {\n+    public void testThatConnectionToClientTypeConnectionIsRejected() throws IOException {\n         Settings dataNodeSettings = internalCluster().getDataNodeInstance(Settings.class);\n         String systemKeyFile = dataNodeSettings.get(InternalCryptoService.FILE_SETTING);\n ",
    "output": "Fix test compilation failures"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/ESTestCase.java\n@@ -629,13 +629,12 @@ public interface ThrowingRunnable {\n     }\n \n     /** Checks a specific exception class is thrown by the given runnable, and returns it. */\n-    @SuppressWarnings(\"unchecked\")\n     public static <T extends Throwable> T expectThrows(Class<T> expectedType, ThrowingRunnable runnable) {\n         try {\n             runnable.run();\n         } catch (Throwable e) {\n             if (expectedType.isInstance(e)) {\n-                return (T) e;\n+                return expectedType.cast(e);\n             }\n             AssertionFailedError assertion = new AssertionFailedError(\"Unexpected exception type, expected \" + expectedType.getSimpleName());\n             assertion.initCause(e);",
    "output": "Remove unnecessary unchecked cast"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/ESSingleNodeTestCase.java b/test/framework/src/main/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n@@ -18,6 +18,7 @@\n  */\n package org.elasticsearch.test;\n \n+import org.apache.lucene.util.IOUtils;\n import org.elasticsearch.Version;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;\n@@ -87,7 +88,7 @@ private void startNode() {\n     private static void stopNode() throws IOException {\n         Node node = NODE;\n         NODE = null;\n-        node.close();\n+        IOUtils.close(node);\n     }\n \n     private void cleanup(boolean resetNode) throws IOException {",
    "output": "Use IOUtils#close() where needed"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.bootstrap;\n \n import org.apache.lucene.util.Constants;\n+import org.apache.lucene.util.IOUtils;\n import org.apache.lucene.util.StringHelper;\n import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.Version;\n@@ -159,12 +160,10 @@ private void setup(boolean addShutdownHook, Settings settings, Environment envir\n             Runtime.getRuntime().addShutdownHook(new Thread() {\n                 @Override\n                 public void run() {\n-                    if (node != null) {\n-                        try {\n-                            node.close();\n-                        } catch (IOException ex) {\n-                            throw new ElasticsearchException(\"failed to stop node\", ex);\n-                        }\n+                    try {\n+                        IOUtils.close(node);\n+                    } catch (IOException ex) {\n+                        throw new ElasticsearchException(\"failed to stop node\", ex);\n                     }\n                 }\n             });\n@@ -233,7 +232,7 @@ private void start() {\n \n     static void stop() throws IOException {\n         try {\n-            INSTANCE.node.close();\n+            IOUtils.close(INSTANCE.node);\n         } finally {\n             INSTANCE.keepAliveLatch.countDown();\n         }",
    "output": "Use IOUtils#close() where needed"
  },
  {
    "input": "diff --git a/plugins/reindex/src/main/java/org/elasticsearch/plugin/reindex/AbstractBaseReindexRestHandler.java b/plugins/reindex/src/main/java/org/elasticsearch/plugin/reindex/AbstractBaseReindexRestHandler.java\n--- a/plugins/reindex/src/main/java/org/elasticsearch/plugin/reindex/AbstractBaseReindexRestHandler.java\n+++ b/plugins/reindex/src/main/java/org/elasticsearch/plugin/reindex/AbstractBaseReindexRestHandler.java\n@@ -19,6 +19,8 @@\n \n package org.elasticsearch.plugin.reindex;\n \n+import java.io.IOException;\n+\n import org.elasticsearch.action.ActionRequest;\n import org.elasticsearch.action.ActionRequestValidationException;\n import org.elasticsearch.action.NoopActionListener;\n@@ -36,8 +38,6 @@\n import org.elasticsearch.rest.RestStatus;\n import org.elasticsearch.tasks.Task;\n \n-import java.io.IOException;\n-\n public abstract class AbstractBaseReindexRestHandler<Request extends ActionRequest<Request>, Response extends BulkIndexByScrollResponse, TA extends TransportAction<Request, Response>>\n         extends BaseRestHandler {\n     protected final IndicesQueriesRegistry indicesQueriesRegistry;\n@@ -58,8 +58,9 @@ protected void execute(RestRequest request, Request internalRequest, RestChannel\n             return;\n         }\n         /*\n-         * Lets try and validate before forking launching the task so we can\n-         * return errors even if we aren't waiting.\n+         * Lets try and validate before forking so the user gets some error. The\n+         * task can't totally validate until it starts but this is better than\n+         * nothing.\n          */\n         ActionRequestValidationException validationException = internalRequest.validate();\n         if (validationException != null) {",
    "output": "Fix from review"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -288,6 +288,9 @@ static void init(String[] args) throws Throwable {\n             // fail if using broken version\n             JVMCheck.check();\n \n+            // fail if somebody replaced the lucene jars\n+            checkLucene();\n+\n             INSTANCE.setup(true, settings, environment);\n \n             INSTANCE.start();\n@@ -364,4 +367,11 @@ private static void checkUnsetAndMaybeExit(String confFileSetting, String settin\n     private static void exit(int status) {\n         System.exit(status);\n     }\n+\n+    private static void checkLucene() {\n+        if (Version.CURRENT.luceneVersion.equals(org.apache.lucene.util.Version.LATEST) == false) {\n+            throw new AssertionError(\"Lucene version mismatch this version of Elasticsearch requires lucene version [\"\n+                + Version.CURRENT.luceneVersion + \"]  but the current lucene version is [\" + org.apache.lucene.util.Version.LATEST + \"]\");\n+        }\n+    }\n }",
    "output": "Add a hard check to ensure we are running with the expected lucene version"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -288,6 +288,9 @@ static void init(String[] args) throws Throwable {\n             // fail if using broken version\n             JVMCheck.check();\n \n+            // fail if somebody replaced the lucene jars\n+            checkLucene();\n+\n             INSTANCE.setup(true, settings, environment);\n \n             INSTANCE.start();\n@@ -364,4 +367,11 @@ private static void checkUnsetAndMaybeExit(String confFileSetting, String settin\n     private static void exit(int status) {\n         System.exit(status);\n     }\n+\n+    private static void checkLucene() {\n+        if (Version.CURRENT.luceneVersion.equals(org.apache.lucene.util.Version.LATEST) == false) {\n+            throw new AssertionError(\"Lucene version mismatch this version of Elasticsearch requires lucene version [\"\n+                + Version.CURRENT.luceneVersion + \"]  but the current lucene version is [\" + org.apache.lucene.util.Version.LATEST + \"]\");\n+        }\n+    }\n }",
    "output": "Add a hard check to ensure we are running with the expected lucene version"
  },
  {
    "input": "diff --git a/plugins/store-smb/src/main/java/org/apache/lucene/store/SmbDirectoryWrapper.java b/plugins/store-smb/src/main/java/org/apache/lucene/store/SmbDirectoryWrapper.java\n--- a/plugins/store-smb/src/main/java/org/apache/lucene/store/SmbDirectoryWrapper.java\n+++ b/plugins/store-smb/src/main/java/org/apache/lucene/store/SmbDirectoryWrapper.java\n@@ -58,8 +58,6 @@ final class SmbFSIndexOutput extends OutputStreamIndexOutput {\n          */\n         static final int CHUNK_SIZE = 8192;\n \n-        private final String name;\n-\n         public SmbFSIndexOutput(String name) throws IOException {\n             super(\"SmbFSIndexOutput(path=\\\"\" + fsDirectory.getDirectory().resolve(name) + \"\\\")\", new FilterOutputStream(Channels.newOutputStream(Files.newByteChannel(fsDirectory.getDirectory().resolve(name), StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING, StandardOpenOption.READ, StandardOpenOption.WRITE))) {\n                 // This implementation ensures, that we never write more than CHUNK_SIZE bytes:\n@@ -73,7 +71,6 @@ public void write(byte[] b, int offset, int length) throws IOException {\n                     }\n                 }\n             }, CHUNK_SIZE);\n-            this.name = name;\n         }\n     }\n }",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -170,7 +170,6 @@ private List<String> startCluster(int numberOfNodes, int minimumMasterNode, @Nul\n             .put(\"discovery.zen.join_timeout\", \"10s\")  // still long to induce failures but to long so test won't time out\n             .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), \"1s\") // <-- for hitting simulated network failures quickly\n             .put(\"http.enabled\", false) // just to make test quicker\n-            .put(\"gateway.local.list_timeout\", \"10s\") // still long to induce failures but to long so test won't time out\n             .build();\n \n     @Override",
    "output": "Remove unused / unsupported setting"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java b/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java\n@@ -224,6 +224,7 @@ public boolean isLoggerSetting(String key) {\n         IndicesFieldDataCache.INDICES_FIELDDATA_CACHE_SIZE_KEY,\n         IndicesRequestCache.INDICES_CACHE_QUERY_SIZE,\n         IndicesRequestCache.INDICES_CACHE_QUERY_EXPIRE,\n+        IndicesRequestCache.INDICES_CACHE_REQUEST_CLEAN_INTERVAL,\n         HunspellService.HUNSPELL_LAZY_LOAD,\n         HunspellService.HUNSPELL_IGNORE_CASE,\n         HunspellService.HUNSPELL_DICTIONARY_OPTIONS,",
    "output": "Add indices.requests.cache.clean_interval as a known settings"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java b/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java\n--- a/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java\n+++ b/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java\n@@ -225,7 +225,7 @@ public void sendRequest(final DiscoveryNode node, final long requestId, final St\n             transportServiceAdapter.sent(data.length);\n             transportServiceAdapter.onRequestSent(node, requestId, action, request, options);\n             targetTransport.workers().execute(() -> {\n-                ThreadContext threadContext = threadPool.getThreadContext();\n+                ThreadContext threadContext = targetTransport.threadPool.getThreadContext();\n                 try (ThreadContext.StoredContext context = threadContext.stashContext()) {\n                     targetTransport.messageReceived(data, action, LocalTransport.this, version, requestId);\n                 }",
    "output": "Use targetTransport.threadPool to stash context not the local one"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/tribe/TribeService.java b/core/src/main/java/org/elasticsearch/tribe/TribeService.java\n--- a/core/src/main/java/org/elasticsearch/tribe/TribeService.java\n+++ b/core/src/main/java/org/elasticsearch/tribe/TribeService.java\n@@ -107,7 +107,7 @@ public static Settings processSettings(Settings settings) {\n         if (sb.get(\"cluster.name\") == null) {\n             sb.put(\"cluster.name\", \"tribe_\" + Strings.randomBase64UUID()); // make sure it won't join other tribe nodes in the same JVM\n         }\n-        sb.put(TransportMasterNodeReadAction.FORCE_LOCAL_SETTING, true);\n+        sb.put(TransportMasterNodeReadAction.FORCE_LOCAL_SETTING.getKey(), true);\n         return sb.build();\n     }\n ",
    "output": "Use real setting instead of the settings object"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/searchafter/SearchAfterIT.java b/core/src/test/java/org/elasticsearch/search/searchafter/SearchAfterIT.java\n--- a/core/src/test/java/org/elasticsearch/search/searchafter/SearchAfterIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/searchafter/SearchAfterIT.java\n@@ -51,9 +51,8 @@ public class SearchAfterIT extends ESIntegTestCase {\n     private static final int NUM_DOCS = 100;\n \n     public void testsShouldFail() throws Exception {\n-        client().admin().indices().prepareCreate(\"test\").execute().actionGet();\n-        client().prepareIndex(\"test\", \"type1\", \"0\").setSource(\"field1\", 0, \"field2\", \"toto\").execute().actionGet();\n-        refresh();\n+        createIndex(\"test\");\n+        indexRandom(true, client().prepareIndex(\"test\", \"type1\", \"0\").setSource(\"field1\", 0, \"field2\", \"toto\"));\n \n         try {\n             client().prepareSearch(\"test\")",
    "output": "Fix sporadic errors in SearchAfterIT: ack the create and index method calls in the search_after integ test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/script/ScriptEngineRegistry.java b/core/src/main/java/org/elasticsearch/script/ScriptEngineRegistry.java\n--- a/core/src/main/java/org/elasticsearch/script/ScriptEngineRegistry.java\n+++ b/core/src/main/java/org/elasticsearch/script/ScriptEngineRegistry.java\n@@ -72,6 +72,11 @@ public static class ScriptEngineRegistration {\n         private final List<String> scriptEngineLanguages;\n \n         public ScriptEngineRegistration(Class<? extends ScriptEngineService> scriptEngineService, List<String> scriptEngineLanguages) {\n+            Objects.requireNonNull(scriptEngineService);\n+            Objects.requireNonNull(scriptEngineLanguages);\n+            if (scriptEngineLanguages.isEmpty()) {\n+                throw new IllegalArgumentException(\"languages for script engine service [\" + scriptEngineService.getCanonicalName() + \"] should be non-empty\");\n+            }\n             this.scriptEngineService = scriptEngineService;\n             this.scriptEngineLanguages = scriptEngineLanguages;\n         }",
    "output": "Add guards for invalid script engine registrations This commit adds some simple checks against invalid script engine service registrations"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/transport/action/stats/SlowWatchStatsTests.java b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/transport/action/stats/SlowWatchStatsTests.java\n--- a/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/transport/action/stats/SlowWatchStatsTests.java\n+++ b/elasticsearch/x-pack/watcher/src/test/java/org/elasticsearch/watcher/transport/action/stats/SlowWatchStatsTests.java\n@@ -55,7 +55,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return Settings.builder()\n                 .put(super.nodeSettings(nodeOrdinal))\n                 // So it is predictable how many slow watches we need to add to accumulate pending watches\n-                .put(EsExecutors.PROCESSORS, \"1\")\n+                .put(EsExecutors.PROCESSORS_SETTING.getKey(), \"1\")\n                 .build();\n     }\n ",
    "output": "Fix renamed constant"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/integration/FieldLevelSecurityTests.java b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/integration/FieldLevelSecurityTests.java\n--- a/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/integration/FieldLevelSecurityTests.java\n+++ b/elasticsearch/x-pack/shield/src/test/java/org/elasticsearch/integration/FieldLevelSecurityTests.java\n@@ -427,7 +427,7 @@ public void testRequestCache() throws Exception {\n \n     public void testFields() throws Exception {\n         assertAcked(client().admin().indices().prepareCreate(\"test\")\n-                        .addMapping(\"type1\", \"field1\", \"type=string,store=yes\", \"field2\", \"type=string,store=yes\")\n+                        .addMapping(\"type1\", \"field1\", \"type=string,store=true\", \"field2\", \"type=string,store=true\")\n         );\n         client().prepareIndex(\"test\", \"type1\", \"1\").setSource(\"field1\", \"value1\", \"field2\", \"value2\")\n                 .setRefresh(true)",
    "output": "Fix mapping definitions"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java b/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java\n--- a/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java\n+++ b/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java\n@@ -65,8 +65,6 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return settingsBuilder()\n                 .put(super.nodeSettings(nodeOrdinal))\n                 .put(\"indices.ttl.interval\", PURGE_INTERVAL, TimeUnit.MILLISECONDS)\n-                .put(\"cluster.routing.operation.use_type\", false) // make sure we control the shard computation\n-                .put(\"cluster.routing.operation.hash.type\", \"djb\")\n                 .build();\n     }\n ",
    "output": "Remove unsupported settings"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/transport/filter/IPFilter.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/transport/filter/IPFilter.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/transport/filter/IPFilter.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/transport/filter/IPFilter.java\n@@ -42,7 +42,7 @@ public class IPFilter {\n     public static final String HTTP_PROFILE_NAME = \".http\";\n \n     public static final Setting<Boolean> IP_FILTER_ENABLED_HTTP_SETTING = Setting.boolSetting(\"shield.http.filter.enabled\", true, true, Setting.Scope.CLUSTER);\n-    public static final Setting<Boolean> IP_FILTER_ENABLED_SETTING = new Setting<>(\"shield.transport.filter.enabled\", (s) -> IP_FILTER_ENABLED_HTTP_SETTING.getDefault(s), Booleans::parseBooleanExact, true, Setting.Scope.CLUSTER);\n+    public static final Setting<Boolean> IP_FILTER_ENABLED_SETTING = new Setting<>(\"shield.transport.filter.enabled\", (s) -> IP_FILTER_ENABLED_HTTP_SETTING.getDefaultRaw(s), Booleans::parseBooleanExact, true, Setting.Scope.CLUSTER);\n     public static final Setting<List<String>> TRANSPORT_FILTER_ALLOW_SETTING = Setting.listSetting(\"shield.transport.filter.allow\", Collections.emptyList(), Function.identity(), true, Setting.Scope.CLUSTER);\n     public static final Setting<List<String>> TRANSPORT_FILTER_DENY_SETTING = Setting.listSetting(\"shield.transport.filter.deny\", Collections.emptyList(), Function.identity(), true, Setting.Scope.CLUSTER);\n ",
    "output": "Fix build - compilation"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ingest/processor/DateProcessor.java b/core/src/main/java/org/elasticsearch/ingest/processor/DateProcessor.java\n--- a/core/src/main/java/org/elasticsearch/ingest/processor/DateProcessor.java\n+++ b/core/src/main/java/org/elasticsearch/ingest/processor/DateProcessor.java\n@@ -71,7 +71,6 @@ public final class DateProcessor extends AbstractProcessor {\n     @Override\n     public void execute(IngestDocument ingestDocument) {\n         String value = ingestDocument.getFieldValue(matchField, String.class);\n-        // TODO(talevy): handle custom timestamp fields\n \n         DateTime dateTime = null;\n         Exception lastException = null;",
    "output": "Remove old todo in DateProcessor"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -45,6 +45,7 @@\n import org.elasticsearch.common.Priority;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.math.MathUtils;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.discovery.zen.ZenDiscovery;\n@@ -465,7 +466,7 @@ public void run() {\n                                 logger.info(\"[{}] Acquired semaphore and it has {} permits left\", name, semaphore.availablePermits());\n                                 try {\n                                     id = Integer.toString(idGenerator.incrementAndGet());\n-                                    int shard = Murmur3HashFunction.hash(id) % numPrimaries;\n+                                    int shard = MathUtils.mod(Murmur3HashFunction.hash(id), numPrimaries);\n                                     logger.trace(\"[{}] indexing id [{}] through node [{}] targeting shard [{}]\", name, id, node, shard);\n                                     IndexResponse response = client.prepareIndex(\"test\", \"type\", id).setSource(\"{}\").setTimeout(\"1s\").get();\n                                     assertThat(response.getVersion(), equalTo(1l));",
    "output": "Fix shard ID logging in DWSDIT#testAckedIndexing This commit fixes a minor issue with the shard ID that is logged while indexing in DiscoveryWithServiceDisruptionsIT#testAckedIndexing. The issue is that the operation routing hash could lead to a negative remainder modulo the number of primaries (if the hash itself is negative) but should instead be the normalized positive remainder. This issue only impacts the logging of the shard ID as the actual shard ID used during indexing is computed elsewhere but would cause the shard ID in the affected logging statement to not match shard IDs that are logged elsewhere"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ingest/processor/DeDotProcessor.java b/core/src/main/java/org/elasticsearch/ingest/processor/DeDotProcessor.java\n--- a/core/src/main/java/org/elasticsearch/ingest/processor/DeDotProcessor.java\n+++ b/core/src/main/java/org/elasticsearch/ingest/processor/DeDotProcessor.java\n@@ -41,7 +41,7 @@ public class DeDotProcessor implements Processor {\n     private final String processorTag;\n     private final String separator;\n \n-    public DeDotProcessor(String processorTag, String separator) {\n+    DeDotProcessor(String processorTag, String separator) {\n         this.processorTag = processorTag;\n         this.separator = separator;\n     }",
    "output": "Make DeDotProcessor's constructor package-private"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n--- a/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n+++ b/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n@@ -73,7 +73,6 @@\n import org.elasticsearch.threadpool.ThreadPool;\n \n import java.util.Arrays;\n-import java.util.Collections;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Map;",
    "output": "Remove import in IndicesClusterStateService.java This commit removes an unused import from o/e/i/c/IndicesClusterStateService.java"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java\n--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java\n+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java\n@@ -79,7 +79,7 @@\n import static org.hamcrest.Matchers.is;\n \n @ClusterScope(scope = SUITE)\n-public class ContextAndHeaderTransportTests extends ESIntegTestCase {\n+public class ContextAndHeaderTransportIT extends ESIntegTestCase {\n     private static final List<RequestAndHeaders> requests =  new CopyOnWriteArrayList<>();\n     private String randomHeaderKey = randomAsciiOfLength(10);\n     private String randomHeaderValue = randomAsciiOfLength(20);",
    "output": "Fix naming Tests -> IT since it's an integ test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java b/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java\n--- a/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java\n+++ b/core/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java\n@@ -141,7 +141,7 @@ public class NettyHttpServerTransport extends AbstractLifecycleComponent<HttpSer\n     protected final String publishHosts[];\n \n     protected final boolean detailedErrorsEnabled;\n-    private final ThreadPool threadPool;\n+    protected final ThreadPool threadPool;\n \n     protected int publishPort;\n ",
    "output": "Fix threadpool visibility to be consisten with others"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java\n@@ -30,8 +30,9 @@ final class AutoExpandReplicas {\n     // the value we recognize in the \"max\" position to mean all the nodes\n     private static final String ALL_NODES_VALUE = \"all\";\n     public static final Setting<AutoExpandReplicas> SETTING = new Setting<>(IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, \"false\", (value) -> {\n-        final int min;\n-        final int max;\n+        // TODO change the following back to be final, https://github.com/elastic/elasticsearch/issues/16097\n+        int min;\n+        int max;\n         if (Booleans.parseBoolean(value, true) == false) {\n             return new AutoExpandReplicas(0, 0, false);\n         }",
    "output": "Fix compilation issue with final assignment in lambda on windows jdk Relates to"
  },
  {
    "input": "diff --git a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java\n--- a/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java\n+++ b/plugins/repository-azure/src/main/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceImpl.java\n@@ -125,7 +125,8 @@ CloudBlobClient getSelectedClient(String account, LocationMode mode) {\n             int timeout = (int) azureStorageSettings.getTimeout().getMillis();\n             client.getDefaultRequestOptions().setTimeoutIntervalInMs(timeout);\n         } catch (ClassCastException e) {\n-            throw new IllegalArgumentException(\"Can not cast [\" + azureStorageSettings.getTimeout() + \"] to int.\");\n+            throw new IllegalArgumentException(\"Can not convert [\" + azureStorageSettings.getTimeout() +\n+                \"]. It can not be longer than 2,147,483,647ms.\");\n         }\n         return client;\n     }",
    "output": "Change exception message for wrong timeout in azure repository settings Backport in master this change: https://github.com/elastic/elasticsearch/pull/15950#discussion-diff-50128378 Related to Related to"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n--- a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n@@ -50,7 +50,6 @@\n import org.elasticsearch.transport.ConnectTransportException;\n import org.elasticsearch.transport.EmptyTransportResponseHandler;\n import org.elasticsearch.transport.NodeDisconnectedException;\n-import org.elasticsearch.transport.NodeNotConnectedException;\n import org.elasticsearch.transport.TransportChannel;\n import org.elasticsearch.transport.TransportException;\n import org.elasticsearch.transport.TransportRequest;\n@@ -90,6 +89,7 @@ private void sendShardAction(final String actionName, final ClusterStateObserver\n             logger.warn(\"{} no master known for action [{}] for shard [{}]\", shardRoutingEntry.getShardRouting().shardId(), actionName, shardRoutingEntry.getShardRouting());\n             waitForNewMasterAndRetry(actionName, observer, shardRoutingEntry, listener);\n         } else {\n+            logger.debug(\"{} sending [{}] for shard [{}]\", shardRoutingEntry.getShardRouting().getId(), actionName, shardRoutingEntry);\n             transportService.sendRequest(masterNode,\n                 actionName, shardRoutingEntry, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {\n                     @Override",
    "output": "Add logging statement on shard state request send This commit restores a debug-level logging statement when sending shard state requests to the master node"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n@@ -196,21 +196,20 @@ protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query,\n             assertTrue(numericRangeQuery.includesMax());\n \n             double value;\n+            double width = 0;\n             try {\n                 value = Double.parseDouble(queryBuilder.value().toString());\n             } catch (NumberFormatException e) {\n                 // Maybe its a date\n                 value = ISODateTimeFormat.dateTimeParser().parseMillis(queryBuilder.value().toString());\n+                width = queryBuilder.fuzziness().asTimeValue().getMillis();\n             }\n-            double width;\n-            if (queryBuilder.fuzziness().equals(Fuzziness.AUTO)) {\n-                width = 1;\n-            } else {\n-                try {\n+\n+            if (width == 0) {\n+                if (queryBuilder.fuzziness().equals(Fuzziness.AUTO)) {\n+                    width = 1;\n+                } else {\n                     width = queryBuilder.fuzziness().asDouble();\n-                } catch (NumberFormatException e) {\n-                    // Maybe a time value?\n-                    width = queryBuilder.fuzziness().asTimeValue().getMillis();\n                 }\n             }\n             assertEquals(value - width, numericRangeQuery.getMin().doubleValue(), width * .1);",
    "output": "Fix for MatchQueryBuilderTests.testToQuery test failure Relates to"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java b/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java\n--- a/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java\n+++ b/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java\n@@ -66,6 +66,12 @@ public void testOsStats() {\n             assertThat(loadAverage[0], greaterThanOrEqualTo((double) 0));\n             assertThat(loadAverage[1], greaterThanOrEqualTo((double) 0));\n             assertThat(loadAverage[2], greaterThanOrEqualTo((double) 0));\n+        } else if (Constants.FREE_BSD) {\n+            // five- and fifteen-minute load averages not available if linprocfs is not mounted at /compat/linux/proc\n+            assertNotNull(loadAverage);\n+            assertThat(loadAverage[0], greaterThanOrEqualTo((double) 0));\n+            assertThat(loadAverage[1], anyOf(equalTo((double) -1), greaterThanOrEqualTo((double) 0)));\n+            assertThat(loadAverage[2], anyOf(equalTo((double) -1), greaterThanOrEqualTo((double) 0)));\n         } else {\n             // one minute load average is available, but 10-minute and 15-minute load averages are not\n             // load average can be negative if not available or not computed yet, otherwise it should be >= 0",
    "output": "Fix test for load average on FreeBSD This commit fixes the test for load averages on FreeBSD. On FreeBSD, it is either the case that linprocfs is mounted at /compat/linux/proc in which case the load averages are available, or this is not the case and no load average are available. Previously, the test on FreeBSD was falling back to the catch all case which asserts that the five-minute and fifteen-minute load averages are not available"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/shield/SecuredClient.java b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/shield/SecuredClient.java\n--- a/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/shield/SecuredClient.java\n+++ b/elasticsearch/x-pack/marvel/src/main/java/org/elasticsearch/marvel/shield/SecuredClient.java\n@@ -28,7 +28,8 @@ public SecuredClient(Client in, MarvelShieldIntegration shieldIntegration) {\n     }\n \n     @Override\n-    protected <Request extends ActionRequest, Response extends ActionResponse, RequestBuilder extends ActionRequestBuilder<Request, Response, RequestBuilder>> void doExecute(Action<Request, Response, RequestBuilder> action, Request request, ActionListener<Response> listener) {\n+    protected <Request extends ActionRequest<Request>, Response extends ActionResponse, RequestBuilder extends ActionRequestBuilder<Request, Response, RequestBuilder>> void doExecute(\n+            Action<Request, Response, RequestBuilder> action, Request request, ActionListener<Response> listener) {\n         this.shieldIntegration.bindInternalMarvelUser(request);\n         super.doExecute(action, request, listener);\n     }",
    "output": "Fix compilation error after core shifted Core is slowly removing raw types. Slowly. And one such removal broke shield"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n@@ -196,21 +196,20 @@ protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query,\n             assertTrue(numericRangeQuery.includesMax());\n \n             double value;\n+            double width = 0;\n             try {\n                 value = Double.parseDouble(queryBuilder.value().toString());\n             } catch (NumberFormatException e) {\n                 // Maybe its a date\n                 value = ISODateTimeFormat.dateTimeParser().parseMillis(queryBuilder.value().toString());\n+                width = queryBuilder.fuzziness().asTimeValue().getMillis();\n             }\n-            double width;\n-            if (queryBuilder.fuzziness().equals(Fuzziness.AUTO)) {\n-                width = 1;\n-            } else {\n-                try {\n+\n+            if (width == 0) {\n+                if (queryBuilder.fuzziness().equals(Fuzziness.AUTO)) {\n+                    width = 1;\n+                } else {\n                     width = queryBuilder.fuzziness().asDouble();\n-                } catch (NumberFormatException e) {\n-                    // Maybe a time value?\n-                    width = queryBuilder.fuzziness().asTimeValue().getMillis();\n                 }\n             }\n             assertEquals(value - width, numericRangeQuery.getMin().doubleValue(), width * .1);",
    "output": "Fix test failure with numeric range query"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/create/CreateIndexIT.java b/core/src/test/java/org/elasticsearch/action/admin/indices/create/CreateIndexIT.java\n--- a/core/src/test/java/org/elasticsearch/action/admin/indices/create/CreateIndexIT.java\n+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/create/CreateIndexIT.java\n@@ -57,7 +57,7 @@ public void testCreationDateGivenFails() {\n             prepareCreate(\"test\").setSettings(Settings.builder().put(IndexMetaData.SETTING_CREATION_DATE, 4l)).get();\n             fail();\n         } catch (IllegalArgumentException ex) {\n-            assertEquals(\"unknow setting [index.creation_date]\", ex.getMessage());\n+            assertEquals(\"unknown setting [index.creation_date]\", ex.getMessage());\n         }\n     }\n ",
    "output": "Fix error message assertion"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n@@ -78,6 +78,7 @@ public final class EngineConfig {\n         switch(s) {\n             case \"default\":\n             case \"best_compression\":\n+            case \"lucene_default\":\n                 return s;\n             default:\n                 if (Codec.availableCodecs().contains(s) == false) { // we don't error message the not officially supported ones",
    "output": "Add back lcuene_default as a valid setting for our tests to work out of the box"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AutoExpandReplicas.java\n@@ -24,7 +24,7 @@\n final class AutoExpandReplicas {\n     // the value we recognize in the \"max\" position to mean all the nodes\n     private static final String ALL_NODES_VALUE = \"all\";\n-    public static final Setting<AutoExpandReplicas> SETTING = new Setting<>(IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, \"\", (value) -> {\n+    public static final Setting<AutoExpandReplicas> SETTING = new Setting<>(IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, \"false\", (value) -> {\n         final int min;\n         final int max;\n         if (Booleans.parseBoolean(value, true) == false) {",
    "output": "Use a valid default"
  },
  {
    "input": "diff --git a/plugins/ingest-geoip/src/main/java/org/elasticsearch/ingest/geoip/IngestGeoIpPlugin.java b/plugins/ingest-geoip/src/main/java/org/elasticsearch/ingest/geoip/IngestGeoIpPlugin.java\n--- a/plugins/ingest-geoip/src/main/java/org/elasticsearch/ingest/geoip/IngestGeoIpPlugin.java\n+++ b/plugins/ingest-geoip/src/main/java/org/elasticsearch/ingest/geoip/IngestGeoIpPlugin.java\n@@ -44,7 +44,7 @@ public String name() {\n \n     @Override\n     public String description() {\n-        return \"Plugin that allows to plug in ingest processors\";\n+        return \"Ingest processor that adds information about the geographical location of ip addresses\";\n     }\n \n     public void onModule(NodeModule nodeModule) throws IOException {",
    "output": "Upgrade ingest-geoip plugin description"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java\n--- a/core/src/main/java/org/elasticsearch/index/IndexService.java\n+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java\n@@ -687,10 +687,10 @@ boolean mustReschedule() {\n \n         private synchronized void onTaskCompletion() {\n             if (mustReschedule()) {\n-                indexService.logger.debug(\"scheduling {} every {}\", toString(), interval);\n+                indexService.logger.trace(\"scheduling {} every {}\", toString(), interval);\n                 this.scheduledFuture = threadPool.schedule(interval, getThreadPool(), BaseAsyncTask.this);\n             } else {\n-                indexService.logger.debug(\"scheduled {} disabled\", toString());\n+                indexService.logger.trace(\"scheduled {} disabled\", toString());\n                 this.scheduledFuture = null;\n             }\n         }",
    "output": "Use trace for annoying schedule logs"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java b/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java\n@@ -58,7 +58,6 @@\n public class ShardStateActionTests extends ESTestCase {\n     private static ThreadPool THREAD_POOL;\n \n-    private AtomicBoolean timeout;\n     private TestShardStateAction shardStateAction;\n     private CapturingTransport transport;\n     private TransportService transportService;\n@@ -102,7 +101,6 @@ public void setUp() throws Exception {\n         clusterService = new TestClusterService(THREAD_POOL);\n         transportService = new TransportService(transport, THREAD_POOL);\n         transportService.start();\n-        this.timeout = new AtomicBoolean();\n         shardStateAction = new TestShardStateAction(Settings.EMPTY, clusterService, transportService, null, null);\n         shardStateAction.setOnBeforeWaitForNewMasterAndRetry(() -> {});\n         shardStateAction.setOnAfterWaitForNewMasterAndRetry(() -> {});",
    "output": "Remove dead field in o.e.c.a.s.ShardStateActionTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -101,6 +101,7 @@ public enum OutputMode {\n             \"discovery-ec2\",\n             \"discovery-gce\",\n             \"discovery-multicast\",\n+            \"ingest-geoip\",\n             \"lang-javascript\",\n             \"lang-plan-a\",\n             \"lang-python\",",
    "output": "Add ingest-geoip to official plugins"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java\n@@ -35,7 +35,7 @@ public class GetAliasesRequest extends MasterNodeReadRequest<GetAliasesRequest>\n     private String[] indices = Strings.EMPTY_ARRAY;\n     private String[] aliases = Strings.EMPTY_ARRAY;\n \n-    private IndicesOptions indicesOptions = IndicesOptions.strictExpandOpen();\n+    private IndicesOptions indicesOptions = IndicesOptions.strictExpand();\n \n     public GetAliasesRequest(String[] aliases) {\n         this.aliases = aliases;",
    "output": "Make get alias expand to open and closed indices by default"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/xcontent/ObjectParserTests.java b/core/src/test/java/org/elasticsearch/common/xcontent/ObjectParserTests.java\n--- a/core/src/test/java/org/elasticsearch/common/xcontent/ObjectParserTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/xcontent/ObjectParserTests.java\n@@ -188,6 +188,25 @@ public void setObject(StaticTestStruct object) {\n         }\n     }\n \n+    enum TestEnum {\n+        FOO, BAR\n+    };\n+\n+    public void testParseEnumFromString() throws IOException {\n+        class TestStruct {\n+            public TestEnum test;\n+\n+            public void set(TestEnum value) {\n+                test = value;\n+            }\n+        }\n+        XContentParser parser = XContentType.JSON.xContent().createParser(\"{ \\\"test\\\" : \\\"FOO\\\" }\");\n+        ObjectParser<TestStruct, Void> objectParser = new ObjectParser(\"foo\");\n+        objectParser.declareString((struct, value) -> struct.set(TestEnum.valueOf(value)), new ParseField(\"test\"));\n+        TestStruct s = objectParser.parse(parser, new TestStruct());\n+        assertEquals(s.test, TestEnum.FOO);\n+    }\n+\n     public void testAllVariants() throws IOException {\n         XContentBuilder builder = XContentBuilder.builder(XContentType.JSON.xContent());\n         builder.startObject();",
    "output": "Add test to show how to parse an enum from a string in ObjectParser.java"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/GetAliasesRequest.java\n@@ -35,7 +35,7 @@ public class GetAliasesRequest extends MasterNodeReadRequest<GetAliasesRequest>\n     private String[] indices = Strings.EMPTY_ARRAY;\n     private String[] aliases = Strings.EMPTY_ARRAY;\n \n-    private IndicesOptions indicesOptions = IndicesOptions.strictExpandOpen();\n+    private IndicesOptions indicesOptions = IndicesOptions.strictExpand();\n \n     public GetAliasesRequest(String[] aliases) {\n         this.aliases = aliases;",
    "output": "Make get alias expand to open and closed indices by default This change affects get alias, get aliases as well as cat aliases. They all return closed indices too by default. get alias and get aliases also allow to return open indices only through the `expand_wildcards` option (set it to `open`)"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java b/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java\n--- a/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java\n@@ -111,8 +111,9 @@ public long getTotalSwapSpaceSize() {\n      * Returns the system load averages\n      */\n     public double[] getSystemLoadAverage() {\n-        if (Constants.LINUX) {\n-            double[] loadAverage = readProcLoadavg(\"/proc/loadavg\");\n+        if (Constants.LINUX || Constants.FREE_BSD) {\n+            final String procLoadAvg = Constants.LINUX ? \"/proc/loadavg\" : \"/compat/linux/proc/loadavg\";\n+            double[] loadAverage = readProcLoadavg(procLoadAvg);\n             if (loadAverage != null) {\n                 return loadAverage;\n             }",
    "output": "Add load averages to OS stats on FreeBSD"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java b/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/routing/PrimaryAllocationIT.java\n@@ -22,11 +22,14 @@\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.gateway.GatewayAllocator;\n+import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.test.ESIntegTestCase;\n import org.elasticsearch.test.InternalTestCluster;\n import org.elasticsearch.test.disruption.NetworkDisconnectPartition;\n+import org.elasticsearch.test.transport.MockTransportService;\n \n import java.util.Arrays;\n+import java.util.Collection;\n import java.util.Collections;\n import java.util.HashSet;\n import java.util.List;\n@@ -41,6 +44,12 @@\n @ESIntegTestCase.SuppressLocalMode\n public class PrimaryAllocationIT extends ESIntegTestCase {\n \n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        // disruption tests need MockTransportService\n+        return pluginList(MockTransportService.TestPlugin.class);\n+    }\n+\n     public void testDoNotAllowStaleReplicasToBePromotedToPrimary() throws Exception {\n         logger.info(\"--> starting 3 nodes, 1 master, 2 data\");\n         String master = internalCluster().startMasterOnlyNode(Settings.EMPTY);",
    "output": "Add required plugin to PrimaryAllocationIT"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ingest/core/CompoundProcessor.java b/core/src/main/java/org/elasticsearch/ingest/core/CompoundProcessor.java\n--- a/core/src/main/java/org/elasticsearch/ingest/core/CompoundProcessor.java\n+++ b/core/src/main/java/org/elasticsearch/ingest/core/CompoundProcessor.java\n@@ -30,7 +30,7 @@\n  * A Processor that executes a list of other \"processors\". It executes a separate list of\n  * \"onFailureProcessors\" when any of the processors throw an {@link Exception}.\n  */\n-public final class CompoundProcessor implements Processor {\n+public class CompoundProcessor implements Processor {\n     static final String ON_FAILURE_MESSAGE_FIELD = \"on_failure_message\";\n     static final String ON_FAILURE_PROCESSOR_FIELD = \"on_failure_processor\";\n ",
    "output": "Remove final keyword"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/ingest/SimulateDocumentSimpleResult.java b/core/src/main/java/org/elasticsearch/action/ingest/SimulateDocumentSimpleResult.java\n--- a/core/src/main/java/org/elasticsearch/action/ingest/SimulateDocumentSimpleResult.java\n+++ b/core/src/main/java/org/elasticsearch/action/ingest/SimulateDocumentSimpleResult.java\n@@ -67,7 +67,7 @@ public SimulateDocumentSimpleResult readFrom(StreamInput in) throws IOException\n             Exception exception = in.readThrowable();\n             return new SimulateDocumentSimpleResult(exception);\n         }\n-        return new SimulateDocumentSimpleResult(WriteableIngestDocument.readWriteableIngestDocumentFrom(in));\n+        return new SimulateDocumentSimpleResult(new WriteableIngestDocument(in));\n     }\n \n     @Override\n\ndiff --git a/core/src/test/java/org/elasticsearch/action/ingest/WriteableIngestDocumentTests.java b/core/src/test/java/org/elasticsearch/action/ingest/WriteableIngestDocumentTests.java\n--- a/core/src/test/java/org/elasticsearch/action/ingest/WriteableIngestDocumentTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/ingest/WriteableIngestDocumentTests.java\n@@ -108,7 +108,7 @@ public void testSerialization() throws IOException {\n         BytesStreamOutput out = new BytesStreamOutput();\n         writeableIngestDocument.writeTo(out);\n         StreamInput streamInput = StreamInput.wrap(out.bytes());\n-        WriteableIngestDocument otherWriteableIngestDocument = WriteableIngestDocument.readWriteableIngestDocumentFrom(streamInput);\n+        WriteableIngestDocument otherWriteableIngestDocument = new WriteableIngestDocument(streamInput);\n         assertThat(otherWriteableIngestDocument, equalTo(writeableIngestDocument));\n     }\n }",
    "output": "Fix compile errors"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsIT.java b/core/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsIT.java\n@@ -335,6 +335,7 @@ public void testMissingUnitsLenient() {\n             assertAcked(prepareCreate(\"test\"));\n             ensureGreen();\n             client().admin().indices().prepareUpdateSettings(\"test\").setSettings(Settings.builder().put(\"index.refresh_interval\", \"10\")).execute().actionGet();\n+            client().admin().indices().prepareDelete(\"test\").get();\n         } finally {\n             // Restore the default so subsequent tests require units:\n             assertFalse(Settings.getSettingsRequireUnits());",
    "output": "Fix test to wipe lenient index first"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java\n--- a/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java\n+++ b/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java\n@@ -256,6 +256,8 @@ public void bytesWritten(int bytes) {\n                     } finally {\n                         runLock.unlock();\n                     }\n+                    // Could be while we were checking, more bytes arrived:\n+                    totalBytes = bytesWrittenSinceCheck.addAndGet(bytes);\n                 } else {\n                     break;\n                 }",
    "output": "Fix possible concurrency bug in IMC when indexing threads are faster in writing bytes than the status checker is in checking all shards"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ingest/processor/RenameProcessorTests.java b/core/src/test/java/org/elasticsearch/ingest/processor/RenameProcessorTests.java\n--- a/core/src/test/java/org/elasticsearch/ingest/processor/RenameProcessorTests.java\n+++ b/core/src/test/java/org/elasticsearch/ingest/processor/RenameProcessorTests.java\n@@ -125,7 +125,6 @@ public void testRenameExistingFieldNullValue() throws Exception {\n \n     public void testRenameAtomicOperationSetFails() throws Exception {\n         Map<String, Object> source = new HashMap<String, Object>() {\n-            private static final long serialVersionUID = 362498820763181265L;\n             @Override\n             public Object put(String key, Object value) {\n                 if (key.equals(\"new_field\")) {\n@@ -150,7 +149,6 @@ public Object put(String key, Object value) {\n \n     public void testRenameAtomicOperationRemoveFails() throws Exception {\n         Map<String, Object> source = new HashMap<String, Object>() {\n-            private static final long serialVersionUID = 362498820763181265L;\n             @Override\n             public Object remove(Object key) {\n                 if (key.equals(\"list\")) {",
    "output": "Remove declared serialVersionUid"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java b/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java\n--- a/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/os/OsProbe.java\n@@ -111,8 +111,9 @@ public long getTotalSwapSpaceSize() {\n      * Returns the system load averages\n      */\n     public double[] getSystemLoadAverage() {\n-        if (Constants.LINUX) {\n-            double[] loadAverage = readProcLoadavg(\"/proc/loadavg\");\n+        if (Constants.LINUX || Constants.FREE_BSD) {\n+            final String procLoadAvg = Constants.LINUX ? \"/proc/loadavg\" : \"/compat/linux/proc/loadavg\";\n+            double[] loadAverage = readProcLoadavg(procLoadAvg);\n             if (loadAverage != null) {\n                 return loadAverage;\n             }",
    "output": "Add load averages to OS stats on FreeBSD This commit adds load averages to the OS stats on FreeBSD. For these stats to be available, linprocfs must be available and mounted at /compat/linux/proc"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java b/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n--- a/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n+++ b/core/src/test/java/org/elasticsearch/ingest/IngestClientIT.java\n@@ -36,6 +36,7 @@\n import org.elasticsearch.action.ingest.SimulatePipelineAction;\n import org.elasticsearch.action.ingest.SimulatePipelineRequestBuilder;\n import org.elasticsearch.action.ingest.SimulatePipelineResponse;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.ingest.core.IngestDocument;\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.test.ESIntegTestCase;\n@@ -51,8 +52,17 @@\n import static org.hamcrest.Matchers.nullValue;\n import static org.hamcrest.core.Is.is;\n \n+@ESIntegTestCase.ClusterScope(minNumDataNodes = 2)\n public class IngestClientIT extends ESIntegTestCase {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        if (nodeOrdinal % 2 == 0) {\n+            return Settings.builder().put(\"node.ingest\", false).put(super.nodeSettings(nodeOrdinal)).build();\n+        }\n+        return super.nodeSettings(nodeOrdinal);\n+    }\n+\n     @Override\n     protected Collection<Class<? extends Plugin>> nodePlugins() {\n         return pluginList(IngestPlugin.class);",
    "output": "Add some nodes with ingest set to false to test redirect"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/ingest/IngestProxyActionFilter.java b/core/src/main/java/org/elasticsearch/action/ingest/IngestProxyActionFilter.java\n--- a/core/src/main/java/org/elasticsearch/action/ingest/IngestProxyActionFilter.java\n+++ b/core/src/main/java/org/elasticsearch/action/ingest/IngestProxyActionFilter.java\n@@ -31,6 +31,7 @@\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Randomness;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.ingest.IngestModule;\n@@ -49,7 +50,7 @@ public final class IngestProxyActionFilter implements ActionFilter {\n \n     private final ClusterService clusterService;\n     private final TransportService transportService;\n-    private final AtomicInteger randomNodeGenerator = new AtomicInteger();\n+    private final AtomicInteger randomNodeGenerator = new AtomicInteger(Randomness.get().nextInt());\n \n     @Inject\n     public IngestProxyActionFilter(ClusterService clusterService, TransportService transportService) {",
    "output": "Add randomness init for random node generator"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/trigger/schedule/Cron.java b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/trigger/schedule/Cron.java\n--- a/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/trigger/schedule/Cron.java\n+++ b/elasticsearch/x-pack/watcher/src/main/java/org/elasticsearch/watcher/trigger/schedule/Cron.java\n@@ -195,9 +195,6 @@\n  * @author Refactoring from CronTrigger to CronExpression by Aaron Craven\n  */\n public class Cron {\n-\n-    private static final long serialVersionUID = 12423409423L;\n-\n     protected static final TimeZone UTC = DateTimeZone.UTC.toTimeZone();\n     protected static final DateTimeFormatter formatter = DateTimeFormat.forPattern(\"YYYY-MM-dd'T'HH:mm:ss\");\n ",
    "output": "Remove serialVersionUID It doesn't do anything and Elasticsearch will likely ban using it"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/ingest/IngestActionFilterTests.java b/core/src/test/java/org/elasticsearch/action/ingest/IngestActionFilterTests.java\n--- a/core/src/test/java/org/elasticsearch/action/ingest/IngestActionFilterTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/ingest/IngestActionFilterTests.java\n@@ -85,6 +85,19 @@ public void testApplyNoPipelineId() throws Exception {\n         verifyZeroInteractions(executionService, actionFilterChain);\n     }\n \n+    public void testApplyBulkNoPipelineId() throws Exception {\n+        BulkRequest bulkRequest = new BulkRequest();\n+        bulkRequest.add(new IndexRequest());\n+        Task task = mock(Task.class);\n+        ActionListener actionListener = mock(ActionListener.class);\n+        ActionFilterChain actionFilterChain = mock(ActionFilterChain.class);\n+\n+        filter.apply(task, BulkAction.NAME, bulkRequest, actionListener, actionFilterChain);\n+\n+        verify(actionFilterChain).proceed(task, BulkAction.NAME, bulkRequest, actionListener);\n+        verifyZeroInteractions(executionService, actionFilterChain);\n+    }\n+\n     @SuppressWarnings(\"unchecked\")\n     public void testApplyIngestIdViaRequestParam() throws Exception {\n         Task task = mock(Task.class);",
    "output": "Add test for bulk without any request holiding a pipeline id"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/ingest/IngestActionFilter.java b/core/src/main/java/org/elasticsearch/action/ingest/IngestActionFilter.java\n--- a/core/src/main/java/org/elasticsearch/action/ingest/IngestActionFilter.java\n+++ b/core/src/main/java/org/elasticsearch/action/ingest/IngestActionFilter.java\n@@ -58,7 +58,6 @@ public IngestActionFilter(Settings settings, IngestBootstrapper bootstrapper) {\n \n     @Override\n     public void apply(Task task, String action, ActionRequest request, ActionListener listener, ActionFilterChain chain) {\n-\n         if (IndexAction.NAME.equals(action)) {\n             assert request instanceof IndexRequest;\n             IndexRequest indexRequest = (IndexRequest) request;\n@@ -70,10 +69,22 @@ public void apply(Task task, String action, ActionRequest request, ActionListene\n         if (BulkAction.NAME.equals(action)) {\n             assert request instanceof BulkRequest;\n             BulkRequest bulkRequest = (BulkRequest) request;\n-            @SuppressWarnings(\"unchecked\")\n-            ActionListener<BulkResponse> actionListener = (ActionListener<BulkResponse>) listener;\n-            processBulkIndexRequest(task, bulkRequest, action, chain, actionListener);\n-            return;\n+            boolean isIngestRequest = false;\n+            for (ActionRequest actionRequest : bulkRequest.requests()) {\n+                if (actionRequest instanceof IndexRequest) {\n+                    IndexRequest indexRequest = (IndexRequest) actionRequest;\n+                    if (Strings.hasText(indexRequest.pipeline())) {\n+                        isIngestRequest = true;\n+                        break;\n+                    }\n+                }\n+            }\n+            if (isIngestRequest) {\n+                @SuppressWarnings(\"unchecked\")\n+                ActionListener<BulkResponse> actionListener = (ActionListener<BulkResponse>) listener;\n+                processBulkIndexRequest(task, bulkRequest, action, chain, actionListener);\n+                return;\n+            }\n         }\n \n         chain.proceed(task, action, request, listener);",
    "output": "Make sure we don't go ahead if no index request holds a pipeline id"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceQueryBuilderTests.java\n@@ -204,6 +204,7 @@ private void assertGeoPointQuery(GeoDistanceQueryBuilder queryBuilder, Query que\n         double distance = queryBuilder.distance();\n         if (queryBuilder.geoDistance() != null) {\n             distance = queryBuilder.geoDistance().normalize(distance, DistanceUnit.DEFAULT);\n+            distance = org.elasticsearch.common.geo.GeoUtils.maxRadialDistance(queryBuilder.point(), distance);\n             assertThat(geoQuery.getRadiusMeters(), closeTo(distance, GeoUtils.TOLERANCE));\n         }\n     }",
    "output": "Fix small error in distance normalization in test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java b/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n--- a/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n+++ b/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n@@ -39,10 +39,12 @@ public class BytesStreamOutput extends StreamOutput implements BytesStream {\n     protected int count;\n \n     /**\n-     * Create a non recycling {@link BytesStreamOutput} with 1 initial page acquired.\n+     * Create a non recycling {@link BytesStreamOutput} with an initial capacity of 0.\n      */\n     public BytesStreamOutput() {\n-        this(BigArrays.PAGE_SIZE_IN_BYTES);\n+        // since this impl is not recycling anyway, don't bother aligning to\n+        // the page size, this will even save memory\n+        this(0);\n     }\n \n     /**",
    "output": "Fix initial sizing of BytesStreamOutput"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java\n--- a/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java\n+++ b/core/src/main/java/org/elasticsearch/indices/IndexingMemoryController.java\n@@ -132,6 +132,7 @@ protected ScheduledFuture<?> scheduleTask(ThreadPool threadPool) {\n         return threadPool.scheduleWithFixedDelay(statusChecker, interval);\n     }\n \n+    @Override\n     public void close() {\n         FutureUtils.cancel(scheduler);\n     }",
    "output": "Add @Override annotation"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java\n--- a/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java\n+++ b/elasticsearch/x-pack/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/indices/IndexStatsRendererTests.java\n@@ -10,11 +10,11 @@\n import org.elasticsearch.action.admin.indices.stats.ShardStats;\n import org.elasticsearch.index.engine.SegmentsStats;\n import org.elasticsearch.index.fielddata.FieldDataStats;\n-import org.elasticsearch.index.indexing.IndexingStats;\n import org.elasticsearch.index.merge.MergeStats;\n import org.elasticsearch.index.refresh.RefreshStats;\n import org.elasticsearch.index.search.stats.SearchStats;\n import org.elasticsearch.index.shard.DocsStats;\n+import org.elasticsearch.index.shard.IndexingStats;\n import org.elasticsearch.index.store.StoreStats;\n import org.elasticsearch.marvel.agent.collector.indices.IndexStatsMarvelDoc;\n import org.elasticsearch.marvel.agent.renderer.Renderer;",
    "output": "Fix import after IndexingOperationListeners infrastructure cleanup in elasticsearch/15875"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n@@ -55,12 +55,10 @@\n import org.elasticsearch.common.lucene.index.ElasticsearchLeafReader;\n import org.elasticsearch.common.lucene.uid.Versions;\n import org.elasticsearch.common.math.MathUtils;\n-import org.elasticsearch.common.metrics.CounterMetric;\n import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n import org.elasticsearch.common.util.concurrent.ReleasableLock;\n import org.elasticsearch.index.IndexSettings;\n-import org.elasticsearch.index.indexing.ShardIndexingService;\n import org.elasticsearch.index.mapper.Uid;\n import org.elasticsearch.index.merge.MergeStats;\n import org.elasticsearch.index.merge.OnGoingMerge;",
    "output": "Remove unused imports from o/e/i/e/InternalEngine.java"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java b/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n--- a/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n+++ b/core/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n@@ -39,10 +39,12 @@ public class BytesStreamOutput extends StreamOutput implements BytesStream {\n     protected int count;\n \n     /**\n-     * Create a non recycling {@link BytesStreamOutput} with 1 initial page acquired.\n+     * Create a non recycling {@link BytesStreamOutput} with an initial capacity of 0.\n      */\n     public BytesStreamOutput() {\n-        this(BigArrays.PAGE_SIZE_IN_BYTES);\n+        // since this impl is not recycling anyway, don't bother aligning to\n+        // the page size, this will even save memory\n+        this(0);\n     }\n \n     /**",
    "output": "Fix initial sizing of BytesStreamOutput. It currently tries to align to the page size (16KB) by default. However, this might waste a significant memory (if many BytesStreamOutputs are allocated) and is also useless given that BytesStreamOutput does not recycle (on the contrary to ReleasableBytesStreamOutput). So the initial size has been changed to 0"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java b/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java\n--- a/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java\n+++ b/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java\n@@ -218,7 +218,7 @@ public PercolateShardResponse percolate(PercolateShardRequest request) throws IO\n             if (context.aggregations() != null) {\n                 AggregationContext aggregationContext = new AggregationContext(context);\n                 context.aggregations().aggregationContext(aggregationContext);\n-\n+                context.aggregations().factories().init(aggregationContext);\n                 Aggregator[] aggregators = context.aggregations().factories().createTopLevelAggregators();\n                 List<Aggregator> aggregatorCollectors = new ArrayList<>(aggregators.length);\n                 for (int i = 0; i < aggregators.length; i++) {",
    "output": "Fix merge errors"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/ingest/reload/ReloadPipelinesAction.java b/core/src/main/java/org/elasticsearch/action/ingest/reload/ReloadPipelinesAction.java\n--- a/core/src/main/java/org/elasticsearch/action/ingest/reload/ReloadPipelinesAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/ingest/reload/ReloadPipelinesAction.java\n@@ -55,7 +55,7 @@ public ReloadPipelinesAction(Settings settings, PipelineStore pipelineStore, Clu\n         this.pipelineStore = pipelineStore;\n         this.clusterService = clusterService;\n         this.transportService = transportService;\n-        transportService.registerRequestHandler(ACTION_NAME, ReloadPipelinesRequest::new, ThreadPool.Names.SAME, this);\n+        transportService.registerRequestHandler(ACTION_NAME, ReloadPipelinesRequest::new, ThreadPool.Names.MANAGEMENT, this);\n     }\n \n     public void reloadPipelinesOnAllNodes(Consumer<Boolean> listener) {\n@@ -101,7 +101,7 @@ void decrementAndReturn() {\n \n                 @Override\n                 public String executor() {\n-                    return ThreadPool.Names.MANAGEMENT;\n+                    return ThreadPool.Names.SAME;\n                 }\n             });\n         }",
    "output": "Fix thread pools, use management the do the operation and response handeling"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java\n--- a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java\n+++ b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java\n@@ -181,6 +181,7 @@ private void registerBuiltInTokenizer(Map<String, AnalysisModule.AnalysisProvide\n         tokenizers.put(\"standard\", StandardTokenizerFactory::new);\n         tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n         tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n+        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n         tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n         tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n         tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n@@ -409,6 +410,7 @@ private PrebuiltAnalysis() {\n             // Tokenizer aliases\n             tokenizerFactories.put(\"nGram\", new PreBuiltTokenizerFactoryFactory(PreBuiltTokenizers.NGRAM.getTokenizerFactory(Version.CURRENT)));\n             tokenizerFactories.put(\"edgeNGram\", new PreBuiltTokenizerFactoryFactory(PreBuiltTokenizers.EDGE_NGRAM.getTokenizerFactory(Version.CURRENT)));\n+            tokenizerFactories.put(\"PathHierarchy\", new PreBuiltTokenizerFactoryFactory(PreBuiltTokenizers.PATH_HIERARCHY.getTokenizerFactory(Version.CURRENT)));\n \n \n             // Token filters",
    "output": "Add PathHierarchy type back to path_hierarchy tokenizer for backward compatibility with 1.x"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java\n--- a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java\n+++ b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java\n@@ -181,6 +181,7 @@ private void registerBuiltInTokenizer(Map<String, AnalysisModule.AnalysisProvide\n         tokenizers.put(\"standard\", StandardTokenizerFactory::new);\n         tokenizers.put(\"uax_url_email\", UAX29URLEmailTokenizerFactory::new);\n         tokenizers.put(\"path_hierarchy\", PathHierarchyTokenizerFactory::new);\n+        tokenizers.put(\"PathHierarchy\", PathHierarchyTokenizerFactory::new);\n         tokenizers.put(\"keyword\", KeywordTokenizerFactory::new);\n         tokenizers.put(\"letter\", LetterTokenizerFactory::new);\n         tokenizers.put(\"lowercase\", LowerCaseTokenizerFactory::new);\n@@ -409,6 +410,7 @@ private PrebuiltAnalysis() {\n             // Tokenizer aliases\n             tokenizerFactories.put(\"nGram\", new PreBuiltTokenizerFactoryFactory(PreBuiltTokenizers.NGRAM.getTokenizerFactory(Version.CURRENT)));\n             tokenizerFactories.put(\"edgeNGram\", new PreBuiltTokenizerFactoryFactory(PreBuiltTokenizers.EDGE_NGRAM.getTokenizerFactory(Version.CURRENT)));\n+            tokenizerFactories.put(\"PathHierarchy\", new PreBuiltTokenizerFactoryFactory(PreBuiltTokenizers.PATH_HIERARCHY.getTokenizerFactory(Version.CURRENT)));\n \n \n             // Token filters",
    "output": "Add PathHierarchy type back to path_hierarchy tokenizer for backward compatibility with 1.x"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java b/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java\n--- a/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java\n+++ b/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java\n@@ -30,7 +30,6 @@\n import org.elasticsearch.common.io.Channels;\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.util.Callback;\n-import org.elasticsearch.common.util.concurrent.ReleasableLock;\n import org.elasticsearch.index.shard.ShardId;\n \n import java.io.BufferedOutputStream;\n@@ -42,9 +41,6 @@\n import java.nio.file.OpenOption;\n import java.nio.file.Path;\n import java.nio.file.StandardOpenOption;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.concurrent.locks.ReadWriteLock;\n-import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n public class TranslogWriter extends TranslogReader {\n \n@@ -268,12 +264,12 @@ public boolean syncUpTo(long offset) throws IOException {\n \n     @Override\n     protected void readBytes(ByteBuffer targetBuffer, long position) throws IOException {\n-        if (position+targetBuffer.limit() > getWrittenOffset()) {\n+        if (position+targetBuffer.remaining() > getWrittenOffset()) {\n             synchronized (this) {\n                 outputStream.flush();\n             }\n         }\n-        // we don't have to have a read lock here because we only write ahead to the file, so all writes has been complete\n+        // we don't have to have a lock here because we only write ahead to the file, so all writes has been complete\n         // for the requested location.\n         Channels.readFromFileChannelWithEofException(channel, position, targetBuffer);\n     }",
    "output": "Add pending review from @bleskes on"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java b/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java\n@@ -184,9 +184,11 @@ public void add(final TimeValue timeout, final TimeoutClusterStateListener liste\n         if (threadPool == null) {\n             throw new UnsupportedOperationException(\"TestClusterService wasn't initialized with a thread pool\");\n         }\n-        NotifyTimeout notifyTimeout = new NotifyTimeout(listener, timeout);\n-        notifyTimeout.future = threadPool.schedule(timeout, ThreadPool.Names.GENERIC, notifyTimeout);\n-        onGoingTimeouts.add(notifyTimeout);\n+        if (timeout != null) {\n+            NotifyTimeout notifyTimeout = new NotifyTimeout(listener, timeout);\n+            notifyTimeout.future = threadPool.schedule(timeout, ThreadPool.Names.GENERIC, notifyTimeout);\n+            onGoingTimeouts.add(notifyTimeout);\n+        }\n         listeners.add(listener);\n         listener.postAdded();\n     }",
    "output": "Fix NPE in TestClusterService when waiting indefinitely"
  },
  {
    "input": "diff --git a/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java b/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java\n--- a/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java\n+++ b/test/framework/src/main/java/org/elasticsearch/test/cluster/TestClusterService.java\n@@ -184,9 +184,11 @@ public void add(final TimeValue timeout, final TimeoutClusterStateListener liste\n         if (threadPool == null) {\n             throw new UnsupportedOperationException(\"TestClusterService wasn't initialized with a thread pool\");\n         }\n-        NotifyTimeout notifyTimeout = new NotifyTimeout(listener, timeout);\n-        notifyTimeout.future = threadPool.schedule(timeout, ThreadPool.Names.GENERIC, notifyTimeout);\n-        onGoingTimeouts.add(notifyTimeout);\n+        if (timeout != null) {\n+            NotifyTimeout notifyTimeout = new NotifyTimeout(listener, timeout);\n+            notifyTimeout.future = threadPool.schedule(timeout, ThreadPool.Names.GENERIC, notifyTimeout);\n+            onGoingTimeouts.add(notifyTimeout);\n+        }\n         listeners.add(listener);\n         listener.postAdded();\n     }",
    "output": "Fix NPE in TestClusterService when waiting indefinitely When waiting indefinitely for a new cluster state in a test, TestClusterService#add will throw a NullPointerException if the timeout is null. Instead, TestClusterService#add should guard against a null timeout and not even attempt to add a notification for the timeout expiring. Note that the usage of null is the agreed upon contract for specifying an indefinite wait from ClusterStateObserver"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java b/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java\n--- a/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java\n+++ b/core/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java\n@@ -146,9 +146,6 @@ public void sync() throws IOException {\n                     outputStream.flush();\n                     offsetToSync = totalOffset;\n                     opsCounter = operationCounter;\n-                    // we can do this outside of the write lock but we have to protect from\n-                    // concurrent syncs\n-                    ensureOpen(); // just for kicks - the checkpoint happens or not either way\n                     try {\n                         checkpoint(offsetToSync, opsCounter, channelReference);\n                     } catch (Throwable ex) {",
    "output": "Remove stale comments"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java\n@@ -69,7 +69,7 @@ public void testLatLonValues() throws Exception {\n \n         boolean indexCreatedBefore22 = version.before(Version.V_2_2_0);\n         assertThat(doc.rootDoc().getField(\"point.lat\"), notNullValue());\n-        final boolean stored = indexCreatedBefore22 == false;\n+        final boolean stored = false;\n         assertThat(doc.rootDoc().getField(\"point.lat\").fieldType().stored(), is(stored));\n         assertThat(doc.rootDoc().getField(\"point.lon\"), notNullValue());\n         assertThat(doc.rootDoc().getField(\"point.lon\").fieldType().stored(), is(stored));",
    "output": "Fix GeoPointFieldMapperTests expectations"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n--- a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n@@ -137,7 +137,7 @@ public void onFailure(String source, Throwable t) {\n                         try {\n                             channel.sendResponse(t);\n                         } catch (Throwable channelThrowable) {\n-                            logger.warn(\"{} failed to send failure [{}] while failing shard [{}]\", channelThrowable, t, request.shardRouting.shardId(), request.shardRouting);\n+                            logger.warn(\"{} failed to send failure [{}] while failing shard [{}]\", channelThrowable, request.shardRouting.shardId(), t, request.shardRouting);\n                         }\n                     }\n ",
    "output": "Fix order of logging parameters in ShardStateAction"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java\n@@ -147,9 +147,9 @@ private static List<IngestDocument> parseDocs(Map<String, Object> config) {\n         List<IngestDocument> ingestDocumentList = new ArrayList<>();\n         for (Map<String, Object> dataMap : docs) {\n             Map<String, Object> document = ConfigurationUtils.readMap(dataMap, Fields.SOURCE);\n-            IngestDocument ingestDocument = new IngestDocument(ConfigurationUtils.readStringProperty(dataMap, MetaData.INDEX.getFieldName()),\n-                    ConfigurationUtils.readStringProperty(dataMap, MetaData.TYPE.getFieldName()),\n-                    ConfigurationUtils.readStringProperty(dataMap, MetaData.ID.getFieldName()),\n+            IngestDocument ingestDocument = new IngestDocument(ConfigurationUtils.readStringProperty(dataMap, MetaData.INDEX.getFieldName(), \"_index\"),\n+                    ConfigurationUtils.readStringProperty(dataMap, MetaData.TYPE.getFieldName(), \"_type\"),\n+                    ConfigurationUtils.readStringProperty(dataMap, MetaData.ID.getFieldName(), \"_id\"),\n                     ConfigurationUtils.readOptionalStringProperty(dataMap, MetaData.ROUTING.getFieldName()),\n                     ConfigurationUtils.readOptionalStringProperty(dataMap, MetaData.PARENT.getFieldName()),\n                     ConfigurationUtils.readOptionalStringProperty(dataMap, MetaData.TIMESTAMP.getFieldName()),",
    "output": "Make index type and id optional in simulate api"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/transport/simulate/SimulatePipelineRequest.java\n@@ -147,9 +147,9 @@ private static List<IngestDocument> parseDocs(Map<String, Object> config) {\n         List<IngestDocument> ingestDocumentList = new ArrayList<>();\n         for (Map<String, Object> dataMap : docs) {\n             Map<String, Object> document = ConfigurationUtils.readMap(dataMap, Fields.SOURCE);\n-            IngestDocument ingestDocument = new IngestDocument(ConfigurationUtils.readStringProperty(dataMap, MetaData.INDEX.getFieldName()),\n-                    ConfigurationUtils.readStringProperty(dataMap, MetaData.TYPE.getFieldName()),\n-                    ConfigurationUtils.readStringProperty(dataMap, MetaData.ID.getFieldName()),\n+            IngestDocument ingestDocument = new IngestDocument(ConfigurationUtils.readStringProperty(dataMap, MetaData.INDEX.getFieldName(), \"_index\"),\n+                    ConfigurationUtils.readStringProperty(dataMap, MetaData.TYPE.getFieldName(), \"_type\"),\n+                    ConfigurationUtils.readStringProperty(dataMap, MetaData.ID.getFieldName(), \"_id\"),\n                     ConfigurationUtils.readOptionalStringProperty(dataMap, MetaData.ROUTING.getFieldName()),\n                     ConfigurationUtils.readOptionalStringProperty(dataMap, MetaData.PARENT.getFieldName()),\n                     ConfigurationUtils.readOptionalStringProperty(dataMap, MetaData.TIMESTAMP.getFieldName()),",
    "output": "Make index type and id optional in simulate api Default values are _index, _type and _id"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java\n@@ -258,7 +258,7 @@ public void testRandom() throws Exception {\n             }\n             tv_stored |= tv_positions || tv_payloads || tv_offsets;\n             if (randomBoolean()) {\n-                mappingBuilder.field(\"similarity\", similarity = randomBoolean() ? \"BM25\" : \"TF/IDF\");\n+                mappingBuilder.field(\"similarity\", similarity = randomBoolean() ? \"BM25\" : null);\n             }\n             mappingBuilder.endObject();\n         }\n@@ -296,7 +296,7 @@ public void testRandom() throws Exception {\n         } else {\n             assertThat(field, nullValue());\n         }\n-        if (similarity == null || similarity.equals(\"TF/IDF\")) {\n+        if (similarity == null) {\n             assertThat(builtDocMapper.allFieldMapper().fieldType().similarity(), nullValue());\n         }   else {\n             assertThat(similarity, equalTo(builtDocMapper.allFieldMapper().fieldType().similarity().name()));",
    "output": "Upgrade test which assumes that an unknown similarity type is accepted"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java b/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/TypeParsers.java\n@@ -460,8 +460,7 @@ public static void parseCopyFields(Object propNode, FieldMapper.Builder builder)\n     }\n \n     private static SimilarityProvider resolveSimilarity(Mapper.TypeParser.ParserContext parserContext, String name, String value) {\n-        if (parserContext.indexVersionCreated().before(Version.V_3_0_0) &&\n-            \"default\".equals(value) && parserContext.getSimilarity(value) == null) {\n+        if (parserContext.indexVersionCreated().before(Version.V_3_0_0) && \"default\".equals(value)) {\n             // \"default\" similarity has been renamed into \"classic\" in 3.x.\n             value = SimilarityService.DEFAULT_SIMILARITY;\n         }",
    "output": "Remove not relevant part of the bw compat test"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java\n@@ -710,7 +710,7 @@ public ChannelPipeline getPipeline() throws Exception {\n             Channel channel = serverBootstrap.bind(new InetSocketAddress(InetAddress.getByName(\"localhost\"), 0));\n             int port = ((InetSocketAddress) channel.getLocalAddress()).getPort();\n             // IO_ERROR because there is no real file delivered...\n-            assertStatus(String.format(Locale.ROOT, \"install https://user:pass@localhost:%s/foo.zip --verbose --timeout 1s\", port), ExitStatus.IO_ERROR);\n+            assertStatus(String.format(Locale.ROOT, \"install https://user:pass@localhost:%s/foo.zip --verbose --timeout 10s\", port), ExitStatus.IO_ERROR);\n \n             // ensure that we did not try any other data source like download.elastic.co, in case we specified our own local URL\n             assertThat(terminal.getTerminalOutput(), not(hasItem(containsString(\"download.elastic.co\"))));",
    "output": "Use a longer timeout for plugin manager in test"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java b/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n--- a/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n+++ b/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n@@ -83,8 +83,6 @@ public void testEvilGroovyScripts() throws Exception {\n         assertSuccess(\"def range = 1..doc['foo'].value; def v = range.get(0)\");\n         // Maps\n         assertSuccess(\"def v = doc['foo'].value; def m = [:]; m.put(\\\"value\\\", v)\");\n-        // serialization to json (this is best effort considering the unsafe etc at play)\n-        assertSuccess(\"def x = 5; groovy.json.JsonOutput.toJson(x)\");\n         // Times\n         assertSuccess(\"def t = Instant.now().getMillis()\");\n         // GroovyCollections",
    "output": "Improve thirdPartyAudit check, round 3"
  },
  {
    "input": "diff --git a/plugins/ingest/src/test/java/org/elasticsearch/plugin/ingest/IngestBootstrapperTests.java b/plugins/ingest/src/test/java/org/elasticsearch/plugin/ingest/IngestBootstrapperTests.java\n--- a/plugins/ingest/src/test/java/org/elasticsearch/plugin/ingest/IngestBootstrapperTests.java\n+++ b/plugins/ingest/src/test/java/org/elasticsearch/plugin/ingest/IngestBootstrapperTests.java\n@@ -192,7 +192,7 @@ public void testPipelineStoreBootstrappingIngestIndexShardsNotStarted() throws E\n         metaDateBuilder.put(IndexMetaData.builder(PipelineStore.INDEX).settings(settings).numberOfShards(1).numberOfReplicas(1));\n         IndexRoutingTable.Builder indexRoutingTableBuilder = IndexRoutingTable.builder(PipelineStore.INDEX);\n         indexRoutingTableBuilder.addIndexShard(new IndexShardRoutingTable.Builder(new ShardId(PipelineStore.INDEX, 0))\n-                .addShard(TestShardRouting.newShardRouting(PipelineStore.INDEX, 0, \"_node_id\", null, null, true, ShardRoutingState.UNASSIGNED, 1, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, \"\")))\n+                .addShard(TestShardRouting.newShardRouting(PipelineStore.INDEX, 0, \"_node_id\", null, null, true, ShardRoutingState.INITIALIZING, 1, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, \"\")))\n                 .build());\n         indexRoutingTableBuilder.addReplica();\n         routingTableBuilder.add(indexRoutingTableBuilder.build());",
    "output": "Fix test after merging in master branch"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java b/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n--- a/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n+++ b/modules/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n@@ -83,8 +83,6 @@ public void testEvilGroovyScripts() throws Exception {\n         assertSuccess(\"def range = 1..doc['foo'].value; def v = range.get(0)\");\n         // Maps\n         assertSuccess(\"def v = doc['foo'].value; def m = [:]; m.put(\\\"value\\\", v)\");\n-        // serialization to json (this is best effort considering the unsafe etc at play)\n-        assertSuccess(\"def x = 5; groovy.json.JsonOutput.toJson(x)\");\n         // Times\n         assertSuccess(\"def t = Instant.now().getMillis()\");\n         // GroovyCollections",
    "output": "Improve thirdPartyAudit check, round 3"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n@@ -892,7 +892,6 @@ public boolean containsShard(ShardRouting shard) {\n     static final class ModelIndex {\n         private final String id;\n         private final Map<ShardRouting, Decision> shards = new HashMap<>();\n-        private int numPrimaries = -1;\n         private int highestPrimary = -1;\n \n         public ModelIndex(String id) {\n@@ -924,26 +923,13 @@ public Collection<ShardRouting> getAllShards() {\n             return shards.keySet();\n         }\n \n-        public int numPrimaries() {\n-            if (numPrimaries == -1) {\n-                int num = 0;\n-                for (ShardRouting shard : shards.keySet()) {\n-                    if (shard.primary()) {\n-                        num++;\n-                    }\n-                }\n-                return numPrimaries = num;\n-            }\n-            return numPrimaries;\n-        }\n-\n         public Decision removeShard(ShardRouting shard) {\n-            highestPrimary = numPrimaries = -1;\n+            highestPrimary = -1;\n             return shards.remove(shard);\n         }\n \n         public void addShard(ShardRouting shard, Decision decision) {\n-            highestPrimary = numPrimaries = -1;\n+            highestPrimary = -1;\n             assert decision != null;\n             assert !shards.containsKey(shard) : \"Shard already allocated on current node: \" + shards.get(shard) + \" \" + shard;\n             shards.put(shard, decision);",
    "output": "Remove superfluous method numPrimaries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n@@ -259,14 +259,6 @@ public float avgShardsPerNode() {\n             return avgShardsPerNode;\n         }\n \n-        /**\n-         * Returns the global average of primaries per node\n-         */\n-        public float avgPrimariesPerNode() {\n-            return ((float) metaData.numberOfShards()) / nodes.size();\n-        }\n-\n-\n         /**\n          * Returns a new {@link NodeSorter} that sorts the nodes based on their\n          * current weight with respect to the index passed to the sorter. The",
    "output": "Remove superfluous method"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n@@ -332,7 +332,7 @@ private boolean balance(boolean onlyAssign) {\n             if (onlyAssign == false && changed == false && allocation.deciders().canRebalance(allocation).type() == Type.YES) {\n                 NodeSorter sorter = newNodeSorter();\n                 if (nodes.size() > 1) { /* skip if we only have one node */\n-                    for (String index : buildWeightOrderedIndidces(sorter)) {\n+                    for (String index : buildWeightOrderedIndices(sorter)) {\n                         sorter.reset(index);\n                         final float[] weights = sorter.weights;\n                         final ModelNode[] modelNodes = sorter.modelNodes;\n@@ -423,7 +423,7 @@ private boolean balance(boolean onlyAssign) {\n          * average. To re-balance we need to move shards back eventually likely\n          * to the nodes we relocated them from.\n          */\n-        private String[] buildWeightOrderedIndidces(NodeSorter sorter) {\n+        private String[] buildWeightOrderedIndices(NodeSorter sorter) {\n             final String[] indices = this.indices.toArray(new String[this.indices.size()]);\n             final float[] deltas = new float[indices.length];\n             for (int i = 0; i < deltas.length; i++) {",
    "output": "Fix typo in method name"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n@@ -856,14 +856,6 @@ public int numShards(String idx) {\n             return index == null ? 0 : index.numShards();\n         }\n \n-        public Collection<ShardRouting> shards() {\n-            Collection<ShardRouting> result = new ArrayList<>();\n-            for (ModelIndex index : indices.values()) {\n-                result.addAll(index.getAllShards());\n-            }\n-            return result;\n-        }\n-\n         public int highestPrimary(String index) {\n             ModelIndex idx = indices.get(index);\n             if (idx != null) {\n@@ -941,10 +933,6 @@ public String getIndexId() {\n             return id;\n         }\n \n-        public Decision getDecicion(ShardRouting shard) {\n-            return shards.get(shard);\n-        }\n-\n         public int numShards() {\n             return shards.size();\n         }",
    "output": "Remove unused methods"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java b/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java\n--- a/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java\n+++ b/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java\n@@ -54,7 +54,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 //.put(\"threadpool.listener.queue_size\", 1)\n                 .put(\"threadpool.get.queue_size\", 1)\n                 // default is 50\n-                .put(\"threadpool.bulk.queue_size\", 20)\n+                .put(\"threadpool.bulk.queue_size\", 30)\n                 .build();\n     }\n ",
    "output": "Make BulkProcessorRetryIT less sensitive In this commit we increase the queue size of the bulk pool in BulkProcessorRetryIT to make it less sensitive. As this test case should stress the pool so bulk processor needs to back off but not so much that the backoff policy will give up at some point (which is a valid condition), we still keep it below the default queue size of 50"
  },
  {
    "input": "diff --git a/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsRepository.java b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsRepository.java\n--- a/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsRepository.java\n+++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsRepository.java\n@@ -131,17 +131,7 @@ public FileContext run() throws IOException {\n                 }\n             });\n         } catch (PrivilegedActionException pae) {\n-            Throwable th = pae.getCause();\n-            if (th instanceof Error) {\n-                throw (Error) th;\n-            }\n-            if (th instanceof RuntimeException) {\n-                throw (RuntimeException) th;\n-            }\n-            if (th instanceof IOException) {\n-                throw (IOException) th;\n-            }\n-            throw new ElasticsearchException(pae);\n+            throw (IOException) pae.getException();\n         }\n     }\n ",
    "output": "Fix exc handling"
  },
  {
    "input": "diff --git a/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/SecurityUtils.java b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/SecurityUtils.java\n--- a/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/SecurityUtils.java\n+++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/SecurityUtils.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.repositories.hdfs;\n \n import org.apache.hadoop.fs.FileContext;\n-import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.SpecialPermission;\n \n import java.io.IOException;\n@@ -49,17 +48,7 @@ public V run() throws IOException {\n                 }\n             });\n         } catch (PrivilegedActionException pae) {\n-            Throwable th = pae.getCause();\n-            if (th instanceof Error) {\n-                throw (Error) th;\n-            }\n-            if (th instanceof RuntimeException) {\n-                throw (RuntimeException) th;\n-            }\n-            if (th instanceof IOException) {\n-                throw (IOException) th;\n-            }\n-            throw new ElasticsearchException(pae);\n+            throw (IOException) pae.getException();\n         }\n     }\n }",
    "output": "Fix exc handling"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n--- a/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n+++ b/elasticsearch/x-pack/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n@@ -227,7 +227,7 @@ private void resolveParentChildJoinFields(Set<String> allowedFields) {\n \n     static void intersectScorerAndRoleBits(Scorer scorer, SparseFixedBitSet roleBits, LeafCollector collector, Bits acceptDocs) throws IOException {\n         // ConjunctionDISI uses the DocIdSetIterator#cost() to order the iterators, so if roleBits has the lowest cardinality it should be used first:\n-        DocIdSetIterator iterator = ConjunctionDISI.intersect(Arrays.asList(new BitSetIterator(roleBits, roleBits.approximateCardinality()), scorer));\n+        DocIdSetIterator iterator = ConjunctionDISI.intersectIterators(Arrays.asList(new BitSetIterator(roleBits, roleBits.approximateCardinality()), scorer.iterator()));\n         for (int docId = iterator.nextDoc(); docId < DocIdSetIterator.NO_MORE_DOCS; docId = iterator.nextDoc()) {\n             if (acceptDocs == null || acceptDocs.get(docId)) {\n                 collector.collect(docId);",
    "output": "Upgrade to lucene-5.5.0-snapshot-1721183"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -279,6 +279,8 @@ public class Version {\n     public static final Version V_2_1_2 = new Version(V_2_1_2_ID, true, org.apache.lucene.util.Version.LUCENE_5_3_1);\n     public static final int V_2_2_0_ID = 2020099;\n     public static final Version V_2_2_0 = new Version(V_2_2_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_4_0);\n+    public static final int V_2_3_0_ID = 2030099;\n+    public static final Version V_2_3_0 = new Version(V_2_3_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_4_0);\n     public static final int V_3_0_0_ID = 3000099;\n     public static final Version V_3_0_0 = new Version(V_3_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_5_0);\n     public static final Version CURRENT = V_3_0_0;\n@@ -295,6 +297,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_3_0_0_ID:\n                 return V_3_0_0;\n+            case V_2_3_0_ID:\n+                return V_2_3_0;\n             case V_2_2_0_ID:\n                 return V_2_2_0;\n             case V_2_1_2_ID:",
    "output": "Add 2.3.0-SNAPSHOT as a Version constant"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/profile/CollectorResult.java b/core/src/main/java/org/elasticsearch/search/profile/CollectorResult.java\n--- a/core/src/main/java/org/elasticsearch/search/profile/CollectorResult.java\n+++ b/core/src/main/java/org/elasticsearch/search/profile/CollectorResult.java\n@@ -123,8 +123,8 @@ public List<CollectorResult> getProfiledChildren() {\n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, ToXContent.Params params) throws IOException {\n         builder = builder.startObject()\n-                .field(NAME.getPreferredName(), toString())\n-                .field(REASON.getPreferredName(), reason)\n+                .field(NAME.getPreferredName(), getName())\n+                .field(REASON.getPreferredName(), getReason())\n                 .field(TIME.getPreferredName(), String.format(Locale.US, \"%.10gms\", (double) (getTime() / 1000000.0)));\n \n         if (!children.isEmpty()) {",
    "output": "Fix collector's class name on response output"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/gateway/QuorumGatewayIT.java b/core/src/test/java/org/elasticsearch/gateway/QuorumGatewayIT.java\n--- a/core/src/test/java/org/elasticsearch/gateway/QuorumGatewayIT.java\n+++ b/core/src/test/java/org/elasticsearch/gateway/QuorumGatewayIT.java\n@@ -51,7 +51,7 @@ public void testQuorumRecovery() throws Exception {\n         logger.info(\"--> starting 3 nodes\");\n         // we are shutting down nodes - make sure we don't have 2 clusters if we test network\n         internalCluster().startNodesAsync(3,\n-                Settings.builder().put(ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES, 2).build()).get();\n+                Settings.builder().put(ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey(), 2).build()).get();\n \n \n         createIndex(\"test\");",
    "output": "Use new settings infra"
  },
  {
    "input": "diff --git a/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionSearchTests.java b/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionSearchTests.java\n--- a/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionSearchTests.java\n+++ b/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionSearchTests.java\n@@ -95,7 +95,7 @@ public void testExecuteAccessHits() throws Exception {\n         hit.score(1f);\n         hit.shard(new SearchShardTarget(\"a\", \"a\", 0));\n \n-        InternalSearchResponse internalSearchResponse = new InternalSearchResponse(new InternalSearchHits(new InternalSearchHit[]{hit}, 1l, 1f), null, null, false, false);\n+        InternalSearchResponse internalSearchResponse = new InternalSearchResponse(new InternalSearchHits(new InternalSearchHit[]{hit}, 1l, 1f), null, null, null, false, false);\n         SearchResponse response = new SearchResponse(internalSearchResponse, \"\", 3, 3, 500l, new ShardSearchFailure[0]);\n \n         WatchExecutionContext ctx = mockExecutionContext(\"_watch_name\", new Payload.XContent(response));",
    "output": "Fix compile due to change in InternalSearchResponse signature"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java\n--- a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java\n@@ -375,7 +375,7 @@ public void readFrom(StreamInput in) throws IOException {\n         mem.readFrom(in);\n         gcCollectors = in.readStringArray();\n         memoryPools = in.readStringArray();\n-        useCompressedOops = in.readOptionalString();\n+        useCompressedOops = in.readString();\n     }\n \n     @Override\n@@ -400,7 +400,7 @@ public void writeTo(StreamOutput out) throws IOException {\n         mem.writeTo(out);\n         out.writeStringArray(gcCollectors);\n         out.writeStringArray(memoryPools);\n-        out.writeOptionalString(useCompressedOops);\n+        out.writeString(useCompressedOops);\n     }\n \n     public static class Mem implements Streamable {",
    "output": "Remove optionality from streaming useCompressedOops field"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/transport/Transport.java b/core/src/main/java/org/elasticsearch/transport/Transport.java\n--- a/core/src/main/java/org/elasticsearch/transport/Transport.java\n+++ b/core/src/main/java/org/elasticsearch/transport/Transport.java\n@@ -36,7 +36,7 @@\n public interface Transport extends LifecycleComponent<Transport> {\n \n \n-    Setting<Settings> TRANSPORT_PROFILES_SETTING = Setting.groupSetting(\"transport.profiles.\", false, Setting.Scope.CLUSTER);\n+    Setting<Settings> TRANSPORT_PROFILES_SETTING = Setting.groupSetting(\"transport.profiles.\", true, Setting.Scope.CLUSTER);\n \n     public static class TransportSettings {\n         public static final String TRANSPORT_TCP_COMPRESS = \"transport.tcp.compress\";",
    "output": "Make it updateable"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/bulk/RetryTests.java b/core/src/test/java/org/elasticsearch/action/bulk/RetryTests.java\n--- a/core/src/test/java/org/elasticsearch/action/bulk/RetryTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/bulk/RetryTests.java\n@@ -126,9 +126,9 @@ public void testAsyncRetryFailsAfterBacksOff() throws Exception {\n \n     private static class AssertingListener implements ActionListener<BulkResponse> {\n         private final CountDownLatch latch;\n-        private int countOnResponseCalled = 0;\n-        private Throwable lastFailure;\n-        private BulkResponse response;\n+        private volatile int countOnResponseCalled = 0;\n+        private volatile Throwable lastFailure;\n+        private volatile BulkResponse response;\n \n         private AssertingListener() {\n             latch = new CountDownLatch(1);",
    "output": "Fix visibility issue in RetryTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/Setting.java b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n@@ -120,6 +120,8 @@ public T get(Settings settings) {\n             return parser.apply(value);\n         } catch (ElasticsearchParseException ex) {\n             throw new IllegalArgumentException(ex.getMessage(), ex);\n+        } catch (NumberFormatException ex) {\n+            throw new IllegalArgumentException(\"Failed to parse value [\" + value + \"] for setting [\" + getKey() + \"]\", ex);\n         } catch (IllegalArgumentException ex) {\n             throw ex;\n         } catch (Exception t) {\n\ndiff --git a/core/src/test/java/org/elasticsearch/action/admin/cluster/settings/SettingsUpdaterTests.java b/core/src/test/java/org/elasticsearch/action/admin/cluster/settings/SettingsUpdaterTests.java\n--- a/core/src/test/java/org/elasticsearch/action/admin/cluster/settings/SettingsUpdaterTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/admin/cluster/settings/SettingsUpdaterTests.java\n@@ -91,6 +91,7 @@ public void testAllOrNothing() {\n                 Settings.builder().put(BalancedShardsAllocator.INDEX_BALANCE_FACTOR_SETTING.getKey(), \"not a float\").put(BalancedShardsAllocator.SHARD_BALANCE_FACTOR_SETTING.getKey(), 1.0f).build());\n             fail(\"all or nothing\");\n         } catch (IllegalArgumentException ex) {\n+            logger.info(\"\", ex);\n             assertEquals(\"Failed to parse value [not a float] for setting [cluster.routing.allocation.balance.index]\", ex.getMessage());\n         }\n         assertNull(\"updater only does a dryRun\", index.get());",
    "output": "Fix more excpption useage"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java b/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java\n@@ -225,7 +225,7 @@ public void testFineGrainedSettings() throws IOException {\n             } while (scriptContextSettings.containsKey(scriptContext));\n             scriptContextSettings.put(scriptContext, randomFrom(ScriptMode.values()));\n         }\n-        int numEngineSettings = randomIntBetween(0, 10);\n+        int numEngineSettings = randomIntBetween(0, ScriptType.values().length * scriptContexts.length);\n         Map<String, ScriptMode> engineSettings = new HashMap<>();\n         for (int i = 0; i < numEngineSettings; i++) {\n             String settingKey;",
    "output": "Fix ScriptServiceTests.testFineGrainedSettings that can loop indefinitely"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java b/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n@@ -22,7 +22,6 @@\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.common.settings.Settings;\n-import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.node.settings.NodeSettingsService;\n ",
    "output": "Remove unused import"
  },
  {
    "input": "diff --git a/plugins/ingest/src/test/java/IngestRunner.java b/plugins/ingest/src/test/java/IngestRunner.java\n--- a/plugins/ingest/src/test/java/IngestRunner.java\n+++ b/plugins/ingest/src/test/java/IngestRunner.java\n@@ -19,6 +19,7 @@\n \n import org.elasticsearch.Version;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.discovery.DiscoveryService;\n import org.elasticsearch.node.MockNode;\n import org.elasticsearch.node.Node;\n import org.elasticsearch.plugin.ingest.IngestPlugin;\n@@ -34,6 +35,7 @@ public static void main(String[] args) throws Exception {\n         settings.put(\"http.cors.allow-origin\", \"*\");\n         settings.put(\"script.inline\", \"on\");\n         settings.put(\"cluster.name\", IngestRunner.class.getSimpleName());\n+        settings.put(DiscoveryService.SETTING_DISCOVERY_SEED, 0L);\n \n         final CountDownLatch latch = new CountDownLatch(1);\n         final Node node = new MockNode(settings.build(), Version.CURRENT, Collections.singleton(IngestPlugin.class));",
    "output": "Fix ingest runner"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/highlight/HighlightBuilderTests.java b/core/src/test/java/org/elasticsearch/search/highlight/HighlightBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/search/highlight/HighlightBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/highlight/HighlightBuilderTests.java\n@@ -416,6 +416,30 @@ public void testParsingEmptyStructure() throws IOException {\n         System.out.println(Math.log(1/(double)(1+1)) + 1.0);\n     }\n \n+    /**\n+     * test ordinals of {@link Order}, since serialization depends on it\n+     */\n+    public void testValidOrderOrdinals() {\n+        assertThat(Order.NONE.ordinal(), equalTo(0));\n+        assertThat(Order.SCORE.ordinal(), equalTo(1));\n+    }\n+\n+    public void testOrderSerialization() throws Exception {\n+        try (BytesStreamOutput out = new BytesStreamOutput()) {\n+            Order.NONE.writeTo(out);\n+            try (StreamInput in = StreamInput.wrap(out.bytes())) {\n+                assertThat(in.readVInt(), equalTo(0));\n+            }\n+        }\n+\n+        try (BytesStreamOutput out = new BytesStreamOutput()) {\n+            Order.SCORE.writeTo(out);\n+            try (StreamInput in = StreamInput.wrap(out.bytes())) {\n+                assertThat(in.readVInt(), equalTo(1));\n+            }\n+        }\n+    }\n+\n     protected static XContentBuilder toXContent(HighlightBuilder highlight, XContentType contentType) throws IOException {\n         XContentBuilder builder = XContentFactory.contentBuilder(contentType);\n         if (randomBoolean()) {",
    "output": "Add test for Order enum ordinals"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/tribe/TribeUnitTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/tribe/TribeUnitTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/tribe/TribeUnitTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/tribe/TribeUnitTests.java\n@@ -62,14 +62,14 @@ public static void createTribes() {\n             Settings.builder()\n                 .put(baseSettings)\n                 .put(\"cluster.name\", \"tribe1\")\n-                .put(\"node.name\", \"tribe1_node\")\n+                .put(\"name\", \"tribe1_node\")\n                 .put(DiscoveryService.SETTING_DISCOVERY_SEED, random().nextLong())\n                 .build()).start();\n         tribe2 = new TribeClientNode(\n             Settings.builder()\n                 .put(baseSettings)\n                 .put(\"cluster.name\", \"tribe2\")\n-                .put(\"node.name\", \"tribe2_node\")\n+                .put(\"name\", \"tribe2_node\")\n                 .put(DiscoveryService.SETTING_DISCOVERY_SEED, random().nextLong())\n                 .build()).start();\n     }",
    "output": "Fix settings for TribeUnitTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/Randomness.java b/core/src/main/java/org/elasticsearch/common/Randomness.java\n--- a/core/src/main/java/org/elasticsearch/common/Randomness.java\n+++ b/core/src/main/java/org/elasticsearch/common/Randomness.java\n@@ -114,7 +114,7 @@ public static Random get() {\n \n     private static Random getWithoutSeed() {\n         assert currentMethod == null && getRandomMethod == null : \"running under tests but tried to create non-reproducible random\";\n-        if (LOCAL.get() == null) {\n+        if (LOCAL == null) {\n             byte[] bytes = SR.generateSeed(8);\n             long accumulator = 0;\n             for (int i = 0; i < bytes.length; i++) {",
    "output": "Fix NullPointerException in o.e.c.Randomness"
  },
  {
    "input": "diff --git a/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java b/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java\n--- a/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java\n+++ b/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java\n@@ -469,7 +469,7 @@ public void testIssue2991() {\n     }\n \n     public void testSimpleSorts() throws Exception {\n-        Random random = getRandom();\n+        Random random = random();\n         assertAcked(prepareCreate(\"test\")\n                 .addMapping(\"type1\", XContentFactory.jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                         .startObject(\"str_value\").field(\"type\", \"string\").field(\"index\", \"not_analyzed\").startObject(\"fielddata\").field(\"format\", random().nextBoolean() ? \"doc_values\" : null).endObject().endObject()\n@@ -496,7 +496,7 @@ public void testSimpleSorts() throws Exception {\n                     .endObject());\n             builders.add(builder);\n         }\n-        Randomness.shuffle(builders);\n+        Collections.shuffle(builders, random);\n         for (IndexRequestBuilder builder : builders) {\n             builder.execute().actionGet();\n             if (random.nextBoolean()) {",
    "output": "Fix compilation in o.e.m.t.SimpleSortTests"
  },
  {
    "input": "diff --git a/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionPlugin.java b/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionPlugin.java\n--- a/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionPlugin.java\n+++ b/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionPlugin.java\n@@ -19,38 +19,11 @@\n \n package org.elasticsearch.script.expression;\n \n-import org.apache.lucene.expressions.js.JavascriptCompiler;\n-import org.elasticsearch.SpecialPermission;\n import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.script.ScriptModule;\n \n-import java.security.AccessController;\n-import java.security.PrivilegedAction;\n-import java.text.ParseException;\n-\n public class ExpressionPlugin extends Plugin {\n     \n-    // lucene expressions has crazy checks in its clinit for the functions map\n-    // it violates rules of classloaders to detect accessibility\n-    // TODO: clean that up\n-    static {\n-        SecurityManager sm = System.getSecurityManager();\n-        if (sm != null) {\n-            sm.checkPermission(new SpecialPermission());\n-        }\n-        AccessController.doPrivileged(new PrivilegedAction<Void>() {\n-            @Override\n-            public Void run() {\n-                try {\n-                    JavascriptCompiler.compile(\"0\");\n-                } catch (ParseException e) {\n-                    throw new RuntimeException(e);\n-                }\n-                return null;\n-            }\n-        });\n-    }\n-\n     @Override\n     public String name() {\n         return \"lang-expression\";",
    "output": "Remove now-dead code in expressions (fixed in https://issues.apache.org/jira/browse/LUCENE-6920)"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n@@ -506,9 +506,6 @@ public Engine.Delete prepareDeleteOnPrimary(String type, String id, long version\n     }\n \n     public Engine.Delete prepareDeleteOnReplica(String type, String id, long version, VersionType versionType) {\n-        if (shardRouting.primary() && shardRouting.isRelocationTarget() == false) {\n-            throw new IllegalIndexShardStateException(shardId, state, \"shard is not a replica\");\n-        }\n         final DocumentMapper documentMapper = docMapper(type).getDocumentMapper();\n         return prepareDelete(type, id, documentMapper.uidMapper().term(Uid.createUid(type, id)), version, versionType, Engine.Operation.Origin.REPLICA);\n     }",
    "output": "Remove safety check from IndexShard#prepareDeleteOnReplica we are not ready for this yet: ``` if (shardRouting.primary() && shardRouting.isRelocationTarget() == false) { throw new IllegalIndexShardStateException(shardId, state, \"shard is not a replica\"); } ```"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/Setting.java b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n--- a/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n+++ b/core/src/main/java/org/elasticsearch/common/settings/Setting.java\n@@ -226,10 +226,7 @@ public Updater(Consumer<T> consumer, ESLogger logger, Settings settings,  Consum\n \n \n         public boolean prepareApply(Settings settings) {\n-            String newValue = settings.get(key);\n-            if (newValue == null) {\n-                newValue = getRaw(settings);\n-            }\n+            final String newValue = getRaw(settings);\n             if (value.equals(newValue) == false) {\n                 T inst = get(settings);\n                 try {",
    "output": "Use raw value directly"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java\n--- a/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java\n+++ b/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java\n@@ -160,7 +160,8 @@ public void testRestorePersistentSettings() throws Exception {\n             client.admin().cluster().prepareRestoreSnapshot(\"test-repo\", \"test-snap\").setRestoreGlobalState(true).setWaitForCompletion(true).execute().actionGet();\n             fail(\"can't restore minimum master nodes\");\n         } catch (IllegalArgumentException ex) {\n-            assertEquals(\"cannot set discovery.zen.minimum_master_nodes to more than the current master nodes count [1]\", ex.getMessage());\n+            assertEquals(\"illegal value can't update [discovery.zen.minimum_master_nodes] from [1] to [2]\", ex.getMessage());\n+            assertEquals(\"cannot set discovery.zen.minimum_master_nodes to more than the current master nodes count [1]\", ex.getCause().getMessage());\n         }\n         logger.info(\"--> ensure that zen discovery minimum master nodes wasn't restored\");\n         assertThat(client.admin().cluster().prepareState().setRoutingTable(false).setNodes(false).execute().actionGet().getState()",
    "output": "Fix expcetion msg comparison"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/tribe/TribeService.java b/core/src/main/java/org/elasticsearch/tribe/TribeService.java\n--- a/core/src/main/java/org/elasticsearch/tribe/TribeService.java\n+++ b/core/src/main/java/org/elasticsearch/tribe/TribeService.java\n@@ -135,7 +135,6 @@ public TribeService(Settings settings, ClusterService clusterService, DiscoveryS\n             sb.put(\"name\", settings.get(\"name\") + \"/\" + entry.getKey());\n             sb.put(\"path.home\", settings.get(\"path.home\")); // pass through ES home dir\n             sb.put(TRIBE_NAME, entry.getKey());\n-            sb.put(InternalSettingsPreparer.IGNORE_SYSTEM_PROPERTIES_SETTING, true);\n             if (sb.get(\"http.enabled\") == null) {\n                 sb.put(\"http.enabled\", false);\n             }",
    "output": "Remove unnecessary setting previously used to ignore sysprops in tribe nodes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java\n@@ -278,6 +278,8 @@ public static HighlightBuilder fromXContent(QueryParseContext parseContext) thro\n                 } else {\n                     throw new ParsingException(parser.getTokenLocation(), \"cannot parse object with name [{}]\", topLevelFieldName);\n                 }\n+            } else if (topLevelFieldName != null) {\n+                throw new ParsingException(parser.getTokenLocation(), \"unexpected token [{}] after [{}]\", token, topLevelFieldName);\n             }\n         }\n \n@@ -482,6 +484,8 @@ private static HighlightBuilder.Field fromXContent(String fieldname, QueryParseC\n                     } else {\n                         throw new ParsingException(parser.getTokenLocation(), \"cannot parse object with name [{}]\", currentFieldName);\n                     }\n+                } else if (currentFieldName != null) {\n+                    throw new ParsingException(parser.getTokenLocation(), \"unexpected token [{}] after [{}]\", token, currentFieldName);\n                 }\n             }\n             return field;",
    "output": "Add checks for unexpected tokens in parser"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n@@ -347,9 +347,9 @@ static List<Bundle> getPluginBundles(Path pluginsDirectory) throws IOException {\n                 final PluginInfo info;\n                 try {\n                     info = PluginInfo.readFromProperties(plugin);\n-                } catch (NoSuchFileException e) {\n-                    throw new IllegalStateException(\"Existing plugin [\" + plugin.getFileName() + \"] missing plugin descriptor. \" +\n-                        \"Was the plugin built before 2.0?\", e);\n+                } catch (IOException e) {\n+                    throw new IllegalStateException(\"Could not load plugin descriptor for existing plugin [\"\n+                        + plugin.getFileName() + \"]. Was the plugin built before 2.0?\", e);\n                 }\n \n                 List<URL> urls = new ArrayList<>();\n\ndiff --git a/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java\n@@ -133,7 +133,7 @@ public void testExistingPluginMissingDescriptor() throws Exception {\n             PluginsService.getPluginBundles(pluginsDir);\n             fail();\n         } catch (IllegalStateException e) {\n-            assertTrue(e.getMessage(), e.getMessage().contains(\"missing plugin descriptor\"));\n+            assertTrue(e.getMessage(), e.getMessage().contains(\"Could not load plugin descriptor for existing plugin\"));\n         }\n     }\n }",
    "output": "Fix plugin service check for missing descriptor to allow ioexception"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java b/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java\n--- a/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java\n+++ b/core/src/main/java/org/elasticsearch/common/MacAddressProvider.java\n@@ -65,8 +65,8 @@ public static byte[] getSecureMungedAddress() {\n         byte[] address = null;\n         try {\n             address = getMacAddress();\n-        } catch( SocketException se ) {\n-            logger.warn(\"Unable to get mac address, will use a dummy address\", se);\n+        } catch (Throwable t) {\n+            logger.warn(\"Unable to get mac address, will use a dummy address\", t);\n             // address will be set below\n         }\n ",
    "output": "Use dummy mac address if anything goes wrong asking for the real one"
  },
  {
    "input": "diff --git a/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionTests.java b/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionTests.java\n--- a/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionTests.java\n+++ b/elasticsearch/qa/messy-test-watcher-with-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptConditionTests.java\n@@ -187,7 +187,7 @@ public void testScriptConditionReturnObject() throws Exception {\n \n     public void testScriptConditionAccessCtx() throws Exception {\n         ScriptServiceProxy scriptService = getScriptServiceProxy(tp);\n-        ExecutableScriptCondition condition = new ExecutableScriptCondition(new ScriptCondition(Script.inline(\"ctx.trigger.scheduled_time.getMillis() < System.currentTimeMillis() \").build()), logger, scriptService);\n+        ExecutableScriptCondition condition = new ExecutableScriptCondition(new ScriptCondition(Script.inline(\"ctx.trigger.scheduled_time.getMillis() < new Date().time \").build()), logger, scriptService);\n         SearchResponse response = new SearchResponse(InternalSearchResponse.empty(), \"\", 3, 3, 500l, new ShardSearchFailure[0]);\n         WatchExecutionContext ctx = mockExecutionContext(\"_name\", new DateTime(DateTimeZone.UTC), new Payload.XContent(response));\n         Thread.sleep(10);",
    "output": "Use Date instead of System in groovy script... its absurd to expect scripts can use System"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java\n--- a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java\n+++ b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java\n@@ -254,7 +254,6 @@ public synchronized void run() {\n             // is actually using (using IW.ramBytesUsed), so that small indices (e.g. Marvel) would not\n             // get the same indexing buffer as large indices.  But it quickly gets tricky...\n             if (activeShardCount == 0) {\n-                logger.debug(\"no active shards\");\n                 return;\n             }\n ",
    "output": "Remove logging statement when no shards are active"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java\n@@ -133,7 +133,7 @@ public void testExistingPluginMissingDescriptor() throws Exception {\n             PluginsService.getPluginBundles(pluginsDir);\n             fail();\n         } catch (IllegalStateException e) {\n-            assertTrue(e.getMessage().contains(\"[plugin-missing-descriptor] missing plugin descriptor\"));\n+            assertTrue(e.getMessage(), e.getMessage().contains(\"missing plugin descriptor\"));\n         }\n     }\n }",
    "output": "Fix plugin test to account for possibly extra dir by mock fs"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterServiceIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ClusterServiceIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterServiceIT.java\n@@ -836,7 +836,9 @@ public void clusterStateProcessed(String source, ClusterState oldState, ClusterS\n \n         // assert each executor executed the correct number of tasks\n         for (TaskExecutor executor : executors) {\n-            assertEquals((int)counts.get(executor), executor.counter.get());\n+            if (counts.containsKey(executor)) {\n+                assertEquals((int) counts.get(executor), executor.counter.get());\n+            }\n         }\n \n         // assert the correct number of clusterStateProcessed events were triggered",
    "output": "Fix test bug in ClusterServiceIT#testClusterStateBatchedUpdates This commit fixes a test bug in ClusterService#testClusterStateBatchedUpdates. In particular, in the case that an executor did not receive a task assignment from the random assignments, it would not have an entry in the map of executors to counts of assigned tasks. The fix is to just check if each executor has an entry in the counts map"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n@@ -164,7 +164,18 @@ public PluginsService(Settings settings, Path modulesDirectory, Path pluginsDire\n             }\n         }\n \n-        logger.info(\"loaded {}, sites {}\", jvmPlugins.keySet(), sitePlugins);\n+        // we don't log jars in lib/ we really shouldnt log modules,\n+        // but for now: just be transparent so we can debug any potential issues\n+        Set<String> moduleNames = new HashSet<>();\n+        Set<String> jvmPluginNames = new HashSet<>();\n+        for (PluginInfo moduleInfo : info.getModuleInfos()) {\n+            moduleNames.add(moduleInfo.getName());\n+        }\n+        for (PluginInfo pluginInfo : info.getPluginInfos()) {\n+            jvmPluginNames.add(pluginInfo.getName());\n+        }\n+\n+        logger.info(\"modules {}, plugins {}, sites {}\", moduleNames, jvmPluginNames, sitePlugins);\n \n         Map<Plugin, List<OnModuleReference>> onModuleReferences = new HashMap<>();\n         for (Plugin plugin : jvmPlugins.values()) {",
    "output": "Improve logger output on startup"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java\n@@ -276,6 +276,10 @@ static class Bundle {\n     // similar in impl to getPluginBundles, but DO NOT try to make them share code.\n     // we don't need to inherit all the leniency, and things are different enough.\n     static List<Bundle> getModuleBundles(Path modulesDirectory) throws IOException {\n+        // damn leniency\n+        if (Files.notExists(modulesDirectory)) {\n+            return Collections.emptyList();\n+        }\n         List<Bundle> bundles = new ArrayList<>();\n         try (DirectoryStream<Path> stream = Files.newDirectoryStream(modulesDirectory)) {\n             for (Path module : stream) {",
    "output": "Add leniency for tests"
  },
  {
    "input": "diff --git a/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilSecurityTests.java b/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilSecurityTests.java\n--- a/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilSecurityTests.java\n+++ b/qa/evil-tests/src/test/java/org/elasticsearch/bootstrap/EvilSecurityTests.java\n@@ -111,6 +111,8 @@ public void testEnvironmentPaths() throws Exception {\n         assertExactPermissions(new FilePermission(environment.binFile().toString(), \"read,readlink\"), permissions);\n         // lib file: ro\n         assertExactPermissions(new FilePermission(environment.libFile().toString(), \"read,readlink\"), permissions);\n+        // modules file: ro\n+        assertExactPermissions(new FilePermission(environment.modulesFile().toString(), \"read,readlink\"), permissions);\n         // config file: ro\n         assertExactPermissions(new FilePermission(environment.configFile().toString(), \"read,readlink\"), permissions);\n         // scripts file: ro",
    "output": "Add test for modules/"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/forcemerge/RestForceMergeAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/forcemerge/RestForceMergeAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/forcemerge/RestForceMergeAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/forcemerge/RestForceMergeAction.java\n@@ -45,9 +45,6 @@ public RestForceMergeAction(Settings settings, RestController controller, Client\n         super(settings, controller, client);\n         controller.registerHandler(POST, \"/_forcemerge\", this);\n         controller.registerHandler(POST, \"/{index}/_forcemerge\", this);\n-\n-        controller.registerHandler(GET, \"/_forcemerge\", this);\n-        controller.registerHandler(GET, \"/{index}/_forcemerge\", this);\n     }\n \n     @Override",
    "output": "Remove `GET` option for /_forcemerge POST should be used to indicate this is not just a retrieval operation"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n--- a/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/action/shard/ShardStateAction.java\n@@ -151,7 +151,6 @@ public BatchResult<ShardRoutingEntry> execute(ClusterState currentState, List<Sh\n             BatchResult.Builder<ShardRoutingEntry> batchResultBuilder = BatchResult.builder();\n             List<FailedRerouteAllocation.FailedShard> shardRoutingsToBeApplied = new ArrayList<>(tasks.size());\n             for (ShardRoutingEntry task : tasks) {\n-                task.processed = true;\n                 shardRoutingsToBeApplied.add(new FailedRerouteAllocation.FailedShard(task.shardRouting, task.message, task.failure));\n             }\n             ClusterState maybeUpdatedState = currentState;\n@@ -201,7 +200,6 @@ public BatchResult<ShardRoutingEntry> execute(ClusterState currentState, List<Sh\n             BatchResult.Builder<ShardRoutingEntry> builder = BatchResult.builder();\n             List<ShardRouting> shardRoutingsToBeApplied = new ArrayList<>(tasks.size());\n             for (ShardRoutingEntry task : tasks) {\n-                task.processed = true;\n                 shardRoutingsToBeApplied.add(task.shardRouting);\n             }\n             ClusterState maybeUpdatedState = currentState;\n@@ -250,8 +248,6 @@ public static class ShardRoutingEntry extends TransportRequest {\n         String message;\n         Throwable failure;\n \n-        volatile boolean processed; // state field, no need to serialize\n-\n         public ShardRoutingEntry() {\n         }\n ",
    "output": "Remove obsolete flag in ShardStateAction$ShardRoutingEntry"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n@@ -98,11 +98,7 @@ public RoutingAllocation.Result applyStartedShards(ClusterState clusterState, Li\n     }\n \n     public RoutingAllocation.Result applyFailedShard(ClusterState clusterState, ShardRouting failedShard) {\n-        return applyFailedShard(clusterState, new FailedRerouteAllocation.FailedShard(failedShard, null, null));\n-    }\n-\n-    public RoutingAllocation.Result applyFailedShard(ClusterState clusterState, FailedRerouteAllocation.FailedShard failedShard) {\n-        return applyFailedShards(clusterState, Collections.singletonList(failedShard));\n+        return applyFailedShards(clusterState, Collections.singletonList(new FailedRerouteAllocation.FailedShard(failedShard, null, null)));\n     }\n \n     /**",
    "output": "Remove unnecessary method in AllocationService"
  },
  {
    "input": "diff --git a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n--- a/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n+++ b/elasticsearch/x-pack/src/main/java/org/elasticsearch/xpack/XPackPlugin.java\n@@ -14,7 +14,6 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.http.HttpServerModule;\n import org.elasticsearch.index.IndexModule;\n-import org.elasticsearch.index.IndexService;\n import org.elasticsearch.license.plugin.LicensePlugin;\n import org.elasticsearch.marvel.MarvelPlugin;\n import org.elasticsearch.plugins.Plugin;\n@@ -123,12 +122,6 @@ public void onModule(AuthorizationModule module) {\n         marvelPlugin.onModule(module);\n     }\n \n-    public void onIndexService(IndexService indexService) {\n-        shieldPlugin.onIndexService(indexService);\n-        watcherPlugin.onIndexService(indexService);\n-        marvelPlugin.onIndexService(indexService);\n-    }\n-\n     public void onIndexModule(IndexModule module) {\n         shieldPlugin.onIndexModule(module);\n         watcherPlugin.onIndexModule(module);",
    "output": "Remove leftover use of onIndexService and disable license check"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -90,10 +90,6 @@ public BatchResult<RefreshTask> execute(ClusterState currentState, List<RefreshT\n      * and generate a single cluster change event out of all of those.\n      */\n     ClusterState executeRefresh(final ClusterState currentState, final List<RefreshTask> allTasks) throws Exception {\n-        if (allTasks.isEmpty()) {\n-            return currentState;\n-        }\n-\n         // break down to tasks per index, so we can optimize the on demand index service creation\n         // to only happen for the duration of a single index processing of its respective events\n         Map<String, List<RefreshTask>> tasksPerIndex = new HashMap<>();",
    "output": "Remove unnecessary early-out in MetaDataMappingService#executeRefresh This commit removes a simple early-out check in MetaDataMappingService#executeRefresh. The early-out is unnecessary because the cluster state task execution framework will not invoke ClusterStateTaskExecutor#execute if the list of tasks is empty"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lease/Releasables.java b/core/src/main/java/org/elasticsearch/common/lease/Releasables.java\n--- a/core/src/main/java/org/elasticsearch/common/lease/Releasables.java\n+++ b/core/src/main/java/org/elasticsearch/common/lease/Releasables.java\n@@ -19,8 +19,6 @@\n \n package org.elasticsearch.common.lease;\n \n-import org.elasticsearch.ElasticsearchException;\n-\n import java.util.Arrays;\n \n /** Utility methods to work with {@link Releasable}s. */",
    "output": "Remove unused import in o.e.c.l.Releasables"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/script/Template.java b/core/src/main/java/org/elasticsearch/script/Template.java\n--- a/core/src/main/java/org/elasticsearch/script/Template.java\n+++ b/core/src/main/java/org/elasticsearch/script/Template.java\n@@ -119,12 +119,10 @@ public static Template readTemplate(StreamInput in) throws IOException {\n         return template;\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n     public static Script parse(Map<String, Object> config, boolean removeMatchedEntries, ParseFieldMatcher parseFieldMatcher) {\n         return new TemplateParser(Collections.emptyMap(), MustacheScriptEngineService.NAME).parse(config, removeMatchedEntries, parseFieldMatcher);\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n     public static Template parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException {\n         return new TemplateParser(Collections.emptyMap(), MustacheScriptEngineService.NAME).parse(parser, parseFieldMatcher);\n     }",
    "output": "Remove unchecked warnings rendered unnecessary"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java b/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java\n--- a/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/ShieldPlugin.java\n@@ -192,12 +192,7 @@ public void onIndexModule(IndexModule module) {\n         }\n         if (clientMode == false) {\n             module.registerQueryCache(ShieldPlugin.OPT_OUT_QUERY_CACHE, OptOutQueryCache::new);\n-            module.addIndexEventListener(new IndexEventListener() {\n-                @Override\n-                public void afterIndexCreated(IndexService indexService) {\n-                    failIfShieldQueryCacheIsNotActive(indexService.getIndexSettings().getSettings(), false);\n-                }\n-            });\n+            failIfShieldQueryCacheIsNotActive(module.getSettings(), false);\n         }\n     }\n ",
    "output": "Use IndexModule.getSettings() to get the settings"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -53,7 +53,7 @@ public class MetaDataMappingService extends AbstractComponent {\n     private final ClusterService clusterService;\n     private final IndicesService indicesService;\n \n-    final ClusterStateTaskExecutor<RefreshTask> refreshExectuor = new RefreshTaskExecutor();\n+    final ClusterStateTaskExecutor<RefreshTask> refreshExecutor = new RefreshTaskExecutor();\n     final ClusterStateTaskExecutor<PutMappingClusterStateUpdateRequest> putMappingExecutor = new PutMappingExecutor();\n     private final NodeServicesProvider nodeServicesProvider;\n \n@@ -211,10 +211,10 @@ private boolean processIndexMappingTasks(List<RefreshTask> tasks, IndexService i\n     public void refreshMapping(final String index, final String indexUUID, final String... types) {\n         final RefreshTask refreshTask = new RefreshTask(index, indexUUID, types);\n         clusterService.submitStateUpdateTask(\"refresh-mapping [\" + index + \"][\" + Arrays.toString(types) + \"]\",\n-                refreshTask,\n-                ClusterStateTaskConfig.build(Priority.HIGH),\n-                refreshExectuor,\n-                (source, t) -> logger.warn(\"failure during [{}]\", t, source)\n+            refreshTask,\n+            ClusterStateTaskConfig.build(Priority.HIGH),\n+            refreshExecutor,\n+            (source, t) -> logger.warn(\"failure during [{}]\", t, source)\n         );\n     }\n ",
    "output": "Fix typo in field name in MetaDataMappingService"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -243,8 +243,9 @@ public BatchResult<PutMappingClusterStateUpdateRequest> execute(ClusterState cur\n                                 } else {\n                                     indexService = indicesService.indexService(index);\n                                 }\n-                                // only add the current relevant mapping (if exists)\n-                                if (indexMetaData.getMappings().containsKey(request.type())) {\n+                                // only add the current relevant mapping (if exists and not yet added)\n+                                if (indexMetaData.getMappings().containsKey(request.type()) &&\n+                                        !indexService.mapperService().hasMapping(request.type())) {\n                                     indexService.mapperService().merge(request.type(), indexMetaData.getMappings().get(request.type()).source(), false, request.updateAllTypes());\n                                 }\n                             }",
    "output": "Add each mapping at most once on batch mapping updates When creating an index on master for the purpose of updating mappings, a mapping being updated could needlessly be merged multiple times. This commit ensures that each mapping is merged at most once while preparing to update mappings"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -234,15 +234,15 @@ public BatchResult<PutMappingClusterStateUpdateRequest> execute(ClusterState cur\n                                 final IndexMetaData indexMetaData = currentState.metaData().index(index);\n                                 IndexService indexService;\n                                 if (indicesService.hasIndex(index) == false) {\n-                                    indexService = indicesService.createIndex(nodeServicesProvider, indexMetaData, Collections.EMPTY_LIST);\n                                     indicesToClose.add(index);\n+                                    indexService = indicesService.createIndex(nodeServicesProvider, indexMetaData, Collections.EMPTY_LIST);\n+                                    // make sure to add custom default mapping if exists\n+                                    if (indexMetaData.getMappings().containsKey(MapperService.DEFAULT_MAPPING)) {\n+                                        indexService.mapperService().merge(MapperService.DEFAULT_MAPPING, indexMetaData.getMappings().get(MapperService.DEFAULT_MAPPING).source(), false, request.updateAllTypes());\n+                                    }\n                                 } else {\n                                     indexService = indicesService.indexService(index);\n                                 }\n-                                // make sure to add custom default mapping if exists\n-                                if (indexMetaData.getMappings().containsKey(MapperService.DEFAULT_MAPPING)) {\n-                                    indexService.mapperService().merge(MapperService.DEFAULT_MAPPING, indexMetaData.getMappings().get(MapperService.DEFAULT_MAPPING).source(), false, request.updateAllTypes());\n-                                }\n                                 // only add the current relevant mapping (if exists)\n                                 if (indexMetaData.getMappings().containsKey(request.type())) {\n                                     indexService.mapperService().merge(request.type(), indexMetaData.getMappings().get(request.type()).source(), false, request.updateAllTypes());",
    "output": "Add the default mapping at most once on batch mapping updates When creating an index on master for the purpose of updating mappings, the default mapping could needlessly be added multiple times. This commit ensures that the default mapping is added at most once while preparing to update mappings"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/audit/AuditTrailModuleTests.java b/shield/src/test/java/org/elasticsearch/shield/audit/AuditTrailModuleTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/audit/AuditTrailModuleTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/audit/AuditTrailModuleTests.java\n@@ -8,6 +8,8 @@\n import org.elasticsearch.Version;\n import org.elasticsearch.common.inject.Guice;\n import org.elasticsearch.common.inject.Injector;\n+import org.elasticsearch.common.network.NetworkModule;\n+import org.elasticsearch.common.network.NetworkService;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.settings.SettingsFilter;\n import org.elasticsearch.common.settings.SettingsModule;\n@@ -51,7 +53,15 @@ public void testLogfile() throws Exception {\n                 .build();\n         ThreadPool pool = new ThreadPool(\"testLogFile\");\n         try {\n-            Injector injector = Guice.createInjector(new SettingsModule(settings, new SettingsFilter(settings)), new AuditTrailModule(settings), new TransportModule(settings), new CircuitBreakerModule(settings), new ThreadPoolModule(pool), new Version.Module(Version.CURRENT));\n+            Injector injector = Guice.createInjector(\n+                    new SettingsModule(settings, new SettingsFilter(settings)),\n+                    new AuditTrailModule(settings),\n+                    new TransportModule(settings),\n+                    new CircuitBreakerModule(settings),\n+                    new ThreadPoolModule(pool),\n+                    new Version.Module(Version.CURRENT),\n+                    new NetworkModule(new NetworkService(settings))\n+            );\n             AuditTrail auditTrail = injector.getInstance(AuditTrail.class);\n             assertThat(auditTrail, instanceOf(AuditTrailService.class));\n             AuditTrailService service = (AuditTrailService) auditTrail;",
    "output": "Add dependency on NetworkModule in AuditTrailModuleTests"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/PipelineStore.java b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/PipelineStore.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/PipelineStore.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/PipelineStore.java\n@@ -122,7 +122,7 @@ public Pipeline constructPipeline(String id, Map<String, Object> config) throws\n         return factory.create(id, config, processorFactoryRegistry);\n     }\n \n-    void updatePipelines() throws IOException {\n+    synchronized void updatePipelines() throws IOException {\n         // note: this process isn't fast or smart, but the idea is that there will not be many pipelines,\n         // so for that reason the goal is to keep the update logic simple.\n ",
    "output": "Make updatePipelines() to not make it prone to race conditions"
  },
  {
    "input": "diff --git a/plugins/ingest/src/test/java/org/elasticsearch/ingest/processor/date/DateProcessorFactoryTests.java b/plugins/ingest/src/test/java/org/elasticsearch/ingest/processor/date/DateProcessorFactoryTests.java\n--- a/plugins/ingest/src/test/java/org/elasticsearch/ingest/processor/date/DateProcessorFactoryTests.java\n+++ b/plugins/ingest/src/test/java/org/elasticsearch/ingest/processor/date/DateProcessorFactoryTests.java\n@@ -85,7 +85,7 @@ public void testParseLocale() throws Exception {\n         config.put(\"locale\", locale.toLanguageTag());\n \n         DateProcessor processor = factory.create(config);\n-        assertThat(processor.getLocale(), equalTo(locale));\n+        assertThat(processor.getLocale().toLanguageTag(), equalTo(locale.toLanguageTag()));\n     }\n \n     public void testParseTimezone() throws Exception {",
    "output": "Fix locale comparison"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java b/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n@@ -32,6 +32,7 @@\n import org.elasticsearch.index.shard.IndexShard;\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.index.similarity.SimilarityService;\n+import org.elasticsearch.indices.IndicesModule;\n import org.elasticsearch.indices.IndicesWarmer;\n import org.elasticsearch.search.aggregations.LeafBucketCollector;\n import org.elasticsearch.shield.authz.InternalAuthorizationService;\n@@ -67,7 +68,7 @@ public void before() throws Exception {\n         AnalysisService analysisService = new AnalysisService(indexSettings, Collections.emptyMap(), Collections.emptyMap(),\n                 Collections.emptyMap(), Collections.emptyMap());\n         SimilarityService similarityService = new SimilarityService(indexSettings, Collections.emptyMap());\n-        mapperService = new MapperService(indexSettings, analysisService, similarityService);\n+        mapperService = new MapperService(indexSettings, analysisService, similarityService, new IndicesModule().getMapperRegistry());\n \n         ShardId shardId = new ShardId(index, 0);\n         licenseState = mock(ShieldLicenseState.class);",
    "output": "Fix compilation of ShieldIndexSearcherWrapperUnitTests. The break was introduced in elastic/elasticsearchelastic/elasticsearch#14896"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java\n@@ -188,7 +188,6 @@ public GroupShardsIterator allAssignedShardsGrouped(String[] indices, boolean in\n     private static Predicate<ShardRouting> ACTIVE_PREDICATE = shardRouting -> shardRouting.active();\n     private static Predicate<ShardRouting> ASSIGNED_PREDICATE = shardRouting -> shardRouting.assignedToNode();\n \n-    // TODO: replace with JDK 8 native java.util.function.Predicate\n     private GroupShardsIterator allSatisfyingPredicateShardsGrouped(String[] indices, boolean includeEmpty, boolean includeRelocationTargets, Predicate<ShardRouting> predicate) {\n         // use list here since we need to maintain identity across shards\n         ArrayList<ShardIterator> set = new ArrayList<>();\n@@ -222,7 +221,6 @@ public ShardsIterator allShardsIncludingRelocationTargets(String[] indices) {\n         return allShardsSatisfyingPredicate(indices, shardRouting -> true, true);\n     }\n \n-    // TODO: replace with JDK 8 native java.util.function.Predicate\n     private ShardsIterator allShardsSatisfyingPredicate(String[] indices, Predicate<ShardRouting> predicate, boolean includeRelocationTargets) {\n         // use list here since we need to maintain identity across shards\n         List<ShardRouting> shards = new ArrayList<>();",
    "output": "Remove leftover TODOs in o.e.c.r.RoutingTable"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java b/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/ShardStateMetaData.java\n@@ -46,7 +46,7 @@ public final class ShardStateMetaData {\n     public final String indexUUID;\n     public final boolean primary;\n     @Nullable\n-    public final AllocationId allocationId; // can be null if we read from legacy format (see fromXContent)\n+    public final AllocationId allocationId; // can be null if we read from legacy format (see fromXContent and MultiDataPathUpgrader)\n \n     public ShardStateMetaData(long version, boolean primary, String indexUUID, AllocationId allocationId) {\n         assert indexUUID != null;\n@@ -111,7 +111,9 @@ public void toXContent(XContentBuilder builder, ShardStateMetaData shardStateMet\n             builder.field(VERSION_KEY, shardStateMetaData.version);\n             builder.field(PRIMARY_KEY, shardStateMetaData.primary);\n             builder.field(INDEX_UUID_KEY, shardStateMetaData.indexUUID);\n-            builder.field(ALLOCATION_ID_KEY, shardStateMetaData.allocationId);\n+            if (shardStateMetaData.allocationId != null) {\n+                builder.field(ALLOCATION_ID_KEY, shardStateMetaData.allocationId);\n+            }\n         }\n \n         @Override",
    "output": "Fix issue where shard state metadata is written while containing no allocation id Such a write can happen when upgrading shard state metadata using the MultiDataPathUpgrader Relates to"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java b/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java\n--- a/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java\n@@ -413,8 +413,7 @@ public boolean equals(Object o) {\n \n                 Value that = (Value) o;\n \n-                return value == that.value;\n-\n+                return value.equals(that.value);\n             }\n \n             @Override",
    "output": "Use correct equality in CacheTests#testReplaceRecomputesSize.Value"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java\n@@ -146,7 +146,7 @@ private void assertLegacyQuery(GeoDistanceRangeQueryBuilder queryBuilder, Query\n             }\n             double fromSlop = Math.abs(fromValue) / 1000;\n             if (queryBuilder.includeLower() == false) {\n-                fromSlop = NumericUtils.sortableLongToDouble((NumericUtils.doubleToSortableLong(fromValue) + 1L));\n+                fromSlop = NumericUtils.sortableLongToDouble((NumericUtils.doubleToSortableLong(Math.abs(fromValue)) + 1L)) / 1000.0;\n             }\n             assertThat(geoQuery.minInclusiveDistance(), closeTo(fromValue, fromSlop));\n         }\n@@ -160,7 +160,7 @@ private void assertLegacyQuery(GeoDistanceRangeQueryBuilder queryBuilder, Query\n             }\n             double toSlop = Math.abs(toValue) / 1000;\n             if (queryBuilder.includeUpper() == false) {\n-                toSlop = NumericUtils.sortableLongToDouble((NumericUtils.doubleToSortableLong(toValue) + 1L));\n+                toSlop = NumericUtils.sortableLongToDouble((NumericUtils.doubleToSortableLong(Math.abs(toValue)) - 1L)) / 1000.0;\n             }\n             assertThat(geoQuery.maxInclusiveDistance(), closeTo(toValue, toSlop));\n         }",
    "output": "Fix assertion precision for legacy GeoDistanceRangeQuery tests This bug existed for GeoDistanceRangeQuery exclusion limits only (e.g., min/max included == false)"
  },
  {
    "input": "diff --git a/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/PhoneticTokenFilterFactory.java b/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/PhoneticTokenFilterFactory.java\n--- a/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/PhoneticTokenFilterFactory.java\n+++ b/plugins/analysis-phonetic/src/main/java/org/elasticsearch/index/analysis/PhoneticTokenFilterFactory.java\n@@ -30,7 +30,6 @@\n import org.apache.lucene.analysis.phonetic.DoubleMetaphoneFilter;\n import org.apache.lucene.analysis.phonetic.PhoneticFilter;\n import org.elasticsearch.common.inject.Inject;\n-import org.elasticsearch.common.inject.assistedinject.Assisted;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.env.Environment;\n import org.elasticsearch.index.IndexSettings;\n@@ -105,6 +104,8 @@ public PhoneticTokenFilterFactory(IndexSettings indexSettings, Environment envir\n             this.encoder = new HaasePhonetik();\n         } else if (\"nysiis\".equalsIgnoreCase(encodername)) {\n             this.encoder = new Nysiis();\n+        } else if (\"daitch_mokotoff\".equalsIgnoreCase(encodername)) {\n+            this.encoder = new DaitchMokotoffSoundex();\n         } else {\n             throw new IllegalArgumentException(\"unknown encoder [\" + encodername + \"] for phonetic token filter\");\n         }",
    "output": "Add support for `daitch_mokotoff` [Daitch Mokotoff](https://en.wikipedia.org/wiki/Daitch%E2%80%93Mokotoff_Soundex) support has been added in Lucene 5. So we can now support it as well"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Build.java b/core/src/main/java/org/elasticsearch/Build.java\n--- a/core/src/main/java/org/elasticsearch/Build.java\n+++ b/core/src/main/java/org/elasticsearch/Build.java\n@@ -33,9 +33,13 @@\n import java.util.jar.Manifest;\n \n /**\n+ * Information about a build of Elasticsearch.\n  */\n public class Build {\n-\n+    /**\n+     * The current build of Elasticsearch. Filled with information scanned at\n+     * startup from the jar.\n+     */\n     public static final Build CURRENT;\n \n     static {\n@@ -56,6 +60,14 @@ public class Build {\n             shortHash = \"Unknown\";\n             date = \"Unknown\";\n         }\n+        if (shortHash == null) {\n+            throw new IllegalStateException(\"Error finding the build shortHash. \" +\n+                \"Stopping Elasticsearch now so it doesn't run in subtly broken ways. This is likely a build bug.\");\n+        }\n+        if (date == null) {\n+            throw new IllegalStateException(\"Error finding the build date. \" +\n+                \"Stopping Elasticsearch now so it doesn't run in subtly broken ways. This is likely a build bug.\");\n+        }\n \n         CURRENT = new Build(shortHash, date);\n     }",
    "output": "Make Build work without git"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Build.java b/core/src/main/java/org/elasticsearch/Build.java\n--- a/core/src/main/java/org/elasticsearch/Build.java\n+++ b/core/src/main/java/org/elasticsearch/Build.java\n@@ -33,9 +33,13 @@\n import java.util.jar.Manifest;\n \n /**\n+ * Information about a build of Elasticsearch.\n  */\n public class Build {\n-\n+    /**\n+     * The current build of Elasticsearch. Filled with information scanned at\n+     * startup from the jar.\n+     */\n     public static final Build CURRENT;\n \n     static {\n@@ -56,6 +60,14 @@ public class Build {\n             shortHash = \"Unknown\";\n             date = \"Unknown\";\n         }\n+        if (shortHash == null) {\n+            throw new IllegalStateException(\"Error finding the build shortHash. \" +\n+                \"Stopping Elasticsearch now so it doesn't run in subtly broken ways. This is likely a build bug.\");\n+        }\n+        if (date == null) {\n+            throw new IllegalStateException(\"Error finding the build date. \" +\n+                \"Stopping Elasticsearch now so it doesn't run in subtly broken ways. This is likely a build bug.\");\n+        }\n \n         CURRENT = new Build(shortHash, date);\n     }",
    "output": "Make Build work without git If you build elasticsearch without a git repository it was creating a null shortHash which was causing Elasticsearch not to be able to form transport connections"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIT.java b/core/src/test/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIT.java\n--- a/core/src/test/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIT.java\n+++ b/core/src/test/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIT.java\n@@ -171,7 +171,7 @@ public void testAllocatedProcessors() throws Exception {\n         assertThat(response.getNodesStats().getOs().getAllocatedProcessors(), equalTo(7));\n     }\n \n-    public void testClusterStatus() throws Exception {\n+    public void testClusterStatusWhenStateNotRecovered() throws Exception {\n         // stop all other nodes\n         internalCluster().ensureAtMostNumDataNodes(0);\n \n@@ -180,6 +180,8 @@ public void testClusterStatus() throws Exception {\n         assertThat(response.getStatus(), equalTo(ClusterHealthStatus.RED));\n \n         internalCluster().ensureAtLeastNumDataNodes(3);\n+        // wait for the cluster status to settle\n+        ensureGreen();\n         response = client().admin().cluster().prepareClusterStats().get();\n         assertThat(response.getStatus(), equalTo(ClusterHealthStatus.GREEN));\n     }",
    "output": "Fix race in ClusterStatsIT ClusterStatsIT#testClusterStatus() contained a race where the test cluster might still be initializing while test already checks for a green health status. With this commit the test waits until the cluster status changed and checks health afterwards. Checked with @bleskes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java b/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java\n--- a/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java\n+++ b/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java\n@@ -172,6 +172,16 @@ public boolean matches() throws IOException {\n                         }\n                         return false;\n                     }\n+\n+                    @Override\n+                    public float matchCost() {\n+                        if (distanceBoundingCheck == GeoDistance.ALWAYS_INSTANCE) {\n+                            return 0.0f;\n+                        } else {\n+                            // TODO: is this right (up to 4 comparisons from GeoDistance.SimpleDistanceBoundingCheck)?\n+                            return 4.0f;\n+                        }\n+                    }\n                 };\n                 return new ConstantScoreScorer(this, score(), twoPhaseIterator);\n             }",
    "output": "Upgrade Lucene to 5.4.0-snapshot-1714615"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java\n@@ -44,14 +44,14 @@ public class GeoDistanceRangeQueryTests extends AbstractQueryTestCase<GeoDistanc\n     protected GeoDistanceRangeQueryBuilder doCreateTestQueryBuilder() {\n         Version version = queryShardContext().indexVersionCreated();\n         GeoDistanceRangeQueryBuilder builder;\n+        GeoPoint randomPoint = RandomGeoGenerator.randomPointIn(random(), -180.0, -89.9, 180.0, 89.9);\n         if (randomBoolean()) {\n-            builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME, randomGeohash(3, 12));\n+            builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME, randomPoint.geohash());\n         } else {\n-            GeoPoint point = RandomGeoGenerator.randomPoint(random());\n             if (randomBoolean()) {\n-                builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME, point);\n+                builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME, randomPoint);\n             } else {\n-                builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME, point.lat(), point.lon());\n+                builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME, randomPoint.lat(), randomPoint.lon());\n             }\n         }\n         GeoPoint point = builder.point();",
    "output": "Fix reproducible GeoDistanceRangeQueryTests.testToQuery error This issue occurs if the center latitude of the GeoPointDistance query is set to one of the poles. Since this issue is set to be fixed in LUCENE-6897 this commit temporarily limits the random latitudinal location to not include the poles"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java b/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n@@ -34,10 +34,6 @@\n  */\n public class IndexStoreConfig implements NodeSettingsService.Listener {\n \n-    /** \"Effectively\" infinite (20 GB/sec) default value, because store throttling is disabled by default since\n-     *  we use Lucene's auto-IO throttling instead. */ \n-    private static final ByteSizeValue DEFAULT_THROTTLE = new ByteSizeValue(10240, ByteSizeUnit.MB);\n-\n     /**\n      * Configures the node / cluster level throttle type. See {@link StoreRateLimiting.Type}.\n      */\n@@ -55,7 +51,7 @@ public IndexStoreConfig(Settings settings) {\n         // we don't limit by default (we default to CMS's auto throttle instead):\n         this.rateLimitingType = settings.get(\"indices.store.throttle.type\", StoreRateLimiting.Type.NONE.name());\n         rateLimiting.setType(rateLimitingType);\n-        this.rateLimitingThrottle = settings.getAsBytesSize(\"indices.store.throttle.max_bytes_per_sec\", DEFAULT_THROTTLE);\n+        this.rateLimitingThrottle = settings.getAsBytesSize(\"indices.store.throttle.max_bytes_per_sec\", new ByteSizeValue(0));\n         rateLimiting.setMaxRate(rateLimitingThrottle);\n         logger.debug(\"using indices.store.throttle.type [{}], with index.store.throttle.max_bytes_per_sec [{}]\", rateLimitingType, rateLimitingThrottle);\n     }",
    "output": "Remove confusing private default constant"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java b/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/store/IndexStoreConfig.java\n@@ -32,10 +32,12 @@\n  * {@value #INDICES_STORE_THROTTLE_TYPE} or {@value #INDICES_STORE_THROTTLE_MAX_BYTES_PER_SEC} are reflected immediately\n  * on all referencing {@link IndexStore} instances\n  */\n-public class IndexStoreConfig implements NodeSettingsService.Listener{\n-\n+public class IndexStoreConfig implements NodeSettingsService.Listener {\n \n+    /** \"Effectively\" infinite (20 GB/sec) default value, because store throttling is disabled by default since\n+     *  we use Lucene's auto-IO throttling instead. */ \n     private static final ByteSizeValue DEFAULT_THROTTLE = new ByteSizeValue(10240, ByteSizeUnit.MB);\n+\n     /**\n      * Configures the node / cluster level throttle type. See {@link StoreRateLimiting.Type}.\n      */",
    "output": "Add comment about confusing constant value"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java b/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java\n--- a/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java\n+++ b/core/src/main/java/org/elasticsearch/index/search/geo/GeoDistanceRangeQuery.java\n@@ -172,6 +172,16 @@ public boolean matches() throws IOException {\n                         }\n                         return false;\n                     }\n+\n+                    @Override\n+                    public float matchCost() {\n+                        if (distanceBoundingCheck == GeoDistance.ALWAYS_INSTANCE) {\n+                            return 0.0f;\n+                        } else {\n+                            // TODO: is this right (up to 4 comparisons from GeoDistance.SimpleDistanceBoundingCheck)?\n+                            return 4.0f;\n+                        }\n+                    }\n                 };\n                 return new ConstantScoreScorer(this, score(), twoPhaseIterator);\n             }",
    "output": "Upgrade lucene 5.4 snapshot"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java\n--- a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java\n@@ -22,6 +22,7 @@\n import com.carrotsearch.randomizedtesting.generators.CodepointSetGenerator;\n import com.fasterxml.jackson.core.JsonParseException;\n import com.fasterxml.jackson.core.io.JsonStringEncoder;\n+\n import org.apache.lucene.search.BoostQuery;\n import org.apache.lucene.search.Query;\n import org.apache.lucene.search.TermQuery;\n@@ -128,6 +129,7 @@ public abstract class AbstractQueryTestCase<QB extends AbstractQueryBuilder<QB>>\n     private static IndicesQueriesRegistry indicesQueriesRegistry;\n     private static QueryShardContext queryShardContext;\n     private static IndexFieldDataService indexFieldDataService;\n+    private static int queryNameId = 0;\n \n \n     protected static QueryShardContext queryShardContext() {\n@@ -316,12 +318,21 @@ protected final QB createTestQueryBuilder() {\n                 query.boost(2.0f / randomIntBetween(1, 20));\n             }\n             if (randomBoolean()) {\n-                query.queryName(randomAsciiOfLengthBetween(1, 10));\n+                query.queryName(createUniqueRandomName());\n             }\n         }\n         return query;\n     }\n \n+    /**\n+     * make sure query names are unique by suffixing them with increasing counter\n+     */\n+    private static String createUniqueRandomName() {\n+        String queryName = randomAsciiOfLengthBetween(1, 10) + queryNameId;\n+        queryNameId++;\n+        return queryName;\n+    }\n+\n     /**\n      * Create the query that is being tested\n      */",
    "output": "Add unique id to query names to avoid naming conflicts"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n@@ -39,7 +39,6 @@\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.util.CancellableThreads;\n import org.elasticsearch.common.util.CancellableThreads.Interruptable;\n-import org.elasticsearch.index.engine.Engine;\n import org.elasticsearch.index.engine.RecoveryEngineException;\n import org.elasticsearch.index.shard.*;\n import org.elasticsearch.index.store.Store;",
    "output": "Remove unused import in RecoverySourceHandler"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/Processor.java b/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/Processor.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/Processor.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/Processor.java\n@@ -59,11 +59,8 @@ interface Factory<P extends Processor> extends Closeable {\n         default void setConfigDirectory(Path configDirectory) {\n         }\n \n-\n         @Override\n         default void close() throws IOException {\n         }\n-        \n     }\n-\n }",
    "output": "Remove unnecessary line breaks"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/mutate/MutateProcessor.java b/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/mutate/MutateProcessor.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/mutate/MutateProcessor.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/ingest/processor/mutate/MutateProcessor.java\n@@ -277,28 +277,6 @@ private void doLowercase(Data data) {\n         }\n     }\n \n-    @Override\n-    public boolean equals(Object o) {\n-        if (this == o) return true;\n-        if (o == null || getClass() != o.getClass()) return false;\n-        MutateProcessor that = (MutateProcessor) o;\n-        return Objects.equals(update, that.update) &&\n-                Objects.equals(rename, that.rename) &&\n-                Objects.equals(convert, that.convert) &&\n-                Objects.equals(split, that.split) &&\n-                Objects.equals(gsub, that.gsub) &&\n-                Objects.equals(join, that.join) &&\n-                Objects.equals(remove, that.remove) &&\n-                Objects.equals(trim, that.trim) &&\n-                Objects.equals(uppercase, that.uppercase) &&\n-                Objects.equals(lowercase, that.lowercase);\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return Objects.hash(update, rename, convert, split, gsub, join, remove, trim, uppercase, lowercase);\n-    }\n-\n     public static final class Factory implements Processor.Factory<MutateProcessor> {\n         @Override\n         public MutateProcessor create(Map<String, Object> config) throws IOException {",
    "output": "Remove leftover equals/hashcode"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java b/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java\n@@ -89,7 +89,7 @@ public int hashCode() {\n     public final static class Factory {\n \n         public Pipeline create(String id, Map<String, Object> config, Map<String, Processor.Factory> processorRegistry) throws IOException {\n-            String description = ConfigurationUtils.readStringProperty(config, \"description\");\n+            String description = ConfigurationUtils.readOptionalStringProperty(config, \"description\");\n             List<Processor> processors = new ArrayList<>();\n             @SuppressWarnings(\"unchecked\")\n             List<Map<String, Map<String, Object>>> processorConfigs = (List<Map<String, Map<String, Object>>>) config.get(\"processors\");",
    "output": "Make description optional as part of a Pipeline"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java b/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/ingest/Pipeline.java\n@@ -20,6 +20,7 @@\n \n package org.elasticsearch.ingest;\n \n+import org.elasticsearch.ingest.processor.ConfigurationUtils;\n import org.elasticsearch.ingest.processor.Processor;\n \n import java.io.IOException;\n@@ -73,7 +74,7 @@ public List<Processor> getProcessors() {\n     public final static class Factory {\n \n         public Pipeline create(String id, Map<String, Object> config, Map<String, Processor.Factory> processorRegistry) throws IOException {\n-            String description = (String) config.get(\"description\");\n+            String description = ConfigurationUtils.readStringProperty(config, \"description\");\n             List<Processor> processors = new ArrayList<>();\n             @SuppressWarnings(\"unchecked\")\n             List<Map<String, Map<String, Object>>> processorConfigs = (List<Map<String, Map<String, Object>>>) config.get(\"processors\");",
    "output": "Use ConfigurationUtils to read string value from config"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java b/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/action/shard/ShardStateActionTests.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.cluster.action.shard;\n \n import org.apache.lucene.index.CorruptIndexException;\n-import org.elasticsearch.action.search.TransportSearchAction;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n import org.elasticsearch.cluster.node.DiscoveryNodes;\n@@ -44,7 +43,6 @@\n \n import static org.elasticsearch.action.support.replication.ClusterStateCreationUtils.stateWithStartedPrimary;\n import static org.hamcrest.CoreMatchers.equalTo;\n-import static org.junit.Assert.*;\n \n public class ShardStateActionTests extends ESTestCase {\n     private static ThreadPool THREAD_POOL;",
    "output": "Remove unused imports in o.e.c.a.s.ShardStateActionTests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java b/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n--- a/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n@@ -310,7 +310,7 @@ public void testRequestsAreNotSentToFailedMaster() {\n         ShardsIterator shardIt = clusterService.state().routingTable().allShards(new String[]{TEST_INDEX});\n         Set<String> set = new HashSet<>();\n         for (ShardRouting shard : shardIt.asUnordered()) {\n-            if (shard.currentNodeId() != masterNode.id()) {\n+            if (!shard.currentNodeId().equals(masterNode.id())) {\n                 set.add(shard.currentNodeId());\n             }\n         }",
    "output": "Use String#equals instead of reference equality"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java b/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n--- a/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n@@ -23,7 +23,6 @@\n import org.elasticsearch.Version;\n import org.elasticsearch.action.IndicesRequest;\n import org.elasticsearch.action.ShardOperationFailedException;\n-import org.elasticsearch.action.support.ActionFilter;\n import org.elasticsearch.action.support.ActionFilters;\n import org.elasticsearch.action.support.PlainActionFuture;\n import org.elasticsearch.action.support.broadcast.BroadcastRequest;\n@@ -190,7 +189,7 @@ public void setUp() throws Exception {\n         action = new TestTransportBroadcastByNodeAction(\n                 Settings.EMPTY,\n                 transportService,\n-                new ActionFilters(new HashSet<ActionFilter>()),\n+                new ActionFilters(new HashSet<>()),\n                 new MyResolver(),\n                 Request::new,\n                 ThreadPool.Names.SAME\n@@ -398,7 +397,7 @@ public void testResultAggregation() throws ExecutionException, InterruptedExcept\n         Map<String, List<ShardRouting>> map = new HashMap<>();\n         for (ShardRouting shard : shardIt.asUnordered()) {\n             if (!map.containsKey(shard.currentNodeId())) {\n-                map.put(shard.currentNodeId(), new ArrayList<ShardRouting>());\n+                map.put(shard.currentNodeId(), new ArrayList<>());\n             }\n             map.get(shard.currentNodeId()).add(shard);\n         }",
    "output": "Remove unnecessary generic type parameters"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/recovery/FullRollingRestartIT.java b/core/src/test/java/org/elasticsearch/recovery/FullRollingRestartIT.java\n--- a/core/src/test/java/org/elasticsearch/recovery/FullRollingRestartIT.java\n+++ b/core/src/test/java/org/elasticsearch/recovery/FullRollingRestartIT.java\n@@ -134,7 +134,7 @@ public void testFullRollingRestart() throws Exception {\n     public void testNoRebalanceOnRollingRestart() throws Exception {\n         // see https://github.com/elastic/elasticsearch/issues/14387\n         internalCluster().startMasterOnlyNode(Settings.EMPTY);\n-        internalCluster().startNodesAsync(3, Settings.builder().put(\"node.master\", false).build()).get();\n+        internalCluster().startDataOnlyNodesAsync(3).get();\n         /**\n          * We start 3 nodes and a dedicated master. Restart on of the data-nodes and ensure that we got no relocations.\n          * Yet we have 6 shards 0 replica so that means if the restarting node comes back both other nodes are subject",
    "output": "Use syntactic sugar for starting data only nodes"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java\n@@ -677,6 +677,7 @@ public boolean allocateUnassigned(RoutingAllocation allocation) {\n         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())\n                 .put(newNode(\"node2\")))\n                 .build();\n+        logger.debug(\"reroute and check that nothing has changed\");\n         RoutingAllocation.Result reroute = strategy.reroute(clusterState);\n         assertFalse(reroute.changed());\n         routingTable = reroute.routingTable();\n@@ -690,7 +691,7 @@ public boolean allocateUnassigned(RoutingAllocation allocation) {\n             assertThat(routingTable.index(\"test1\").shard(i).shards().size(), equalTo(1));\n             assertThat(routingTable.index(\"test1\").shard(i).primaryShard().state(), equalTo(UNASSIGNED));\n         }\n-\n+        logger.debug(\"now set hasFetches to true and reroute we should now see exactly one relocating shard\");\n         hasFetches.set(false);\n         reroute = strategy.reroute(clusterState);\n         assertTrue(reroute.changed());",
    "output": "Add more logging to test for better readability"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java b/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java\n--- a/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java\n+++ b/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java\n@@ -21,15 +21,10 @@\n \n import org.apache.lucene.document.Field;\n import org.apache.lucene.index.IndexOptions;\n-import org.apache.tika.Tika;\n-import org.apache.tika.exception.TikaException;\n import org.apache.tika.language.LanguageIdentifier;\n import org.apache.tika.metadata.Metadata;\n-import org.apache.tika.parser.Parser;\n-import org.elasticsearch.SpecialPermission;\n import org.elasticsearch.Version;\n import org.elasticsearch.common.collect.Iterators;\n-import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.logging.ESLoggerFactory;\n import org.elasticsearch.common.settings.Settings;\n@@ -38,9 +33,6 @@\n import org.elasticsearch.index.mapper.*;\n \n import java.io.IOException;\n-import java.security.AccessController;\n-import java.security.PrivilegedActionException;\n-import java.security.PrivilegedExceptionAction;\n import java.util.*;\n \n import static org.elasticsearch.index.mapper.MapperBuilders.*;",
    "output": "Remove unused imports"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java b/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java\n--- a/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java\n+++ b/src/main/java/org/elasticsearch/mapper/attachments/AttachmentMapper.java\n@@ -486,10 +486,6 @@ public Mapper parse(ParseContext context) throws IOException {\n         try {\n             parsedContent = parseWithTika(content, metadata, indexedChars);\n         } catch (Throwable e) {\n-            // unbox checked exception\n-            if (e instanceof PrivilegedActionException) {\n-              e = e.getCause();\n-            }\n             // #18: we could ignore errors when Tika does not parse data\n             if (!ignoreErrors) {\n                 logger.trace(\"exception caught\", e);",
    "output": "Remove unnecessary unboxing, we do that as impl detail in parseTika"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java\n@@ -81,6 +81,7 @@\n import org.elasticsearch.test.DummyShardLock;\n import org.elasticsearch.test.ESSingleNodeTestCase;\n import org.elasticsearch.test.VersionUtils;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n \n import java.io.IOException;\n import java.nio.file.Files;\n@@ -329,6 +330,7 @@ public void testIndexShardCounter() throws InterruptedException, ExecutionExcept\n         assertEquals(0, indexShard.getOperationsCount());\n     }\n \n+    @TestLogging(\"indices.flush:TRACE,index.shard:TRACE,index.engine:TRACE\")\n     public void testMarkAsInactiveTriggersSyncedFlush() throws Exception {\n         assertAcked(client().admin().indices().prepareCreate(\"test\")\n                 .setSettings(SETTING_NUMBER_OF_SHARDS, 1, SETTING_NUMBER_OF_REPLICAS, 0, IndexShard.INDEX_SHARD_INACTIVE_TIME_SETTING, \"0s\"));",
    "output": "Use TRACE Logging for syncFlush tests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java b/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java\n@@ -25,6 +25,7 @@\n import java.security.CodeSource;\n import java.security.Permission;\n import java.security.PermissionCollection;\n+import java.security.Permissions;\n import java.security.Policy;\n import java.security.ProtectionDomain;\n import java.util.Map;\n@@ -89,6 +90,21 @@ public boolean implies(ProtectionDomain domain, Permission permission) {\n         return template.implies(domain, permission) || dynamic.implies(permission);\n     }\n \n+    @Override\n+    public PermissionCollection getPermissions(CodeSource codesource) {\n+        // code should not rely on this method, or at least use it correctly:\n+        // https://bugs.openjdk.java.net/browse/JDK-8014008\n+        // return them a new empty permissions object so jvisualvm etc work\n+        for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n+            if (\"sun.rmi.server.LoaderHandler\".equals(element.getClassName()) &&\n+                    \"loadClass\".equals(element.getMethodName())) {\n+                return new Permissions();\n+            }\n+        }\n+        // return UNSUPPORTED_EMPTY_COLLECTION since it is safe.\n+        return super.getPermissions(codesource);\n+    }\n+\n     /**\n      * Classy puzzler to rethrow any checked exception as an unchecked one.\n      */",
    "output": "Add workaround for JDK-8014008"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java\n--- a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java\n+++ b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java\n@@ -398,8 +398,9 @@ protected Boolean checkIdle(ShardId shardId) {\n                     logger.debug(\"marking shard {} as inactive (inactive_time[{}]) indexing wise\",\n                             shardId,\n                             shard.getInactiveTime());\n+                    return Boolean.TRUE;\n                 }\n-                return Boolean.TRUE;\n+                return Boolean.FALSE;\n             } catch (EngineClosedException e) {\n                 // ignore\n                 ignoreReason = \"EngineClosedException\";",
    "output": "Fix return value"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/integration/DocumentLevelSecurityTests.java b/shield/src/test/java/org/elasticsearch/integration/DocumentLevelSecurityTests.java\n--- a/shield/src/test/java/org/elasticsearch/integration/DocumentLevelSecurityTests.java\n+++ b/shield/src/test/java/org/elasticsearch/integration/DocumentLevelSecurityTests.java\n@@ -5,13 +5,11 @@\n  */\n package org.elasticsearch.integration;\n \n-import org.apache.lucene.search.TermQuery;\n import org.elasticsearch.action.get.GetResponse;\n import org.elasticsearch.action.get.MultiGetResponse;\n import org.elasticsearch.action.percolate.PercolateResponse;\n import org.elasticsearch.action.percolate.PercolateSourceBuilder;\n import org.elasticsearch.action.search.SearchResponse;\n-import org.elasticsearch.action.support.QuerySourceBuilder;\n import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;\n import org.elasticsearch.action.termvectors.TermVectorsRequest;\n import org.elasticsearch.action.termvectors.TermVectorsResponse;",
    "output": "Fix compile error by removing unused imports"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/collect/Iterators.java b/core/src/main/java/org/elasticsearch/common/collect/Iterators.java\n--- a/core/src/main/java/org/elasticsearch/common/collect/Iterators.java\n+++ b/core/src/main/java/org/elasticsearch/common/collect/Iterators.java\n@@ -28,7 +28,8 @@ public static <T> Iterator<T> concat(Iterator<? extends T>... iterators) {\n             throw new NullPointerException(\"iterators\");\n         }\n \n-        return new ConcatenatedIterator<>(iterators);\n+        // explicit generic type argument needed for type inference\n+        return new ConcatenatedIterator<T>(iterators);\n     }\n \n     static class ConcatenatedIterator<T> implements Iterator<T> {",
    "output": "Fix Java 9 type inference issue"
  },
  {
    "input": "diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n@@ -64,6 +64,8 @@ public void testEvilGroovyScripts() throws Exception {\n         assertSuccess(\"def range = 1..doc['foo'].value; def v = range.get(0)\");\n         // Maps\n         assertSuccess(\"def v = doc['foo'].value; def m = [:]; m.put(\\\"value\\\", v)\");\n+        // serialization to json (this is best effort considering the unsafe etc at play)\n+        assertSuccess(\"def x = 5; groovy.json.JsonOutput.toJson(x)\");\n         // Times\n         assertSuccess(\"def t = Instant.now().getMillis()\");\n         // GroovyCollections",
    "output": "Add property permissions so groovy scripts can serialize json"
  },
  {
    "input": "diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/script/groovy/GroovySecurityTests.java\n@@ -64,6 +64,8 @@ public void testEvilGroovyScripts() throws Exception {\n         assertSuccess(\"def range = 1..doc['foo'].value; def v = range.get(0)\");\n         // Maps\n         assertSuccess(\"def v = doc['foo'].value; def m = [:]; m.put(\\\"value\\\", v)\");\n+        // serialization to json (this is best effort considering the unsafe etc at play)\n+        assertSuccess(\"def x = 5; groovy.json.JsonOutput.toJson(x)\");\n         // Times\n         assertSuccess(\"def t = Instant.now().getMillis()\");\n         // GroovyCollections",
    "output": "Add property permissions so groovy scripts can serialize json Allowing read to these properties is not really dangerous, even if the code surrounding them is"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/collect/Iterators.java b/core/src/main/java/org/elasticsearch/common/collect/Iterators.java\n--- a/core/src/main/java/org/elasticsearch/common/collect/Iterators.java\n+++ b/core/src/main/java/org/elasticsearch/common/collect/Iterators.java\n@@ -28,7 +28,8 @@ public static <T> Iterator<T> concat(Iterator<? extends T>... iterators) {\n             throw new NullPointerException(\"iterators\");\n         }\n \n-        return new ConcatenatedIterator<>(iterators);\n+        // explicit generic type argument needed for type inference\n+        return new ConcatenatedIterator<T>(iterators);\n     }\n \n     static class ConcatenatedIterator<T> implements Iterator<T> {",
    "output": "Fix Java 9 type inference issue This commit fixes a compilation issue due to modified type inference in the latest JDK 9 early access builds. We just have to lend a helping hand to type inference by being explicit about the type"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/http/HttpServer.java b/core/src/main/java/org/elasticsearch/http/HttpServer.java\n--- a/core/src/main/java/org/elasticsearch/http/HttpServer.java\n+++ b/core/src/main/java/org/elasticsearch/http/HttpServer.java\n@@ -189,7 +189,7 @@ void handlePluginSite(HttpRequest request, HttpChannel channel) throws IOExcepti\n             sitePath = null;\n             // If a trailing / is missing, we redirect to the right page #2654\n             String redirectUrl = request.rawPath() + \"/\";\n-            BytesRestResponse restResponse = new BytesRestResponse(RestStatus.MOVED_PERMANENTLY, \"text/html\", \"<head><meta http-equiv=\\\"refresh\\\" content=\\\"0; URL=\" + redirectUrl + \"></head>\");\n+            BytesRestResponse restResponse = new BytesRestResponse(RestStatus.MOVED_PERMANENTLY, \"text/html\", \"<head><meta http-equiv=\\\"refresh\\\" content=\\\"0; URL=\" + redirectUrl + \"\\\"></head>\");\n             restResponse.addHeader(\"Location\", redirectUrl);\n             channel.sendResponse(restResponse);\n             return;",
    "output": "Fix HTML response during redirection It misses a quote"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestThreadPoolAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestThreadPoolAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestThreadPoolAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestThreadPoolAction.java\n@@ -288,7 +288,7 @@ private Table buildTable(RestRequest req, ClusterStateResponse state, NodesInfoR\n                     }\n                 }\n \n-                table.addCell(poolInfo == null  ? null : poolInfo.getThreadPoolType());\n+                table.addCell(poolInfo == null  ? null : poolInfo.getThreadPoolType().getType());\n                 table.addCell(poolStats == null ? null : poolStats.getActive());\n                 table.addCell(poolStats == null ? null : poolStats.getThreads());\n                 table.addCell(poolStats == null ? null : poolStats.getQueue());",
    "output": "Fix bug in cat thread pool This commit fixes a bug in cat thread pool. This bug resulted from a refactoring of the handling of thread pool types. To get the previously displayed thread pool type from the ThreadPoolType object, ThreadPoolType#getType needs to be called"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java b/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java\n--- a/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java\n+++ b/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java\n@@ -49,7 +49,13 @@ public void testCorrectThreadPoolTypePermittedInSettings() throws InterruptedExc\n                     .put(\"name\", \"testCorrectThreadPoolTypePermittedInSettings\")\n                     .put(\"threadpool.\" + threadPoolName + \".type\", correctThreadPoolType.getType())\n                     .build());\n-            assertEquals(info(threadPool, threadPoolName).getThreadPoolType(), correctThreadPoolType);\n+            ThreadPool.Info info = info(threadPool, threadPoolName);\n+            if (ThreadPool.Names.SAME.equals(threadPoolName)) {\n+                assertNull(info); // we don't report on the \"same\" threadpool\n+            } else {\n+                // otherwise check we have the expected type\n+                assertEquals(info.getThreadPoolType(), correctThreadPoolType);\n+            }\n         } finally {\n             terminateThreadPoolIfNeeded(threadPool);\n         }",
    "output": "Fix test bug in UpdateThreadPoolSettingsTests"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/rest/IngestRestFilter.java b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/rest/IngestRestFilter.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/rest/IngestRestFilter.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/rest/IngestRestFilter.java\n@@ -34,7 +34,9 @@ public IngestRestFilter(RestController controller) {\n \n     @Override\n     public void process(RestRequest request, RestChannel channel, RestFilterChain filterChain) throws Exception {\n-        request.putInContext(INGEST_PARAM_CONTEXT_KEY, request.param(INGEST_PARAM));\n+        if (request.hasParam(INGEST_PARAM)) {\n+            request.putInContext(INGEST_PARAM_CONTEXT_KEY, request.param(INGEST_PARAM));\n+        }\n         filterChain.continueProcessing(request, channel);\n     }\n }",
    "output": "Add the ingest param to the context only if present"
  },
  {
    "input": "diff --git a/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java b/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java\n--- a/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java\n+++ b/plugins/discovery-ec2/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryTests.java\n@@ -251,7 +251,7 @@ protected List<DiscoveryNode> fetchDynamicNodes() {\n         for (int i=0; i<3; i++) {\n             provider.buildDynamicNodes();\n         }\n-        assertEquals(provider.fetchCount, is(3));\n+        assertThat(provider.fetchCount, is(3));\n     }\n \n     public void testGetNodeListCached() throws Exception {\n@@ -268,11 +268,11 @@ protected List<DiscoveryNode> fetchDynamicNodes() {\n         for (int i=0; i<3; i++) {\n             provider.buildDynamicNodes();\n         }\n-        assertEquals(provider.fetchCount, is(1));\n+        assertThat(provider.fetchCount, is(1));\n         Thread.sleep(1_000L); // wait for cache to expire\n         for (int i=0; i<3; i++) {\n             provider.buildDynamicNodes();\n         }\n-        assertEquals(provider.fetchCount, is(2));\n+        assertThat(provider.fetchCount, is(2));\n     }\n }",
    "output": "Fix test for ec2 discovery"
  },
  {
    "input": "diff --git a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/IngestPlugin.java b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/IngestPlugin.java\n--- a/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/IngestPlugin.java\n+++ b/plugins/ingest/src/main/java/org/elasticsearch/plugin/ingest/IngestPlugin.java\n@@ -22,6 +22,7 @@\n \n import org.elasticsearch.action.ActionModule;\n import org.elasticsearch.client.Client;\n+import org.elasticsearch.client.transport.TransportClient;\n import org.elasticsearch.common.component.LifecycleComponent;\n import org.elasticsearch.common.inject.Module;\n import org.elasticsearch.common.settings.Settings;\n@@ -56,7 +57,7 @@ public class IngestPlugin extends Plugin {\n \n     public IngestPlugin(Settings nodeSettings) {\n         this.nodeSettings = nodeSettings;\n-        transportClient = \"transport\".equals(nodeSettings.get(Client.CLIENT_TYPE_SETTING));\n+        transportClient = TransportClient.CLIENT_TYPE.equals(nodeSettings.get(Client.CLIENT_TYPE_SETTING));\n     }\n \n     @Override\n@@ -95,7 +96,7 @@ public Settings additionalSettings() {\n     }\n \n     public void onModule(ActionModule module) {\n-        if (!transportClient) {\n+        if (transportClient == false) {\n             module.registerFilter(IngestActionFilter.class);\n         }\n         module.registerAction(PutPipelineAction.INSTANCE, PutPipelineTransportAction.class);\n@@ -108,5 +109,4 @@ public void onModule(RestModule restModule) {\n         restModule.addRestAction(RestGetPipelineAction.class);\n         restModule.addRestAction(RestDeletePipelineAction.class);\n     }\n-\n }",
    "output": "Use existing constant to check whether client is a transport client"
  },
  {
    "input": "diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/InternalAwsS3Service.java b/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/InternalAwsS3Service.java\n--- a/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/InternalAwsS3Service.java\n+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/InternalAwsS3Service.java\n@@ -193,6 +193,8 @@ private static String getEndpoint(String region) {\n             return \"s3-sa-east-1.amazonaws.com\";\n         } else if (\"cn-north\".equals(region) || \"cn-north-1\".equals(region)) {\n             return \"s3.cn-north-1.amazonaws.com.cn\";\n+        } else if (\"us-gov-west\".equals(region) || \"us-gov-west-1\".equals(region)) {\n+            return \"s3-us-gov-west-1.amazonaws.com\";\n         } else {\n             throw new IllegalArgumentException(\"No automatic endpoint could be derived from region [\" + region + \"]\");\n         }",
    "output": "Add US-Gov-West for S3 Follow up for"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/cache/Cache.java b/core/src/main/java/org/elasticsearch/common/cache/Cache.java\n--- a/core/src/main/java/org/elasticsearch/common/cache/Cache.java\n+++ b/core/src/main/java/org/elasticsearch/common/cache/Cache.java\n@@ -237,7 +237,7 @@ Tuple<Entry<K, V>, Entry<K, V>> put(K key, V value, long now) {\n                         }).get();\n                     }\n                 } catch (ExecutionException | InterruptedException e) {\n-                    throw new IllegalStateException(\"future should be a completedFuture for which get should not throw\", e);\n+                    throw new IllegalStateException(e);\n                 }\n             }\n             return Tuple.tuple(entry, existing);",
    "output": "Make throw statement consistent with others in same class"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/integration/IndexPrivilegeTests.java b/shield/src/test/java/org/elasticsearch/integration/IndexPrivilegeTests.java\n--- a/shield/src/test/java/org/elasticsearch/integration/IndexPrivilegeTests.java\n+++ b/shield/src/test/java/org/elasticsearch/integration/IndexPrivilegeTests.java\n@@ -340,7 +340,7 @@ private void assertUserExecutes(String user, String action, String index, boolea\n                     Map<String, String> analyzeParams = singletonMap(\"text\", \"test\");\n                     assertAccessIsAllowed(user, \"GET\", \"/\" + index + \"/_analyze\", null, analyzeParams);\n                     assertAccessIsAllowed(user, \"POST\", \"/\" + index + \"/_flush\");\n-                    assertAccessIsAllowed(user, \"POST\", \"/\" + index + \"/_optimize\");\n+                    assertAccessIsAllowed(user, \"POST\", \"/\" + index + \"/_forcemerge\");\n                     assertAccessIsAllowed(user, \"POST\", \"/\" + index + \"/_upgrade\", null);\n                     assertAccessIsAllowed(user, \"POST\", \"/\" + index + \"/_close\");\n                     assertAccessIsAllowed(user, \"POST\", \"/\" + index + \"/_open\");\n@@ -361,7 +361,7 @@ private void assertUserExecutes(String user, String action, String index, boolea\n                     Map<String, String> analyzeParams = singletonMap(\"text\", \"test\");\n                     assertAccessIsDenied(user, \"GET\", \"/\" + index + \"/_analyze\", null, analyzeParams);\n                     assertAccessIsDenied(user, \"POST\", \"/\" + index + \"/_flush\");\n-                    assertAccessIsDenied(user, \"POST\", \"/\" + index + \"/_optimize\");\n+                    assertAccessIsDenied(user, \"POST\", \"/\" + index + \"/_forcemerge\");\n                     assertAccessIsDenied(user, \"POST\", \"/\" + index + \"/_upgrade\", null);\n                     assertAccessIsDenied(user, \"POST\", \"/\" + index + \"/_close\");\n                     assertAccessIsDenied(user, \"POST\", \"/\" + index + \"/_open\");",
    "output": "Fix IndexPrivilegeTests for the _optimize removal"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java b/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java\n--- a/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/cache/CacheTests.java\n@@ -542,7 +542,14 @@ public int hashCode() {\n                 for (int j = 0; j < numberOfEntries; j++) {\n                     Key key = new Key(random.nextInt(numberOfEntries));\n                     try {\n-                        cache.computeIfAbsent(key, k -> k.key != 0 ? cache.get(new Key(k.key / 2)) : 0);\n+                        cache.computeIfAbsent(key, k -> {\n+                            if (k.key == 0) {\n+                                return 0;\n+                            } else {\n+                                Integer value = cache.get(new Key(k.key / 2));\n+                                return value != null ? value : 0;\n+                            }\n+                        });\n                     } catch (ExecutionException e) {\n                         fail(e.getMessage());\n                     }",
    "output": "Fix test bug in CacheTests#testDependentKeyDeadlock"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n@@ -287,17 +287,20 @@ protected Query doToQuery(QueryShardContext context) throws IOException {\n         sqp.setDefaultOperator(defaultOperator.toBooleanClauseOccur());\n \n         Query query = sqp.parse(queryText);\n-        if (minimumShouldMatch != null && query instanceof BooleanQuery) {\n+        if (query instanceof BooleanQuery) {\n             BooleanQuery booleanQuery = (BooleanQuery) query;\n-            // treat special case for one term query and more than one field\n-            // we need to wrap this in additional BooleanQuery so minimum_should_match is applied correctly\n             if (booleanQuery.clauses().size() > 1\n                     && ((booleanQuery.clauses().iterator().next().getQuery() instanceof BooleanQuery) == false)) {\n+                // special case for one term query and more than one field: (f1:t1 f2:t1 f3:t1)\n+                // we need to wrap this in additional BooleanQuery so minimum_should_match is applied correctly\n                 BooleanQuery.Builder builder = new BooleanQuery.Builder();\n                 builder.add(new BooleanClause(booleanQuery, Occur.SHOULD));\n                 booleanQuery = builder.build();\n             }\n-            query = Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);\n+            if (minimumShouldMatch != null) {\n+                booleanQuery = Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);\n+            }\n+            query = booleanQuery;\n         }\n         return query;\n     }",
    "output": "Fix CI failure for recent commit in SimpleQueryStringBuilder"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n--- a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n+++ b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n@@ -92,7 +92,6 @@ public QueryPhase(AggregationPhase aggregationPhase, SuggestPhase suggestPhase,\n         parseElements.put(\"query\", new QueryParseElement());\n         parseElements.put(\"queryBinary\", new QueryBinaryParseElement());\n         parseElements.put(\"query_binary\", new QueryBinaryParseElement());\n-        parseElements.put(\"filter\", new PostFilterParseElement()); // For bw comp reason, should be removed in version 1.1\n         parseElements.put(\"post_filter\", new PostFilterParseElement());\n         parseElements.put(\"postFilter\", new PostFilterParseElement());\n         parseElements.put(\"filterBinary\", new FilterBinaryParseElement());",
    "output": "Remove support for deprecated top level filter in search api Replaced by post_filter since 1.0"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestParser.java b/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestParser.java\n--- a/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestParser.java\n+++ b/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestParser.java\n@@ -19,7 +19,6 @@\n package org.elasticsearch.search.suggest.completion;\n \n import org.elasticsearch.common.HasContextAndHeaders;\n-import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.unit.Fuzziness;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n@@ -43,7 +42,6 @@\n public class CompletionSuggestParser implements SuggestContextParser {\n \n     private CompletionSuggester completionSuggester;\n-    private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation(\"edit_distance\");\n \n     public CompletionSuggestParser(CompletionSuggester completionSuggester) {\n         this.completionSuggester = completionSuggester;\n@@ -75,7 +73,7 @@ public SuggestionSearchContext.SuggestionContext parse(XContentParser parser, Ma\n                         if (token == XContentParser.Token.FIELD_NAME) {\n                             fuzzyConfigName = parser.currentName();\n                         } else if (token.isValue()) {\n-                            if (queryParserService.parseFieldMatcher().match(fuzzyConfigName, FUZZINESS)) {\n+                            if (queryParserService.parseFieldMatcher().match(fuzzyConfigName, Fuzziness.FIELD)) {\n                                 suggestion.setFuzzyEditDistance(Fuzziness.parse(parser).asDistance());\n                             } else if (\"transpositions\".equals(fuzzyConfigName)) {\n                                 suggestion.setFuzzyTranspositions(parser.booleanValue());",
    "output": "Remove support for edit_distance in completion suggester Replaced by fuzziness, consistent with other queries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.index.query;\n \n-import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.ParsingException;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.unit.Fuzziness;\n@@ -35,8 +34,6 @@\n  */\n public class QueryStringQueryParser implements QueryParser {\n \n-    private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation(\"fuzzy_min_sim\");\n-\n     @Override\n     public String[] names() {\n         return new String[]{QueryStringQueryBuilder.NAME, Strings.toCamelCase(QueryStringQueryBuilder.NAME)};\n@@ -134,7 +131,7 @@ public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOExcept\n                     fuzzyRewrite = parser.textOrNull();\n                 } else if (\"phrase_slop\".equals(currentFieldName) || \"phraseSlop\".equals(currentFieldName)) {\n                     phraseSlop = parser.intValue();\n-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, FUZZINESS)) {\n+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fuzziness.FIELD)) {\n                     fuzziness = Fuzziness.parse(parser);\n                 } else if (\"boost\".equals(currentFieldName)) {\n                     boost = parser.floatValue();",
    "output": "Remove support for fuzzy_min_sim in query_string query Replaced by fuzziness, consistent with other queries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java\n@@ -19,16 +19,14 @@\n \n package org.elasticsearch.index.query;\n \n-import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.ParsingException;\n import org.elasticsearch.common.unit.Fuzziness;\n import org.elasticsearch.common.xcontent.XContentParser;\n+\n import java.io.IOException;\n \n public class FuzzyQueryParser implements QueryParser<FuzzyQueryBuilder> {\n \n-    private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation(\"min_similarity\");\n-\n     @Override\n     public String[] names() {\n         return new String[]{ FuzzyQueryBuilder.NAME };\n@@ -68,7 +66,7 @@ public FuzzyQueryBuilder fromXContent(QueryParseContext parseContext) throws IOE\n                         value = parser.objectBytes();\n                     } else if (\"boost\".equals(currentFieldName)) {\n                         boost = parser.floatValue();\n-                    } else if (parseContext.parseFieldMatcher().match(currentFieldName, FUZZINESS)) {\n+                    } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fuzziness.FIELD)) {\n                         fuzziness = Fuzziness.parse(parser);\n                     } else if (\"prefix_length\".equals(currentFieldName) || \"prefixLength\".equals(currentFieldName)) {\n                         prefixLength = parser.intValue();",
    "output": "Remove support for min_similarity in fuzzy query Replaced by fuzziness, consistent with other queries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java\n@@ -41,7 +41,6 @@ public class TermsQueryParser implements QueryParser {\n     private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField(\"min_match\", \"min_should_match\", \"minimum_should_match\")\n             .withAllDeprecated(\"Use [bool] query instead\");\n     private static final ParseField DISABLE_COORD_FIELD = new ParseField(\"disable_coord\").withAllDeprecated(\"Use [bool] query instead\");\n-    private static final ParseField EXECUTION_FIELD = new ParseField(\"execution\").withAllDeprecated(\"execution is deprecated and has no effect\");\n \n     @Override\n     public String[] names() {\n@@ -78,9 +77,7 @@ public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOExcept\n                 fieldName = currentFieldName;\n                 termsLookup = TermsLookup.parseTermsLookup(parser);\n             } else if (token.isValue()) {\n-                if (parseContext.parseFieldMatcher().match(currentFieldName, EXECUTION_FIELD)) {\n-                    // ignore\n-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, MIN_SHOULD_MATCH_FIELD)) {\n+                if (parseContext.parseFieldMatcher().match(currentFieldName, MIN_SHOULD_MATCH_FIELD)) {\n                     if (minShouldMatch != null) {\n                         throw new IllegalArgumentException(\"[\" + currentFieldName + \"] is not allowed in a filter context for the [\" + TermsQueryBuilder.NAME + \"] query\");\n                     }",
    "output": "Remove support for deprecated execution element in terms query"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java\n@@ -32,8 +32,8 @@\n  */\n public class IndicesQueryParser implements QueryParser {\n \n-    private static final ParseField QUERY_FIELD = new ParseField(\"query\", \"filter\");\n-    private static final ParseField NO_MATCH_QUERY = new ParseField(\"no_match_query\", \"no_match_filter\");\n+    private static final ParseField QUERY_FIELD = new ParseField(\"query\");\n+    private static final ParseField NO_MATCH_QUERY = new ParseField(\"no_match_query\");\n \n     @Override\n     public String[] names() {",
    "output": "Remove filter and no_match_filter element support from indices query Use query and no_match_query elements instead"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java b/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n--- a/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapper.java\n@@ -12,11 +12,9 @@\n import org.apache.lucene.util.BitSet;\n import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.common.bytes.BytesReference;\n-import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.common.logging.support.LoggerMessageFormat;\n-import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.IndexSettings;\n import org.elasticsearch.index.cache.bitset.BitsetFilterCache;\n import org.elasticsearch.index.engine.EngineConfig;\n@@ -59,7 +57,6 @@ public final class ShieldIndexSearcherWrapper extends IndexSearcherWrapper {\n     private final ShieldLicenseState shieldLicenseState;\n     private final ESLogger logger;\n \n-    @Inject\n     public ShieldIndexSearcherWrapper(IndexSettings indexSettings, IndexQueryParserService parserService,\n                                       MapperService mapperService, BitsetFilterCache bitsetFilterCache, ShieldLicenseState shieldLicenseState) {\n         this.logger = Loggers.getLogger(getClass(), indexSettings.getSettings());",
    "output": "Remove useless @Inject annoation to make sure nobody loads this in anger"
  },
  {
    "input": "diff --git a/qa/smoke-test-found-license-with-shield-and-watcher/src/test/java/org/elasticsearch/smoketest/MarvelClusterInfoIT.java b/qa/smoke-test-found-license-with-shield-and-watcher/src/test/java/org/elasticsearch/smoketest/MarvelClusterInfoIT.java\n--- a/qa/smoke-test-found-license-with-shield-and-watcher/src/test/java/org/elasticsearch/smoketest/MarvelClusterInfoIT.java\n+++ b/qa/smoke-test-found-license-with-shield-and-watcher/src/test/java/org/elasticsearch/smoketest/MarvelClusterInfoIT.java\n@@ -44,7 +44,6 @@ public void testMarvelClusterInfoCollectorWorks() throws Exception {\n         final String clusterUUID = client().admin().cluster().prepareState().setMetaData(true).get().getState().metaData().clusterUUID();\n         assertTrue(Strings.hasText(clusterUUID));\n         awaitIndexExists(\".marvel-es-data\");\n-        ensureGreen(\".marvel-es-data\");\n         awaitMarvelDocsCount(equalTo(1L), \"cluster_info\");\n         GetResponse response = client().prepareGet(\".marvel-es-data\", \"cluster_info\", clusterUUID).get();\n         assertTrue(\".marvel-es-data\" + \" document does not exist\", response.isExists());",
    "output": "Remove the ensure green The random index template can set a number of replicas that will prevent the index from ever being green in a single node cluster"
  },
  {
    "input": "diff --git a/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java b/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n--- a/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n+++ b/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/AbstractCollectorTestCase.java\n@@ -235,14 +235,6 @@ public static class LicensesManagerServiceForCollectors implements LicensesManag\n \n         private volatile License license;\n \n-        @Override\n-        public void registerLicense(PutLicenseRequest request, ActionListener<LicensesService.LicensesUpdateResponse> listener) {\n-        }\n-\n-        @Override\n-        public void removeLicense(DeleteLicenseRequest request, ActionListener<ClusterStateUpdateResponse> listener) {\n-        }\n-\n         @Override\n         public List<String> licenseesWithState(LicenseState state) {\n             return null;",
    "output": "Remove register and remove license from license manager service"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -511,7 +511,7 @@ public void removePlugin(String name, Terminal terminal) throws IOException {\n         if (removed) {\n             terminal.println(\"Removed %s\", name);\n         } else {\n-            terminal.println(\"Plugin %s not found. Run plugin --list to get list of installed plugins.\", name);\n+            terminal.println(\"Plugin %s not found. Run \\\"plugin list\\\" to get list of installed plugins.\", name);\n         }\n     }\n ",
    "output": "Fix plugin list command error message"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -511,7 +511,7 @@ public void removePlugin(String name, Terminal terminal) throws IOException {\n         if (removed) {\n             terminal.println(\"Removed %s\", name);\n         } else {\n-            terminal.println(\"Plugin %s not found. Run plugin --list to get list of installed plugins.\", name);\n+            terminal.println(\"Plugin %s not found. Run \\\"plugin list\\\" to get list of installed plugins.\", name);\n         }\n     }\n ",
    "output": "Fix plugin list command error message"
  },
  {
    "input": "diff --git a/plugins/store-smb/src/main/java/org/elasticsearch/plugin/store/smb/SMBStorePlugin.java b/plugins/store-smb/src/main/java/org/elasticsearch/plugin/store/smb/SMBStorePlugin.java\n--- a/plugins/store-smb/src/main/java/org/elasticsearch/plugin/store/smb/SMBStorePlugin.java\n+++ b/plugins/store-smb/src/main/java/org/elasticsearch/plugin/store/smb/SMBStorePlugin.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.plugin.store.smb;\n \n import org.elasticsearch.index.IndexModule;\n-import org.elasticsearch.index.store.IndexStoreModule;\n import org.elasticsearch.index.store.smbmmapfs.SmbMmapFsIndexStore;\n import org.elasticsearch.index.store.smbsimplefs.SmbSimpleFsIndexStore;\n import org.elasticsearch.plugins.Plugin;",
    "output": "Remove unused import"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n@@ -57,7 +57,7 @@ public final class EngineConfig {\n     private volatile boolean compoundOnFlush = true;\n     private long gcDeletesInMillis = DEFAULT_GC_DELETES.millis();\n     private volatile boolean enableGcDeletes = true;\n-    private final TimeValue flushMergesAfter = TimeValue.timeValueMinutes(5);\n+    private final TimeValue flushMergesAfter;\n     private final String codecName;\n     private final ThreadPool threadPool;\n     private final ShardIndexingService indexingService;\n@@ -145,6 +145,7 @@ public EngineConfig(ShardId shardId, ThreadPool threadPool, ShardIndexingService\n         this.queryCache = queryCache;\n         this.queryCachingPolicy = queryCachingPolicy;\n         this.translogConfig = translogConfig;\n+        this.flushMergesAfter = flushMergesAfter;\n     }\n \n     /** updates {@link #versionMapSize} based on current setting and {@link #indexingBufferSize} */",
    "output": "Use actual parameter passed to the ctor"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java\n@@ -80,7 +80,7 @@ public abstract class Engine implements Closeable {\n     protected final ReleasableLock readLock = new ReleasableLock(rwl.readLock());\n     protected final ReleasableLock writeLock = new ReleasableLock(rwl.writeLock());\n     protected volatile Throwable failedEngine = null;\n-    protected volatile long lastWriteNanos;\n+    protected volatile long lastWriteNanos = Long.MAX_VALUE; // no write yet!\n \n     protected Engine(EngineConfig engineConfig) {\n         Objects.requireNonNull(engineConfig.getStore(), \"Store must be provided to the engine\");",
    "output": "Use Long.MAX_VALUE to indicate that there has not yet been any modifications Relates to"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ack/AckClusterUpdateSettingsIT.java b/core/src/test/java/org/elasticsearch/cluster/ack/AckClusterUpdateSettingsIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ack/AckClusterUpdateSettingsIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ack/AckClusterUpdateSettingsIT.java\n@@ -29,6 +29,7 @@\n import org.elasticsearch.cluster.routing.IndexRoutingTable;\n import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.allocation.decider.ConcurrentRebalanceAllocationDecider;\n import org.elasticsearch.cluster.routing.allocation.decider.ThrottlingAllocationDecider;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.discovery.DiscoverySettings;\n@@ -50,6 +51,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 //make sure that enough concurrent reroutes can happen at the same time\n                 //we have a minimum of 2 nodes, and a maximum of 10 shards, thus 5 should be enough\n                 .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES, 5)\n+                .put(ConcurrentRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_CLUSTER_CONCURRENT_REBALANCE, 10)\n                 .build();\n     }\n ",
    "output": "Fix AckClusterUpdateSettingsIT.testClusterUpdateSettingsAcknowledgement() after changes in"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java b/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java\n@@ -26,6 +26,7 @@\n import java.security.CodeSource;\n import java.security.Permission;\n import java.security.PermissionCollection;\n+import java.security.Permissions;\n import java.security.Policy;\n import java.security.ProtectionDomain;\n import java.security.URIParameter;\n@@ -92,6 +93,21 @@ public boolean implies(ProtectionDomain domain, Permission permission) {\n         return template.implies(domain, permission) || dynamic.implies(permission);\n     }\n \n+    @Override\n+    public PermissionCollection getPermissions(CodeSource codesource) {\n+        // code should not rely on this method, or at least use it correctly:\n+        // https://bugs.openjdk.java.net/browse/JDK-8014008\n+        // return them a new empty permissions object so jvisualvm etc work\n+        for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n+            if (\"sun.rmi.server.LoaderHandler\".equals(element.getClassName()) &&\n+                    \"loadClass\".equals(element.getMethodName())) {\n+                return new Permissions();\n+            }\n+        }\n+        // return UNSUPPORTED_EMPTY_COLLECTION since it is safe.\n+        return super.getPermissions(codesource);\n+    }\n+\n     /**\n      * Classy puzzler to rethrow any checked exception as an unchecked one.\n      */",
    "output": "Add workaround for JDK-8014008 We should not implement this method, it is a real problem. But I think it is ok to workaround the JDK bug (https://bugs.openjdk.java.net/browse/JDK-8014008). This allows jconsole/visualvm to work in the meantime"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java b/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n@@ -496,10 +496,6 @@ public Mapper parse(ParseContext context) throws IOException {\n             // Set the maximum length of strings returned by the parseToString method, -1 sets no limit\n             parsedContent = tika.parseToString(StreamInput.wrap(content), metadata, indexedChars);\n         } catch (Throwable e) {\n-            // It could happen that Tika adds a System property `sun.font.fontmanager` which should not happen\n-            // TODO Remove when this will be fixed in Tika. See https://issues.apache.org/jira/browse/TIKA-1548\n-            System.clearProperty(\"sun.font.fontmanager\");\n-\n             // #18: we could ignore errors when Tika does not parse data\n             if (!ignoreErrors) {\n                 logger.trace(\"exception caught\", e);",
    "output": "Remove call to System.clearProperty(\"sun.font.fontmanager\"); This has been fixed in Tika 1.8. See https://issues.apache.org/jira/browse/TIKA-1548 We can now remove that call in `AttachmentMapper` class. . (cherry picked from commit eacb040)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/SettingsListenerIT.java b/core/src/test/java/org/elasticsearch/index/SettingsListenerIT.java\n--- a/core/src/test/java/org/elasticsearch/index/SettingsListenerIT.java\n+++ b/core/src/test/java/org/elasticsearch/index/SettingsListenerIT.java\n@@ -21,7 +21,6 @@\n import org.elasticsearch.cluster.ClusterModule;\n import org.elasticsearch.cluster.settings.Validator;\n import org.elasticsearch.common.inject.AbstractModule;\n-import org.elasticsearch.common.inject.Binder;\n import org.elasticsearch.common.inject.Module;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.plugins.Plugin;\n@@ -34,9 +33,8 @@\n \n import static org.elasticsearch.test.ESIntegTestCase.Scope.SUITE;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n-import static org.hamcrest.Matchers.nullValue;\n \n-@ClusterScope(scope = SUITE, numDataNodes = 1, transportClientRatio = 0.0)\n+@ClusterScope(scope = SUITE, numDataNodes = 1, numClientNodes = 0)\n public class SettingsListenerIT extends ESIntegTestCase {\n \n     @Override\n@@ -94,7 +92,8 @@ protected void configure() {\n     }\n \n     public static class SettingsTestingService implements Consumer<Settings> {\n-        public volatile  int value;\n+        public volatile int value;\n+\n         @Override\n         public void accept(Settings settings) {\n             value = settings.getAsInt(\"index.test.new.setting\", -1);",
    "output": "Fix test to not use client nodes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n@@ -717,13 +717,6 @@ public void delete() {\n         }\n     }\n \n-    /**\n-     * Is it an empty {@link DocIdSet}?\n-     */\n-    public static boolean isEmpty(@Nullable DocIdSet set) {\n-        return set == null || set == DocIdSet.EMPTY;\n-    }\n-\n     /**\n      * Given a {@link Scorer}, return a {@link Bits} instance that will match\n      * all documents contained in the set. Note that the returned {@link Bits}",
    "output": "Remove Lucene.isEmpty(DocIdSet). After the Filter ban, this method is not used anymore"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java\n@@ -25,15 +25,12 @@\n import org.apache.lucene.search.QueryCache;\n import org.apache.lucene.search.QueryCachingPolicy;\n import org.apache.lucene.search.similarities.Similarity;\n-import org.apache.lucene.util.SetOnce;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.settings.Settings;\n-import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.index.codec.CodecService;\n import org.elasticsearch.index.indexing.ShardIndexingService;\n-import org.elasticsearch.index.shard.IndexSearcherWrapper;\n import org.elasticsearch.index.shard.MergeSchedulerConfig;\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.index.shard.TranslogRecoveryPerformer;\n@@ -76,7 +73,6 @@ public final class EngineConfig {\n     private final boolean forceNewTranslog;\n     private final QueryCache queryCache;\n     private final QueryCachingPolicy queryCachingPolicy;\n-    private final SetOnce<IndexSearcherWrapper> searcherWrapper = new SetOnce<>();\n \n     /**\n      * Index setting for compound file on flush. This setting is realtime updateable.",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/QueryDSLDocumentationTests.java b/core/src/test/java/org/elasticsearch/index/query/QueryDSLDocumentationTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/QueryDSLDocumentationTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/QueryDSLDocumentationTests.java\n@@ -30,6 +30,7 @@\n import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder.FilterFunctionBuilder;\n import org.elasticsearch.script.Script;\n import org.elasticsearch.script.ScriptService.ScriptType;\n+import org.elasticsearch.test.ESTestCase;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -48,7 +49,7 @@\n  * There are no assertions here on purpose - all of these tests ((ideally) should) equal to what is\n  * documented in the java api query dsl part of our reference guide. \n  * */\n-public class QueryDSLDocumentationTests {\n+public class QueryDSLDocumentationTests extends ESTestCase {\n     @Test\n     public void testBool() {\n         boolQuery()",
    "output": "Fix the naming check"
  },
  {
    "input": "diff --git a/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/RetryHttpInitializerWrapperTests.java b/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/RetryHttpInitializerWrapperTests.java\n--- a/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/RetryHttpInitializerWrapperTests.java\n+++ b/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/RetryHttpInitializerWrapperTests.java\n@@ -113,7 +113,7 @@ public void testSimpleRetry() throws Exception {\n \n     @Test\n     public void testRetryWaitTooLong() throws Exception {\n-        int maxWait = 50;\n+        int maxWait = 10;\n \n         FailThenSuccessBackoffTransport fakeTransport =\n                 new FailThenSuccessBackoffTransport(HttpStatusCodes.STATUS_CODE_SERVER_ERROR, 50);\n@@ -124,7 +124,7 @@ public void testRetryWaitTooLong() throws Exception {\n         MockSleeper oneTimeSleeper = new MockSleeper() {\n             @Override\n             public void sleep(long millis) throws InterruptedException {\n-                Thread.sleep(maxWait);\n+                Thread.sleep(maxWait * 10);\n                 super.sleep(0); // important number, use this to get count\n             }\n         };",
    "output": "Fix a test bug"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -285,7 +285,7 @@ private int getNodeNumber() {\n \n     private void ensureNodesAreAvailable(List<DiscoveryNode> nodes) {\n         if (nodes.isEmpty()) {\n-            String message = String.format(Locale.ROOT, \"None of the configured nodes are available: %s\", nodes);\n+            String message = String.format(Locale.ROOT, \"None of the configured nodes are available: %s\", this.listedNodes);\n             throw new NoNodeAvailableException(message);\n         }\n     }",
    "output": "Fix ensureNodesAreAvailable's error message"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ConcurrentRebalanceAllocationDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ConcurrentRebalanceAllocationDecider.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ConcurrentRebalanceAllocationDecider.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/ConcurrentRebalanceAllocationDecider.java\n@@ -70,7 +70,7 @@ public Decision canRebalance(ShardRouting shardRouting, RoutingAllocation alloca\n             return allocation.decision(Decision.YES, NAME, \"all concurrent rebalances are allowed\");\n         }\n         if (allocation.routingNodes().getRelocatingShardCount() >= clusterConcurrentRebalance) {\n-            return allocation.decision(Decision.NO, NAME, \"too man concurrent rebalances [%d], limit: [%d]\",\n+            return allocation.decision(Decision.NO, NAME, \"too many concurrent rebalances [%d], limit: [%d]\",\n                     allocation.routingNodes().getRelocatingShardCount(), clusterConcurrentRebalance);\n         }\n         return allocation.decision(Decision.YES, NAME, \"below threshold [%d] for concurrent rebalances\", clusterConcurrentRebalance);",
    "output": "Fix typo in o.e.c.r.a.d.ConcurrentRebalanceAllocationDecider"
  },
  {
    "input": "diff --git a/watcher/src/test/java/org/elasticsearch/watcher/actions/index/IndexActionTests.java b/watcher/src/test/java/org/elasticsearch/watcher/actions/index/IndexActionTests.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/actions/index/IndexActionTests.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/actions/index/IndexActionTests.java\n@@ -161,8 +161,7 @@ public void testIndexActionExecute_MultiDoc() throws Exception {\n \n         SearchResponse searchResponse = client().prepareSearch(\"test-index\")\n                 .setTypes(\"test-type\")\n-                .addSort(\"foo\", SortOrder.ASC)\n-                .setSource(searchSource()\n+                .setSource(searchSource().sort(\"foo\", SortOrder.ASC)\n                         .query(matchAllQuery())\n                         .aggregation(terms(\"timestamps\").field(customTimestampField ? timestampField : \"_timestamp\")))\n                 .get();",
    "output": "Fix test problem after search refactoring"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java\n@@ -111,9 +111,9 @@ public Explanation explainScore(int docId, Explanation subQueryScore) throws IOE\n                     exp = ((ExplainableSearchScript) leafScript).explain(subQueryScore);\n                 } else {\n                     double score = score(docId, subQueryScore.getValue());\n-                    String explanation = \"script score function, computed with script:\\\"\" + sScript;\n+                    String explanation = \"script score function, computed with script:\\\"\" + sScript + \"\\\"\";\n                     if (sScript.getParams() != null) {\n-                        explanation += \"\\\" and parameters: \\n\" + sScript.getParams().toString();\n+                        explanation += \" and parameters: \\n\" + sScript.getParams().toString();\n                     }\n                     Explanation scoreExp = Explanation.match(\n                             subQueryScore.getValue(), \"_score: \",",
    "output": "Fix the quotes in the explain message for a script score function without parameters"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/geocentroid/InternalGeoCentroid.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/geocentroid/InternalGeoCentroid.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/geocentroid/InternalGeoCentroid.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/geocentroid/InternalGeoCentroid.java\n@@ -63,6 +63,7 @@ public InternalGeoCentroid(String name, GeoPoint centroid, long count, List<Pipe\n             pipelineAggregators, Map<String, Object> metaData) {\n         super(name, pipelineAggregators, metaData);\n         this.centroid = centroid;\n+        assert count >= 0;\n         this.count = count;\n     }\n \n@@ -127,16 +128,21 @@ public Object getProperty(List<String> path) {\n     @Override\n     protected void doReadFrom(StreamInput in) throws IOException {\n         count = in.readVLong();\n-        if (count > 0) {\n+        if (in.readBoolean()) {\n             centroid = GeoPoint.fromIndexLong(in.readLong());\n+        } else {\n+            centroid = null;\n         }\n     }\n \n     @Override\n     protected void doWriteTo(StreamOutput out) throws IOException {\n         out.writeVLong(count);\n         if (centroid != null) {\n+            out.writeBoolean(true);\n             out.writeLong(XGeoUtils.mortonHash(centroid.lon(), centroid.lat()));\n+        } else {\n+            out.writeBoolean(false);\n         }\n     }\n ",
    "output": "Fix GeoCenteriod Aggregation serialization"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/gateway/MetaDataWriteDataNodesIT.java b/core/src/test/java/org/elasticsearch/gateway/MetaDataWriteDataNodesIT.java\n--- a/core/src/test/java/org/elasticsearch/gateway/MetaDataWriteDataNodesIT.java\n+++ b/core/src/test/java/org/elasticsearch/gateway/MetaDataWriteDataNodesIT.java\n@@ -155,13 +155,8 @@ protected void assertIndexDirectoryDeleted(final String nodeName, final String i\n         assertBusy(new Runnable() {\n                        @Override\n                        public void run() {\n-                           logger.info(\"checking if meta state exists...\");\n-                           try {\n-                               assertFalse(\"Expecting index directory of \" + indexName + \" to be deleted from node \" + nodeName, indexDirectoryExists(nodeName, indexName));\n-                           } catch (Exception e) {\n-                               logger.info(\"failed to check for data director of index {} on node {}\", indexName, nodeName);\n-                               fail(\"could not check if data directory still exists\");\n-                           }\n+                           logger.info(\"checking if index directory exists...\");\n+                           assertFalse(\"Expecting index directory of \" + indexName + \" to be deleted from node \" + nodeName, indexDirectoryExists(nodeName, indexName));\n                        }\n                    }\n         );\n@@ -184,7 +179,7 @@ public void run() {\n     }\n \n \n-    private boolean indexDirectoryExists(String nodeName, String indexName) throws Exception {\n+    private boolean indexDirectoryExists(String nodeName, String indexName) {\n         NodeEnvironment nodeEnv = ((InternalTestCluster) cluster()).getInstance(NodeEnvironment.class, nodeName);\n         for (Path path : nodeEnv.indexPaths(new Index(indexName))) {\n             if (Files.exists(path)) {",
    "output": "Remove unneeded Exception and handling thereof"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java b/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java\n@@ -67,7 +67,7 @@ public final Engine.Searcher wrap(EngineConfig engineConfig, Engine.Searcher eng\n         if (elasticsearchDirectoryReader == null) {\n             throw new IllegalStateException(\"Can't wrap non elasticsearch directory reader\");\n         }\n-        DirectoryReader reader = wrap((DirectoryReader)engineSearcher.reader());\n+        DirectoryReader reader = wrap(engineSearcher.reader());\n         IndexSearcher innerIndexSearcher = new IndexSearcher(new CacheFriendlyReaderWrapper(reader, elasticsearchDirectoryReader));\n         innerIndexSearcher.setQueryCache(engineConfig.getQueryCache());\n         innerIndexSearcher.setQueryCachingPolicy(engineConfig.getQueryCachingPolicy());",
    "output": "Remove unnecessary cast"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java\n--- a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java\n+++ b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java\n@@ -97,6 +97,7 @@\n import static org.hamcrest.Matchers.containsString;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.lessThan;\n import static org.hamcrest.Matchers.notNullValue;\n import static org.hamcrest.Matchers.nullValue;",
    "output": "Fix import in SharedClusterSnapshotRestoreIT"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java\n@@ -111,9 +111,9 @@ public Explanation explainScore(int docId, Explanation subQueryScore) throws IOE\n                     exp = ((ExplainableSearchScript) leafScript).explain(subQueryScore);\n                 } else {\n                     double score = score(docId, subQueryScore.getValue());\n-                    String explanation = \"script score function, computed with script:\\\"\" + sScript;\n+                    String explanation = \"script score function, computed with script:\\\"\" + sScript + \"\\\"\";\n                     if (sScript.getParams() != null) {\n-                        explanation += \"\\\" and parameters: \\n\" + sScript.getParams().toString();\n+                        explanation += \" and parameters: \\n\" + sScript.getParams().toString();\n                     }\n                     Explanation scoreExp = Explanation.match(\n                             subQueryScore.getValue(), \"_score: \",",
    "output": "Fix the quotes in the explain message for a script score function without parameters"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n@@ -18,7 +18,6 @@\n  */\n package org.elasticsearch.plugins;\n \n-import com.google.common.hash.Hashing;\n import org.apache.http.impl.client.HttpClients;\n import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.Version;",
    "output": "Remove unused import in o.e.p.PluginManagerIT"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java\n@@ -30,7 +30,7 @@\n /**\n  * Builder for the {@link ScriptedMetric} aggregation.\n  */\n-public class ScriptedMetricBuilder extends MetricsAggregationBuilder {\n+public class ScriptedMetricBuilder extends MetricsAggregationBuilder<ScriptedMetricBuilder> {\n \n     private Script initScript = null;\n     private Script mapScript = null;",
    "output": "Add correct generic type parameter on ScriptedMetricBuilder"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java\n--- a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java\n+++ b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java\n@@ -95,7 +95,7 @@ public void restoreOldSnapshots() throws Exception {\n             if (Modifier.isStatic(field.getModifiers()) && field.getType() == Version.class) {\n                 Version v = (Version) field.get(Version.class);\n                 if (v.snapshot()) continue;\n-                if (v.onOrBefore(Version.V_1_0_0_Beta1)) continue;\n+                if (v.onOrBefore(Version.V_2_0_0_beta1)) continue;\n                 if (v.equals(Version.CURRENT)) continue;\n \n                 expectedVersions.add(v.toString());",
    "output": "Fix min supported version"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n@@ -182,11 +182,15 @@ private void checkSupportedVersion(IndexMetaData indexMetaData) {\n      */\n     private static boolean isSupportedVersion(IndexMetaData indexMetaData) {\n         if (indexMetaData.creationVersion().onOrAfter(Version.V_2_0_0_beta1)) {\n-            // The index was created with elasticsearch that was using Lucene 4.0\n+            // The index was created with elasticsearch that was using Lucene 5.2.1\n             return true;\n         }\n+        if (indexMetaData.getUpgradeVersion().onOrAfter(Version.V_2_0_0_beta1) == false) {\n+            // early terminate if we are not upgrade - we don't even need to look at the segment version\n+            return false;\n+        }\n         if (indexMetaData.getMinimumCompatibleVersion() != null &&\n-                indexMetaData.getMinimumCompatibleVersion().onOrAfter(org.apache.lucene.util.Version.LUCENE_4_0_0)) {\n+                indexMetaData.getMinimumCompatibleVersion().onOrAfter(org.apache.lucene.util.Version.LUCENE_5_0_0)) {\n             //The index was upgraded we can work with it\n             return true;\n         }",
    "output": "Add additional checks for version compatibility"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/scripted/ScriptedMetricBuilder.java\n@@ -30,7 +30,7 @@\n /**\n  * Builder for the {@link ScriptedMetric} aggregation.\n  */\n-public class ScriptedMetricBuilder extends MetricsAggregationBuilder {\n+public class ScriptedMetricBuilder extends MetricsAggregationBuilder<ScriptedMetricBuilder> {\n \n     private Script initScript = null;\n     private Script mapScript = null;",
    "output": "Add correct generic type parameter on ScriptedMetricBuilder Make ScriptedMetricBuilder class declaration consistent with all other Builder declarations"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -53,7 +53,7 @@\n import java.util.Iterator;\n import java.util.List;\n import java.util.Locale;\n-import java.util.Map;\n+import java.util.Map;c\n import java.util.Set;\n import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.CountDownLatch;\n@@ -285,7 +285,7 @@ private int getNodeNumber() {\n \n     private void ensureNodesAreAvailable(List<DiscoveryNode> nodes) {\n         if (nodes.isEmpty()) {\n-            String message = String.format(Locale.ROOT, \"None of the configured nodes are available: %s\", nodes);\n+            String message = String.format(Locale.ROOT, \"None of the configured nodes are available: %s\", this.listedNodes);\n             throw new NoNodeAvailableException(message);\n         }\n     }",
    "output": "Fix ensureNodesAreAvailable's error message listedNodes are the \"configured nodes\" and not the empty list of nodes that is passed to the method and causes this exception to be thrown"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java b/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/authz/accesscontrol/ShieldIndexSearcherWrapperUnitTests.java\n@@ -45,8 +45,7 @@\n import org.elasticsearch.index.mapper.internal.ParentFieldMapper;\n import org.elasticsearch.index.shard.IndexShard;\n import org.elasticsearch.index.shard.ShardId;\n-import org.elasticsearch.index.similarity.SimilarityLookupService;\n-import org.elasticsearch.indices.InternalIndicesLifecycle;\n+import org.elasticsearch.index.similarity.SimilarityService;\n import org.elasticsearch.script.ScriptService;\n import org.elasticsearch.search.aggregations.LeafBucketCollector;\n import org.elasticsearch.shield.authz.InternalAuthorizationService;\n@@ -81,9 +80,9 @@ public void before() throws Exception {\n         Index index = new Index(\"_index\");\n         Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT).build();\n             AnalysisService analysisService = new AnalysisService(index, settings);\n-        SimilarityLookupService similarityLookupService = new SimilarityLookupService(index, settings);\n+        SimilarityService similarityService = new SimilarityService(index, settings);\n         ScriptService scriptService = mock(ScriptService.class);\n-        mapperService = new MapperService(index, settings, analysisService, similarityLookupService, scriptService);\n+        mapperService = new MapperService(index, settings, analysisService, similarityService, scriptService);\n \n         shardId = new ShardId(index, 0);\n         shieldIndexSearcherWrapper = new ShieldIndexSearcherWrapper(settings, null, mapperService, null);",
    "output": "Fix compile error. SimilarityLookupService -> SimilarityService"
  },
  {
    "input": "diff --git a/watcher/src/main/java/org/elasticsearch/watcher/support/text/xmustache/XMustacheScriptEngineService.java b/watcher/src/main/java/org/elasticsearch/watcher/support/text/xmustache/XMustacheScriptEngineService.java\n--- a/watcher/src/main/java/org/elasticsearch/watcher/support/text/xmustache/XMustacheScriptEngineService.java\n+++ b/watcher/src/main/java/org/elasticsearch/watcher/support/text/xmustache/XMustacheScriptEngineService.java\n@@ -114,11 +114,6 @@ public SearchScript search(CompiledScript compiledScript, SearchLookup lookup,\n         throw new UnsupportedOperationException();\n     }\n \n-    @Override\n-    public Object unwrap(Object value) {\n-        return value;\n-    }\n-\n     @Override\n     public void close() {\n         // Nothing to do here",
    "output": "Fix compile error due to upstream change"
  },
  {
    "input": "diff --git a/marvel/src/main/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterInfoRenderer.java b/marvel/src/main/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterInfoRenderer.java\n--- a/marvel/src/main/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterInfoRenderer.java\n+++ b/marvel/src/main/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterInfoRenderer.java\n@@ -5,7 +5,6 @@\n  */\n package org.elasticsearch.marvel.agent.renderer.cluster;\n \n-import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.action.admin.cluster.stats.ClusterStatsResponse;\n import org.elasticsearch.common.hash.MessageDigests;\n import org.elasticsearch.common.xcontent.ToXContent;\n@@ -16,10 +15,7 @@\n import org.elasticsearch.marvel.agent.renderer.AbstractRenderer;\n \n import java.io.IOException;\n-import java.io.UnsupportedEncodingException;\n import java.nio.charset.StandardCharsets;\n-import java.security.MessageDigest;\n-import java.security.NoSuchAlgorithmException;\n import java.util.List;\n \n public class ClusterInfoRenderer extends AbstractRenderer<ClusterInfoMarvelDoc> {",
    "output": "Remove unused imports in o.e.m.a.r.c.ClusterInfoRenderer"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginInfo.java b/core/src/main/java/org/elasticsearch/plugins/PluginInfo.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginInfo.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginInfo.java\n@@ -114,7 +114,8 @@ public static PluginInfo readFromProperties(Path dir) throws IOException {\n             }\n             Version esVersion = Version.fromString(esVersionString);\n             if (esVersion.equals(Version.CURRENT) == false) {\n-                throw new IllegalArgumentException(\"Elasticsearch version [\" + esVersionString + \"] is too old for plugin [\" + name + \"]\");\n+                throw new IllegalArgumentException(\"Plugin [\" + name + \"] is incompatible with Elasticsearch [\" + Version.CURRENT.toString() +\n+                        \"]. Was designed for version [\" + esVersionString + \"]\");\n             }\n             String javaVersionString = props.getProperty(\"java.version\");\n             if (javaVersionString == null) {\n\ndiff --git a/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java\n@@ -221,7 +221,7 @@ public void testReadFromPropertiesOldElasticsearchVersion() throws Exception {\n             PluginInfo.readFromProperties(pluginDir);\n             fail(\"expected old elasticsearch version exception\");\n         } catch (IllegalArgumentException e) {\n-            assertTrue(e.getMessage().contains(\"Elasticsearch version [1.7.0] is too old\"));\n+            assertTrue(e.getMessage().contains(\"Was designed for version [1.7.0]\"));\n         }\n     }\n ",
    "output": "Upgrade version incompatibility message for plugin manager When the plugin manager does not find in `plugin-descriptor.properties` the exact same elasticsearch version it was built on as the current elasticsearch version, it fails with a message like: ``` ERROR: Elasticsearch version [2.0.0-beta1] is too old for plugin [elasticsearch-mapper-attachments] ``` Actually, the message should be: ``` Plugin [elasticsearch-mapper-attachments] is incompatible with Elasticsearch [2.0.0.beta2]. Was designed for version [2.0.0.beta1]. ``` The opposite is true. If you try to install a version of a plugin which was built with a newer version of elasticsearch, it will fail the same way: ``` Plugin [elasticsearch-mapper-attachments] is incompatible with Elasticsearch [2.0.0.beta1]. Was designed for version [2.0.0.beta2]. ```"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/cache/Cache.java b/core/src/main/java/org/elasticsearch/common/cache/Cache.java\n--- a/core/src/main/java/org/elasticsearch/common/cache/Cache.java\n+++ b/core/src/main/java/org/elasticsearch/common/cache/Cache.java\n@@ -139,24 +139,6 @@ public Entry(K key, V value, long writeTime) {\n             this.value = value;\n             this.writeTime = this.accessTime = writeTime;\n         }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (obj == null) {\n-                return false;\n-            } else if (!(obj instanceof Entry)) {\n-                return false;\n-            } else {\n-                @SuppressWarnings(\"unchecked\")\n-                Entry<K, V> e = (Entry<K, V>) obj;\n-                return Objects.equals(key, e.key);\n-            }\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return Objects.hashCode(key);\n-        }\n     }\n \n     /**",
    "output": "Remove unnecessary overrides of equals/hashCode in Cache.Entry"
  },
  {
    "input": "diff --git a/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterStatsTests.java b/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterStatsTests.java\n--- a/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterStatsTests.java\n+++ b/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/cluster/ClusterStatsTests.java\n@@ -12,7 +12,6 @@\n import org.elasticsearch.marvel.agent.settings.MarvelSettings;\n import org.elasticsearch.marvel.test.MarvelIntegTestCase;\n import org.elasticsearch.search.SearchHit;\n-import org.elasticsearch.test.ESIntegTestCase;\n import org.elasticsearch.test.ESIntegTestCase.ClusterScope;\n import org.junit.Test;\n \n@@ -23,10 +22,7 @@\n import static org.elasticsearch.test.ESIntegTestCase.Scope.SUITE;\n import static org.hamcrest.Matchers.greaterThan;\n \n-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;\n-\n-@ClusterScope(scope = SUITE, maxNumDataNodes = 2)\n-@AwaitsFix(bugUrl = \"https://github.com/elastic/x-plugins/issues/729\")\n+@ClusterScope(scope = SUITE, numClientNodes = 0)\n public class ClusterStatsTests extends MarvelIntegTestCase {\n \n     @Override",
    "output": "Fix ClusterStatsIT test (take 2)"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -263,6 +263,8 @@ public class Version {\n     public static final Version V_2_0_0 = new Version(V_2_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_2_1);\n     public static final int V_2_1_0_ID = 2010099;\n     public static final Version V_2_1_0 = new Version(V_2_1_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_3_0);\n+    public static final int V_2_2_0_ID = 2020099;\n+    public static final Version V_2_2_0 = new Version(V_2_2_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_3_0);\n     public static final int V_3_0_0_ID = 3000099;\n     public static final Version V_3_0_0 = new Version(V_3_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_4_0);\n     public static final Version CURRENT = V_3_0_0;\n@@ -279,6 +281,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_3_0_0_ID:\n                 return V_3_0_0;\n+            case V_2_2_0_ID:\n+                return V_2_2_0;\n             case V_2_1_0_ID:\n                 return V_2_1_0;\n             case V_2_0_0_ID:",
    "output": "Add 2.2.0 version to master"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java\n@@ -196,7 +196,7 @@ public void testParseFromJSON() throws IOException {\n         // now assert that we actually generate the same JSON\n         XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();\n         queryBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);\n-        assertEquals(query, builder.string());\n+        assertEquals(query, builder.string().replaceAll(\"\\\\r\\\\n\", \"\\n\")); // jackson uses system linefeed - will fail on windows otherwise\n     }\n \n }",
    "output": "Make test pass on windows - jackson uses platform line.separator which messes up comparisons"
  },
  {
    "input": "diff --git a/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java b/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java\n--- a/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java\n+++ b/marvel/src/test/java/org/elasticsearch/marvel/test/MarvelIntegTestCase.java\n@@ -62,9 +62,8 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 // we do this by default in core, but for marvel this isn't needed and only adds noise.\n                 .put(\"index.store.mock.check_index_on_close\", false);\n \n-        if (shieldEnabled) {\n-            ShieldSettings.apply(builder);\n-        }\n+        ShieldSettings.apply(shieldEnabled, builder);\n+\n         return builder.build();\n     }\n \n@@ -97,7 +96,7 @@ protected Collection<Class<? extends Plugin>> transportClientPlugins() {\n      * Override and returns {@code false} to force running without shield\n      */\n     protected boolean enableShield() {\n-        return true; //randomBoolean();\n+        return randomBoolean();\n     }\n \n     protected void stopCollection() {\n@@ -292,7 +291,11 @@ public static class ShieldSettings {\n                 ;\n \n \n-        public static void apply(Settings.Builder builder)  {\n+        public static void apply(boolean enabled, Settings.Builder builder)  {\n+            if (!enabled) {\n+                builder.put(\"shield.enabled\", false);\n+                return;\n+            }\n             try {\n                 Path folder = createTempDir().resolve(\"marvel_shield\");\n                 Files.createDirectories(folder);",
    "output": "Fix tests when shield is disabled - also turned shield testing to be random"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java\n--- a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java\n+++ b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java\n@@ -20,6 +20,7 @@\n \n import com.fasterxml.jackson.core.JsonLocation;\n import com.fasterxml.jackson.core.JsonParseException;\n+\n import org.apache.lucene.util.Constants;\n import org.codehaus.groovy.runtime.typehandling.GroovyCastException;\n import org.elasticsearch.action.FailedNodeException;\n@@ -59,12 +60,7 @@\n import org.elasticsearch.index.engine.IndexFailedEngineException;\n import org.elasticsearch.index.engine.RecoveryEngineException;\n import org.elasticsearch.index.mapper.MergeMappingException;\n-<<<<<<< HEAD\n-import org.elasticsearch.index.query.TestParsingException;\n-=======\n-import org.elasticsearch.common.ParsingException;\n import org.elasticsearch.index.query.QueryShardException;\n->>>>>>> master\n import org.elasticsearch.index.shard.IllegalIndexShardStateException;\n import org.elasticsearch.index.shard.IndexShardState;\n import org.elasticsearch.index.shard.ShardId;",
    "output": "Fix merge error"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java b/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java\n--- a/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java\n@@ -739,7 +739,7 @@ Settings customAuditIndexSettings(Settings nodeSettings) {\n         Settings.Builder builder = Settings.builder();\n         for (Map.Entry<String, String> entry : newSettings.getAsMap().entrySet()) {\n             String name = \"index.\" + entry.getKey();\n-            if (FORBIDDEN_INDEX_SETTING.contains(name)) {\n+            if (FORBIDDEN_INDEX_SETTING.equals(name)) {\n                 logger.warn(\"overriding the default [{}} setting is forbidden. ignoring...\", name);\n                 continue;\n             }",
    "output": "Fix Set->String conversion"
  },
  {
    "input": "diff --git a/watcher/src/test/java/org/elasticsearch/watcher/trigger/schedule/IntervalScheduleTests.java b/watcher/src/test/java/org/elasticsearch/watcher/trigger/schedule/IntervalScheduleTests.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/trigger/schedule/IntervalScheduleTests.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/trigger/schedule/IntervalScheduleTests.java\n@@ -51,7 +51,7 @@ public void testParse_NegativeNumber() throws Exception {\n \n     @Test\n     public void testParse_String() throws Exception {\n-        IntervalSchedule.Interval value = randomTimeValue();\n+        IntervalSchedule.Interval value = randomTimeInterval();\n         XContentBuilder builder = jsonBuilder().value(value);\n         BytesReference bytes = builder.bytes();\n         XContentParser parser = JsonXContent.jsonXContent.createParser(bytes);\n@@ -79,7 +79,7 @@ public void testParse_Invalid_Object() throws Exception {\n         new IntervalSchedule.Parser().parse(parser);\n     }\n \n-    private static IntervalSchedule.Interval randomTimeValue() {\n+    private static IntervalSchedule.Interval randomTimeInterval() {\n         IntervalSchedule.Interval.Unit unit = IntervalSchedule.Interval.Unit.values()[randomIntBetween(0, IntervalSchedule.Interval.Unit.values().length - 1)];\n         return new IntervalSchedule.Interval(randomIntBetween(1, 100), unit);\n     }",
    "output": "Fix method clash due to randomTimeValue addition to ESTestCase"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/core/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -889,7 +889,6 @@ private void parseSource(SearchContext context, SearchSourceBuilder source) thro\n                 throw new SearchParseException(context, \"failed to parse ext source [\" + sSource + \"]\", location, e);\n             }\n         }\n-        // NOCOMMIT need to work out what to do about term_vectors_fetch (previously handled by TermVectorsFetchParseElement) as this is not available as an option in SearchSourceBuilder\n         if (source.version() != null) {\n             context.version(source.version());\n         }",
    "output": "Remove obselete NOCOMMIT"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.index.query;\n \n import org.apache.lucene.search.Query;\n+import org.elasticsearch.action.support.ToXContentToBytes;\n import org.elasticsearch.common.bytes.BytesArray;\n import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.xcontent.XContentFactory;\n@@ -44,9 +45,9 @@ protected WrapperQueryBuilder doCreateTestQueryBuilder() {\n             case 0:\n                 return new WrapperQueryBuilder(wrappedQuery.toString());\n             case 1:\n-                return new WrapperQueryBuilder(((AbstractQueryBuilder<?>)wrappedQuery).buildAsBytes().toBytes());\n+                return new WrapperQueryBuilder(((ToXContentToBytes)wrappedQuery).buildAsBytes().toBytes());\n             case 2:\n-                return new WrapperQueryBuilder(((AbstractQueryBuilder<?>)wrappedQuery).buildAsBytes());\n+                return new WrapperQueryBuilder(((ToXContentToBytes)wrappedQuery).buildAsBytes());\n             default:\n                 throw new UnsupportedOperationException();\n         }",
    "output": "Fix test bug"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/core/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -73,7 +73,6 @@\n import org.elasticsearch.indices.IndicesWarmer.TerminationHandle;\n import org.elasticsearch.indices.IndicesWarmer.WarmerContext;\n import org.elasticsearch.indices.cache.request.IndicesRequestCache;\n-import org.elasticsearch.indices.query.IndicesQueriesRegistry;\n import org.elasticsearch.node.settings.NodeSettingsService;\n import org.elasticsearch.script.ExecutableScript;\n import org.elasticsearch.script.ScriptContext;\n@@ -578,10 +577,9 @@ final SearchContext createContext(ShardSearchRequest request, @Nullable Engine.S\n                 ExecutableScript executable = this.scriptService.executable(request.template(), ScriptContext.Standard.SEARCH, context);\n                 BytesReference run = (BytesReference) executable.run();\n                 try (XContentParser parser = XContentFactory.xContent(run).createParser(run)) {\n-                    // NOCOMMIT this override the source entirely\n                     QueryParseContext queryParseContext = new QueryParseContext(indexService.queryParserService().indicesQueriesRegistry());\n                     queryParseContext.reset(parser);\n-                    request.source(SearchSourceBuilder.PROTOTYPE.fromXContent(parser, queryParseContext));\n+                    parseSource(context, SearchSourceBuilder.PROTOTYPE.fromXContent(parser, queryParseContext));\n                 }\n             }\n             parseSource(context, request.source());",
    "output": "Fix to make parseSource in SearchService work with source overriding template"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java b/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java\n--- a/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java\n@@ -807,6 +807,11 @@ public SearchSourceBuilder fromXContent(XContentParser parser, QueryParseContext\n                     XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType());\n                     xContentBuilder.copyCurrentStructure(parser);\n                     builder.suggestBuilder = xContentBuilder.bytes();\n+                } else if (context.parseFieldMatcher().match(currentFieldName, SORT_FIELD)) {\n+                    List<BytesReference> sorts = new ArrayList<>();\n+                    XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);\n+                    sorts.add(xContentBuilder.bytes());\n+                    builder.sorts = sorts;\n                 } else {\n                     throw new ParsingException(parser.getTokenLocation(), \"Unknown key for a \" + token + \" in [\" + currentFieldName + \"].\",\n                             parser.getTokenLocation());",
    "output": "Fix SearchSourceBuilder.fromXContent to allow sort to be an object"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n@@ -165,6 +165,7 @@ public MapperService(Index index, @IndexSettings Settings indexSettings, Analysi\n         }\n     }\n \n+    @Override\n     public void close() {\n         for (DocumentMapper documentMapper : mappers.values()) {\n             documentMapper.close();\n@@ -290,7 +291,7 @@ private DocumentMapper merge(DocumentMapper mapper, boolean updateAllTypes) {\n                     Set<String> parentTypesCopy = new HashSet<String>();\n                     parentTypesCopy.addAll(parentTypes);\n                     parentTypesCopy.add(mapper.parentFieldMapper().type());\n-                    parentTypes = unmodifiableSet(parentTypes);\n+                    parentTypes = unmodifiableSet(parentTypesCopy);\n                 }\n                 assert assertSerialization(mapper);\n                 return mapper;",
    "output": "Fix silly mistake"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/core/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -842,7 +842,8 @@ private void parseSource(SearchContext context, SearchSourceBuilder source) thro\n             XContentParser innerHitsParser = null;\n             try {\n                 innerHitsParser = XContentFactory.xContent(source.innerHits()).createParser(source.innerHits());\n-                this.elementParsers.get(\"highlight\").parse(innerHitsParser, context);\n+                innerHitsParser.nextToken();\n+                this.elementParsers.get(\"inner_hits\").parse(innerHitsParser, context);\n             } catch (Exception e) {\n                 String sSource = \"_na_\";\n                 try {",
    "output": "Fix inner_hits parsing in SearchService"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/core/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -695,16 +695,20 @@ private void parseSource(SearchContext context, SearchSourceBuilder source) thro\n             XContentParser completeSortParser = null;\n             try {\n                 XContentBuilder completeSortBuilder = XContentFactory.jsonBuilder();\n-                completeSortBuilder.startArray();\n+                completeSortBuilder.startObject();\n+                completeSortBuilder.startArray(\"sort\");\n                 for (BytesReference sort : source.sorts()) {\n                     XContentParser parser = XContentFactory.xContent(sort).createParser(sort);\n                     parser.nextToken();\n                     completeSortBuilder.copyCurrentStructure(parser);\n                 }\n                 completeSortBuilder.endArray();\n+                completeSortBuilder.endObject();\n                 BytesReference completeSortBytes = completeSortBuilder.bytes();\n                 completeSortParser = XContentFactory.xContent(completeSortBytes).createParser(completeSortBytes);\n                 completeSortParser.nextToken();\n+                completeSortParser.nextToken();\n+                completeSortParser.nextToken();\n                 this.elementParsers.get(\"sort\").parse(completeSortParser, context);\n             } catch (Exception e) {\n                 String sSource = \"_na_\";",
    "output": "Fix to sort parsing in SearchService"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapCliParserTests.java\n@@ -226,7 +226,7 @@ public void testThatHelpfulErrorMessageIsGivenWhenParametersAreOutOfOrder() thro\n             parser.parse(\"start\", new String[]{\"--foo=bar\", \"-Dbaz=qux\"});\n             fail(\"expected IllegalArgumentException for out-of-order parameters\");\n         } catch (IllegalArgumentException e) {\n-            assertThat(e.getMessage(), containsString(\"must appear before any parameters starting with --\"));\n+            assertThat(e.getMessage(), containsString(\"must be before any parameters starting with --\"));\n         }\n     }\n ",
    "output": "Fix broken test in BootstrapCliParserTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n--- a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n@@ -25,7 +25,6 @@\n import org.elasticsearch.common.ParseFieldMatcher;\n import org.elasticsearch.common.ParsingException;\n import org.elasticsearch.common.xcontent.XContentParser;\n-import org.elasticsearch.index.Index;\n import org.elasticsearch.indices.query.IndicesQueriesRegistry;\n \n import java.io.IOException;\n@@ -44,10 +43,6 @@ public class QueryParseContext {\n     private IndicesQueriesRegistry indicesQueriesRegistry;\n \n     public QueryParseContext(IndicesQueriesRegistry registry) {\n-        this(null, registry); // NOCOMMIT - remove index\n-    }\n-\n-    public QueryParseContext(Index index, IndicesQueriesRegistry registry) {\n         this.indicesQueriesRegistry = registry;\n         this.shardContext = null;\n     }",
    "output": "Remove index from QueryParseContext Constructor"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -217,7 +217,6 @@ static void stop() {\n      * This method is invoked by {@link Elasticsearch#main(String[])}\n      * to startup elasticsearch.\n      */\n-    @SuppressForbidden(reason = \"System#out\")\n     static void init(String[] args) throws Throwable {\n         // Set the system property before anything has a chance to trigger its use\n         System.setProperty(\"es.logger.prefix\", \"\");",
    "output": "Remove unnecessary suppression"
  },
  {
    "input": "diff --git a/watcher/src/main/java/org/elasticsearch/watcher/support/xcontent/WatcherXContentParser.java b/watcher/src/main/java/org/elasticsearch/watcher/support/xcontent/WatcherXContentParser.java\n--- a/watcher/src/main/java/org/elasticsearch/watcher/support/xcontent/WatcherXContentParser.java\n+++ b/watcher/src/main/java/org/elasticsearch/watcher/support/xcontent/WatcherXContentParser.java\n@@ -7,6 +7,7 @@\n \n import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.ParseFieldMatcher;\n import org.elasticsearch.common.xcontent.XContentLocation;\n import org.elasticsearch.common.xcontent.XContentParser;\n import org.elasticsearch.common.xcontent.XContentType;\n@@ -69,6 +70,8 @@ public static Clock clock(XContentParser parser) {\n     private final XContentParser parser;\n     private final @Nullable SecretService secretService;\n \n+    private ParseFieldMatcher parseFieldMatcher = ParseFieldMatcher.EMPTY;\n+\n     public WatcherXContentParser(XContentParser parser, Clock clock, @Nullable SecretService secretService) {\n         this.clock = clock;\n         this.parser = parser;\n@@ -260,6 +263,16 @@ public boolean isClosed() {\n         return parser.isClosed();\n     }\n \n+    @Override\n+    public ParseFieldMatcher getParseFieldMatcher() {\n+        return parseFieldMatcher;\n+    }\n+\n+    @Override\n+    public void setParseFieldMatcher(ParseFieldMatcher matcher) {\n+        this.parseFieldMatcher = matcher;\n+    }\n+\n     @Override\n     public void close() throws ElasticsearchException {\n         parser.close();",
    "output": "Fix compilation error due to changed XContentParser interface"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ElasticsearchException.java b/core/src/main/java/org/elasticsearch/ElasticsearchException.java\n--- a/core/src/main/java/org/elasticsearch/ElasticsearchException.java\n+++ b/core/src/main/java/org/elasticsearch/ElasticsearchException.java\n@@ -606,8 +606,9 @@ public static <T extends Throwable> T writeStackTraces(T throwable, StreamOutput\n         exceptions.put(org.elasticsearch.indices.TypeMissingException.class, 139);\n         // added in 3.x\n         exceptions.put(org.elasticsearch.discovery.Discovery.FailedToCommitClusterStateException.class, 140);\n+        exceptions.put(org.elasticsearch.index.query.QueryShardException.class, 141);\n \n-        final int maxOrd = 140;\n+        final int maxOrd = 141;\n         assert exceptions.size() == maxOrd + 1;\n         Constructor<? extends ElasticsearchException>[] idToSupplier = new Constructor[maxOrd + 1];\n         for (Map.Entry<Class<? extends ElasticsearchException>, Integer> e : exceptions.entrySet()) {",
    "output": "Add QueryShardException to list in ElasticsearchException"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java\n@@ -19,9 +19,6 @@\n \n package org.elasticsearch.bootstrap;\n \n-import java.util.Collections;\n-import java.util.Set;\n-\n /** \n  * Exposes system startup information \n  */\n@@ -46,14 +43,4 @@ public static boolean isNativesAvailable() {\n     public static boolean isMemoryLocked() {\n         return Natives.isMemoryLocked();\n     }\n-\n-    /**\n-     * Returns set of insecure plugins.\n-     * <p>\n-     * These are plugins with unresolved issues in third-party libraries,\n-     * that require additional privileges as a workaround.\n-     */\n-    public static Set<String> getInsecurePluginList() {\n-        return Collections.unmodifiableSet(Security.SPECIAL_PLUGINS.keySet());\n-    }\n }",
    "output": "Remove this: we are gonna manage these right"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -114,6 +114,11 @@ public class BootstrapForTesting {\n                     // in case we get fancy and use the -integration goals later:\n                     perms.add(new FilePermission(coverageDir.resolve(\"jacoco-it.exec\").toString(), \"read,write\"));\n                 }\n+                // intellij hack: intellij test runner wants setIO and will\n+                // screw up all test logging without it!\n+                if (System.getProperty(\"tests.maven\") == null) {\n+                    perms.add(new RuntimePermission(\"setIO\"));\n+                }\n \n                 final Policy policy;\n                 // if its a plugin with special permissions, we use a wrapper policy impl to try",
    "output": "Fix intellij test logging"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java b/core/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java\n--- a/core/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java\n+++ b/core/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java\n@@ -64,10 +64,6 @@ public class GroovyScriptEngineService extends AbstractComponent implements Scri\n     /**\n      * The setting to enable or disable <code>invokedynamic</code> instruction support in Java 7+.\n      * <p>\n-     * This should only be used with Java 7u60 or later because of issues related to the instruction.\n-     * The <code>invokedynamic</code> instruction allows near-Java performance from many of Groovy's\n-     * dynamic features, which is why it is enabled by default.\n-     * <p>\n      * Note: If this is disabled because <code>invokedynamic</code> is causing issues, then the Groovy\n      * <code>indy</code> jar needs to be replaced by the non-<code>indy</code> variant of it on the classpath (e.g.,\n      * <code>groovy-all-2.4.4-indy.jar</code> should be replaced by <code>groovy-all-2.4.4.jar</code>).",
    "output": "Remove note about 7u60 from master, which is Java 8+ only"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashSet.java b/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashSet.java\n--- a/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashSet.java\n+++ b/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashSet.java\n@@ -75,7 +75,7 @@ public CopyOnWriteHashSet<T> copyAndAdd(T entry) {\n      */\n     public CopyOnWriteHashSet<T> copyAndAddAll(Collection<? extends T> entries) {\n         CopyOnWriteHashMap<T, Boolean> updated = this.map.copyAndPutAll(entries.stream().map(\n-                p -> new AbstractMap.SimpleImmutableEntry<>(p, true)\n+                p -> new AbstractMap.SimpleImmutableEntry<T, Boolean>(p, true)\n         ));\n         return new CopyOnWriteHashSet<>(updated);\n     }",
    "output": "Fix compilation with ECJ (eclipse IDE etc)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -71,6 +71,7 @@\n import org.elasticsearch.transport.TransportRequestOptions;\n import org.elasticsearch.transport.TransportService;\n import org.junit.Before;\n+import org.junit.BeforeClass;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -100,6 +101,11 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return discoveryConfig.nodeSettings(nodeOrdinal);\n     }\n \n+    @BeforeClass\n+    public static void beforeClassDisruption() {\n+        assumeTrue(\"test cannot run with security manager: does evil stuff with threads\", System.getSecurityManager() == null);\n+    }\n+\n     @Before\n     public void clearConfig() {\n         discoveryConfig = null;",
    "output": "Remove some bogus permissions only needed for tests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n@@ -161,11 +161,11 @@ public void testClusterInfoServiceCollectsInformation() throws Exception {\n         }\n         for (DiskUsage usage : mostUsages.values()) {\n             logger.info(\"--> usage: {}\", usage);\n-            assertThat(\"usage has be retrieved\", usage.getFreeBytes(), greaterThanOrEqualTo(0L));\n+            assertThat(\"usage has be retrieved\", usage.getFreeBytes(), greaterThan(0L));\n         }\n         for (Long size : shardSizes.values()) {\n             logger.info(\"--> shard size: {}\", size);\n-            assertThat(\"shard size is greater than 0\", size, greaterThan(0L));\n+            assertThat(\"shard size is greater than 0\", size, greaterThanOrEqualTo(0L));\n         }\n         ClusterService clusterService = internalTestCluster.getInstance(ClusterService.class, internalTestCluster.getMasterName());\n         ClusterState state = clusterService.state();",
    "output": "Fix incorrect location for greaterThanOrEqual fix"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n--- a/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n+++ b/core/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsIT.java\n@@ -71,6 +71,7 @@\n import org.elasticsearch.transport.TransportRequestOptions;\n import org.elasticsearch.transport.TransportService;\n import org.junit.Before;\n+import org.junit.BeforeClass;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -100,6 +101,11 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return discoveryConfig.nodeSettings(nodeOrdinal);\n     }\n \n+    @BeforeClass\n+    public static void beforeClassDisruption() {\n+        assumeTrue(\"test cannot run with security manager: does evil stuff with threads\", System.getSecurityManager() == null);\n+    }\n+\n     @Before\n     public void clearConfig() {\n         discoveryConfig = null;",
    "output": "Remove some bogus permissions only needed for tests. Especially the worst of the worst with thread permissions: for example, this prevents some code from starting daemon thread that will outlive the elasticsearch process and hang around doing evil shit"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n@@ -41,6 +41,7 @@\n import org.apache.lucene.util.IOUtils;\n import org.apache.lucene.util.TestUtil;\n import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.Version;\n import org.elasticsearch.action.support.TransportActions;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n@@ -1728,9 +1729,11 @@ public void testTranslogReplayWithFailure() throws IOException {\n                     engine = createEngine(store, primaryTranslogDir);\n                     started = true;\n                     break;\n-                } catch (EngineCreationFailureException | AssertionError ex) {\n-                    // IndexWriter can throw AssertionError on init (if asserts are enabled) if we throw FNFE/NSFE when it asserts that all\n-                    // referenced files in the current commit point do exist\n+                } catch (EngineCreationFailureException ex) {\n+                } catch (AssertionError ex) {\n+                    // IndexWriter can throw AssertionError on init (if asserts are enabled) if our directory randomly throws FNFE/NSFE when\n+                    // it asserts that all referenced files in the current commit point do exist\n+                    assertTrue(ExceptionsHelper.stackTrace(ex).contains(\"org.apache.lucene.index.IndexWriter.filesExist\"));\n                 }\n             }\n ",
    "output": "Fix test case to verify the AssertionError did in fact come from IndexWriter.filesExist"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java b/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java\n--- a/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java\n+++ b/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java\n@@ -19,8 +19,6 @@\n \n package org.elasticsearch.common.util.iterable;\n \n-import org.elasticsearch.common.lucene.store.IndexOutputOutputStream;\n-\n import java.util.*;\n import java.util.stream.Stream;\n import java.util.stream.StreamSupport;\n\ndiff --git a/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java b/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java\n@@ -30,6 +30,7 @@\n import java.util.Collection;\n import java.util.Iterator;\n import java.util.List;\n+import java.util.stream.StreamSupport;\n \n public class FieldTypeLookupTests extends ESTestCase {\n ",
    "output": "Remove unused import in o.e.c.u.i.Iterables"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n@@ -1728,7 +1728,9 @@ public void testTranslogReplayWithFailure() throws IOException {\n                     engine = createEngine(store, primaryTranslogDir);\n                     started = true;\n                     break;\n-                } catch (EngineCreationFailureException ex) {\n+                } catch (EngineCreationFailureException | AssertionError ex) {\n+                    // IndexWriter can throw AssertionError on init (if asserts are enabled) if we throw FNFE/NSFE when it asserts that all\n+                    // referenced files in the current commit point do exist\n                 }\n             }\n ",
    "output": "Fix InternalEngineTests.testTranslogReplayWithFailure to expect AssertionError as well"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java\n@@ -1728,7 +1728,9 @@ public void testTranslogReplayWithFailure() throws IOException {\n                     engine = createEngine(store, primaryTranslogDir);\n                     started = true;\n                     break;\n-                } catch (EngineCreationFailureException ex) {\n+                } catch (EngineCreationFailureException | AssertionError ex) {\n+                    // IndexWriter can throw AssertionError on init (if asserts are enabled) if we throw FNFE/NSFE when it asserts that all\n+                    // referenced files in the current commit point do exist\n                 }\n             }\n ",
    "output": "Fix test to expect AssertionError as well"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java b/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java\n--- a/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java\n+++ b/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.threadpool;\n \n-import com.google.common.util.concurrent.MoreExecutors;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor;\n import org.elasticsearch.test.ESTestCase;",
    "output": "Remove unused import in o.e.t.UpdateThreadPoolSettingsTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java\n--- a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java\n+++ b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java\n@@ -18,7 +18,6 @@\n  */\n package org.elasticsearch.action.termvectors;\n \n-import com.google.common.util.concurrent.AtomicLongMap;\n import org.apache.lucene.index.*;\n import org.apache.lucene.search.TermStatistics;\n import org.apache.lucene.search.similarities.DefaultSimilarity;",
    "output": "Remove unused import in o.e.a.t.TermVectorsFilter"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java b/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java\n--- a/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java\n@@ -24,7 +24,6 @@\n import com.carrotsearch.randomizedtesting.annotations.TestGroup;\n import com.carrotsearch.randomizedtesting.generators.RandomInts;\n import com.carrotsearch.randomizedtesting.generators.RandomPicks;\n-import com.google.common.base.Joiner;\n import org.apache.http.impl.client.HttpClients;\n import org.apache.lucene.util.IOUtils;\n import org.apache.lucene.util.LuceneTestCase;",
    "output": "Remove unused import in o.e.t.ESIntegTestCase"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java b/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java\n--- a/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java\n+++ b/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java\n@@ -18,7 +18,6 @@\n  */\n package org.elasticsearch.common.util;\n \n-import com.google.common.math.LongMath;\n import com.google.common.primitives.Ints;\n import org.apache.lucene.store.DataInput;\n import org.apache.lucene.store.DataOutput;\n@@ -33,7 +32,6 @@\n import org.elasticsearch.common.unit.SizeValue;\n \n import java.io.IOException;\n-import java.math.RoundingMode;\n import java.util.Arrays;\n import java.util.Comparator;\n \n@@ -321,7 +319,13 @@ static final class BitArray {\n         long bitCount;\n \n         BitArray(long bits) {\n-            this(new long[Ints.checkedCast(LongMath.divide(bits, 64, RoundingMode.CEILING))]);\n+            this(new long[size(bits)]);\n+        }\n+\n+        private static int size(long bits) {\n+            long quotient = bits / 64;\n+            long remainder = bits - quotient * 64;\n+            return Ints.checkedCast(remainder == 0 ? quotient : 1 + quotient);\n         }\n \n         // Used by serialization",
    "output": "Remove and forbid use of com.google.common.math.LongMath"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java b/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java\n--- a/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java\n+++ b/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java\n@@ -18,7 +18,6 @@\n  */\n package org.elasticsearch.common.util;\n \n-import com.google.common.math.LongMath;\n import com.google.common.primitives.Ints;\n import org.apache.lucene.store.DataInput;\n import org.apache.lucene.store.DataOutput;\n@@ -33,7 +32,6 @@\n import org.elasticsearch.common.unit.SizeValue;\n \n import java.io.IOException;\n-import java.math.RoundingMode;\n import java.util.Arrays;\n import java.util.Comparator;\n \n@@ -321,7 +319,13 @@ static final class BitArray {\n         long bitCount;\n \n         BitArray(long bits) {\n-            this(new long[Ints.checkedCast(LongMath.divide(bits, 64, RoundingMode.CEILING))]);\n+            this(new long[size(bits)]);\n+        }\n+\n+        private static int size(long bits) {\n+            long quotient = bits / 64;\n+            long remainder = bits - quotient * 64;\n+            return Ints.checkedCast(remainder == 0 ? quotient : 1 + quotient);\n         }\n \n         // Used by serialization",
    "output": "Remove and forbid use of com.google.common.math.LongMath This commit removes and now forbids all uses of com.google.common.math.LongMath across the codebase. This is one step of many in the eventual removal of Guava as a dependency"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n@@ -161,7 +161,7 @@ public void testClusterInfoServiceCollectsInformation() throws Exception {\n         }\n         for (DiskUsage usage : mostUsages.values()) {\n             logger.info(\"--> usage: {}\", usage);\n-            assertThat(\"usage has be retrieved\", usage.getFreeBytes(), greaterThan(0L));\n+            assertThat(\"usage has be retrieved\", usage.getFreeBytes(), greaterThanOrEqualTo(0L));\n         }\n         for (Long size : shardSizes.values()) {\n             logger.info(\"--> shard size: {}\", size);",
    "output": "Use greaterThanOrEqualTo for testClusterInfoServiceCollectsInformation"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java b/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n--- a/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n@@ -20,6 +20,7 @@\n \n import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n+import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;\n import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;\n import org.elasticsearch.cache.recycler.PageCacheRecycler;\n import org.elasticsearch.client.Client;\n@@ -66,6 +67,10 @@ private static void reset() {\n     private static void startNode() {\n         assert NODE == null;\n         NODE = newNode();\n+        // we must wait for the node to actually be up and running. otherwise the node might have started, elected itself master but might not yet have removed the\n+        // SERVICE_UNAVAILABLE/1/state not recovered / initialized block\n+        ClusterHealthResponse clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForGreenStatus().get();\n+        assertFalse(clusterHealthResponse.isTimedOut());\n     }\n \n     private static void stopNode() {",
    "output": "Make sure ESSingleNodeTestCase waits after starting node until"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java b/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n--- a/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java\n@@ -20,6 +20,7 @@\n \n import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n+import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;\n import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;\n import org.elasticsearch.cache.recycler.PageCacheRecycler;\n import org.elasticsearch.client.Client;\n@@ -66,6 +67,10 @@ private static void reset() {\n     private static void startNode() {\n         assert NODE == null;\n         NODE = newNode();\n+        // we must wait for the node to actually be up and running. otherwise the node might have started, elected itself master but might not yet have removed the\n+        // SERVICE_UNAVAILABLE/1/state not recovered / initialized block\n+        ClusterHealthResponse clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForGreenStatus().get();\n+        assertFalse(clusterHealthResponse.isTimedOut());\n     }\n \n     private static void stopNode() {",
    "output": "Make sure ESSingleNodeTestCase waits after starting node until all blocks removed When a single node starts up it will first elect itself as master and then tries to recover the cluster state or, if there is none, initialize an empty one and publish it. Until it has done that, the cluster state will contain a global block and requests might fail with SERVICE_UNAVAILABLE/1/state not recovered / initialized We need to wait for green"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridIT.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridIT.java\n@@ -24,6 +24,7 @@\n import com.carrotsearch.hppc.ObjectObjectMap;\n import com.carrotsearch.hppc.cursors.ObjectIntCursor;\n \n+import org.apache.lucene.util.LuceneTestCase;\n import org.apache.lucene.util.XGeoHashUtils;\n import org.elasticsearch.action.index.IndexRequestBuilder;\n import org.elasticsearch.action.search.SearchResponse;\n@@ -148,6 +149,7 @@ public void setupSuiteScopeCluster() throws Exception {\n \n \n     @Test\n+    @LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/13558\")\n     public void simple() throws Exception {\n         for (int precision = 1; precision <= XGeoHashUtils.PRECISION; precision++) {\n             SearchResponse response = client().prepareSearch(\"idx\")",
    "output": "Add AwaitsFix for https://github.com/elastic/elasticsearch/issues/13558"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java b/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n--- a/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java\n@@ -206,7 +206,7 @@ void setClusterState(TestClusterService clusterService, String index) {\n         for (int i = 0; i < numberOfNodes; i++) {\n             final DiscoveryNode node = newNode(i);\n             discoBuilder = discoBuilder.put(node);\n-            int numberOfShards = randomIntBetween(0, 10);\n+            int numberOfShards = randomIntBetween(1, 10);\n             for (int j = 0; j < numberOfShards; j++) {\n                 final ShardId shardId = new ShardId(index, ++shardIndex);\n                 ShardRouting shard = TestShardRouting.newShardRouting(index, shardId.getId(), node.id(), true, ShardRoutingState.STARTED, 1);",
    "output": "Fix test bug in o.e.a.s.b.n.TransportBroadcastByNodeActionTests This commit fixes a test bug in o.e.a.s.b.n.TransportBroadcastByNodeActionTests. Namely, the randomized test allowed for the creation of cluster states that allocated indices having zero shards. This ultimately surfaced in a NoSuchElementException when attempting to iterate over the nonexistent shards. The fix is merely to draw the random number of shards from 1 to 10 instead of 0 to 10"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n@@ -1241,6 +1241,10 @@ private void commitIndexWriter(IndexWriter writer, Translog translog) throws IOE\n     public void onSettingsChanged() {\n         mergeScheduler.refreshConfig();\n         updateIndexWriterSettings();\n+        // config().getVersionMapSize() may have changed:\n+        checkVersionMapRefresh();\n+        // config().isEnableGcDeletes() or config.getGcDeletesInMillis() may have changed:\n+        maybePruneDeletedTombstones();\n     }\n \n     public MergeStats getMergeStats() {\n\ndiff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n@@ -1137,8 +1137,6 @@ public void onRefreshSettings(Settings settings) {\n             indexingService.onRefreshSettings(settings);\n             if (change) {\n                 engine().onSettingsChanged();\n-                // TODO: why force a refresh here...?\n-                refresh(\"apply settings\");\n             }\n         }\n     }",
    "output": "Remove forced refresh on settings update"
  },
  {
    "input": "diff --git a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java\n--- a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java\n+++ b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java\n@@ -111,7 +111,7 @@ public MulticastZenPing(Settings settings, ThreadPool threadPool, TransportServi\n \n         logger.debug(\"using group [{}], with port [{}], ttl [{}], and address [{}]\", group, port, ttl, address);\n \n-        this.transportService.registerRequestHandler(ACTION_NAME, MulticastPingResponse.class, ThreadPool.Names.SAME, new MulticastPingResponseRequestHandler());\n+        this.transportService.registerRequestHandler(ACTION_NAME, MulticastPingResponse::new, ThreadPool.Names.SAME, new MulticastPingResponseRequestHandler());\n     }\n \n     @Override",
    "output": "Fix compilation error"
  },
  {
    "input": "diff --git a/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherIndexTemplateRegistry.java b/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherIndexTemplateRegistry.java\n--- a/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherIndexTemplateRegistry.java\n+++ b/watcher/src/main/java/org/elasticsearch/watcher/support/WatcherIndexTemplateRegistry.java\n@@ -152,7 +152,7 @@ public void onRefreshSettings(Settings settings) {\n     private void putTemplate(final TemplateConfig config, boolean wait) {\n         final Executor executor;\n         if (wait) {\n-            executor = MoreExecutors.directExecutor();\n+            executor = Runnable::run;\n         } else {\n             executor = threadPool.generic();\n         }\n\ndiff --git a/watcher/src/test/java/org/elasticsearch/watcher/WatcherLifeCycleServiceTests.java b/watcher/src/test/java/org/elasticsearch/watcher/WatcherLifeCycleServiceTests.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/WatcherLifeCycleServiceTests.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/WatcherLifeCycleServiceTests.java\n@@ -18,6 +18,8 @@\n import org.mockito.invocation.InvocationOnMock;\n import org.mockito.stubbing.Answer;\n \n+import java.util.concurrent.Executor;\n+\n import static org.mockito.Matchers.anyString;\n import static org.mockito.Mockito.*;\n \n@@ -32,7 +34,7 @@ public class WatcherLifeCycleServiceTests extends ESTestCase {\n     @Before\n     public void prepareServices() {\n         ThreadPool threadPool = mock(ThreadPool.class);\n-        when(threadPool.executor(anyString())).thenReturn(MoreExecutors.newDirectExecutorService());\n+        when(threadPool.executor(anyString())).thenReturn(Runnable::run);\n         clusterService = mock(ClusterService.class);\n         Answer<Object> answer = new Answer<Object>() {\n             @Override",
    "output": "Fix forbidden usage of Guava's MoreExecutors in Watcher"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditUserHolder.java b/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditUserHolder.java\n--- a/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditUserHolder.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditUserHolder.java\n@@ -6,6 +6,7 @@\n package org.elasticsearch.shield.audit.index;\n \n import org.elasticsearch.action.admin.indices.exists.indices.IndicesExistsAction;\n+import org.elasticsearch.action.admin.indices.mapping.put.PutMappingAction;\n import org.elasticsearch.action.admin.indices.template.put.PutIndexTemplateAction;\n import org.elasticsearch.action.bulk.BulkAction;\n import org.elasticsearch.shield.User;\n@@ -27,6 +28,7 @@ public class IndexAuditUserHolder {\n         .add(Privilege.Index.INDEX, IndexAuditTrail.INDEX_NAME_PREFIX + \"*\")\n         .add(Privilege.Index.action(IndicesExistsAction.NAME), IndexAuditTrail.INDEX_NAME_PREFIX + \"*\")\n         .add(Privilege.Index.action(BulkAction.NAME), IndexAuditTrail.INDEX_NAME_PREFIX + \"*\")\n+        .add(Privilege.Index.action(PutMappingAction.NAME), IndexAuditTrail.INDEX_NAME_PREFIX + \"*\")\n         .build();\n \n     public IndexAuditUserHolder() {",
    "output": "Add missing PutMapping privilege for index audit trail user"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java\n@@ -24,6 +24,7 @@\n import org.junit.Test;\n \n import java.io.IOException;\n+import java.net.MalformedURLException;\n import java.nio.file.Path;\n \n import static org.elasticsearch.common.cli.CliTool.ExitStatus.OK_AND_EXIT;\n@@ -54,11 +55,12 @@ public void testHelpWorks() throws IOException {\n         assertTerminalOutputContainsHelpFile(terminal, \"/org/elasticsearch/plugins/plugin-list.help\");\n     }\n \n-    public void testUrlSpacesInPath() {\n+    public void testUrlSpacesInPath() throws MalformedURLException {\n         CliToolTestCase.CaptureOutputTerminal terminal = new CliToolTestCase.CaptureOutputTerminal();\n-        Path tmpDir = createTempDir().resolve(\"foo\");\n-        String finalDir = tmpDir.toAbsolutePath().toString() + \"%20deps\";\n-        CliTool.ExitStatus execute = new PluginManagerCliParser(terminal).execute(args(\"install file://\" + finalDir));\n+        Path tmpDir = createTempDir().resolve(\"foo deps\");\n+        String finalDir = tmpDir.toAbsolutePath().toUri().toURL().toString();\n+        logger.warn(finalDir);\n+        CliTool.ExitStatus execute = new PluginManagerCliParser(terminal).execute(args(\"install \" + finalDir));\n         assertThat(execute.status(), is(IO_ERROR.status()));\n     }\n }",
    "output": "Fix urls for windows"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java\n@@ -24,6 +24,7 @@\n import org.junit.Test;\n \n import java.io.IOException;\n+import java.nio.file.Path;\n \n import static org.elasticsearch.common.cli.CliTool.ExitStatus.OK_AND_EXIT;\n import static org.elasticsearch.common.cli.CliTool.ExitStatus.IO_ERROR;\n@@ -55,8 +56,9 @@ public void testHelpWorks() throws IOException {\n \n     public void testUrlSpacesInPath() {\n         CliToolTestCase.CaptureOutputTerminal terminal = new CliToolTestCase.CaptureOutputTerminal();\n-        CliTool.ExitStatus execute = new PluginManagerCliParser(terminal).execute(args(\"install file://foo%20deps\"));\n+        Path tmpDir = createTempDir().resolve(\"foo\");\n+        String finalDir = tmpDir.toAbsolutePath().toString() + \"%20deps\";\n+        CliTool.ExitStatus execute = new PluginManagerCliParser(terminal).execute(args(\"install file://\" + finalDir));\n         assertThat(execute.status(), is(IO_ERROR.status()));\n-\n     }\n }",
    "output": "Use tmp dir otherwise the security manager will complain"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java\n@@ -19,8 +19,6 @@\n \n package org.elasticsearch.index.query;\n \n-import com.google.common.collect.Sets;\n-\n import org.apache.lucene.queries.TermsQuery;\n import org.apache.lucene.search.Query;\n import org.elasticsearch.cluster.metadata.MetaData;\n@@ -42,7 +40,7 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {\n \n     public static final String NAME = \"ids\";\n \n-    private final Set<String> ids = Sets.newHashSet();\n+    private final Set<String> ids = new HashSet<>();\n \n     private final String[] types;\n \n@@ -135,7 +133,8 @@ protected Query doToQuery(QueryShardContext context) throws IOException {\n             } else if (types.length == 1 && MetaData.ALL.equals(types[0])) {\n                 typesForQuery = context.mapperService().types();\n             } else {\n-                typesForQuery = Sets.newHashSet(types);\n+                typesForQuery = new HashSet<>();\n+                Collections.addAll(typesForQuery, types);\n             }\n \n             query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(typesForQuery, ids));",
    "output": "Remove guava usage from IdsQueryBuilder"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java\n@@ -19,8 +19,6 @@\n \n package org.elasticsearch.index.query;\n \n-import com.carrotsearch.randomizedtesting.annotations.Repeat;\n-\n import org.apache.lucene.search.BooleanQuery;\n import org.apache.lucene.search.ConstantScoreQuery;\n import org.apache.lucene.search.Query;\n@@ -47,7 +45,6 @@\n import static org.hamcrest.Matchers.instanceOf;\n import static org.hamcrest.Matchers.notNullValue;\n \n-@Repeat(iterations = 100)\n public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQueryBuilder> {\n \n     private static String indexedShapeId;",
    "output": "Remove @Repeat Annotation"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java b/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java\n--- a/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java\n+++ b/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java\n@@ -28,7 +28,7 @@\n \n import static org.hamcrest.Matchers.equalTo;\n \n-public class ShapeRalationTests extends ESTestCase {\n+public class ShapeRelationTests extends ESTestCase {\n \n     public void testValidOrdinals() {\n         assertThat(ShapeRelation.INTERSECTS.ordinal(), equalTo(0));",
    "output": "Fix Typo in Test Name"
  },
  {
    "input": "diff --git a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n--- a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n+++ b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java\n@@ -69,7 +69,7 @@ public abstract class ESSmokeClientTestCase extends LuceneTestCase {\n      */\n     public static final String TESTS_CLUSTER_DEFAULT = \"localhost:9300\";\n \n-    protected static ESLogger logger = ESLoggerFactory.getLogger(ESSmokeClientTestCase.class.getName());\n+    protected static final ESLogger logger = ESLoggerFactory.getLogger(ESSmokeClientTestCase.class.getName());\n \n     private static final AtomicInteger counter = new AtomicInteger();\n     private static Client client;",
    "output": "Make logger final so its not detected as a static leak"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java b/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java\n--- a/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java\n+++ b/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java\n@@ -20,8 +20,8 @@\n package org.elasticsearch.common.recycler;\n \n import com.carrotsearch.hppc.BitMixer;\n-import com.google.common.collect.Queues;\n-import org.elasticsearch.ElasticsearchException;\n+\n+import java.util.ArrayDeque;\n \n public enum Recyclers {\n     ;\n@@ -44,7 +44,7 @@ public static <T> Recycler<T> concurrentDeque(Recycler.C<T> c, int limit) {\n      * Return a recycler based on a deque.\n      */\n     public static <T> Recycler<T> deque(Recycler.C<T> c, int limit) {\n-        return new DequeRecycler<>(c, Queues.<T>newArrayDeque(), limit);\n+        return new DequeRecycler<>(c, new ArrayDeque<>(), limit);\n     }\n \n     /**",
    "output": "Remove and forbid use of com.google.common.collect.Queues"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java b/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java\n--- a/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java\n+++ b/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java\n@@ -20,8 +20,8 @@\n package org.elasticsearch.common.recycler;\n \n import com.carrotsearch.hppc.BitMixer;\n-import com.google.common.collect.Queues;\n-import org.elasticsearch.ElasticsearchException;\n+\n+import java.util.ArrayDeque;\n \n public enum Recyclers {\n     ;\n@@ -44,7 +44,7 @@ public static <T> Recycler<T> concurrentDeque(Recycler.C<T> c, int limit) {\n      * Return a recycler based on a deque.\n      */\n     public static <T> Recycler<T> deque(Recycler.C<T> c, int limit) {\n-        return new DequeRecycler<>(c, Queues.<T>newArrayDeque(), limit);\n+        return new DequeRecycler<>(c, new ArrayDeque<>(), limit);\n     }\n \n     /**",
    "output": "Remove and forbid use of com.google.common.collect.Queues This commit removes and now forbids all uses of com.google.common.collect.Queues across the codebase. This is one of many steps in the eventual removal of Guava as a dependency. Relates"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java\n--- a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java\n+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java\n@@ -73,7 +73,16 @@ public class JvmInfo implements Streamable, ToXContent {\n             // ignore\n         }\n         info.inputArguments = runtimeMXBean.getInputArguments().toArray(new String[runtimeMXBean.getInputArguments().size()]);\n-        info.bootClassPath = runtimeMXBean.getBootClassPath();\n+        try {\n+            info.bootClassPath = runtimeMXBean.getBootClassPath();\n+        } catch (UnsupportedOperationException e) {\n+            // oracle java 9\n+            info.bootClassPath = System.getProperty(\"sun.boot.class.path\");\n+            if (info.bootClassPath == null) {\n+                // something else\n+                info.bootClassPath = \"<unknown>\";\n+            }\n+        }\n         info.classPath = runtimeMXBean.getClassPath();\n         info.systemProperties = runtimeMXBean.getSystemProperties();\n ",
    "output": "Add java 9 support for bootclasspath to JvmInfo (it throws UOE otherwise which is not properly handled)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java\n--- a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java\n@@ -155,6 +155,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return Settings.builder()\n             .putArray(URLRepository.ALLOWED_URLS_SETTING, \"http://snapshot.test*\")\n             .put(Node.HTTP_ENABLED, true)\n+            .put(\"node.testattr\", \"test\")\n             .put(super.nodeSettings(nodeOrdinal)).build();\n     }\n     ",
    "output": "Fix test for _cat/nodeattrs"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java\n--- a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java\n@@ -155,6 +155,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return Settings.builder()\n             .putArray(URLRepository.ALLOWED_URLS_SETTING, \"http://snapshot.test*\")\n             .put(Node.HTTP_ENABLED, true)\n+            .put(\"node.testattr\", \"test\")\n             .put(super.nodeSettings(nodeOrdinal)).build();\n     }\n     ",
    "output": "Fix test for _cat/nodeattrs Adds a node attribute to all test runs and uses the attribute to test `_cat/nodeattrs`. Note that its quite possible create an impressively slow regex while doing this and you have to be careful. See comment in commit for more if curious"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java\n@@ -42,18 +42,19 @@\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.notNullValue;\n \n-public class MatchQueryBuilderTests extends BaseQueryTestCase<MatchQueryBuilder> {\n+public class MatchQueryBuilderTests extends AbstractQueryTestCase<MatchQueryBuilder> {\n \n     @Override\n     protected MatchQueryBuilder doCreateTestQueryBuilder() {\n         String fieldName = randomFrom(new String[] { STRING_FIELD_NAME, BOOLEAN_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME });\n         Object value = \"\";\n         if (fieldName.equals(STRING_FIELD_NAME)) {\n             int terms = randomIntBetween(0, 3);\n+            StringBuilder builder = new StringBuilder();\n             for (int i = 0; i < terms; i++) {\n-                value += randomAsciiOfLengthBetween(1, 10) + \" \";\n+                builder.append(randomAsciiOfLengthBetween(1, 10) + \" \");\n             }\n-            value = ((String) value).trim();\n+            value = builder.toString().trim();\n         } else {\n             value = getRandomValueForFieldName(fieldName);\n         }",
    "output": "Use AbstractQueryTestCase in MatchQueryBuilderTests"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersTool.java b/shield/src/main/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersTool.java\n--- a/shield/src/main/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersTool.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersTool.java\n@@ -389,7 +389,7 @@ public ExitStatus doExecute(Settings settings, Environment env) throws Exception\n             roles.addAll(Arrays.asList(addRoles));\n             roles.removeAll(Arrays.asList(removeRoles));\n \n-            Map<String, String[]> userRolesToWrite = Maps.newHashMapWithExpectedSize(userRoles.size());\n+            Map<String, String[]> userRolesToWrite = new HashMap<>(userRoles.size());\n             userRolesToWrite.putAll(userRoles);\n             if (roles.size() == 0) {\n                 userRolesToWrite.remove(username);",
    "output": "Fix build - cleaned up the use of guava Maps"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java\n--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java\n@@ -57,7 +57,7 @@ protected TemplateQueryBuilder doCreateTestQueryBuilder() {\n \n     @Override\n     protected void doAssertLuceneQuery(TemplateQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {\n-        assertEquals(templateBase.toQuery(createShardContext()), query);\n+        assertEquals(templateBase.toQuery(context), query);\n     }\n \n     @Test",
    "output": "Fix template query with unmapped fields"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java\n--- a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java\n@@ -19,8 +19,8 @@\n \n package org.elasticsearch.client;\n \n-import com.google.common.base.Throwables;\n import com.google.common.collect.ImmutableMap;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.ActionListener;\n import org.elasticsearch.action.GenericAction;\n import org.elasticsearch.action.admin.cluster.reroute.ClusterRerouteAction;\n@@ -59,7 +59,9 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-import static org.hamcrest.Matchers.*;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n \n /**\n  *\n@@ -228,7 +230,7 @@ public Throwable unwrap(Throwable t, Class<? extends Throwable> exceptionType) {\n                 }\n                 if (counter++ > 10) {\n                     // dear god, if we got more than 10 levels down, WTF? just bail\n-                    fail(\"Exception cause unwrapping ran for 10 levels: \" + Throwables.getStackTraceAsString(t));\n+                    fail(\"Exception cause unwrapping ran for 10 levels: \" + ExceptionsHelper.stackTrace(t));\n                     return null;\n                 }\n                 result = result.getCause();",
    "output": "Remove and forbid use of com.google.common.base.Throwables"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java\n--- a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java\n@@ -19,8 +19,8 @@\n \n package org.elasticsearch.client;\n \n-import com.google.common.base.Throwables;\n import com.google.common.collect.ImmutableMap;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.ActionListener;\n import org.elasticsearch.action.GenericAction;\n import org.elasticsearch.action.admin.cluster.reroute.ClusterRerouteAction;\n@@ -59,7 +59,9 @@\n import java.util.HashMap;\n import java.util.Map;\n \n-import static org.hamcrest.Matchers.*;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n \n /**\n  *\n@@ -228,7 +230,7 @@ public Throwable unwrap(Throwable t, Class<? extends Throwable> exceptionType) {\n                 }\n                 if (counter++ > 10) {\n                     // dear god, if we got more than 10 levels down, WTF? just bail\n-                    fail(\"Exception cause unwrapping ran for 10 levels: \" + Throwables.getStackTraceAsString(t));\n+                    fail(\"Exception cause unwrapping ran for 10 levels: \" + ExceptionsHelper.stackTrace(t));\n                     return null;\n                 }\n                 result = result.getCause();",
    "output": "Remove and forbid use of com.google.common.base.Throwables This commit removes and now forbids all uses of com.google.common.base.Throwables across the codebase. For uses of com.google.common.base.Throwables#getStackTraceAsString, use org.elasticsearch.ExceptionsHelper#stackTrace. Relates"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -61,13 +61,7 @@ public class BootstrapForTesting {\n         try {\n             JarHell.checkJarHell();\n         } catch (Exception e) {\n-            if (Boolean.parseBoolean(System.getProperty(\"tests.maven\"))) {\n-                throw new RuntimeException(\"found jar hell in test classpath\", e);\n-            } else {\n-                Loggers.getLogger(BootstrapForTesting.class)\n-                    .warn(\"Your ide or custom test runner has jar hell issues, \" +\n-                          \"you might want to look into that\", e);\n-            }\n+            throw new RuntimeException(\"found jar hell in test classpath\", e);\n         }\n \n         // make sure java.io.tmpdir exists always (in case code uses it in a static initializer)",
    "output": "Remove intellij leniency. fix your IDE instead. it gives people the wrong idea"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java b/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java\n--- a/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/support/single/shard/TransportSingleShardAction.java\n@@ -210,6 +210,14 @@ private void perform(@Nullable final Throwable currentFailure) {\n                 onFailure(shardRouting, new NoShardAvailableActionException(shardRouting.shardId()));\n             } else {\n                 internalRequest.request().internalShardId = shardRouting.shardId();\n+                if (logger.isTraceEnabled()) {\n+                    logger.trace(\n+                            \"sending request [{}] to shard [{}] on node [{}]\",\n+                            internalRequest.request(),\n+                            internalRequest.request().internalShardId,\n+                            node\n+                    );\n+                }\n                 transportService.sendRequest(node, transportShardAction, internalRequest.request(), new BaseTransportResponseHandler<Response>() {\n \n                     @Override",
    "output": "Add trace logging before sending single shard requests"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/authc/pki/PkiRealm.java b/shield/src/main/java/org/elasticsearch/shield/authc/pki/PkiRealm.java\n--- a/shield/src/main/java/org/elasticsearch/shield/authc/pki/PkiRealm.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/authc/pki/PkiRealm.java\n@@ -5,7 +5,7 @@\n  */\n package org.elasticsearch.shield.authc.pki;\n \n-import com.google.common.base.Strings;\n+import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.settings.Settings;",
    "output": "Remove and forbid use of com.google.common.base.Strings This commit removes and now forbids all uses of com.google.common.base.Strings across the codebase. For uses of com.google.common.base.Strings.isNullOrEmpty, use org.elasticsearch.common.Strings.isNullOrEmpty. For uses of com.google.common.base.Strings.padStart use org.elasticsearch.common.Strings.padStart. For uses of com.google.common.base.Strings.nullToEmpty use org.elasticsearch.common.Strings.coalesceToEmpty. Relates elastic/elasticsearchelastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java\n@@ -154,14 +154,14 @@ public AliasAction filter(Map<String, Object> filter) {\n         }\n     }\n \n-    public AliasAction filter(QueryBuilder filterBuilder) {\n-        if (filterBuilder == null) {\n+    public AliasAction filter(QueryBuilder queryBuilder) {\n+        if (queryBuilder == null) {\n             this.filter = null;\n             return this;\n         }\n         try {\n             XContentBuilder builder = XContentFactory.jsonBuilder();\n-            filterBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);\n+            queryBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);\n             builder.close();\n             this.filter = builder.string();\n             return this;",
    "output": "Upgrade param name to match type"
  },
  {
    "input": "diff --git a/watcher/src/test/java/org/elasticsearch/watcher/actions/email/service/EmailTests.java b/watcher/src/test/java/org/elasticsearch/watcher/actions/email/service/EmailTests.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/actions/email/service/EmailTests.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/actions/email/service/EmailTests.java\n@@ -23,7 +23,7 @@\n \n /**\n  */\n-public class EmailTest extends ESTestCase {\n+public class EmailTests extends ESTestCase {\n \n     @Test\n     public void testEmail_Parser_SelfGenerated() throws Exception {",
    "output": "Fix test naming, Test -> Tests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasAction.java\n@@ -154,14 +154,14 @@ public AliasAction filter(Map<String, Object> filter) {\n         }\n     }\n \n-    public AliasAction filter(QueryBuilder filterBuilder) {\n-        if (filterBuilder == null) {\n+    public AliasAction filter(QueryBuilder queryBuilder) {\n+        if (queryBuilder == null) {\n             this.filter = null;\n             return this;\n         }\n         try {\n             XContentBuilder builder = XContentFactory.jsonBuilder();\n-            filterBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);\n+            queryBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);\n             builder.close();\n             this.filter = builder.string();\n             return this;",
    "output": "Upgrade param name to match type"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java b/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java\n--- a/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java\n+++ b/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.common.util.concurrent;\n \n-import com.google.common.annotations.Beta;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.transport.Transports;\n \n@@ -195,7 +194,6 @@ protected boolean setException(Throwable throwable) {\n         return result;\n     }\n \n-    @Beta\n     protected void done() {\n     }\n ",
    "output": "Remove sole usgae of com.google.common.annotations.Beta"
  },
  {
    "input": "diff --git a/watcher/src/test/java/org/elasticsearch/watcher/actions/hipchat/service/HipChatMessageTests.java b/watcher/src/test/java/org/elasticsearch/watcher/actions/hipchat/service/HipChatMessageTests.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/actions/hipchat/service/HipChatMessageTests.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/actions/hipchat/service/HipChatMessageTests.java\n@@ -141,15 +141,15 @@ public void testEquals() throws Exception {\n                         randomFrom(HipChatMessage.Format.values()) :\n                         randomBoolean() ?\n                                 null :\n-                                randomFrom(HipChatMessage.Format.values(), format);\n+                                    randomFromWithExcludes(HipChatMessage.Format.values(), format);\n             }\n             if (rarely()) {\n                 equals = false;\n                 color = color == null ?\n                         randomFrom(HipChatMessage.Color.values()) :\n                         randomBoolean() ?\n                                 null :\n-                                randomFrom(HipChatMessage.Color.values(), color);\n+                                    randomFromWithExcludes(HipChatMessage.Color.values(), color);\n             }\n             if (rarely()) {\n                 equals = false;\n@@ -277,7 +277,7 @@ public void testTemplate_ParseSelfGenerated() throws Exception {\n \n     }\n \n-    static <E extends Enum> E randomFrom(E[] values, E... exclude) {\n+    static <E extends Enum> E randomFromWithExcludes(E[] values, E... exclude) {\n         List<E> excludes = Arrays.asList(exclude);\n         List<E> includes = new ArrayList<>();\n         for (E value : values) {",
    "output": "Fix to make x-plugins repo work in eclipse This includes the following: - Updated .gitignore to be the same as the elasticsearch repo so eclipse files are correctly ignored - Fixes ambiguous method call compile error in HipChatMessageTests"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java\n--- a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java\n+++ b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java\n@@ -159,11 +159,7 @@ public void postIndex(Engine.Index index, Throwable ex) {\n         totalStats.indexCurrent.dec();\n         typeStats(index.type()).indexCurrent.dec();\n         for (IndexingOperationListener listener : listeners) {\n-            try {\n-                listener.postIndex(index, ex);\n-            } catch (Exception e) {\n-                logger.warn(\"postIndex listener [{}] failed\", e, listener);\n-            }\n+            listener.postIndex(index, ex);\n         }\n     }\n ",
    "output": "Remove try in posIndex"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java\n--- a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java\n+++ b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java\n@@ -131,7 +131,7 @@ public Engine.Index preIndex(Engine.Index index) {\n         totalStats.indexCurrent.inc();\n         typeStats(index.type()).indexCurrent.inc();\n         for (IndexingOperationListener listener : listeners) {\n-            listener.preIndex(index);\n+            index = listener.preIndex(index);\n         }\n         return index;\n     }",
    "output": "Fix skipped variable setting"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -106,6 +106,13 @@ public class BootstrapForTesting {\n                 if (Strings.hasLength(System.getProperty(\"tests.config\"))) {\n                     perms.add(new FilePermission(System.getProperty(\"tests.config\"), \"read,readlink\"));\n                 }\n+                // jacoco coverage output file\n+                if (Boolean.getBoolean(\"tests.coverage\")) {\n+                    Path coverageDir = PathUtils.get(System.getProperty(\"tests.coverage.dir\"));\n+                    perms.add(new FilePermission(coverageDir.resolve(\"jacoco.exec\").toString(), \"read,write\"));\n+                    // in case we get fancy and use the -integration goals later:\n+                    perms.add(new FilePermission(coverageDir.resolve(\"jacoco-it.exec\").toString(), \"read,write\"));\n+                }\n                 Policy.setPolicy(new ESPolicy(perms));\n                 System.setSecurityManager(new TestSecurityManager());\n                 Security.selfTest();",
    "output": "Improve jacoco coverage"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -106,6 +106,13 @@ public class BootstrapForTesting {\n                 if (Strings.hasLength(System.getProperty(\"tests.config\"))) {\n                     perms.add(new FilePermission(System.getProperty(\"tests.config\"), \"read,readlink\"));\n                 }\n+                // jacoco coverage output file\n+                if (Boolean.getBoolean(\"tests.coverage\")) {\n+                    Path coverageDir = PathUtils.get(System.getProperty(\"tests.coverage.dir\"));\n+                    perms.add(new FilePermission(coverageDir.resolve(\"jacoco.exec\").toString(), \"read,write\"));\n+                    // in case we get fancy and use the -integration goals later:\n+                    perms.add(new FilePermission(coverageDir.resolve(\"jacoco-it.exec\").toString(), \"read,write\"));\n+                }\n                 Policy.setPolicy(new ESPolicy(perms));\n                 System.setSecurityManager(new TestSecurityManager());\n                 Security.selfTest();",
    "output": "Improve jacoco coverage Upgrade jacoco version and allow it to run with security manager enabled"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/transport/TransportFilterTests.java b/shield/src/test/java/org/elasticsearch/shield/transport/TransportFilterTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/transport/TransportFilterTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/transport/TransportFilterTests.java\n@@ -44,7 +44,8 @@\n  *\n  */\n @ClusterScope(scope = SUITE, numDataNodes = 0)\n-@LuceneTestCase.AwaitsFix(bugUrl = \"fails because the test infrastructure already registers a transport service (InternalTestCluster#getPlugins()) and there for the transport service used here can't be registered\")\n+@LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/pull/13215\")\n+// fails because the test infrastructure already registers a transport service (InternalTestCluster#getPlugins()) and there for the transport service used here can't be registered\n public class TransportFilterTests extends ESIntegTestCase {\n \n     @Override",
    "output": "Upgrade await fix url"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/transport/ShieldServerTransportService.java b/shield/src/main/java/org/elasticsearch/shield/transport/ShieldServerTransportService.java\n--- a/shield/src/main/java/org/elasticsearch/shield/transport/ShieldServerTransportService.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/transport/ShieldServerTransportService.java\n@@ -20,6 +20,7 @@\n \n import java.util.Collections;\n import java.util.Map;\n+import java.util.concurrent.Callable;\n \n import static org.elasticsearch.shield.transport.netty.ShieldNettyTransport.*;\n \n@@ -67,6 +68,12 @@ public <Request extends TransportRequest> void registerRequestHandler(String act\n         super.registerRequestHandler(action, request, executor, forceExecution, wrappedHandler);\n     }\n \n+    @Override\n+    public <Request extends TransportRequest> void registerRequestHandler(String action, Callable<Request> requestFactory, String executor, TransportRequestHandler<Request> handler) {\n+        TransportRequestHandler<Request> wrappedHandler = new ProfileSecuredRequestHandler<>(action, handler, profileFilters);\n+        super.registerRequestHandler(action, requestFactory, executor, wrappedHandler);\n+    }\n+\n     protected Map<String, ServerTransportFilter> initializeProfileFilters() {\n         if (!(transport instanceof ShieldNettyTransport)) {\n             return Collections.<String, ServerTransportFilter>singletonMap(NettyTransport.DEFAULT_PROFILE, new ServerTransportFilter.NodeProfile(authcService, authzService, actionMapper, false));",
    "output": "Add override of handler registration method to wrap handler"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java b/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java\n--- a/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java\n@@ -41,7 +41,6 @@\n import org.elasticsearch.cluster.node.DiscoveryNodes;\n import org.elasticsearch.cluster.routing.ShardRouting;\n import org.elasticsearch.cluster.routing.ShardsIterator;\n-import org.elasticsearch.common.SuppressForbidden;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.io.stream.Streamable;\n@@ -410,13 +409,11 @@ protected class NodeRequest extends TransportRequest implements IndicesRequest {\n         protected NodeRequest() {\n         }\n \n-        @SuppressForbidden(reason = \"debug\")\n         public NodeRequest(String nodeId, Request request, List<ShardRouting> shards) {\n             super(request);\n             this.indicesLevelRequest = request;\n             this.shards = shards;\n             this.nodeId = nodeId;\n-            System.out.println(TransportBroadcastByNodeAction.this.getClass().getName());\n         }\n \n         public List<ShardRouting> getShards() {",
    "output": "Remove leftover debugging statement"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeAction.java b/core/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeAction.java\n--- a/core/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeAction.java\n@@ -97,7 +97,7 @@ private void innerExecute(final Request request, final ActionListener<Response>\n                     listener.onFailure(blockException);\n                     return;\n                 }\n-                logger.trace(\"can't execute due to a cluster block: [{}], retrying\", blockException);\n+                logger.trace(\"can't execute due to a cluster block, retrying\", blockException);\n                 observer.waitForNextChange(\n                         new ClusterStateObserver.Listener() {\n                             @Override",
    "output": "Fix logging statement in o.e.a.s.m.TransportMasterNodeAction"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/compress/lzf/LZFCompressor.java b/core/src/main/java/org/elasticsearch/common/compress/lzf/LZFCompressor.java\n--- a/core/src/main/java/org/elasticsearch/common/compress/lzf/LZFCompressor.java\n+++ b/core/src/main/java/org/elasticsearch/common/compress/lzf/LZFCompressor.java\n@@ -46,8 +46,7 @@ public class LZFCompressor implements Compressor {\n \n     public LZFCompressor() {\n         this.decoder = ChunkDecoderFactory.safeInstance();\n-        Loggers.getLogger(LZFCompressor.class).debug(\"using encoder [{}] and decoder[{}] \",\n-                this.decoder.getClass().getSimpleName());\n+        Loggers.getLogger(LZFCompressor.class).debug(\"using decoder[{}] \", this.decoder.getClass().getSimpleName());\n     }\n \n     @Override",
    "output": "Fix logging statement"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java b/core/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java\n--- a/core/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java\n@@ -59,17 +59,17 @@ public class DiscoverySettings extends AbstractComponent {\n     public final static ClusterBlock NO_MASTER_BLOCK_WRITES = new ClusterBlock(NO_MASTER_BLOCK_ID, \"no master\", true, false, RestStatus.SERVICE_UNAVAILABLE, EnumSet.of(ClusterBlockLevel.WRITE, ClusterBlockLevel.METADATA_WRITE));\n \n     private volatile ClusterBlock noMasterBlock;\n-    private volatile TimeValue publishTimeout = DEFAULT_PUBLISH_TIMEOUT;\n-    private volatile TimeValue commitTimeout = DEFAULT_COMMIT_TIMEOUT;\n-    private volatile boolean publishDiff = DEFAULT_PUBLISH_DIFF_ENABLE;\n+    private volatile TimeValue publishTimeout;\n+    private volatile TimeValue commitTimeout;\n+    private volatile boolean publishDiff;\n \n     @Inject\n     public DiscoverySettings(Settings settings, NodeSettingsService nodeSettingsService) {\n         super(settings);\n         nodeSettingsService.addListener(new ApplySettings());\n         this.noMasterBlock = parseNoMasterBlock(settings.get(NO_MASTER_BLOCK, DEFAULT_NO_MASTER_BLOCK));\n-        this.publishTimeout = settings.getAsTime(PUBLISH_TIMEOUT, publishTimeout);\n-        this.commitTimeout = settings.getAsTime(COMMIT_TIMEOUT, publishTimeout);\n+        this.publishTimeout = settings.getAsTime(PUBLISH_TIMEOUT, DEFAULT_PUBLISH_TIMEOUT);\n+        this.commitTimeout = settings.getAsTime(COMMIT_TIMEOUT, DEFAULT_COMMIT_TIMEOUT);\n         this.publishDiff = settings.getAsBoolean(PUBLISH_DIFF_ENABLE, DEFAULT_PUBLISH_DIFF_ENABLE);\n     }\n ",
    "output": "Fix defaults in DiscoverySettings"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n@@ -439,7 +439,11 @@ public void writeTo(StreamOutput out) throws IOException {\n     }\n \n \n-    public class FailedToCommitException extends ElasticsearchException {\n+    public static class FailedToCommitException extends ElasticsearchException {\n+\n+        public FailedToCommitException(StreamInput in) throws IOException {\n+            super(in);\n+        }\n \n         public FailedToCommitException(String msg, Object... args) {\n             super(msg, args);",
    "output": "Add constructor to FailedToCommitException"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/ElasticsearchException.java b/core/src/main/java/org/elasticsearch/ElasticsearchException.java\n--- a/core/src/main/java/org/elasticsearch/ElasticsearchException.java\n+++ b/core/src/main/java/org/elasticsearch/ElasticsearchException.java\n@@ -596,7 +596,8 @@ public static <T extends Throwable> T writeStackTraces(T throwable, StreamOutput\n                 ResourceNotFoundException.class,\n                 IndexNotFoundException.class,\n                 ShardNotFoundException.class,\n-                NotSerializableExceptionWrapper.class\n+                NotSerializableExceptionWrapper.class,\n+                org.elasticsearch.discovery.zen.publish.PublishClusterStateAction.FailedToCommitException.class\n         };\n         Map<String, Constructor<? extends ElasticsearchException>> mapping = new HashMap<>(exceptions.length);\n         for (Class<? extends ElasticsearchException> e : exceptions) {",
    "output": "Add FailedToCommitException to registration"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java\n--- a/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java\n+++ b/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java\n@@ -121,7 +121,7 @@ public void testScoreAccessWithinScript() throws Exception {\n \n         int docCount = randomIntBetween(100, 200);\n         for (int i = 0; i < docCount; i++) {\n-            client().prepareIndex(\"test\", \"type\", \"\" + i).setSource(\"body\", randomFrom(newArrayList(\"foo\", \"bar\", \"baz\")), \"index\", i)\n+            client().prepareIndex(\"test\", \"type\", \"\" + i).setSource(\"body\", randomFrom(newArrayList(\"foo\", \"bar\", \"baz\")), \"index\", i + 1)// we add 1 to the index field to make sure that the scripts below never compute log(0)\n                     .get();\n         }\n         refresh();",
    "output": "Make sure that the scripts in testScoreAccessWithinScript never compute log(0)"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java\n--- a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java\n@@ -28,7 +28,7 @@\n import org.elasticsearch.index.search.termslookup.TermsLookupFetchService;\n import org.elasticsearch.indices.cache.query.terms.TermsLookup;\n import org.hamcrest.Matchers;\n-import org.junit.BeforeClass;\n+import org.junit.Before;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -40,10 +40,10 @@\n \n public class TermsQueryBuilderTest extends BaseQueryTestCase<TermsQueryBuilder> {\n \n-    private static MockTermsLookupFetchService termsLookupFetchService;\n+    private MockTermsLookupFetchService termsLookupFetchService;\n \n-    @BeforeClass\n-    public static void mockTermsLookupFetchService() throws IOException {\n+    @Before\n+    public void mockTermsLookupFetchService() {\n         termsLookupFetchService = new MockTermsLookupFetchService();\n         queryParserService().setTermsLookupFetchService(termsLookupFetchService);\n     }",
    "output": "Make MockTermsLookupFetchService non static"
  },
  {
    "input": "diff --git a/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/licenses/LicensesRendererIT.java b/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/licenses/LicensesRendererIT.java\n--- a/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/licenses/LicensesRendererIT.java\n+++ b/marvel/src/test/java/org/elasticsearch/marvel/agent/renderer/licenses/LicensesRendererIT.java\n@@ -52,11 +52,11 @@ public void testLicenses() throws Exception {\n             @Override\n             public GetResponse call() throws Exception {\n                 // Checks if the marvel data index exists (it should have been created by the LicenseCollector)\n-                assertTrue(client().admin().indices().prepareExists(MarvelSettings.MARVEL_DATA_INDEX_NAME).get().isExists());\n+                assertTrue(MarvelSettings.MARVEL_DATA_INDEX_NAME + \" index does not exist\", client().admin().indices().prepareExists(MarvelSettings.MARVEL_DATA_INDEX_NAME).get().isExists());\n                 ensureYellow(MarvelSettings.MARVEL_DATA_INDEX_NAME);\n \n                 GetResponse response = client().prepareGet(MarvelSettings.MARVEL_DATA_INDEX_NAME, LicensesCollector.TYPE, clusterUUID).get();\n-                assertTrue(response.isExists());\n+                assertTrue(MarvelSettings.MARVEL_DATA_INDEX_NAME + \" document does not exist\", response.isExists());\n                 return response;\n             }\n         });",
    "output": "Add assertion message"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java\n@@ -61,8 +61,6 @@ public class MultiMatchQueryBuilder extends QueryBuilder implements BoostableQue\n \n     private String minimumShouldMatch;\n \n-    private String rewrite = null;\n-\n     private String fuzzyRewrite = null;\n \n     private Boolean useDisMax;\n@@ -255,11 +253,6 @@ public MultiMatchQueryBuilder minimumShouldMatch(String minimumShouldMatch) {\n         return this;\n     }\n \n-    public MultiMatchQueryBuilder rewrite(String rewrite) {\n-        this.rewrite = rewrite;\n-        return this;\n-    }\n-\n     public MultiMatchQueryBuilder fuzzyRewrite(String fuzzyRewrite) {\n         this.fuzzyRewrite = fuzzyRewrite;\n         return this;\n@@ -367,9 +360,6 @@ public void doXContent(XContentBuilder builder, Params params) throws IOExceptio\n         if (minimumShouldMatch != null) {\n             builder.field(\"minimum_should_match\", minimumShouldMatch);\n         }\n-        if (rewrite != null) {\n-            builder.field(\"rewrite\", rewrite);\n-        }\n         if (fuzzyRewrite != null) {\n             builder.field(\"fuzzy_rewrite\", fuzzyRewrite);\n         }",
    "output": "Remove unsupported `rewrite` from multi_match query builder"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java b/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java\n@@ -75,16 +75,18 @@ static void tryMlockall() {\n         }\n \n         // mlockall failed for some reason\n-        logger.warn(\"Unable to lock JVM Memory: error=\" + errno + \",reason=\" + errMsg + \". This can result in part of the JVM being swapped out.\");\n+        logger.warn(\"Unable to lock JVM Memory: error=\" + errno + \",reason=\" + errMsg);\n+        logger.warn(\"This can result in part of the JVM being swapped out.\");\n         if (errno == JNACLibrary.ENOMEM) {\n             if (rlimitSuccess) {\n                 logger.warn(\"Increase RLIMIT_MEMLOCK, soft limit: \" + rlimitToString(softLimit) + \", hard limit: \" + rlimitToString(hardLimit));\n                 if (Constants.LINUX) {\n                     // give specific instructions for the linux case to make it easy\n+                    String user = System.getProperty(\"user.name\");\n                     logger.warn(\"These can be adjusted by modifying /etc/security/limits.conf, for example: \\n\" +\n-                                \"\\t# allow user 'esuser' mlockall\\n\" +\n-                                \"\\tesuser soft memlock unlimited\\n\" +\n-                                \"\\tesuser hard memlock unlimited\"\n+                                \"\\t# allow user '\" + user + \"' mlockall\\n\" +\n+                                \"\\t\" + user + \" soft memlock unlimited\\n\" +\n+                                \"\\t\" + user + \" hard memlock unlimited\"\n                                );\n                     logger.warn(\"If you are logged in interactively, you will have to re-login for the new limits to take effect.\");\n                 }",
    "output": "Make mlockall configuration easier"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java\n@@ -78,8 +78,6 @@ public enum ZeroTermsQuery {\n \n     private String minimumShouldMatch;\n \n-    private String rewrite = null;\n-\n     private String fuzzyRewrite = null;\n \n     private Boolean lenient;\n@@ -179,11 +177,6 @@ public MatchQueryBuilder minimumShouldMatch(String minimumShouldMatch) {\n         return this;\n     }\n \n-    public MatchQueryBuilder rewrite(String rewrite) {\n-        this.rewrite = rewrite;\n-        return this;\n-    }\n-\n     public MatchQueryBuilder fuzzyRewrite(String fuzzyRewrite) {\n         this.fuzzyRewrite = fuzzyRewrite;\n         return this;\n@@ -249,9 +242,6 @@ public void doXContent(XContentBuilder builder, Params params) throws IOExceptio\n         if (minimumShouldMatch != null) {\n             builder.field(\"minimum_should_match\", minimumShouldMatch);\n         }\n-        if (rewrite != null) {\n-            builder.field(\"rewrite\", rewrite);\n-        }\n         if (fuzzyRewrite != null) {\n             builder.field(\"fuzzy_rewrite\", fuzzyRewrite);\n         }",
    "output": "Remove unsupported `rewrite` option from match query builder"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/support/AbstractShieldModule.java b/shield/src/main/java/org/elasticsearch/shield/support/AbstractShieldModule.java\n--- a/shield/src/main/java/org/elasticsearch/shield/support/AbstractShieldModule.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/support/AbstractShieldModule.java\n@@ -7,8 +7,6 @@\n \n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.inject.AbstractModule;\n-import org.elasticsearch.common.inject.Module;\n-import org.elasticsearch.common.inject.SpawnModules;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.shield.ShieldPlugin;\n \n\ndiff --git a/watcher/src/main/java/org/elasticsearch/watcher/trigger/TriggerModule.java b/watcher/src/main/java/org/elasticsearch/watcher/trigger/TriggerModule.java\n--- a/watcher/src/main/java/org/elasticsearch/watcher/trigger/TriggerModule.java\n+++ b/watcher/src/main/java/org/elasticsearch/watcher/trigger/TriggerModule.java\n@@ -6,14 +6,11 @@\n package org.elasticsearch.watcher.trigger;\n \n import org.elasticsearch.common.inject.AbstractModule;\n-import org.elasticsearch.common.inject.Module;\n-import org.elasticsearch.common.inject.SpawnModules;\n import org.elasticsearch.common.inject.multibindings.Multibinder;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.watcher.trigger.manual.ManualTriggerEngine;\n import org.elasticsearch.watcher.trigger.schedule.ScheduleModule;\n \n-import java.util.Collections;\n import java.util.HashSet;\n import java.util.Set;\n ",
    "output": "Remove unused imports - SpawnModules.java is removed"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java\n--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java\n+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java\n@@ -400,19 +400,18 @@ public String description() {\n         public Collection<Module> nodeModules() {\n             return Collections.<Module>singletonList(new ActionLoggingModule());\n         }\n+\n+        public void onModule(ActionModule module) {\n+            module.registerFilter(LoggingFilter.class);\n+        }\n     }\n \n     public static class ActionLoggingModule extends AbstractModule {\n-\n-\n         @Override\n         protected void configure() {\n             bind(LoggingFilter.class).asEagerSingleton();\n         }\n \n-        public void onModule(ActionModule module) {\n-            module.registerFilter(LoggingFilter.class);\n-        }\n     }\n \n     public static class LoggingFilter extends ActionFilter.Simple {",
    "output": "Fix test plugin to correctly add action"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java b/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java\n@@ -75,16 +75,18 @@ static void tryMlockall() {\n         }\n \n         // mlockall failed for some reason\n-        logger.warn(\"Unable to lock JVM Memory: error=\" + errno + \",reason=\" + errMsg + \". This can result in part of the JVM being swapped out.\");\n+        logger.warn(\"Unable to lock JVM Memory: error=\" + errno + \",reason=\" + errMsg);\n+        logger.warn(\"This can result in part of the JVM being swapped out.\");\n         if (errno == JNACLibrary.ENOMEM) {\n             if (rlimitSuccess) {\n                 logger.warn(\"Increase RLIMIT_MEMLOCK, soft limit: \" + rlimitToString(softLimit) + \", hard limit: \" + rlimitToString(hardLimit));\n                 if (Constants.LINUX) {\n                     // give specific instructions for the linux case to make it easy\n+                    String user = System.getProperty(\"user.name\");\n                     logger.warn(\"These can be adjusted by modifying /etc/security/limits.conf, for example: \\n\" +\n-                                \"\\t# allow user 'esuser' mlockall\\n\" +\n-                                \"\\tesuser soft memlock unlimited\\n\" +\n-                                \"\\tesuser hard memlock unlimited\"\n+                                \"\\t# allow user '\" + user + \"' mlockall\\n\" +\n+                                \"\\t\" + user + \" soft memlock unlimited\\n\" +\n+                                \"\\t\" + user + \" hard memlock unlimited\"\n                                );\n                     logger.warn(\"If you are logged in interactively, you will have to re-login for the new limits to take effect.\");\n                 }",
    "output": "Make mlockall configuration easier"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/audit/index/IndexAuditTrailTests.java b/shield/src/test/java/org/elasticsearch/shield/audit/index/IndexAuditTrailTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/audit/index/IndexAuditTrailTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/audit/index/IndexAuditTrailTests.java\n@@ -161,7 +161,7 @@ public Settings node(int nodeOrdinal) {\n             Settings.Builder builder = Settings.builder()\n                     .put(settings)\n                     .put(ShieldPlugin.ENABLED_SETTING_NAME, useShield)\n-                    .put(remoteSettings(NetworkAddress.format(inet.address().getAddress()), inet.address().getPort(), cluster2Name))\n+                    .put(remoteSettings(NetworkAddress.formatAddress(inet.address().getAddress()), inet.address().getPort(), cluster2Name))\n                     .put(\"shield.audit.index.client.shield.user\", ShieldSettingsSource.DEFAULT_USER_NAME + \":\" + ShieldSettingsSource.DEFAULT_PASSWORD);\n \n             if (useSSL) {",
    "output": "Fix IndexAuditTrail test failure Failure was caused by using NetworkAddress.format instead of NetworkAddress.formatAddress"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java b/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java\n@@ -24,7 +24,7 @@\n  */\n public class Elasticsearch extends Bootstrap {\n \n-    public static void main(String[] args) throws Throwable {\n+    public static void main(String[] args) throws StartupError {\n         Bootstrap.main(args);\n     }\n }\n\\ No newline at end of file",
    "output": "Fix compilation... forgot to 'mvn clean'"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -221,8 +221,17 @@ private void stop() {\n             keepAliveLatch.countDown();\n         }\n     }\n+    \n+    /** Calls doMain(), but with special formatting of errors */\n+    public static void main(String[] args) throws StartupError {\n+        try {\n+            doMain(args);\n+        } catch (Throwable t) {\n+            throw new StartupError(t);\n+        }\n+    }\n \n-    public static void main(String[] args) throws Throwable {\n+    public static void doMain(String[] args) throws Throwable {\n         BootstrapCLIParser bootstrapCLIParser = new BootstrapCLIParser();\n         CliTool.ExitStatus status = bootstrapCLIParser.execute(args);\n \n@@ -291,7 +300,7 @@ public static void main(String[] args) throws Throwable {\n                 Loggers.enableConsoleLogging();\n             }\n             \n-            throw new StartupError(e);\n+            throw e;\n         }\n     }\n ",
    "output": "Use StartupError to format all exceptions hitting the console"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -221,8 +221,17 @@ private void stop() {\n             keepAliveLatch.countDown();\n         }\n     }\n+    \n+    /** Calls doMain(), but with special formatting of errors */\n+    public static void main(String[] args) throws StartupError {\n+        try {\n+            doMain(args);\n+        } catch (Throwable t) {\n+            throw new StartupError(t);\n+        }\n+    }\n \n-    public static void main(String[] args) throws Throwable {\n+    public static void doMain(String[] args) throws Throwable {\n         BootstrapCLIParser bootstrapCLIParser = new BootstrapCLIParser();\n         CliTool.ExitStatus status = bootstrapCLIParser.execute(args);\n \n@@ -291,7 +300,7 @@ public static void main(String[] args) throws Throwable {\n                 Loggers.enableConsoleLogging();\n             }\n             \n-            throw new StartupError(e);\n+            throw e;\n         }\n     }\n ",
    "output": "Use StartupError to format all exceptions hitting the console"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n@@ -563,6 +563,7 @@ public void testOfficialPluginName_ThrowsException() throws IOException {\n         PluginManager.checkForOfficialPlugins(\"lang-python\");\n         PluginManager.checkForOfficialPlugins(\"mapper-murmur3\");\n         PluginManager.checkForOfficialPlugins(\"mapper-size\");\n+        PluginManager.checkForOfficialPlugins(\"discovery-multicast\");\n \n         try {\n             PluginManager.checkForOfficialPlugins(\"elasticsearch-mapper-attachment\");",
    "output": "Add discovery-multicast to PluginManagerIT"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -84,6 +84,7 @@ public enum OutputMode {\n                     \"cloud-azure\",\n                     \"cloud-gce\",\n                     \"delete-by-query\",\n+                    \"discovery-multicast\",\n                     \"lang-javascript\",\n                     \"lang-python\",\n                     \"mapper-murmur3\",",
    "output": "Add multicast plugin to plugin manager official list of plugins"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java\n--- a/core/src/main/java/org/elasticsearch/index/IndexService.java\n+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java\n@@ -301,7 +301,7 @@ public synchronized IndexShard createShard(int sShardId, ShardRouting routing) {\n                 }\n             }\n             if (path == null) {\n-                path = ShardPath.selectNewPathForShard(nodeEnv, shardId, indexSettings, routing.getExpectedShardSize() == -1 ? getAvgShardSizeInBytes() : routing.getExpectedShardSize(), this);\n+                path = ShardPath.selectNewPathForShard(nodeEnv, shardId, indexSettings, routing.getExpectedShardSize() == ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE ? getAvgShardSizeInBytes() : routing.getExpectedShardSize(), this);\n                 logger.debug(\"{} creating using a new path [{}]\", shardId, path);\n             } else {\n                 logger.debug(\"{} creating using an existing path [{}]\", shardId, path);",
    "output": "Use constant to determin if expected size is available"
  },
  {
    "input": "diff --git a/plugins/cloud-gce/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java b/plugins/cloud-gce/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n--- a/plugins/cloud-gce/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n+++ b/plugins/cloud-gce/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n@@ -45,7 +45,5 @@ public GceDiscovery(Settings settings, ClusterName clusterName, ThreadPool threa\n                         ElectMasterService electMasterService) {\n         super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n                 pingService, electMasterService, discoverySettings);\n-\n-        // See related issue in AWS plugin https://github.com/elastic/elasticsearch-cloud-aws/issues/179\n     }\n }",
    "output": "Remove outdated comment"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPingService.java b/core/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPingService.java\n--- a/core/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPingService.java\n+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPingService.java\n@@ -60,7 +60,6 @@ public void setPingContextProvider(PingContextProvider contextProvider) {\n     @Override\n     protected void doStart() {\n         for (ZenPing zenPing : zenPings) {\n-            logger.info(\"Starting ping: \" + zenPing);\n             zenPing.start();\n         }\n     }",
    "output": "Remove logging message from testing"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n--- a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n+++ b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n@@ -717,7 +717,7 @@ public List<String> getLocalAddresses() {\n         local.add(\"127.0.0.1\");\n         // check if v6 is supported, if so, v4 will also work via mapped addresses.\n         if (NetworkUtils.SUPPORTS_V6) {\n-            local.add(\"::1\");\n+            local.add(\"[::1]\"); // may get ports appended!\n         }\n         return local;\n     }",
    "output": "Fix test failure"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/transport/InetSocketTransportAddress.java b/core/src/main/java/org/elasticsearch/common/transport/InetSocketTransportAddress.java\n--- a/core/src/main/java/org/elasticsearch/common/transport/InetSocketTransportAddress.java\n+++ b/core/src/main/java/org/elasticsearch/common/transport/InetSocketTransportAddress.java\n@@ -33,7 +33,7 @@\n  */\n public final class InetSocketTransportAddress implements TransportAddress {\n \n-    public static final InetSocketTransportAddress PROTO = new InetSocketTransportAddress(new InetSocketAddress(\"127.0.0.1\", 0));\n+    public static final InetSocketTransportAddress PROTO = new InetSocketTransportAddress();\n \n     private final InetSocketAddress address;\n \n@@ -51,6 +51,10 @@ public InetSocketTransportAddress(StreamInput in) throws IOException {\n         this.address = new InetSocketAddress(inetAddress, port);\n     }\n \n+    private InetSocketTransportAddress() {\n+        address = null;\n+    }\n+\n     public InetSocketTransportAddress(InetAddress address, int port) {\n         this(new InetSocketAddress(address, port));\n     }",
    "output": "Add back private default ctor"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/transport/netty/IPHostnameVerificationTests.java b/shield/src/test/java/org/elasticsearch/shield/transport/netty/IPHostnameVerificationTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/transport/netty/IPHostnameVerificationTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/transport/netty/IPHostnameVerificationTests.java\n@@ -5,7 +5,6 @@\n  */\n package org.elasticsearch.shield.transport.netty;\n \n-import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.test.ShieldIntegTestCase;\n@@ -17,7 +16,6 @@\n import static org.elasticsearch.common.settings.Settings.settingsBuilder;\n import static org.hamcrest.CoreMatchers.is;\n \n-@LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elastic/x-plugins/issues/468\")\n public class IPHostnameVerificationTests extends ShieldIntegTestCase {\n \n     Path keystore;",
    "output": "Remove AwaitsFix from IPHostnameVerification tests now that it is fixed in core Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n--- a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n+++ b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n@@ -360,10 +360,11 @@ private URLConnection openConnection(URL aSource) throws IOException {\n \n             if (connection instanceof HttpURLConnection) {\n                 ((HttpURLConnection) connection).setInstanceFollowRedirects(false);\n-                ((HttpURLConnection) connection).setUseCaches(true);\n-                ((HttpURLConnection) connection).setConnectTimeout(5000);\n+                connection.setUseCaches(true);\n+                connection.setConnectTimeout(5000);\n             }\n             connection.setRequestProperty(\"ES-Version\", Version.CURRENT.toString());\n+            connection.setRequestProperty(\"ES-Build-Hash\", Build.CURRENT.hashShort());\n             connection.setRequestProperty(\"User-Agent\", \"elasticsearch-plugin-manager\");\n \n             // connect to the remote site (may take some time)",
    "output": "Add build short hash to the download manager headers to identify staging builds"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -277,11 +277,19 @@ public static void main(String[] args) throws Throwable {\n                 closeSysError();\n             }\n         } catch (Throwable e) {\n+            // disable console logging, so user does not see the exception twice (jvm will show it already)\n+            if (foreground) {\n+                Loggers.disableConsoleLogging();\n+            }\n             ESLogger logger = Loggers.getLogger(Bootstrap.class);\n             if (INSTANCE.node != null) {\n                 logger = Loggers.getLogger(Bootstrap.class, INSTANCE.node.settings().get(\"name\"));\n             }\n             logger.error(\"Exception\", e);\n+            // re-enable it if appropriate, so they can see any logging during the shutdown process\n+            if (foreground) {\n+                Loggers.enableConsoleLogging();\n+            }\n             \n             throw e;\n         }",
    "output": "Improve console logging on startup exception"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -277,11 +277,19 @@ public static void main(String[] args) throws Throwable {\n                 closeSysError();\n             }\n         } catch (Throwable e) {\n+            // disable console logging, so user does not see the exception twice (jvm will show it already)\n+            if (foreground) {\n+                Loggers.disableConsoleLogging();\n+            }\n             ESLogger logger = Loggers.getLogger(Bootstrap.class);\n             if (INSTANCE.node != null) {\n                 logger = Loggers.getLogger(Bootstrap.class, INSTANCE.node.settings().get(\"name\"));\n             }\n             logger.error(\"Exception\", e);\n+            // re-enable it if appropriate, so they can see any logging during the shutdown process\n+            if (foreground) {\n+                Loggers.enableConsoleLogging();\n+            }\n             \n             throw e;\n         }",
    "output": "Improve console logging on startup exception Today we show the exception twice: once by the logger and then again by the JVM. This is too noisy, and easy to avoid"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/discovery/ClusterDiscoveryConfiguration.java b/core/src/test/java/org/elasticsearch/test/discovery/ClusterDiscoveryConfiguration.java\n--- a/core/src/test/java/org/elasticsearch/test/discovery/ClusterDiscoveryConfiguration.java\n+++ b/core/src/test/java/org/elasticsearch/test/discovery/ClusterDiscoveryConfiguration.java\n@@ -150,8 +150,7 @@ protected synchronized static int[] unicastHostPorts(int numHosts) {\n                     try (ServerSocket serverSocket = new ServerSocket()) {\n                         // Set SO_REUSEADDR as we may bind here and not be able to reuse the address immediately without it.\n                         serverSocket.setReuseAddress(NetworkUtils.defaultReuseAddress());\n-                        serverSocket.bind(new InetSocketAddress(nextPort));\n-\n+                        serverSocket.bind(new InetSocketAddress(\"127.0.0.1\", nextPort));\n                         // bind was a success\n                         foundPortInRange = true;\n                         unicastHostPorts[i] = nextPort;",
    "output": "Make it clear what address we try to bind"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/repositories/RepositoryTypesRegistry.java b/core/src/main/java/org/elasticsearch/repositories/RepositoryTypesRegistry.java\n--- a/core/src/main/java/org/elasticsearch/repositories/RepositoryTypesRegistry.java\n+++ b/core/src/main/java/org/elasticsearch/repositories/RepositoryTypesRegistry.java\n@@ -29,10 +29,10 @@\n  */\n public class RepositoryTypesRegistry {\n     // invariant: repositories and shardRepositories have the same keyset\n-    private final ExtensionPoint.TypeExtensionPoint<Repository> repositoryTypes =\n-        new ExtensionPoint.TypeExtensionPoint<>(\"repository\", Repository.class);\n-    private final ExtensionPoint.TypeExtensionPoint<IndexShardRepository> shardRepositoryTypes =\n-        new ExtensionPoint.TypeExtensionPoint<>(\"index_repository\", IndexShardRepository.class);\n+    private final ExtensionPoint.SelectedType<Repository> repositoryTypes =\n+        new ExtensionPoint.SelectedType<>(\"repository\", Repository.class);\n+    private final ExtensionPoint.SelectedType<IndexShardRepository> shardRepositoryTypes =\n+        new ExtensionPoint.SelectedType<>(\"index_repository\", IndexShardRepository.class);\n \n     /** Adds a new repository type to the registry, bound to the given implementation classes. */\n     public void registerRepository(String name, Class<? extends Repository> repositoryType, Class<? extends IndexShardRepository> shardRepositoryType) {",
    "output": "Fix compile failure from bad merge after renaming of ExtensionPoint.TypeExtensionPoint"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java\n@@ -146,7 +146,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return Settings.builder()\n                 // manual collection or upon cluster forming.\n                 .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT, \"1s\")\n-                .putArray(\"plugin.types\", Plugin.class.getName(), MockTransportService.TestPlugin.class.getName())\n+                .putArray(\"plugin.types\", TestPlugin.class.getName(), MockTransportService.TestPlugin.class.getName())\n                 .build();\n     }\n ",
    "output": "Fix naming problem with test plugin"
  },
  {
    "input": "diff --git a/plugins/mapper-murmur3/src/main/java/org/elasticsearch/index/mapper/murmur3/Murmur3FieldMapper.java b/plugins/mapper-murmur3/src/main/java/org/elasticsearch/index/mapper/murmur3/Murmur3FieldMapper.java\n--- a/plugins/mapper-murmur3/src/main/java/org/elasticsearch/index/mapper/murmur3/Murmur3FieldMapper.java\n+++ b/plugins/mapper-murmur3/src/main/java/org/elasticsearch/index/mapper/murmur3/Murmur3FieldMapper.java\n@@ -73,7 +73,7 @@ public Murmur3FieldMapper build(BuilderContext context) {\n         @Override\n         protected void setupFieldType(BuilderContext context) {\n             super.setupFieldType(context);\n-            if (context.indexCreatedVersion().onOrAfter(Version.V_2_0_0)) {\n+            if (context.indexCreatedVersion().onOrAfter(Version.V_2_0_0_beta1)) {\n                 fieldType.setIndexOptions(IndexOptions.NONE);\n                 defaultFieldType.setIndexOptions(IndexOptions.NONE);\n                 fieldType.setHasDocValues(true);\n@@ -108,7 +108,7 @@ public Mapper.Builder parse(String name, Map<String, Object> node, ParserContext\n                 }\n             }\n \n-            if (parserContext.indexVersionCreated().before(Version.V_2_0_0)) {\n+            if (parserContext.indexVersionCreated().before(Version.V_2_0_0_beta1)) {\n                 builder.indexOptions(IndexOptions.DOCS);\n             }\n ",
    "output": "Fix mapper-murmur3 compatibility version"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java b/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java\n--- a/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java\n+++ b/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java\n@@ -36,11 +36,11 @@ public class IndexCacheModule extends AbstractModule {\n     public static final String QUERY_CACHE_EVERYTHING = \"index.queries.cache.everything\";\n \n     private final Settings indexSettings;\n-    private final ExtensionPoint.TypeExtensionPoint<QueryCache> queryCaches;\n+    private final ExtensionPoint.SelectedType<QueryCache> queryCaches;\n \n     public IndexCacheModule(Settings settings) {\n         this.indexSettings = settings;\n-        this.queryCaches = new ExtensionPoint.TypeExtensionPoint<>(\"query_cache\", QueryCache.class);\n+        this.queryCaches = new ExtensionPoint.SelectedType<>(\"query_cache\", QueryCache.class);\n \n         registerQueryCache(INDEX_QUERY_CACHE, IndexQueryCache.class);\n         registerQueryCache(NONE_QUERY_CACHE, NoneQueryCache.class);",
    "output": "Fix changed class name after bad merge,"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n--- a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n+++ b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n@@ -360,10 +360,11 @@ private URLConnection openConnection(URL aSource) throws IOException {\n \n             if (connection instanceof HttpURLConnection) {\n                 ((HttpURLConnection) connection).setInstanceFollowRedirects(false);\n-                ((HttpURLConnection) connection).setUseCaches(true);\n-                ((HttpURLConnection) connection).setConnectTimeout(5000);\n+                connection.setUseCaches(true);\n+                connection.setConnectTimeout(5000);\n             }\n             connection.setRequestProperty(\"ES-Version\", Version.CURRENT.toString());\n+            connection.setRequestProperty(\"ES-Build-Hash\", Build.CURRENT.hashShort());\n             connection.setRequestProperty(\"User-Agent\", \"elasticsearch-plugin-manager\");\n \n             // connect to the remote site (may take some time)",
    "output": "Add build short hash to the download manager headers to identify staging builds It might turn out to be useful to have the actual commit hash of the version we are looking for if our download manager can just redirect to the right staging repository"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java b/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n@@ -32,6 +32,6 @@ public void testCompatibility() {\n          * Once es core supports merging cluster level custom metadata (licenses in our case), the tribe node will see some license coming from the tribe and everything will be ok.\n          *\n          */\n-        assertThat(\"Remove workaround in LicenseService class when es core supports merging cluster level custom metadata\", Version.CURRENT.onOrBefore(Version.V_2_0_0), is(true));\n+        assertThat(\"Remove workaround in LicenseService class when es core supports merging cluster level custom metadata\", Version.CURRENT.onOrBefore(Version.V_2_1_0), is(true));\n     }\n }",
    "output": "Change pom version to 2.1.0-SNAPSHOT as ES core does in its master branch"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java b/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n--- a/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n+++ b/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n@@ -78,10 +78,14 @@ public void testFailure(Failure failure) throws Exception {\n \n         final StringBuilder b = new StringBuilder();\n         if (inVerifyPhase()) {\n-            b.append(\"REPRODUCE WITH: mvn verify -Pdev -Dskip.unit.tests\");\n+            b.append(\"REPRODUCE WITH: mvn verify -Pdev -Dskip.unit.tests\" );\n         } else {\n             b.append(\"REPRODUCE WITH: mvn test -Pdev\");\n         }\n+        String project = System.getProperty(\"tests.project\");\n+        if (project != null) {\n+            b.append(\" -pl \" + project);\n+        }\n         MavenMessageBuilder mavenMessageBuilder = new MavenMessageBuilder(b);\n         mavenMessageBuilder.appendAllOpts(failure.getDescription());\n ",
    "output": "Fix reproduction line to include project filters"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n--- a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n+++ b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n@@ -136,7 +136,7 @@ public boolean downloadAndVerifyChecksum(URL checksumURL, Path originalFile, Pat\n         try {\n             if (download(checksumURL, checksumFile, progress, timeout)) {\n                 byte[] fileBytes = Files.readAllBytes(originalFile);\n-                List<String> checksumLines = Files.readAllLines(checksumFile);\n+                List<String> checksumLines = Files.readAllLines(checksumFile, Charsets.UTF_8);\n                 if (checksumLines.size() != 1) {\n                     throw new ElasticsearchCorruptionException(\"invalid format for checksum file (\" +\n                             hashFunc.name() + \"), expected 1 line, got: \" + checksumLines.size());",
    "output": "Use Java 7 version of Files.readAllLines instead of Java 8 version"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java b/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n--- a/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n+++ b/core/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n@@ -78,10 +78,14 @@ public void testFailure(Failure failure) throws Exception {\n \n         final StringBuilder b = new StringBuilder();\n         if (inVerifyPhase()) {\n-            b.append(\"REPRODUCE WITH: mvn verify -Pdev -Dskip.unit.tests\");\n+            b.append(\"REPRODUCE WITH: mvn verify -Pdev -Dskip.unit.tests\" );\n         } else {\n             b.append(\"REPRODUCE WITH: mvn test -Pdev\");\n         }\n+        String project = System.getProperty(\"tests.project\");\n+        if (project != null) {\n+            b.append(\" -pl \" + project);\n+        }\n         MavenMessageBuilder mavenMessageBuilder = new MavenMessageBuilder(b);\n         mavenMessageBuilder.appendAllOpts(failure.getDescription());\n ",
    "output": "Fix reproduction line to include project filters Today on a failure the reproduce line printed out by the test framework will build all projects and might fail if the test class is not present. This commit adds a reactor filter to the reproduction line to ensure unrelated projects are skipped"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -83,7 +83,8 @@ public enum OutputMode {\n                     \"elasticsearch-cloud-gce\",\n                     \"elasticsearch-delete-by-query\",\n                     \"elasticsearch-lang-javascript\",\n-                    \"elasticsearch-lang-python\"\n+                    \"elasticsearch-lang-python\",\n+                    \"elasticsearch-mapper-size\"\n             ).build();\n \n     private final Environment environment;",
    "output": "Add mapper-size to plugin list"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/store/StoreTest.java b/core/src/test/java/org/elasticsearch/index/store/StoreTest.java\n--- a/core/src/test/java/org/elasticsearch/index/store/StoreTest.java\n+++ b/core/src/test/java/org/elasticsearch/index/store/StoreTest.java\n@@ -655,7 +655,7 @@ private void corruptFile(Directory dir, String fileIn, String fileOut) throws IO\n         IndexOutput output = dir.createOutput(fileOut, IOContext.DEFAULT);\n         long len = input.length();\n         byte[] b = new byte[1024];\n-        long broken = randomInt((int) len);\n+        long broken = randomInt((int) len-1);\n         long pos = 0;\n         while (pos < len) {\n             int min = (int) Math.min(input.length() - pos, b.length);",
    "output": "Fix off-by-one bug in corruptFile util function The upper bound must be 0-based since we are corrupting an offset into the file but it can be a 1-based length of the file which results in an uncorrupted file"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java\n--- a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java\n@@ -32,7 +32,7 @@\n /**\n  * Base testcase for testing {@link Module} implementations.\n  */\n-public class ModuleTestCase extends ESTestCase {\n+public abstract class ModuleTestCase extends ESTestCase {\n \n     /** Configures the module and asserts \"clazz\" is bound to \"to\". */\n     public void assertBinding(Module module, Class to, Class clazz) {",
    "output": "Make module testcase abstract to appease test naming convetion checks"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n--- a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n@@ -52,6 +52,7 @@\n import org.elasticsearch.index.query.support.QueryParsers;\n import org.elasticsearch.index.settings.IndexSettingsModule;\n import org.elasticsearch.index.similarity.SimilarityModule;\n+import org.elasticsearch.indices.analysis.IndicesAnalysisService;\n import org.elasticsearch.indices.breaker.CircuitBreakerService;\n import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n import org.elasticsearch.indices.query.IndicesQueriesModule;\n@@ -67,8 +68,6 @@\n import org.junit.*;\n \n import java.io.IOException;\n-import java.util.Arrays;\n-\n import static org.hamcrest.Matchers.*;\n \n public abstract class BaseQueryTestCase<QB extends AbstractQueryBuilder<QB>> extends ESTestCase {\n@@ -116,7 +115,7 @@ public static void init() throws IOException {\n                 new ScriptModule(settings),\n                 new IndexSettingsModule(index, settings),\n                 new IndexCacheModule(settings),\n-                new AnalysisModule(settings),\n+                new AnalysisModule(settings, new IndicesAnalysisService(settings)),\n                 new SimilarityModule(settings),\n                 new IndexNameModule(index),\n                 new FunctionScoreModule(),\n@@ -432,7 +431,7 @@ protected static Tuple<String, Object> getRandomFieldNameAndValue() {\n         }\n         return new Tuple(fieldName, value);\n     }\n-    \n+\n     protected static Fuzziness randomFuzziness(String fieldName) {\n         Fuzziness fuzziness = Fuzziness.AUTO;\n         switch (fieldName) {",
    "output": "Fix BaseQueryTestCase after merge with master"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java\n@@ -502,7 +502,6 @@ public void testThatBasicAuthIsRejectedOnHttp() throws Exception {\n     }\n \n     @Test\n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/pull/12766\")\n     public void testThatBasicAuthIsSupportedWithHttps() throws Exception {\n         assumeTrue(\"test requires security manager to be disabled\", System.getSecurityManager() == null);\n ",
    "output": "Remove @AwaitsFix in PluginMangerIT after merging in fix from master"
  },
  {
    "input": "diff --git a/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java b/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java\n--- a/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java\n+++ b/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java\n@@ -0,0 +1,27 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.smoketest;\n+\n+import com.carrotsearch.randomizedtesting.annotations.Name;\n+import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n+import org.elasticsearch.test.rest.ESRestTestCase;\n+import org.elasticsearch.test.rest.RestTestCandidate;\n+import org.elasticsearch.test.rest.parser.RestTestParseException;\n+\n+import java.io.IOException;\n+\n+public class SmokeTestPluginsIT extends ESRestTestCase {\n+\n+    public SmokeTestPluginsIT(@Name(\"yaml\") RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+\n+    @ParametersFactory\n+    public static Iterable<Object[]> parameters() throws IOException, RestTestParseException {\n+        return ESRestTestCase.createParameters(0, 1);\n+    }\n+}\n+",
    "output": "Add a skeleton for QA tests"
  },
  {
    "input": "diff --git a/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java b/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java\n--- a/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java\n+++ b/qa/smoke-test-plugins/src/test/java/org/elasticsearch/smoketest/SmokeTestPluginsIT.java\n@@ -0,0 +1,27 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.smoketest;\n+\n+import com.carrotsearch.randomizedtesting.annotations.Name;\n+import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n+import org.elasticsearch.test.rest.ESRestTestCase;\n+import org.elasticsearch.test.rest.RestTestCandidate;\n+import org.elasticsearch.test.rest.parser.RestTestParseException;\n+\n+import java.io.IOException;\n+\n+public class SmokeTestPluginsIT extends ESRestTestCase {\n+\n+    public SmokeTestPluginsIT(@Name(\"yaml\") RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+\n+    @ParametersFactory\n+    public static Iterable<Object[]> parameters() throws IOException, RestTestParseException {\n+        return ESRestTestCase.createParameters(0, 1);\n+    }\n+}\n+",
    "output": "Add a skeleton for QA tests. For now this just tries to install license, marvel and watcher, and then checks that these plugins are listed in the node infos. I can do shield once I figure out how to set it up for REST tests"
  },
  {
    "input": "diff --git a/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java b/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java\n@@ -12,22 +12,22 @@\n  * Main class to easily run Watcher from a IDE.\n  * It sets all the options to run the Watcher plugin and access it from Sense, but doesn't run with Shield.\n  *\n- * During startup an error will be printed that the config directory can't be found, to fix this:\n- * 1) Add a config directly to the top level project directory\n- * 2) or set `-Des.path.home=` to a location where there is a config directory on your machine.\n+ * In order to run this class set configure the following:\n+ * 1) Set `-Des.path.home=` to a directory containing an ES config directory\n  */\n public class WatcherF {\n \n     public static void main(String[] args) throws Throwable {\n         System.setProperty(\"es.http.cors.enabled\", \"true\");\n+        System.setProperty(\"es.http.cors.allow-origin\", \"*\");\n         System.setProperty(\"es.script.inline\", \"on\");\n         System.setProperty(\"es.shield.enabled\", \"false\");\n         System.setProperty(\"es.security.manager.enabled\", \"false\");\n         System.setProperty(\"es.plugins.load_classpath_plugins\", \"false\");\n         System.setProperty(\"es.plugin.types\", WatcherPlugin.class.getName() + \",\" + LicensePlugin.class.getName());\n         System.setProperty(\"es.cluster.name\", WatcherF.class.getSimpleName());\n \n-        Elasticsearch.main(args);\n+        Elasticsearch.main(new String[]{\"start\"});\n     }\n \n }",
    "output": "Fix watcher runner"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java\n--- a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java\n+++ b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java\n@@ -26,7 +26,7 @@\n /**\n  * Wraps a {@link StreamInput} and delegates to it. To be used to add functionality to an existing stream by subclassing.\n  */\n-public class FilterStreamInput extends StreamInput {\n+public abstract class FilterStreamInput extends StreamInput {\n \n     private final StreamInput delegate;\n ",
    "output": "Make FilterInputStream abstract"
  },
  {
    "input": "diff --git a/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java b/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n--- a/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n+++ b/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n@@ -77,11 +77,24 @@ public S3BlobStore(Settings settings, AmazonS3 client, String bucket, @Nullable\n         // Also, if invalid security credentials are used to execute this method, the\n         // client is not able to distinguish between bucket permission errors and\n         // invalid credential errors, and this method could return an incorrect result.\n-        if (!client.doesBucketExist(bucket)) {\n-            if (region != null) {\n-                client.createBucket(bucket, region);\n-            } else {\n-                client.createBucket(bucket);\n+        int retry = 0;\n+        while (retry <= maxRetries) {\n+            try {\n+                if (!client.doesBucketExist(bucket)) {\n+                    if (region != null) {\n+                        client.createBucket(bucket, region);\n+                    } else {\n+                        client.createBucket(bucket);\n+                    }\n+                }\n+                break;\n+            } catch (AmazonClientException e) {\n+                if (shouldRetry(e) && retry < maxRetries) {\n+                    retry++;\n+                } else {\n+                    logger.debug(\"S3 client create bucket failed\");\n+                    throw e;\n+                }\n             }\n         }\n     }",
    "output": "Add retry when checking s3 snapshot repository"
  },
  {
    "input": "diff --git a/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java b/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n--- a/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n+++ b/plugins/cloud-aws/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n@@ -77,11 +77,24 @@ public S3BlobStore(Settings settings, AmazonS3 client, String bucket, @Nullable\n         // Also, if invalid security credentials are used to execute this method, the\n         // client is not able to distinguish between bucket permission errors and\n         // invalid credential errors, and this method could return an incorrect result.\n-        if (!client.doesBucketExist(bucket)) {\n-            if (region != null) {\n-                client.createBucket(bucket, region);\n-            } else {\n-                client.createBucket(bucket);\n+        int retry = 0;\n+        while (retry <= maxRetries) {\n+            try {\n+                if (!client.doesBucketExist(bucket)) {\n+                    if (region != null) {\n+                        client.createBucket(bucket, region);\n+                    } else {\n+                        client.createBucket(bucket);\n+                    }\n+                }\n+                break;\n+            } catch (AmazonClientException e) {\n+                if (shouldRetry(e) && retry < maxRetries) {\n+                    retry++;\n+                } else {\n+                    logger.debug(\"S3 client create bucket failed\");\n+                    throw e;\n+                }\n             }\n         }\n     }",
    "output": "Add retry when checking s3 bucket"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n@@ -326,7 +326,7 @@ private Table buildTable(RestRequest request, String[] indices, ClusterHealthRes\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getDocs().getDeleted());\n \n             table.addCell(indexMetaData.creationDate());\n-            table.addCell(new DateTime(indexMetaData.creationDate(), DateTimeZone.getDefault()));\n+            table.addCell(new DateTime(indexMetaData.creationDate(), DateTimeZone.UTC));\n \n             table.addCell(indexStats == null ? null : indexStats.getTotal().getStore().size());\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getStore().size());",
    "output": "Use UTC instead of default timezone for creation date in CAT endpoint"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n@@ -326,7 +326,7 @@ private Table buildTable(RestRequest request, String[] indices, ClusterHealthRes\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getDocs().getDeleted());\n \n             table.addCell(indexMetaData.creationDate());\n-            table.addCell(new DateTime(indexMetaData.creationDate(), DateTimeZone.getDefault()));\n+            table.addCell(new DateTime(indexMetaData.creationDate(), DateTimeZone.UTC));\n \n             table.addCell(indexStats == null ? null : indexStats.getTotal().getStore().size());\n             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getStore().size());",
    "output": "Use UTC instead of default timezone for creation date in CAT endpoint this change was added recently which uses default timezone for the creation date on CAT endpoints. We should be consistent and use UTC across the board. This commit adds #getDefaultTimzone() to forbidden API and fixes the REST tests. Relates to"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n--- a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n@@ -64,7 +64,6 @@\n import org.junit.AfterClass;\n import org.junit.Before;\n import org.junit.BeforeClass;\n-import org.junit.Ignore;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -75,7 +74,6 @@\n import static org.hamcrest.Matchers.notNullValue;\n import static org.hamcrest.Matchers.nullValue;\n \n-@Ignore\n public abstract class BaseQueryTestCase<QB extends AbstractQueryBuilder<QB>> extends ESTestCase {\n \n     protected static final String OBJECT_FIELD_NAME = \"mapped_object\";\n\ndiff --git a/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java\n--- a/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java\n@@ -19,14 +19,13 @@\n \n package org.elasticsearch.index.query;\n \n-import org.junit.Ignore;\n import org.junit.Test;\n \n import static org.hamcrest.Matchers.is;\n \n-@Ignore\n public abstract class BaseTermQueryTestCase<QB extends BaseTermQueryBuilder<QB>> extends BaseQueryTestCase<QB> {\n-    \n+\n+    @Override\n     protected final QB doCreateTestQueryBuilder() {\n         String fieldName = null;\n         Object value;",
    "output": "Remove forbidden @Ignore on base test cases"
  },
  {
    "input": "diff --git a/plugins/site-example/src/test/java/org/elasticsearch/example/SiteContentsIT.java b/plugins/site-example/src/test/java/org/elasticsearch/example/SiteContentsIT.java\n--- a/plugins/site-example/src/test/java/org/elasticsearch/example/SiteContentsIT.java\n+++ b/plugins/site-example/src/test/java/org/elasticsearch/example/SiteContentsIT.java\n@@ -40,7 +40,7 @@ public class SiteContentsIT extends ESIntegTestCase {\n     // define a fake rest spec or anything?\n     public void test() throws Exception {\n         TestCluster cluster = cluster();\n-        assumeTrue(\"this test will not work from an IDE unless you pass test.cluster pointing to a running instance\", cluster instanceof ExternalTestCluster);\n+        assumeTrue(\"this test will not work from an IDE unless you pass tests.cluster pointing to a running instance\", cluster instanceof ExternalTestCluster);\n         ExternalTestCluster externalCluster = (ExternalTestCluster) cluster;\n         try (CloseableHttpClient httpClient = HttpClients.createMinimal(new PoolingHttpClientConnectionManager(15, TimeUnit.SECONDS))) {\n             for (InetSocketAddress address :  externalCluster.httpAddresses()) {",
    "output": "Fix typo in assume() when running from IDE"
  },
  {
    "input": "diff --git a/distribution/rpm/src/test/java/org/elasticsearch/test/rest/RestIT.java b/distribution/rpm/src/test/java/org/elasticsearch/test/rest/RestIT.java\n--- a/distribution/rpm/src/test/java/org/elasticsearch/test/rest/RestIT.java\n+++ b/distribution/rpm/src/test/java/org/elasticsearch/test/rest/RestIT.java\n@@ -26,7 +26,7 @@\n import java.io.IOException;\n \n /** Rest integration test. runs against external cluster in 'mvn verify' */\n-public class RestIT extends ElasticsearchRestTestCase {\n+public class RestIT extends ESRestTestCase {\n     public RestIT(RestTestCandidate testCandidate) {\n         super(testCandidate);\n     }",
    "output": "Fix missed test class"
  },
  {
    "input": "diff --git a/shield/src/test/java/org/elasticsearch/shield/crypto/tool/SystemKeyToolTests.java b/shield/src/test/java/org/elasticsearch/shield/crypto/tool/SystemKeyToolTests.java\n--- a/shield/src/test/java/org/elasticsearch/shield/crypto/tool/SystemKeyToolTests.java\n+++ b/shield/src/test/java/org/elasticsearch/shield/crypto/tool/SystemKeyToolTests.java\n@@ -38,7 +38,8 @@ public class SystemKeyToolTests extends CliToolTestCase {\n     public void init() throws Exception {\n         terminal = mock(Terminal.class);\n         env = mock(Environment.class);\n-        when(env.binFile().getParent()).thenReturn(createTempDir());\n+        Path tmpDir = createTempDir();\n+        when(env.binFile()).thenReturn(tmpDir.resolve(\"bin\"));\n     }\n \n     @Test",
    "output": "Fix mocking here"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n@@ -47,8 +47,11 @@\n public class JarHell {\n \n     /** Simple driver class, can be used eg. from builds. Returns non-zero on jar-hell */\n+    @SuppressForbidden(reason = \"command line tool\")\n     public static void main(String args[]) throws Exception {\n+        System.out.println(\"checking for jar hell...\");\n         checkJarHell();\n+        System.out.println(\"no jar hell found\");\n     }\n \n     /**",
    "output": "Fix shaded jar packaging"
  },
  {
    "input": "diff --git a/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java b/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java\n--- a/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java\n+++ b/watcher/src/test/java/org/elasticsearch/watcher/WatcherF.java\n@@ -18,7 +18,7 @@\n  */\n public class WatcherF {\n \n-    public static void main(String[] args) {\n+    public static void main(String[] args) throws Throwable {\n         System.setProperty(\"es.http.cors.enabled\", \"true\");\n         System.setProperty(\"es.script.inline\", \"on\");\n         System.setProperty(\"es.shield.enabled\", \"false\");",
    "output": "Fix WatcherF compile error"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n@@ -47,8 +47,11 @@\n public class JarHell {\n \n     /** Simple driver class, can be used eg. from builds. Returns non-zero on jar-hell */\n+    @SuppressForbidden(reason = \"command line tool\")\n     public static void main(String args[]) throws Exception {\n+        System.out.println(\"checking for jar hell...\");\n         checkJarHell();\n+        System.out.println(\"no jar hell found\");\n     }\n \n     /**",
    "output": "Add jar hell check test for the shaded jar"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShardUtils.java b/core/src/main/java/org/elasticsearch/index/shard/ShardUtils.java\n--- a/core/src/main/java/org/elasticsearch/index/shard/ShardUtils.java\n+++ b/core/src/main/java/org/elasticsearch/index/shard/ShardUtils.java\n@@ -78,7 +78,11 @@ private static ElasticsearchDirectoryReader getElasticsearchDirectoryReader(Inde\n             if (reader instanceof ElasticsearchDirectoryReader) {\n                 return (ElasticsearchDirectoryReader) reader;\n             } else {\n-                return null; // lucene needs a getDelegate method on FilteredDirectoryReader - not a big deal here\n+                // We need to use FilterDirectoryReader#getDelegate and not FilterDirectoryReader#unwrap, because\n+                // If there are multiple levels of filtered leaf readers then with the unwrap() method it immediately\n+                // returns the most inner leaf reader and thus skipping of over any other filtered leaf reader that\n+                // may be instance of ElasticsearchLeafReader. This can cause us to miss the shardId.\n+                return getElasticsearchDirectoryReader(((FilterDirectoryReader) reader).getDelegate());\n             }\n         }\n         return null;",
    "output": "Fix ShardUtils#getElasticsearchDirectoryReader(...) to use FilterDirectoryReader#getDelegate()"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -222,7 +222,7 @@ private void stop() {\n         }\n     }\n \n-    public static void main(String[] args) throws Exception {\n+    public static void main(String[] args) throws Throwable {\n         BootstrapCLIParser bootstrapCLIParser = new BootstrapCLIParser();\n         CliTool.ExitStatus status = bootstrapCLIParser.execute(args);\n \n\ndiff --git a/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java b/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Elasticsearch.java\n@@ -24,7 +24,7 @@\n  */\n public class Elasticsearch extends Bootstrap {\n \n-    public static void main(String[] args) throws Exception {\n+    public static void main(String[] args) throws Throwable {\n         Bootstrap.main(args);\n     }\n }\n\\ No newline at end of file\n\ndiff --git a/core/src/main/java/org/elasticsearch/bootstrap/ElasticsearchF.java b/core/src/main/java/org/elasticsearch/bootstrap/ElasticsearchF.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/ElasticsearchF.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/ElasticsearchF.java\n@@ -25,7 +25,7 @@\n  */\n public class ElasticsearchF {\n \n-    public static void main(String[] args) throws Exception {\n+    public static void main(String[] args) throws Throwable {\n         System.setProperty(\"es.foreground\", \"yes\");\n         Bootstrap.main(args);\n     }",
    "output": "Make this less syntactically confusing"
  },
  {
    "input": "diff --git a/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java b/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java\n--- a/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java\n+++ b/marvel/src/test/java/org/elasticsearch/marvel/agent/collector/node/NodeStatsCollectorTests.java\n@@ -5,7 +5,6 @@\n  */\n package org.elasticsearch.marvel.agent.collector.node;\n \n-import org.apache.lucene.util.Constants;\n import org.elasticsearch.bootstrap.Bootstrap;\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.ClusterService;\n@@ -27,7 +26,6 @@ public class NodeStatsCollectorTests extends ElasticsearchIntegrationTest {\n \n     @Test\n     public void testNodeStatsCollector() throws Exception {\n-        assumeFalse(\"test is muted on Windows. See https://github.com/elastic/x-plugins/issues/368\", Constants.WINDOWS);\n         String[] nodes = internalCluster().getNodeNames();\n         for (String node : nodes) {\n             logger.info(\"--> collecting node stats on node [{}]\", node);\n@@ -52,7 +50,6 @@ public void testNodeStatsCollector() throws Exception {\n             assertNotNull(payload.getDiskThresholdWaterMarkHigh());\n \n             assertNotNull(payload.getNodeStats());\n-            assertThat(payload.getNodeStats().getProcess().getOpenFileDescriptors(), greaterThan(0L));\n         }\n     }\n ",
    "output": "Remove unnecessary assertion from test closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java\n@@ -51,7 +51,7 @@\n public class IndexNameExpressionResolver extends AbstractComponent {\n \n     private final ImmutableList<ExpressionResolver> expressionResolvers;\n-    private DateMathExpressionResolver dateMathExpressionResolver;\n+    private final DateMathExpressionResolver dateMathExpressionResolver;\n \n     @Inject\n     public IndexNameExpressionResolver(Settings settings) {",
    "output": "Make `dateMathExpressionResolver` final"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java\n@@ -234,7 +234,9 @@ private Decision underCapacity(ShardRouting shardRouting, RoutingNode node, Rout\n             int currentNodeCount = shardPerAttribute.get(node.node().attributes().get(awarenessAttribute));\n             // if we are above with leftover, then we know we are not good, even with mod\n             if (currentNodeCount > (requiredCountPerAttribute + leftoverPerAttribute)) {\n-                return allocation.decision(Decision.NO, NAME, \"too many shards on nodes for attribute: [%s]\", awarenessAttribute);\n+                return allocation.decision(Decision.NO, NAME,\n+                        \"too many shards on node for attribute: [%s], required per attribute: [%d], node count: [%d], leftover: [%d]\",\n+                        awarenessAttribute, requiredCountPerAttribute, currentNodeCount, leftoverPerAttribute);\n             }\n             // all is well, we are below or same as average\n             if (currentNodeCount <= requiredCountPerAttribute) {",
    "output": "Add more debugging information to the Awareness Decider Relates to"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java b/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java\n--- a/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java\n+++ b/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java\n@@ -176,7 +176,7 @@ public void search(Query query, Collector collector) throws IOException {\n \n     @Override\n     public void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {\n-        final boolean timeoutSet = searchContext.timeoutInMillis() != -1;\n+        final boolean timeoutSet = searchContext.timeoutInMillis() != SearchService.NO_TIMEOUT.millis();\n         final boolean terminateAfterSet = searchContext.terminateAfter() != SearchContext.DEFAULT_TERMINATE_AFTER;\n         try {\n             if (timeoutSet || terminateAfterSet) {",
    "output": "Use consistent check whether or not timeout is set"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java b/core/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java\n--- a/core/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java\n+++ b/core/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java\n@@ -145,6 +145,10 @@ public BulkProcessor build() {\n     }\n \n     public static Builder builder(Client client, Listener listener) {\n+        if (client == null) {\n+            throw new Exception(\"The client you specified while building a BulkProcessor is null\");\n+        }\n+        \n         return new Builder(client, listener);\n     }\n ",
    "output": "Upgrade BulkProcessor.java I suggest updating the BulkProcessor so that it prevents users from building a BulkProcessor with a null client. If the client is null, then the class should throw an exception with a message that describes the cause of the exception. Earlier today, when I passed a null client to the builder() method, later received an exception, and attempted to get the exception's message in my afterBulk() listener (e.g. e.getMessage()), the message was null. It took me a while to pinpoint the cause of the problem"
  },
  {
    "input": "diff --git a/plugins/cloud-azure/src/test/java/org/elasticsearch/repositories/azure/AzureSnapshotRestoreITest.java b/plugins/cloud-azure/src/test/java/org/elasticsearch/repositories/azure/AzureSnapshotRestoreITest.java\n--- a/plugins/cloud-azure/src/test/java/org/elasticsearch/repositories/azure/AzureSnapshotRestoreITest.java\n+++ b/plugins/cloud-azure/src/test/java/org/elasticsearch/repositories/azure/AzureSnapshotRestoreITest.java\n@@ -29,7 +29,6 @@\n import org.elasticsearch.client.ClusterAdminClient;\n import org.elasticsearch.cloud.azure.AbstractAzureTest;\n import org.elasticsearch.cloud.azure.storage.AzureStorageService;\n-import org.elasticsearch.cloud.azure.storage.AzureStorageService.Storage;\n import org.elasticsearch.cloud.azure.storage.AzureStorageServiceImpl;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.common.Strings;\n@@ -107,9 +106,9 @@ public void testSimpleWorkflow() {\n         logger.info(\"-->  creating azure repository with path [{}]\", getRepositoryPath());\n         PutRepositoryResponse putRepositoryResponse = client.admin().cluster().preparePutRepository(\"test-repo\")\n                 .setType(\"azure\").setSettings(Settings.settingsBuilder()\n-                        .put(Storage.CONTAINER, getContainerName())\n-                        .put(Storage.BASE_PATH, getRepositoryPath())\n-                        .put(Storage.CHUNK_SIZE, randomIntBetween(1000, 10000), ByteSizeUnit.BYTES)\n+                        .put(Repository.CONTAINER, getContainerName())\n+                        .put(Repository.BASE_PATH, getRepositoryPath())\n+                        .put(Repository.CHUNK_SIZE, randomIntBetween(1000, 10000), ByteSizeUnit.BYTES)\n                 ).get();\n         assertThat(putRepositoryResponse.isAcknowledged(), equalTo(true));\n ",
    "output": "Use correct settings keys for setting container, base path and chunk size in Azure integration test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java\n--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java\n+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsNodes.java\n@@ -395,7 +395,6 @@ public void addNodeStats(NodeStats nodeStats) {\n             }\n             count++;\n             if (nodeStats.getProcess().getCpu() != null) {\n-                // with no sigar, this may not be available\n                 cpuPercent += nodeStats.getProcess().getCpu().getPercent();\n             }\n             long fd = nodeStats.getProcess().getOpenFileDescriptors();",
    "output": "Remove Core Lib directory"
  },
  {
    "input": "diff --git a/watcher/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java b/watcher/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java\n--- a/watcher/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java\n+++ b/watcher/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java\n@@ -230,6 +230,11 @@ public XContentLocation getTokenLocation() {\n         return parser.getTokenLocation();\n     }\n \n+    @Override\n+    public boolean isClosed() {\n+        return parser.isClosed();\n+    }\n+\n     @Override\n     public void close() throws ElasticsearchException {\n         parser.close();",
    "output": "Add isClosed method to SensitiveXContentParser"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/action/ShieldActionMapper.java b/shield/src/main/java/org/elasticsearch/shield/action/ShieldActionMapper.java\n--- a/shield/src/main/java/org/elasticsearch/shield/action/ShieldActionMapper.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/action/ShieldActionMapper.java\n@@ -35,9 +35,10 @@ public String action(String action, TransportRequest request) {\n                 }\n                 break;\n             case AnalyzeAction.NAME:\n+            case AnalyzeAction.NAME + \"[s]\":\n                 assert request instanceof AnalyzeRequest;\n                 String[] indices = ((AnalyzeRequest) request).indices();\n-                if (indices == null || indices.length == 0) {\n+                if (indices == null || (indices.length == 1 && indices[0] == null)) {\n                     return CLUSTER_PERMISSION_ANALYZE;\n                 }\n                 break;",
    "output": "Upgrade ShieldActionMapper to handle the change to use TransportSingleShardAction This relates to commit cafc7078e228ab696d0689ec8b2119cb1626e9cd in elasticsearch"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n@@ -420,7 +420,10 @@ public ClusterState execute(ClusterState currentState) throws Exception {\n                             .put(indexMetaData, false)\n                             .build();\n \n-                    logger.info(\"[{}] creating index, cause [{}], templates {}, shards [{}]/[{}], mappings {}\", request.index(), request.cause(), templateNames, indexMetaData.numberOfShards(), indexMetaData.numberOfReplicas(), mappings.keySet());\n+                    String maybeShadowIndicator = IndexMetaData.isIndexUsingShadowReplicas(indexMetaData.settings()) ? \"s\" : \"\";\n+                    logger.info(\"[{}] creating index, cause [{}], templates {}, shards [{}]/[{}{}], mappings {}\",\n+                            request.index(), request.cause(), templateNames, indexMetaData.numberOfShards(),\n+                            indexMetaData.numberOfReplicas(), maybeShadowIndicator, mappings.keySet());\n \n                     ClusterBlocks.Builder blocks = ClusterBlocks.builder().blocks(currentState.blocks());\n                     if (!request.blocks().isEmpty()) {",
    "output": "Add shadow indicator when using shadow replicas"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java\n@@ -56,9 +56,6 @@ public List<SpanQueryBuilder> clauses() {\n \n     @Override\n     protected void doXContent(XContentBuilder builder, Params params) throws IOException {\n-        if (clauses.isEmpty()) {\n-            throw new IllegalArgumentException(\"Must have at least one clause when building a spanOr query\");\n-        }\n         builder.startObject(NAME);\n         builder.startArray(\"clauses\");\n         for (SpanQueryBuilder clause : clauses) {",
    "output": "Remove empty check in doXContent, parser or validate will take care of this"
  },
  {
    "input": "diff --git a/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/HttpESExporterTests.java b/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/HttpESExporterTests.java\n--- a/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/HttpESExporterTests.java\n+++ b/marvel/src/test/java/org/elasticsearch/marvel/agent/exporter/HttpESExporterTests.java\n@@ -7,10 +7,13 @@\n \n import com.google.common.base.Predicate;\n import com.google.common.collect.ImmutableList;\n+\n import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.cluster.metadata.IndexTemplateMetaData;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.license.plugin.LicensePlugin;\n+import org.elasticsearch.marvel.MarvelPlugin;\n import org.elasticsearch.marvel.agent.AgentService;\n import org.elasticsearch.marvel.agent.collector.indices.IndexStatsMarvelDoc;\n import org.elasticsearch.node.Node;\n@@ -31,6 +34,14 @@\n @ClusterScope(transportClientRatio = 0.0, scope = ElasticsearchIntegrationTest.Scope.TEST, numDataNodes = 0, numClientNodes = 0)\n public class HttpESExporterTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.settingsBuilder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugin.types\", MarvelPlugin.class.getName() + \",\" + LicensePlugin.class.getName())\n+                .build();\n+    }\n+    \n     @Test\n     public void testHttpServerOff() {\n         Settings.Builder builder = Settings.builder()",
    "output": "Fix marvel unit tests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java\n--- a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java\n@@ -68,8 +68,8 @@ public void testInnerQueryNull() {\n     @Test\n     public void testUnsupportedInnerQueryType() throws IOException {\n         QueryParseContext parseContext = createContext();\n-        // test makes only sense if date field is mapped\n-        if (parseContext.fieldMapper(DATE_FIELD_NAME) != null) {\n+        // test makes only sense if we have at least one type registered with date field mapping\n+        if (getCurrentTypes().length > 0 && parseContext.fieldMapper(DATE_FIELD_NAME) != null) {\n             try {\n                 RangeQueryBuilder query = new RangeQueryBuilder(DATE_FIELD_NAME);\n                 new SpanMultiTermQueryBuilder(query).toQuery(createContext());",
    "output": "Fix edge case for SpanMultiTermQueryBuilderTest"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java\n@@ -161,9 +161,6 @@ public double apply(double n) {\n \n         @Override\n         public String toString() {\n-            if (this == NONE) {\n-                return \"\";\n-            }\n             return super.toString().toLowerCase(Locale.ROOT);\n         }\n     }\n\ndiff --git a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueTests.java b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueTests.java\n--- a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueTests.java\n@@ -69,6 +69,14 @@ public void testFieldValueFactor() throws IOException {\n                 .get();\n         assertOrderedSearchHits(response, \"2\", \"1\");\n \n+        // try again, but this time explicitly use the do-nothing modifier\n+        response = client().prepareSearch(\"test\")\n+                .setExplain(randomBoolean())\n+                .setQuery(functionScoreQuery(simpleQueryStringQuery(\"foo\"),\n+                        fieldValueFactorFunction(\"test\").modifier(FieldValueFactorFunction.Modifier.NONE)))\n+                .get();\n+        assertOrderedSearchHits(response, \"2\", \"1\");\n+\n         // document 1 scores higher because 1/5 > 1/17\n         response = client().prepareSearch(\"test\")\n                 .setExplain(randomBoolean())",
    "output": "Fix malformed query generation"
  },
  {
    "input": "diff --git a/shield/src/main/java/org/elasticsearch/shield/authz/Privilege.java b/shield/src/main/java/org/elasticsearch/shield/authz/Privilege.java\n--- a/shield/src/main/java/org/elasticsearch/shield/authz/Privilege.java\n+++ b/shield/src/main/java/org/elasticsearch/shield/authz/Privilege.java\n@@ -150,7 +150,7 @@ public static class Index extends AutomatonPrivilege<Index> {\n         public static final Index SEARCH =          new Index(\"search\",         SearchAction.NAME + \"*\", MultiSearchAction.NAME + \"*\", SuggestAction.NAME + \"*\");\n         public static final Index GET =             new Index(\"get\",            GetAction.NAME + \"*\", MultiGetAction.NAME + \"*\");\n         public static final Index SUGGEST =         new Index(\"suggest\",        SuggestAction.NAME + \"*\");\n-        public static final Index INDEX =           new Index(\"index\",          \"indices:data/write/index*\", \"indices:data/write/update\");\n+        public static final Index INDEX =           new Index(\"index\",          \"indices:data/write/index*\", \"indices:data/write/update*\");\n         public static final Index DELETE =          new Index(\"delete\",         \"indices:data/write/delete*\");\n         public static final Index WRITE =           new Index(\"write\",          \"indices:data/write/*\");\n ",
    "output": "Upgrade index privilege to include shard action for indices:data/write/update"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java\n--- a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java\n+++ b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java\n@@ -456,7 +456,6 @@ protected void doRun() throws Exception {\n                         performOnPrimary(primary, shardsIt);\n                     }\n                 } catch (Throwable t) {\n-                    // no commit: check threadpool rejection.\n                     finishAsFailed(t);\n                 }\n             } else {",
    "output": "Remove left over no commit from TransportReplicationAction It asks to double check thread pool rejection. I did and don't see problems with it"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java b/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java\n--- a/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java\n@@ -92,6 +92,7 @@ public void testBasic() throws Exception {\n         disableAllocation(index);\n         logger.info(\"--> stop random node\");\n         internalCluster().stopRandomNode(new IndexNodePredicate(index));\n+        ensureYellow(index);\n         ClusterState clusterState = client().admin().cluster().prepareState().get().getState();\n         List<ShardRouting> unassignedShards = clusterState.routingTable().index(index).shardsWithState(ShardRoutingState.UNASSIGNED);\n         response = client().admin().indices().shardStores(Requests.indicesShardStoresRequest(index)).get();",
    "output": "Add missing ensureYellow to IndicesShardStoreRequestTests.testBasic"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java\n@@ -333,6 +333,7 @@ public void singleShardMultipleAllocationFailures() {\n     }\n \n     @Test\n+    @AwaitsFix(bugUrl = \"boaz is looking into failures: http://build-us-00.elastic.co/job/es_core_master_strong/4168/\")\n     public void firstAllocationFailureTwoNodes() {\n         AllocationService strategy = createAllocationService(settingsBuilder()\n                 .put(\"cluster.routing.allocation.concurrent_recoveries\", 10)",
    "output": "Add await fix firstAllocationFailureTwoNodes"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java b/core/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n--- a/core/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n@@ -21,8 +21,6 @@\n \n import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n-import org.elasticsearch.action.admin.cluster.stats.ClusterStatsRequest;\n-import org.elasticsearch.action.admin.cluster.stats.ClusterStatsRequestBuilder;\n import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;\n import org.elasticsearch.action.search.SearchResponse;\n import org.elasticsearch.action.search.SearchType;\n@@ -35,14 +33,11 @@\n import org.elasticsearch.index.query.QueryBuilders;\n import org.elasticsearch.index.search.stats.SearchStats.Stats;\n import org.elasticsearch.script.Script;\n-import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n import java.util.HashSet;\n-import java.util.Iterator;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n \n import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;\n import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;",
    "output": "Remove unused imports"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java\n--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java\n+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java\n@@ -161,9 +161,6 @@ public double apply(double n) {\n \n         @Override\n         public String toString() {\n-            if (this == NONE) {\n-                return \"\";\n-            }\n             return super.toString().toLowerCase(Locale.ROOT);\n         }\n     }",
    "output": "Fix malformed query generation"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java b/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java\n--- a/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java\n+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/segments/IndicesShardStoreRequestTests.java\n@@ -22,7 +22,6 @@\n import com.carrotsearch.hppc.cursors.IntObjectCursor;\n \n import com.carrotsearch.hppc.cursors.ObjectCursor;\n-import com.carrotsearch.randomizedtesting.annotations.Seed;\n import com.google.common.base.Predicate;\n import org.apache.lucene.index.CorruptIndexException;\n import org.elasticsearch.action.admin.indices.shards.IndicesShardStoresResponse;",
    "output": "Remove redundant import"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n@@ -535,7 +535,7 @@ public void multiValuedField_WithValueScript_NotUnique() throws Exception {\n                 .addAggregation(terms(\"terms\")\n                         .field(MULTI_VALUED_FIELD_NAME)\n                         .collectMode(randomFrom(SubAggCollectionMode.values()))\n-                                .script(new Script(\"(long) _value / 1000 + 1\")))\n+                                .script(new Script(\"(long) (_value / 1000 + 1)\")))\n                 .execute().actionGet();\n \n         assertSearchResponse(response);",
    "output": "Upgrade groovy from 2.4.0 to 2.4.4"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n@@ -535,7 +535,7 @@ public void multiValuedField_WithValueScript_NotUnique() throws Exception {\n                 .addAggregation(terms(\"terms\")\n                         .field(MULTI_VALUED_FIELD_NAME)\n                         .collectMode(randomFrom(SubAggCollectionMode.values()))\n-                                .script(new Script(\"(long) _value / 1000 + 1\")))\n+                                .script(new Script(\"(long) (_value / 1000 + 1)\")))\n                 .execute().actionGet();\n \n         assertSearchResponse(response);",
    "output": "Upgrade groovy from 2.4.0 to 2.4.4"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java b/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n@@ -21,6 +21,7 @@\n \n import com.google.common.base.Predicate;\n \n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.Priority;\n@@ -44,6 +45,7 @@\n import static org.hamcrest.Matchers.*;\n \n @ClusterScope(scope = Scope.TEST, numDataNodes = 0)\n+@LuceneTestCase.AwaitsFix(bugUrl = \"boaz is looking at failures in this test class. Example failure: http://build-us-00.elastic.co/job/es_g1gc_master_metal/11653/\")\n public class MinimumMasterNodesTests extends ElasticsearchIntegrationTest {\n \n     @Test\n@@ -165,7 +167,6 @@ public void run() {\n     }\n \n     @Test @Slow\n-    @AwaitsFix(bugUrl = \"boaz is looking a this. Example failure: http://build-us-00.elastic.co/job/es_g1gc_master_metal/11653/\")\n     public void multipleNodesShutdownNonMasterNodes() throws Exception {\n         Settings settings = settingsBuilder()\n                 .put(\"discovery.type\", \"zen\")",
    "output": "Add awaitFix the entire MinimumMasterNodesTests class. multiple tests are failing"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java b/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n@@ -165,6 +165,7 @@ public void run() {\n     }\n \n     @Test @Slow\n+    @AwaitsFix(bugUrl = \"boaz is looking a this. Example failure: http://build-us-00.elastic.co/job/es_g1gc_master_metal/11653/\")\n     public void multipleNodesShutdownNonMasterNodes() throws Exception {\n         Settings settings = settingsBuilder()\n                 .put(\"discovery.type\", \"zen\")",
    "output": "Add await fix to multipleNodesShutdownNonMasterNodes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java\n@@ -137,8 +137,8 @@ private IndexMetaData upgradeLegacyRoutingSettings(IndexMetaData indexMetaData)\n         } else if (indexMetaData.getCreationVersion().onOrAfter(Version.V_2_0_0_beta1)) {\n             if (indexMetaData.getSettings().get(IndexMetaData.SETTING_LEGACY_ROUTING_HASH_FUNCTION) != null\n                     || indexMetaData.getSettings().get(IndexMetaData.SETTING_LEGACY_ROUTING_USE_TYPE) != null) {\n-                throw new IllegalStateException(\"Indices created on or after 2.0 should NOT contain [\" + IndexMetaData.SETTING_LEGACY_ROUTING_HASH_FUNCTION\n-                        + \"] + or [\" + IndexMetaData.SETTING_LEGACY_ROUTING_USE_TYPE + \"] in their index settings\");\n+                throw new IllegalStateException(\"Index [\" + indexMetaData.getIndex() + \"] created on or after 2.0 should NOT contain [\" + IndexMetaData.SETTING_LEGACY_ROUTING_HASH_FUNCTION\n+                        + \"] + or [\" + IndexMetaData.SETTING_LEGACY_ROUTING_USE_TYPE + \"] in its index settings\");\n             }\n         }\n         return indexMetaData;",
    "output": "Add index name to the upgrade exception"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterState.java b/core/src/main/java/org/elasticsearch/cluster/ClusterState.java\n--- a/core/src/main/java/org/elasticsearch/cluster/ClusterState.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterState.java\n@@ -417,7 +417,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n         // meta data\n         if (metrics.contains(Metric.METADATA)) {\n             builder.startObject(\"metadata\");\n-\n+            builder.field(\"cluster_uuid\", metaData().clusterUUID());\n             builder.startObject(\"templates\");\n             for (ObjectCursor<IndexTemplateMetaData> cursor : metaData().templates().values()) {\n                 IndexTemplateMetaData templateMetaData = cursor.value;",
    "output": "Add MetaData.clusterUUID to ClusterState.toXContent The MetaData.clusterUUID is guaranteed to be unique across clusters and is handy (which may or may not have the same human readable cluster name)"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java\n@@ -103,7 +103,6 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n \n         WildcardQuery wildcardQuery = new WildcardQuery(new Term(fieldName, valueBytes));\n         QueryParsers.setRewriteMethod(wildcardQuery, parseContext.parseFieldMatcher(), rewriteMethod);\n-        wildcardQuery.setRewriteMethod(QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod));\n         wildcardQuery.setBoost(boost);\n         if (queryName != null) {\n             parseContext.addNamedQuery(queryName, wildcardQuery);",
    "output": "Fix rewrite set twice in WildcardQueryParser"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n@@ -90,7 +90,7 @@ public static void checkJarHell(URL urls[]) throws Exception {\n                 logger.debug(\"excluding system resource: {}\", path);\n                 continue;\n             }\n-            if (path.endsWith(\".jar\")) {\n+            if (path.toString().endsWith(\".jar\")) {\n                 if (!seenJars.add(path)) {\n                     logger.debug(\"excluding duplicate classpath element: {}\", path);\n                     continue; // we can't fail because of sheistiness with joda-time",
    "output": "Fix broken usage of path api"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ShieldIntegrationTest.java b/src/test/java/org/elasticsearch/test/ShieldIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ShieldIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ShieldIntegrationTest.java\n@@ -167,6 +167,13 @@ protected Settings transportClientSettings() {\n                 .build();\n     }\n \n+    @Override\n+    protected Settings externalClusterClientSettings() {\n+        return Settings.builder()\n+                .put(\"shield.user\", ShieldSettingsSource.DEFAULT_USER_NAME + \":\" + ShieldSettingsSource.DEFAULT_PASSWORD)\n+                .build();\n+    }\n+\n     /**\n      * Allows for us to get the system key that is being used for the cluster\n      * @return the system key bytes\n\ndiff --git a/src/test/java/org/elasticsearch/test/ShieldRestIT.java b/src/test/java/org/elasticsearch/test/ShieldRestIT.java\n--- a/src/test/java/org/elasticsearch/test/ShieldRestIT.java\n+++ b/src/test/java/org/elasticsearch/test/ShieldRestIT.java\n@@ -11,12 +11,10 @@\n import org.elasticsearch.test.rest.ElasticsearchRestTestCase;\n import org.elasticsearch.test.rest.RestTestCandidate;\n import org.elasticsearch.test.rest.parser.RestTestParseException;\n-import org.junit.Ignore;\n \n import java.io.IOException;\n \n /** Runs rest tests against external cluster */\n-@Ignore(\"not yet functional\")\n public class ShieldRestIT extends ShieldRestTestCase {\n     public ShieldRestIT(@Name(\"yaml\") RestTestCandidate testCandidate) {\n         super(testCandidate);",
    "output": "Make integration tests work"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java b/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java\n--- a/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java\n+++ b/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java\n@@ -0,0 +1,21 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.watcher.test.rest;\n+\n+import org.elasticsearch.test.rest.RestTestCandidate;\n+\n+/** Runs rest tests against external cluster */\n+public class WatcherRestIT extends WatcherRestTests {\n+\n+    public WatcherRestIT(RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+\n+    @Override\n+    protected boolean enableShield() {\n+        return false;\n+    }\n+}",
    "output": "Add integration test phase to watcher build"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n@@ -175,8 +175,6 @@ private boolean reroute(RoutingAllocation allocation) {\n         // now allocate all the unassigned to available nodes\n         if (allocation.routingNodes().hasUnassigned()) {\n             changed |= shardsAllocators.allocateUnassigned(allocation);\n-            // elect primaries again, in case this is needed with unassigned allocation\n-            changed |= electPrimariesAndUnassignedDanglingReplicas(allocation);\n         }\n \n         // move shards that no longer can be allocated",
    "output": "Remove double call to elect primaries"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n@@ -175,8 +175,6 @@ private boolean reroute(RoutingAllocation allocation) {\n         // now allocate all the unassigned to available nodes\n         if (allocation.routingNodes().hasUnassigned()) {\n             changed |= shardsAllocators.allocateUnassigned(allocation);\n-            // elect primaries again, in case this is needed with unassigned allocation\n-            changed |= electPrimariesAndUnassignedDanglingReplicas(allocation);\n         }\n \n         // move shards that no longer can be allocated",
    "output": "Remove double call to elect primaries There is no need to call the elect logic twice, we used to need it, but no longer since we handle dangling replicas for unassigned primaries properly"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java b/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java\n--- a/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java\n+++ b/src/test/java/org/elasticsearch/watcher/test/rest/WatcherRestIT.java\n@@ -0,0 +1,21 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.watcher.test.rest;\n+\n+import org.elasticsearch.test.rest.RestTestCandidate;\n+\n+/** Runs rest tests against external cluster */\n+public class WatcherRestIT extends WatcherRestTests {\n+\n+    public WatcherRestIT(RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+\n+    @Override\n+    protected boolean enableShield() {\n+        return false;\n+    }\n+}",
    "output": "Add integration test phase to watcher build. Integration tests unzip elasticsearch.zip, install the license and watcher plugins with bin/plugin, starts up es with bin/elasticsearch, runs rest tests, then shuts down es. They are run during `mvn verify` phase"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/HoltWintersModel.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/HoltWintersModel.java\n--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/HoltWintersModel.java\n+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/HoltWintersModel.java\n@@ -470,7 +470,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n             }\n \n             if (seasonalityType != null) {\n-                builder.field(\"seasonalityType\", seasonalityType);\n+                builder.field(\"type\", seasonalityType.getName());\n             }\n \n             builder.endObject();",
    "output": "Fix value of HoltWinters seasonality param in builder Should be `type`, not `seasonalityType`"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n@@ -84,7 +84,7 @@ public static void checkJarHell(URL urls[]) throws Exception {\n         final Map<String,URL> clazzes = new HashMap<>(32768);\n         Set<String> seenJars = new HashSet<>();\n         for (final URL url : urls) {\n-            String path = URLDecoder.decode(url.getPath(), \"UTF-8\");\n+            String path = PathUtils.get(url.toURI()).toString();\n             // exclude system resources\n             if (path.startsWith(javaHome)) {\n                 logger.debug(\"excluding system resource: {}\", path);",
    "output": "Fix JarHell check to properly convert URL to Path so it can be compared to java.home"
  },
  {
    "input": "diff --git a/plugin/src/test/java/org/elasticsearch/license/plugin/rest/LicensesRestIT.java b/plugin/src/test/java/org/elasticsearch/license/plugin/rest/LicensesRestIT.java\n--- a/plugin/src/test/java/org/elasticsearch/license/plugin/rest/LicensesRestIT.java\n+++ b/plugin/src/test/java/org/elasticsearch/license/plugin/rest/LicensesRestIT.java\n@@ -0,0 +1,27 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.license.plugin.rest;\n+\n+\n+import com.carrotsearch.randomizedtesting.annotations.Name;\n+import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n+import org.elasticsearch.test.rest.ElasticsearchRestTestCase;\n+import org.elasticsearch.test.rest.RestTestCandidate;\n+import org.elasticsearch.test.rest.parser.RestTestParseException;\n+\n+import java.io.IOException;\n+\n+public class LicensesRestIT extends ElasticsearchRestTestCase {\n+\n+    public LicensesRestIT(@Name(\"yaml\") RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+\n+    @ParametersFactory\n+    public static Iterable<Object[]> parameters() throws IOException, RestTestParseException {\n+        return ElasticsearchRestTestCase.createParameters(0, 1);\n+    }\n+}",
    "output": "Add basic license integ test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Security.java b/core/src/main/java/org/elasticsearch/bootstrap/Security.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Security.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Security.java\n@@ -96,11 +96,9 @@ static void setCodebaseProperties() {\n                 for (Map.Entry<Pattern,String> e : SPECIAL_JARS.entrySet()) {\n                     if (e.getKey().matcher(url.getPath()).matches()) {\n                         String prop = e.getValue();\n-                        // TODO: we need to fix plugins to not include duplicate e.g. lucene-core jars,\n-                        // to add back this safety check! see https://github.com/elastic/elasticsearch/issues/11647\n-                        // if (System.getProperty(prop) != null) {\n-                        //    throw new IllegalStateException(\"property: \" + prop + \" is unexpectedly set: \" + System.getProperty(prop));\n-                        //}\n+                        if (System.getProperty(prop) != null) {\n+                            throw new IllegalStateException(\"property: \" + prop + \" is unexpectedly set: \" + System.getProperty(prop));\n+                        }\n                         System.setProperty(prop, url.toString());\n                     }\n                 }",
    "output": "Remove temporary leniency"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java\n@@ -78,7 +78,6 @@ public RegexpQueryBuilder flags(RegexpFlag... flags) {\n      */\n     public RegexpQueryBuilder maxDeterminizedStates(int value) {\n         this.maxDeterminizedStates = value;\n-        this.maxDetermizedStatesSet = true;\n         return this;\n     }\n ",
    "output": "Fix RegexpQueryBuilder#maxDeterminizedStates Value was improperly set to `true`. Relates to"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bootstrap/SecurityTests.java b/core/src/test/java/org/elasticsearch/bootstrap/SecurityTests.java\n--- a/core/src/test/java/org/elasticsearch/bootstrap/SecurityTests.java\n+++ b/core/src/test/java/org/elasticsearch/bootstrap/SecurityTests.java\n@@ -204,4 +204,28 @@ public void testProcessExecution() throws Exception {\n             fail(\"didn't get expected exception\");\n         } catch (SecurityException expected) {}\n     }\n+\n+    /** When a configured dir is a symlink, test that permissions work on link target */\n+    public void testSymlinkPermissions() throws IOException {\n+        Path dir = createTempDir();\n+\n+        Path target = dir.resolve(\"target\");\n+        Files.createDirectory(target);\n+\n+        // symlink\n+        Path link = dir.resolve(\"link\");\n+        try {\n+            Files.createSymbolicLink(link, target);\n+        } catch (UnsupportedOperationException | IOException e) {\n+            assumeNoException(\"test requires filesystem that supports symbolic links\", e);\n+        } catch (SecurityException e) {\n+            assumeNoException(\"test cannot create symbolic links with security manager enabled\", e);\n+        }\n+        Permissions permissions = new Permissions();\n+        Security.addPath(permissions, link, \"read\");\n+        assertTrue(permissions.implies(new FilePermission(link.toString(), \"read\")));\n+        assertTrue(permissions.implies(new FilePermission(link.resolve(\"foo\").toString(), \"read\")));\n+        assertTrue(permissions.implies(new FilePermission(target.toString(), \"read\")));\n+        assertTrue(permissions.implies(new FilePermission(target.resolve(\"foo\").toString(), \"read\")));\n+    }\n }",
    "output": "Add symlink permissions test"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java b/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java\n@@ -179,7 +179,7 @@ static List<FieldMapper> newList(FieldMapper... mapper) {\n     static class FakeFieldMapper extends AbstractFieldMapper {\n         static Settings dummySettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT.id).build();\n         public FakeFieldMapper(String fullName, String indexName) {\n-            super(fullName, makeFieldType(fullName, indexName), null, dummySettings, null, null);\n+            super(fullName, makeFieldType(fullName, indexName), makeFieldType(fullName, indexName), dummySettings, null, null);\n         }\n         static MappedFieldType makeFieldType(String fullName, String indexName) {\n             FakeFieldType fieldType = new FakeFieldType();",
    "output": "Fix fake field mapper to not pass null for defaultfieldtype"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java\n--- a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java\n@@ -39,18 +39,16 @@ protected Query doCreateExpectedQuery(SpanContainingQueryBuilder testQueryBuilde\n     protected SpanContainingQueryBuilder doCreateTestQueryBuilder() {\n         SpanTermQueryBuilder bigQuery = new SpanTermQueryBuilderTest().createTestQueryBuilder();\n         // we need same field name and value type as bigQuery for little query\n-        Object bigValue = bigQuery.value;\n+        String fieldName = bigQuery.fieldName();\n         Object littleValue;\n-        if (bigValue instanceof Boolean) {\n-            littleValue = randomBoolean();\n-        } else if (bigValue instanceof Integer) {\n-            littleValue = randomInt();\n-        } else if (bigValue instanceof Double) {\n-            littleValue = randomDouble();\n-        } else {\n-            littleValue = randomAsciiOfLengthBetween(1, 10);\n+        switch (fieldName) {\n+            case BOOLEAN_FIELD_NAME: littleValue = randomBoolean(); break;\n+            case INT_FIELD_NAME: littleValue = randomInt(); break;\n+            case DOUBLE_FIELD_NAME: littleValue = randomDouble(); break;\n+            case STRING_FIELD_NAME: littleValue = randomAsciiOfLengthBetween(1, 10); break;\n+            default : littleValue = randomAsciiOfLengthBetween(1, 10);\n         }\n-        SpanTermQueryBuilder littleQuery = new SpanTermQueryBuilder(bigQuery.fieldName(), littleValue);\n+        SpanTermQueryBuilder littleQuery = new SpanTermQueryBuilder(fieldName, littleValue);\n         return new SpanContainingQueryBuilder(bigQuery, littleQuery);\n     }\n ",
    "output": "Change creation of test query"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/NamingConventionTests.java b/core/src/test/java/org/elasticsearch/NamingConventionTests.java\n--- a/core/src/test/java/org/elasticsearch/NamingConventionTests.java\n+++ b/core/src/test/java/org/elasticsearch/NamingConventionTests.java\n@@ -75,7 +75,10 @@ public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IO\n                         if (filename.endsWith(\".class\")) {\n                             Class<?> clazz = loadClass(filename);\n                             if (Modifier.isAbstract(clazz.getModifiers()) == false && Modifier.isInterface(clazz.getModifiers()) == false) {\n-                                if ((clazz.getName().endsWith(\"Tests\") || clazz.getName().endsWith(\"Test\"))) { // don't worry about the ones that match the pattern\n+                                if (clazz.getName().endsWith(\"Tests\") || \n+                                    clazz.getName().endsWith(\"IT\")    || \n+                                    clazz.getName().endsWith(\"Test\")) { // don't worry about the ones that match the pattern\n+\n                                     if (isTestCase(clazz) == false) {\n                                         notImplementing.add(clazz);\n                                     }",
    "output": "Fix test to allow integration tests"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/rest/RestIT.java b/core/src/test/java/org/elasticsearch/test/rest/RestIT.java\n--- a/core/src/test/java/org/elasticsearch/test/rest/RestIT.java\n+++ b/core/src/test/java/org/elasticsearch/test/rest/RestIT.java\n@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.test.rest;\n+\n+import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n+\n+import org.elasticsearch.test.rest.parser.RestTestParseException;\n+\n+import java.io.IOException;\n+\n+/** Rest integration test. runs against external cluster in 'mvn verify' */\n+public class RestIT extends ElasticsearchRestTestCase {\n+    public RestIT(RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+    // we run them all sequentially: start simple!\n+    @ParametersFactory\n+    public static Iterable<Object[]> parameters() throws IOException, RestTestParseException {\n+        return createParameters(0, 1);\n+    }\n+}",
    "output": "Add integration test harness to maven build"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisTests.java b/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisTests.java\n--- a/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisTests.java\n+++ b/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisTests.java\n@@ -451,14 +451,14 @@ public void testMoreLikeThisArtificialDocs() throws Exception {\n         logger.info(\"Indexing a single document ...\");\n         XContentBuilder doc = jsonBuilder().startObject();\n         for (int i = 0; i < numFields; i++) {\n-            doc.field(\"field\"+i, generateRandomStringArray(5, 10, false));\n+            doc.field(\"field\"+i, generateRandomStringArray(5, 10, false)+\"a\"); // make sure they are not all empty\n         }\n         doc.endObject();\n         indexRandom(true, client().prepareIndex(\"test\", \"type1\", \"0\").setSource(doc));\n \n         logger.info(\"Checking the document matches ...\");\n         MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()\n-                .like((Item) new Item().doc(doc).index(\"test\").type(\"type1\"))\n+                .like((Item) new Item().doc(doc).index(\"test\").type(\"type1\").routing(\"0\"))  // routing to ensure we hit the shard with the doc\n                 .minTermFreq(0)\n                 .minDocFreq(0)\n                 .maxQueryTerms(100)",
    "output": "Fix testMoreLikeThisArtificialDocs Ensure that the indexed doc hasn't all its fields empty and that the artificial doc requested is always routed to the shard having that doc"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java b/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java\n--- a/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java\n+++ b/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java\n@@ -55,13 +55,15 @@ public void stop() {\n     }\n \n     private synchronized void stop(boolean manual) {\n+        //This is set here since even if we are not started if we have requested a manual stop we do not want an automatic start to start watcher\n+        manuallyStopped = manual;\n+\n         WatcherState watcherState = watcherService.state();\n         if (watcherState != WatcherState.STARTED) {\n             logger.debug(\"not stopping watcher. watcher can only stop if its current state is [{}], but its current state now is [{}]\", WatcherState.STARTED, watcherState);\n             return;\n         }\n \n-        manuallyStopped = manual;\n         watcherService.stop();\n     }\n \n@@ -79,6 +81,11 @@ private synchronized void start(ClusterState state, boolean manual) {\n             return;\n         }\n \n+        //If we are manually starting we should clear the manuallyStopped flag\n+        if (manual && manuallyStopped) {\n+            manuallyStopped = false;\n+        }\n+\n         if (!watcherService.validate(state)) {\n             logger.debug(\"not starting watcher. because the cluster isn't ready yet to run watcher\");\n             return;",
    "output": "Change manual stop semantics. This change sets the manually stopped flag even if manual stop is requested but the watcher is not started. Also clears the manually stopped flag if a manual start is initiated"
  },
  {
    "input": "diff --git a/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicenseUtils.java b/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicenseUtils.java\n--- a/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicenseUtils.java\n+++ b/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicenseUtils.java\n@@ -5,8 +5,8 @@\n  */\n package org.elasticsearch.license.plugin.core;\n \n-import org.elasticsearch.ElasticsearchException;\n-import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.ElasticsearchSecurityException;\n+import org.elasticsearch.rest.RestStatus;\n \n public class LicenseUtils {\n \n@@ -19,9 +19,9 @@ public class LicenseUtils {\n      * <code>feature</code> accessible through {@link #EXPIRED_FEATURE_HEADER} in the\n      * exception's rest header\n      */\n-    public static ElasticsearchException newExpirationException(String feature) {\n-        // TODO: after https://github.com/elastic/elasticsearch/pull/12006 use ElasicsearchException with addHeader(EXPIRED_FEATURE_HEADER, feature)\n-        return new ElasticsearchException.WithRestHeadersException(\"license expired for feature [\" + feature + \"]\",\n-                Tuple.tuple(EXPIRED_FEATURE_HEADER, new String[] {feature}));\n+    public static ElasticsearchSecurityException newExpirationException(String feature) {\n+        ElasticsearchSecurityException e = new ElasticsearchSecurityException(\"license expired for feature [{}]\", RestStatus.UNAUTHORIZED, feature);\n+        e.addHeader(EXPIRED_FEATURE_HEADER, feature);\n+        return e;\n     }\n }",
    "output": "Change the license expiration exception to ElasticsearchSecurityException We'd like to have an UNAUTHORIZED behaviour when the license is expired"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n@@ -224,8 +224,8 @@ public boolean equals(Object o) {\n                 if (lowerTerm != null ? !lowerTerm.equals(that.lowerTerm) : that.lowerTerm != null) return false;\n                 if (upperTerm != null ? !upperTerm.equals(that.upperTerm) : that.upperTerm != null) return false;\n                 if (timeZone != null ? !timeZone.equals(that.timeZone) : that.timeZone != null) return false;\n-                return !(forcedDateParser != null ? !forcedDateParser.equals(that.forcedDateParser) : that.forcedDateParser != null);\n \n+                return true;\n             }\n \n             @Override\n@@ -236,7 +236,6 @@ public int hashCode() {\n                 result = 31 * result + (includeLower ? 1 : 0);\n                 result = 31 * result + (includeUpper ? 1 : 0);\n                 result = 31 * result + (timeZone != null ? timeZone.hashCode() : 0);\n-                result = 31 * result + (forcedDateParser != null ? forcedDateParser.hashCode() : 0);\n                 return result;\n             }\n ",
    "output": "Remove forcedDateParser from hashCode() and equals() as it holds no value when it comes to equality"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/rest/RestIT.java b/core/src/test/java/org/elasticsearch/test/rest/RestIT.java\n--- a/core/src/test/java/org/elasticsearch/test/rest/RestIT.java\n+++ b/core/src/test/java/org/elasticsearch/test/rest/RestIT.java\n@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.test.rest;\n+\n+import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n+\n+import org.elasticsearch.test.rest.parser.RestTestParseException;\n+\n+import java.io.IOException;\n+\n+/** Rest integration test. runs against external cluster in 'mvn verify' */\n+public class RestIT extends ElasticsearchRestTestCase {\n+    public RestIT(RestTestCandidate testCandidate) {\n+        super(testCandidate);\n+    }\n+    // we run them all sequentially: start simple!\n+    @ParametersFactory\n+    public static Iterable<Object[]> parameters() throws IOException, RestTestParseException {\n+        return createParameters(0, 1);\n+    }\n+}",
    "output": "Add simple integ testing infra"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/WatcherF.java b/src/test/java/org/elasticsearch/watcher/WatcherF.java\n--- a/src/test/java/org/elasticsearch/watcher/WatcherF.java\n+++ b/src/test/java/org/elasticsearch/watcher/WatcherF.java\n@@ -14,14 +14,15 @@\n  *\n  * During startup an error will be printed that the config directory can't be found, to fix this:\n  * 1) Add a config directly to the top level project directory\n- * 2) or set `-Des.path.conf=` to a location where there is a config directory on your machine.\n+ * 2) or set `-Des.path.home=` to a location where there is a config directory on your machine.\n  */\n public class WatcherF {\n \n     public static void main(String[] args) {\n         System.setProperty(\"es.http.cors.enabled\", \"true\");\n-        System.setProperty(\"es.script.disable_dynamic\", \"false\");\n+        System.setProperty(\"es.script.inline\", \"on\");\n         System.setProperty(\"es.shield.enabled\", \"false\");\n+        System.setProperty(\"es.security.manager.enabled\", \"false\");\n         System.setProperty(\"es.plugins.load_classpath_plugins\", \"false\");\n         System.setProperty(\"es.plugin.types\", WatcherPlugin.class.getName() + \",\" + LicensePlugin.class.getName());\n         System.setProperty(\"es.cluster.name\", WatcherF.class.getSimpleName());",
    "output": "Fix WatcherF to work due to the recent upstream changes"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java\n@@ -167,7 +167,7 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n             throw new QueryParsingException(parseContext, \"failed to parse [{}] query. could not find [{}] field [{}]\", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);\n         }\n         if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {\n-            throw new QueryParsingException(parseContext, \"failed to parse [{}] query. field [{}] is expected to be of type [{}], but is of [{}] type instead\", NAME, fieldName, GeoPointFieldMapper.CONTENT_TYPE, fieldType.names().shortName());\n+            throw new QueryParsingException(parseContext, \"failed to parse [{}] query. field [{}] is expected to be of type [{}], but is of [{}] type instead\", NAME, fieldName, GeoPointFieldMapper.CONTENT_TYPE, fieldType.typeName());\n         }\n         GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);\n ",
    "output": "Fix compile error after bad merge"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java\n--- a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java\n+++ b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java\n@@ -100,7 +100,7 @@ protected Query doCreateExpectedQuery(RangeQueryBuilder queryBuilder, QueryParse\n                 dateTimeZone = DateTimeZone.forID(queryBuilder.timeZone());\n             }\n             MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());\n-            expectedQuery = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(queryBuilder.from(), queryBuilder.to(),\n+            expectedQuery = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(BytesRefs.toBytesRef(queryBuilder.from()), BytesRefs.toBytesRef(queryBuilder.to()),\n                     queryBuilder.includeLower(), queryBuilder.includeUpper(), dateTimeZone, forcedDateParser, context);\n         } else if (queryBuilder.fieldName().equals(INT_FIELD_NAME)) {\n             expectedQuery = NumericRangeQuery.newIntRange(INT_FIELD_NAME, (Integer) queryBuilder.from(), (Integer) queryBuilder.to(),",
    "output": "Fix lucene query comparison in RangeQueryBuilderTest The expected query needs to use BytesRef to represent the from and to, otherwise we try to compare BytesRef with String and that returns false"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/client/transport/TransportClientNodesServiceTests.java b/core/src/test/java/org/elasticsearch/client/transport/TransportClientNodesServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/client/transport/TransportClientNodesServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/client/transport/TransportClientNodesServiceTests.java\n@@ -118,7 +118,7 @@ public void doWithNode(DiscoveryNode node, final ActionListener<TestResponse> re\n                             throw new IllegalArgumentException();\n                         }\n \n-                        iteration.transportService.sendRequest(node, \"action\", new TestRequest(), new TransportRequestOptions().withTimeout(50), new BaseTransportResponseHandler<TestResponse>() {\n+                        iteration.transportService.sendRequest(node, \"action\", new TestRequest(), new TransportRequestOptions(), new BaseTransportResponseHandler<TestResponse>() {\n                             @Override\n                             public TestResponse newInstance() {\n                                 return new TestResponse();",
    "output": "Remove timeout - it's not needed in this test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n@@ -80,6 +80,7 @@ public static void checkJarHell(URL urls[]) throws Exception {\n         // like sun.boot.class.path, and with jigsaw we don't yet have a way to get\n         // a \"list\" at all. So just exclude any elements underneath the java home\n         String javaHome = System.getProperty(\"java.home\");\n+        logger.debug(\"java.home: {}\", javaHome);\n         final Map<String,URL> clazzes = new HashMap<>(32768);\n         Set<String> seenJars = new HashSet<>();\n         for (final URL url : urls) {",
    "output": "Add java.home to debug logging"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java b/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java\n--- a/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java\n+++ b/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java\n@@ -132,7 +132,7 @@ public void add(PercolateStats percolate) {\n     static final class Fields {\n         static final XContentBuilderString PERCOLATE = new XContentBuilderString(\"percolate\");\n         static final XContentBuilderString TOTAL = new XContentBuilderString(\"total\");\n-        static final XContentBuilderString TIME = new XContentBuilderString(\"getTime\");\n+        static final XContentBuilderString TIME = new XContentBuilderString(\"time\");\n         static final XContentBuilderString TIME_IN_MILLIS = new XContentBuilderString(\"time_in_millis\");\n         static final XContentBuilderString CURRENT = new XContentBuilderString(\"current\");\n         static final XContentBuilderString MEMORY_SIZE_IN_BYTES = new XContentBuilderString(\"memory_size_in_bytes\");",
    "output": "Change `percolator.getTime` -> `percolator.time`"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java\n@@ -21,6 +21,8 @@\n \n import org.elasticsearch.common.SuppressForbidden;\n import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.logging.ESLogger;\n+import org.elasticsearch.common.logging.Loggers;\n \n import java.io.IOException;\n import java.net.URL;\n@@ -31,6 +33,7 @@\n import java.nio.file.Path;\n import java.nio.file.SimpleFileVisitor;\n import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Arrays;\n import java.util.Enumeration;\n import java.util.HashMap;\n import java.util.HashSet;\n@@ -52,6 +55,12 @@ public static void checkJarHell() throws Exception {\n         if (loader instanceof URLClassLoader == false) {\n            return;\n         }\n+        ESLogger logger = Loggers.getLogger(JarHell.class);\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"java.class.path= {}\" + System.getProperty(\"java.class.path\"));\n+            logger.debug(\"sun.boot.class.path= {}\" + System.getProperty(\"sun.boot.class.path\"));\n+            logger.debug(\"classloader urls= {}\" + Arrays.toString(((URLClassLoader)loader).getURLs()));\n+        }\n         checkJarHell(((URLClassLoader)loader).getURLs());\n     }\n ",
    "output": "Add debug logging in case classpath is crazy"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java\n--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java\n+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java\n@@ -204,7 +204,9 @@ public void verify(String seed) {\n                 throw new RepositoryVerificationException(repositoryName, \"store location [\" + blobStore + \"] is not accessible on the node [\" + localNode + \"]\", exp);\n             }\n         } else {\n-            throw new RepositoryVerificationException(repositoryName, \"store location [\" + blobStore + \"] is not shared between node [\" + localNode + \"] and the master node\");\n+            throw new RepositoryVerificationException(repositoryName, \"a file written by master to the store [\" + blobStore + \"] cannot be accessed on the node [\" + localNode + \"]. \"\n+                    + \"This might indicate that the store [\" + blobStore + \"] is not shared between this node and the master node or \"\n+                    + \"that permissions on the store don't allow reading files written by the master node\");\n         }\n     }\n ",
    "output": "Improve repository verification failure message"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/integration/ldap/GroupMappingTests.java b/src/test/java/org/elasticsearch/integration/ldap/GroupMappingTests.java\n--- a/src/test/java/org/elasticsearch/integration/ldap/GroupMappingTests.java\n+++ b/src/test/java/org/elasticsearch/integration/ldap/GroupMappingTests.java\n@@ -5,6 +5,7 @@\n  */\n package org.elasticsearch.integration.ldap;\n \n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.test.junit.annotations.Network;\n import org.junit.Test;\n \n@@ -15,6 +16,7 @@\n  * The super class will provide appropriate group mappings via configGroupMappings()\n  */\n @Network\n+@LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch-shield/issues/947\")\n public class GroupMappingTests extends AbstractAdLdapRealmTests {\n \n     @Test",
    "output": "Add awaits fix for exception serialization issue"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ShieldException.java b/src/main/java/org/elasticsearch/shield/ShieldException.java\n--- a/src/main/java/org/elasticsearch/shield/ShieldException.java\n+++ b/src/main/java/org/elasticsearch/shield/ShieldException.java\n@@ -11,7 +11,7 @@\n /**\n  *\n  */\n-public class ShieldException extends ElasticsearchException.WithRestHeaders {\n+public class ShieldException extends ElasticsearchException.WithRestHeadersException {\n \n     public ShieldException(String msg, Tuple... headers) {\n         super(msg, headers);",
    "output": "Fix compile error due to a rename in core"
  },
  {
    "input": "diff --git a/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicensesClientService.java b/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicensesClientService.java\n--- a/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicensesClientService.java\n+++ b/plugin-api/src/main/java/org/elasticsearch/license/plugin/core/LicensesClientService.java\n@@ -11,7 +11,6 @@\n import java.util.Collection;\n \n \n-//@ImplementedBy(LicensesService.class)\n public interface LicensesClientService {\n \n     public interface Listener {",
    "output": "Remove unnecessary comment blocks"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/snapshots/create/RestCreateSnapshotAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/snapshots/create/RestCreateSnapshotAction.java\n--- a/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/snapshots/create/RestCreateSnapshotAction.java\n+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/snapshots/create/RestCreateSnapshotAction.java\n@@ -40,7 +40,7 @@ public class RestCreateSnapshotAction extends BaseRestHandler {\n     public RestCreateSnapshotAction(Settings settings, RestController controller, Client client) {\n         super(settings, controller, client);\n         controller.registerHandler(PUT, \"/_snapshot/{repository}/{snapshot}\", this);\n-        controller.registerHandler(POST, \"/_snapshot/{repository}/{snapshot}/_create\", this);\n+        controller.registerHandler(POST, \"/_snapshot/{repository}/{snapshot}\", this);\n     }\n \n     @Override",
    "output": "Remove _create from POST to match PUT path"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java\n--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java\n@@ -87,6 +87,8 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n                     String sScoreMode = parser.text();\n                     if (\"avg\".equals(sScoreMode)) {\n                         scoreMode = ScoreMode.Avg;\n+                    } else if (\"min\".equals(sScoreMode)) {\n+                        scoreMode = ScoreMode.Min;\n                     } else if (\"max\".equals(sScoreMode)) {\n                         scoreMode = ScoreMode.Max;\n                     } else if (\"total\".equals(sScoreMode) || \"sum\".equals(sScoreMode)) {",
    "output": "Add `min` score mode"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Security.java b/core/src/main/java/org/elasticsearch/bootstrap/Security.java\n--- a/core/src/main/java/org/elasticsearch/bootstrap/Security.java\n+++ b/core/src/main/java/org/elasticsearch/bootstrap/Security.java\n@@ -68,8 +68,11 @@ static void configure(Environment environment) throws Exception {\n     private static final Map<Pattern,String> SPECIAL_JARS;\n     static {\n         Map<Pattern,String> m = new IdentityHashMap<>();\n-        m.put(Pattern.compile(\".*lucene-core-.*\\\\.jar$\"),  \"es.security.jar.lucene.core\");\n-        m.put(Pattern.compile(\".*jsr166e-.*\\\\.jar$\"),      \"es.security.jar.twitter.jsr166e\");\n+        m.put(Pattern.compile(\".*lucene-core-.*\\\\.jar$\"),    \"es.security.jar.lucene.core\");\n+        m.put(Pattern.compile(\".*jsr166e-.*\\\\.jar$\"),        \"es.security.jar.twitter.jsr166e\");\n+        m.put(Pattern.compile(\".*securemock-.*\\\\.jar$\"),     \"es.security.jar.elasticsearch.securemock\");\n+        m.put(Pattern.compile(\".*mockito-core-.*\\\\.jar$\"),   \"es.security.jar.mockito.core\");\n+        m.put(Pattern.compile(\".*objenesis-.*\\\\.jar$\"),      \"es.security.jar.objenesis\");\n         SPECIAL_JARS = Collections.unmodifiableMap(m);\n     }\n ",
    "output": "Remove nasty permission (hack way but works) improving"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java\n@@ -67,6 +67,8 @@ public static class Defaults extends LongFieldMapper.Defaults {\n             TTL_FIELD_TYPE.setStored(true);\n             TTL_FIELD_TYPE.setTokenized(false);\n             TTL_FIELD_TYPE.setNumericPrecisionStep(Defaults.PRECISION_STEP_64_BIT);\n+            TTL_FIELD_TYPE.setIndexAnalyzer(NumericLongAnalyzer.buildNamedAnalyzer(Defaults.PRECISION_STEP_64_BIT));\n+            TTL_FIELD_TYPE.setSearchAnalyzer(NumericLongAnalyzer.buildNamedAnalyzer(Integer.MAX_VALUE));\n             TTL_FIELD_TYPE.setNames(new MappedFieldType.Names(NAME));\n             TTL_FIELD_TYPE.freeze();\n         }",
    "output": "Fix _ttl default field type to include index/search analyzer (numeric 64bit)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java b/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java\n--- a/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java\n+++ b/src/main/java/org/elasticsearch/watcher/support/secret/SensitiveXContentParser.java\n@@ -12,6 +12,7 @@\n import org.elasticsearch.common.xcontent.XContentType;\n \n import java.io.IOException;\n+import java.util.List;\n import java.util.Map;\n \n /**\n@@ -84,6 +85,16 @@ public Map<String, Object> mapOrdered() throws IOException {\n         return parser.mapOrdered();\n     }\n \n+    @Override\n+    public List<Object> list() throws IOException {\n+        return parser.list();\n+    }\n+\n+    @Override\n+    public List<Object> listOrderedMap() throws IOException {\n+        return parser.listOrderedMap();\n+    }\n+\n     @Override\n     public String text() throws IOException {\n         return parser.text();",
    "output": "Fix compile error"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n@@ -263,7 +263,7 @@ public boolean lenient() {\n \n     /** Specifies whether wildcards should be analyzed. Defaults to false. */\n     public SimpleQueryStringBuilder analyzeWildcard(boolean analyzeWildcard) {\n-        this.settings.analyzeWildcard(DEFAULT_ANALYZE_WILDCARD);\n+        this.settings.analyzeWildcard(analyzeWildcard);\n         return this;\n     }\n ",
    "output": "Fix SimpleQueryStringBuilder wildcard handling Forgot to commit the very last change yesterday which led to analyzeWildcard to remain at the default value always. Relates to"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/WatcherService.java b/src/main/java/org/elasticsearch/watcher/WatcherService.java\n--- a/src/main/java/org/elasticsearch/watcher/WatcherService.java\n+++ b/src/main/java/org/elasticsearch/watcher/WatcherService.java\n@@ -61,6 +61,8 @@ public void start(ClusterState clusterState) {\n             triggerService.start(watchStore.watches().values());\n             state.set(WatcherState.STARTED);\n             logger.info(\"watch service has started\");\n+        } else {\n+            logger.debug(\"not starting watcher, because its state is [{}] while [{}] is expected\", state, WatcherState.STOPPED);\n         }\n     }\n \n@@ -81,6 +83,8 @@ public void stop() {\n             watchStore.stop();\n             state.set(WatcherState.STOPPED);\n             logger.info(\"watch service has stopped\");\n+        } else {\n+            logger.debug(\"not stopping watcher, because its state is [{}] while [{}] is expected\", state, WatcherState.STARTED);\n         }\n     }\n \n\ndiff --git a/src/test/java/org/elasticsearch/watcher/test/integration/BootStrapTests.java b/src/test/java/org/elasticsearch/watcher/test/integration/BootStrapTests.java\n--- a/src/test/java/org/elasticsearch/watcher/test/integration/BootStrapTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/test/integration/BootStrapTests.java\n@@ -45,6 +45,7 @@\n \n /**\n  */\n+@TestLogging(\"watcher:TRACE\")\n public class BootStrapTests extends AbstractWatcherIntegrationTests {\n \n     @Override",
    "output": "Add logging in case state is unexpected when starting or stopping. Also increased test logging in BootStrapTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/condition/compare/CompareConditionSearchTests.java b/src/test/java/org/elasticsearch/watcher/condition/compare/CompareConditionSearchTests.java\n--- a/src/test/java/org/elasticsearch/watcher/condition/compare/CompareConditionSearchTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/condition/compare/CompareConditionSearchTests.java\n@@ -32,7 +32,6 @@\n public class CompareConditionSearchTests extends AbstractWatcherIntegrationTests {\n \n     @Test\n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/11692\")\n     public void testExecute_withAggs() throws Exception {\n \n         client().admin().indices().prepareCreate(\"my-index\")\n\ndiff --git a/src/test/java/org/elasticsearch/watcher/condition/script/ScriptConditionSearchTests.java b/src/test/java/org/elasticsearch/watcher/condition/script/ScriptConditionSearchTests.java\n--- a/src/test/java/org/elasticsearch/watcher/condition/script/ScriptConditionSearchTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/condition/script/ScriptConditionSearchTests.java\n@@ -49,7 +49,6 @@ public void cleanup() {\n     }\n \n     @Test\n-    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/11692\")\n     public void testExecute_withAggs() throws Exception {\n \n         client().admin().indices().prepareCreate(\"my-index\")",
    "output": "Remove awaits-fix, the issue is resovled in es-core master"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n--- a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n+++ b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n@@ -50,6 +50,7 @@\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n import org.elasticsearch.common.util.concurrent.EsExecutors;\n import org.elasticsearch.common.util.concurrent.KeyedLock;\n import org.elasticsearch.monitor.jvm.JvmInfo;\n@@ -1122,13 +1123,13 @@ public synchronized void close() {\n         }\n     }\n \n-    class ScheduledPing implements Runnable {\n+    class ScheduledPing extends AbstractRunnable {\n \n         final CounterMetric successfulPings = new CounterMetric();\n         final CounterMetric failedPings = new CounterMetric();\n \n         @Override\n-        public void run() {\n+        protected void doRun() throws Exception {\n             if (lifecycle.stoppedOrClosed()) {\n                 return;\n             }\n@@ -1156,5 +1157,14 @@ public void operationComplete(ChannelFuture future) throws Exception {\n             }\n             threadPool.schedule(pingSchedule, ThreadPool.Names.GENERIC, this);\n         }\n+\n+        @Override\n+        public void onFailure(Throwable t) {\n+            if (lifecycle.stoppedOrClosed()) {\n+                logger.trace(\"[{}] failed to send ping transport message\", t);\n+            } else {\n+                logger.warn(\"[{}] failed to send ping transport message\", t);\n+            }\n+        }\n     }\n }",
    "output": "Use abstract runnable in scheduled ping"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java b/core/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java\n--- a/core/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java\n+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java\n@@ -74,14 +74,14 @@ public ClusterState execute(ClusterState currentState) {\n                 try {\n                     block.await();\n                 } catch (InterruptedException e) {\n-                    fail();\n+                    throw new RuntimeException(e);\n                 }\n                 return currentState;\n             }\n \n             @Override\n             public void onFailure(String source, Throwable t) {\n-                fail();\n+                throw new RuntimeException(t);\n             }\n         });\n \n@@ -109,9 +109,23 @@ public void clusterStateProcessed(String source, ClusterState oldState, ClusterS\n             }\n         });\n \n-        assertThat(timedOut.await(500, TimeUnit.MILLISECONDS), equalTo(true));\n+        timedOut.await();\n         block.countDown();\n-        Thread.sleep(100); // sleep a bit to double check that execute on the timed out update task is not called...\n+        final CountDownLatch allProcessed = new CountDownLatch(1);\n+        clusterService1.submitStateUpdateTask(\"test3\", new ClusterStateUpdateTask() {\n+            @Override\n+            public void onFailure(String source, Throwable t) {\n+                throw new RuntimeException(t);\n+            }\n+\n+            @Override\n+            public ClusterState execute(ClusterState currentState) {\n+                allProcessed.countDown();\n+                return currentState;\n+            }\n+\n+        });\n+        allProcessed.await(); // executed another task to double check that execute on the timed out update task is not called...\n         assertThat(executeCalled.get(), equalTo(false));\n     }\n ",
    "output": "Remove sleeps and latch timeouts from ClusterServiceTests Tests relying on sleeps and latch timeouts are prone to weird timing issues and hard to read / understand error messages. This commit moves towards a more deterministic error model and replaces empty fails with real exceptions"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n--- a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n+++ b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n@@ -50,6 +50,7 @@\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n import org.elasticsearch.common.util.concurrent.EsExecutors;\n import org.elasticsearch.common.util.concurrent.KeyedLock;\n import org.elasticsearch.monitor.jvm.JvmInfo;\n@@ -1122,13 +1123,13 @@ public synchronized void close() {\n         }\n     }\n \n-    class ScheduledPing implements Runnable {\n+    class ScheduledPing extends AbstractRunnable {\n \n         final CounterMetric successfulPings = new CounterMetric();\n         final CounterMetric failedPings = new CounterMetric();\n \n         @Override\n-        public void run() {\n+        protected void doRun() throws Exception {\n             if (lifecycle.stoppedOrClosed()) {\n                 return;\n             }\n@@ -1156,5 +1157,14 @@ public void operationComplete(ChannelFuture future) throws Exception {\n             }\n             threadPool.schedule(pingSchedule, ThreadPool.Names.GENERIC, this);\n         }\n+\n+        @Override\n+        public void onFailure(Throwable t) {\n+            if (lifecycle.stoppedOrClosed()) {\n+                logger.trace(\"[{}] failed to send ping transport message\", t);\n+            } else {\n+                logger.warn(\"[{}] failed to send ping transport message\", t);\n+            }\n+        }\n     }\n }",
    "output": "Use abstract runnable in scheduled ping"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java\n--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java\n+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java\n@@ -348,6 +348,12 @@ public void merge(Mapper mergeWith, MergeResult mergeResult) throws MergeMapping\n             ParentFieldMapper fieldMergeWith = (ParentFieldMapper) mergeWith;\n             this.fieldType = fieldMergeWith.fieldType().clone();\n             this.fieldType().freeze();\n+\n+            if (fieldMergeWith.customFieldDataSettings != null) {\n+                if (!Objects.equal(fieldMergeWith.customFieldDataSettings, this.customFieldDataSettings)) {\n+                    this.customFieldDataSettings = fieldMergeWith.customFieldDataSettings;\n+                }\n+            }\n         }\n     }\n ",
    "output": "Fix parent field mapper to copy customFieldDataSettings on merge"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java b/core/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java\n--- a/core/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java\n+++ b/core/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.index.mapper.update;\n \n-import com.carrotsearch.randomizedtesting.annotations.Seed;\n import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;\n import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;\n@@ -31,7 +30,6 @@\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n-import java.io.IOException;\n import java.util.HashMap;\n import java.util.LinkedHashMap;\n \n@@ -183,7 +181,6 @@ private void compareMappingOnNodes(GetMappingsResponse previousMapping) {\n     }\n \n     @Test\n-    @Seed(value = \"12345678\")\n     public void testUpdateTimestamp() throws Exception {\n         boolean enabled = randomBoolean();\n         XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type\")",
    "output": "Remove hardcoded seed from test"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/rest/RestRequest.java b/core/src/main/java/org/elasticsearch/rest/RestRequest.java\n--- a/core/src/main/java/org/elasticsearch/rest/RestRequest.java\n+++ b/core/src/main/java/org/elasticsearch/rest/RestRequest.java\n@@ -120,7 +120,7 @@ public long paramAsLong(String key, long defaultValue) {\n         try {\n             return Long.parseLong(sValue);\n         } catch (NumberFormatException e) {\n-            throw new IllegalArgumentException(\"Failed to parse int parameter [\" + key + \"] with value [\" + sValue + \"]\", e);\n+            throw new IllegalArgumentException(\"Failed to parse long parameter [\" + key + \"] with value [\" + sValue + \"]\", e);\n         }\n     }\n ",
    "output": "Fix exception message in RestRequest"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/test/integration/ExecutionVarsIntegrationTests.java b/src/test/java/org/elasticsearch/watcher/test/integration/ExecutionVarsIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/watcher/test/integration/ExecutionVarsIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/test/integration/ExecutionVarsIntegrationTests.java\n@@ -107,7 +107,6 @@ public void handle(SearchRequestBuilder builder) {\n     }\n \n     @Test\n-    @Repeat(iterations = 3)\n     public void testVars_Manual() throws Exception {\n         WatcherClient watcherClient = watcherClient();\n ",
    "output": "Remove @Repeat - don't commit hardcoded repeats"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/test/test/SuiteScopeClusterTests.java b/core/src/test/java/org/elasticsearch/test/test/SuiteScopeClusterTests.java\n--- a/core/src/test/java/org/elasticsearch/test/test/SuiteScopeClusterTests.java\n+++ b/core/src/test/java/org/elasticsearch/test/test/SuiteScopeClusterTests.java\n@@ -20,6 +20,7 @@\n \n import com.carrotsearch.randomizedtesting.annotations.Repeat;\n \n+import org.elasticsearch.common.SuppressForbidden;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.TestCluster;\n import org.junit.Test;\n@@ -39,6 +40,7 @@ public class SuiteScopeClusterTests extends ElasticsearchIntegrationTest {\n     private static Long CLUSTER_SEED = null;\n \n     @Test\n+    @SuppressForbidden(reason = \"repeat is a feature here\")\n     @Repeat(iterations = 10, useConstantSeed = true)\n     public void testReproducible() throws IOException {\n         if (ITER++ == 0) {",
    "output": "Add @Repeat to forbidden APIs @Repeat should not be committed just like @Seed. Use -Pdev to run annotated methods"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java b/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java\n--- a/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java\n+++ b/src/main/java/org/elasticsearch/watcher/WatcherLifeCycleService.java\n@@ -78,30 +78,12 @@ private synchronized void start(ClusterState state, boolean manual) {\n             return;\n         }\n \n-        int attempts = 0;\n-        for (; attempts < 3; attempts++) {\n-            try {\n-                if (logger.isDebugEnabled()) {\n-                    logger.debug(\"start attempt [{}]...\", attempts);\n-                } else if (logger.isTraceEnabled()) {\n-                    logger.trace(\"starting... (attempt [{}] - based on cluster state version [{}])\", attempts, state.getVersion());\n-                }\n-                watcherService.start(state);\n-                return;\n-            } catch (Exception e) {\n-                logger.warn(\"error occurred while starting, retrying...\", e);\n-                try {\n-                    Thread.sleep(1000);\n-                } catch (InterruptedException ie) {\n-                    Thread.currentThread().interrupt();\n-                }\n-                if (!clusterService.localNode().masterNode()) {\n-                    logger.error(\"abort retry, we are no longer master\");\n-                    return;\n-                }\n-            }\n+        logger.trace(\"starting... (based on cluster state version [{}])\", state.getVersion());\n+        try {\n+            watcherService.start(state);\n+        } catch (Exception e) {\n+            logger.debug(\"failed to start watcher. please wait for the cluster to become ready or try to start Watcher manually\");\n         }\n-        logger.error(\"failed to start watcher. attempted to start [{}] times. please try to start Watcher manually\", attempts);\n     }\n \n     @Override",
    "output": "Remove retry start watcher mechanism If nodes drop and .watches / .triggered_watches shards are available after those shards were started a new cluster state update will come along that triggers the start watcher logic"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/ImmutableShardRouting.java b/core/src/main/java/org/elasticsearch/cluster/routing/ImmutableShardRouting.java\n--- a/core/src/main/java/org/elasticsearch/cluster/routing/ImmutableShardRouting.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/routing/ImmutableShardRouting.java\n@@ -242,10 +242,8 @@ public void readFromThin(StreamInput in) throws IOException {\n         state = ShardRoutingState.fromValue(in.readByte());\n \n         restoreSource = RestoreSource.readOptionalRestoreSource(in);\n-        if (in.getVersion().onOrAfter(Version.V_1_7_0)) {\n-            if (in.readBoolean()) {\n-                unassignedInfo = new UnassignedInfo(in);\n-            }\n+        if (in.readBoolean()) {\n+            unassignedInfo = new UnassignedInfo(in);\n         }\n     }\n \n@@ -286,13 +284,11 @@ public void writeToThin(StreamOutput out) throws IOException {\n         } else {\n             out.writeBoolean(false);\n         }\n-        if (out.getVersion().onOrAfter(Version.V_1_7_0)) {\n-            if (unassignedInfo != null) {\n-                out.writeBoolean(true);\n-                unassignedInfo.writeTo(out);\n-            } else {\n-                out.writeBoolean(false);\n-            }\n+        if (unassignedInfo != null) {\n+            out.writeBoolean(true);\n+            unassignedInfo.writeTo(out);\n+        } else {\n+            out.writeBoolean(false);\n         }\n     }\n ",
    "output": "Remove 1.7 version check"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java b/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java\n--- a/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java\n+++ b/src/main/java/org/elasticsearch/shield/audit/index/IndexAuditTrail.java\n@@ -623,6 +623,7 @@ void putTemplate(Settings customSettings) {\n                 throw new ShieldException(\"failed to put index template for audit logging\");\n             }\n         } catch (Exception e) {\n+            logger.debug(\"unexpected exception while putting index template\", e);\n             throw new ShieldException(\"failed to load [\" + INDEX_TEMPLATE_NAME + \".json]\", e);\n         }\n     }",
    "output": "Add a debug log to IndexAuditTrail"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java\n--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java\n+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java\n@@ -158,7 +158,7 @@ private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, Quer\n         if (objectMapper == null) {\n             throw new IllegalArgumentException(\"path [\" + nestedPath +\"] doesn't exist\");\n         }\n-        if (!objectMapper.nested().isNested()) {\n+        if (objectMapper.nested().isNested() == false) {\n             throw new IllegalArgumentException(\"path [\" + nestedPath +\"] isn't nested\");\n         }\n         ObjectMapper parentObjectMapper = parseContext.nestedScope().nextLevel(objectMapper);",
    "output": "Make conditional clearer"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/deps/lucene/SimpleLuceneTests.java b/core/src/test/java/org/elasticsearch/deps/lucene/SimpleLuceneTests.java\n--- a/core/src/test/java/org/elasticsearch/deps/lucene/SimpleLuceneTests.java\n+++ b/core/src/test/java/org/elasticsearch/deps/lucene/SimpleLuceneTests.java\n@@ -61,29 +61,6 @@ public void testSortValues() throws Exception {\n         }\n     }\n \n-    @Test\n-    public void testAddDocAfterPrepareCommit() throws Exception {\n-        Directory dir = new RAMDirectory();\n-        IndexWriter indexWriter = new IndexWriter(dir, new IndexWriterConfig(Lucene.STANDARD_ANALYZER));\n-        Document document = new Document();\n-        document.add(new TextField(\"_id\", \"1\", Field.Store.YES));\n-        indexWriter.addDocument(document);\n-        DirectoryReader reader = DirectoryReader.open(indexWriter, true);\n-        assertThat(reader.numDocs(), equalTo(1));\n-\n-        indexWriter.prepareCommit();\n-        // Returns null b/c no changes.\n-        // nocommit: this fails\n-        assertThat(DirectoryReader.openIfChanged(reader), equalTo(null));\n-\n-        document = new Document();\n-        document.add(new TextField(\"_id\", \"2\", Field.Store.YES));\n-        indexWriter.addDocument(document);\n-        indexWriter.commit();\n-        reader = DirectoryReader.openIfChanged(reader);\n-        assertThat(reader.numDocs(), equalTo(2));\n-    }\n-\n     @Test\n     public void testSimpleNumericOps() throws Exception {\n         Directory dir = new RAMDirectory();",
    "output": "Remove SimpleLuceneTests.testAddDocAfterPrepareCommit. It is unnecessary to test features we are not using"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/Version.java b/core/src/main/java/org/elasticsearch/Version.java\n--- a/core/src/main/java/org/elasticsearch/Version.java\n+++ b/core/src/main/java/org/elasticsearch/Version.java\n@@ -242,6 +242,8 @@ public class Version {\n     public static final Version V_1_6_0 = new Version(V_1_6_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_10_4);\n     public static final int V_1_6_1_ID = 1060199;\n     public static final Version V_1_6_1 = new Version(V_1_6_1_ID, true, org.apache.lucene.util.Version.LUCENE_4_10_4);\n+    public static final int V_1_7_0_ID = 1070099;\n+    public static final Version V_1_7_0 = new Version(V_1_7_0_ID, true, org.apache.lucene.util.Version.LUCENE_4_10_4);\n     public static final int V_2_0_0_ID = 2000099;\n     public static final Version V_2_0_0 = new Version(V_2_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_2_0);\n \n@@ -259,6 +261,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_2_0_0_ID:\n                 return V_2_0_0;\n+            case V_1_7_0_ID:\n+                return V_1_7_0;\n             case V_1_6_1_ID:\n                 return V_1_6_1;\n             case V_1_6_0_ID:",
    "output": "Add version 1.7.0 it was added in 1.x, but not in master"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportTests.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportTests.java\n--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportTests.java\n+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportTests.java\n@@ -57,6 +57,7 @@\n import org.junit.Test;\n \n import java.util.*;\n+import java.util.concurrent.CopyOnWriteArrayList;\n \n import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;\n import static org.elasticsearch.common.settings.Settings.settingsBuilder;\n@@ -70,7 +71,7 @@\n @ClusterScope(scope = SUITE)\n public class ContextAndHeaderTransportTests extends ElasticsearchIntegrationTest {\n \n-    private static final List<ActionRequest> requests = Collections.synchronizedList(new ArrayList<ActionRequest>());\n+    private static final List<ActionRequest> requests =  new CopyOnWriteArrayList<>();\n     private String randomHeaderKey = randomAsciiOfLength(10);\n     private String randomHeaderValue = randomAsciiOfLength(20);\n     private String queryIndex = \"query-\" + randomAsciiOfLength(10).toLowerCase(Locale.ROOT);",
    "output": "Use CopyOnWrite list since list is concurrently modified as well as iterated"
  },
  {
    "input": "diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n--- a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n@@ -75,9 +75,9 @@ public void testJavaScriptFilter() throws Exception {\n \n         logger.info(\" --> running doc['num1'].value > 1\");\n         SearchResponse response = client().prepareSearch()\n-                .setQuery(scriptQuery(new Script(\"doc['num1'].value > 1\",  ScriptService.ScriptType.INLINE, \"JS\", null)))\n+                .setQuery(scriptQuery(new Script(\"doc['num1'].value > 1\",  ScriptService.ScriptType.INLINE, \"js\", null)))\n                         .addSort(\"num1\", SortOrder.ASC)\n-                        .addScriptField(\"sNum1\", new Script(\"doc['num1'].value\",  ScriptService.ScriptType.INLINE, \"JS\", null))\n+                        .addScriptField(\"sNum1\", new Script(\"doc['num1'].value\",  ScriptService.ScriptType.INLINE, \"js\", null))\n                         .execute().actionGet();\n \n         assertThat(response.getHits().totalHits(), equalTo(2l));",
    "output": "Fix JavaScript tests - case matters here"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n--- a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n+++ b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n@@ -65,7 +65,6 @@ public QueryPhase(AggregationPhase aggregationPhase, SuggestPhase suggestPhase,\n                 .put(\"query\", new QueryParseElement())\n                 .put(\"queryBinary\", new QueryBinaryParseElement())\n                 .put(\"query_binary\", new QueryBinaryParseElement())\n-                .put(\"filter\", new PostFilterParseElement()) // For bw comp reason, should be removed in version 1.1\n                 .put(\"post_filter\", new PostFilterParseElement())\n                 .put(\"postFilter\", new PostFilterParseElement())\n                 .put(\"filterBinary\", new FilterBinaryParseElement())",
    "output": "Remove top-level filter parameter from search API"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n--- a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n+++ b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n@@ -564,7 +564,7 @@ static class EstimatedTimeThread extends Thread {\n         EstimatedTimeThread(String name, long interval) {\n             super(name);\n             this.interval = interval;\n-            this.estimatedTimeInMillis = System.currentTimeMillis();\n+            this.estimatedTimeInMillis = TimeValue.nsecToMSec(System.nanoTime());\n             this.counter = new TimeCounter();\n             setDaemon(true);\n         }\n@@ -576,7 +576,7 @@ public long estimatedTimeInMillis() {\n         @Override\n         public void run() {\n             while (running) {\n-                estimatedTimeInMillis = System.currentTimeMillis();\n+                estimatedTimeInMillis = TimeValue.nsecToMSec(System.nanoTime());\n                 try {\n                     Thread.sleep(interval);\n                 } catch (InterruptedException e) {",
    "output": "Use System.nanoTime for ThreadPool's estimated time, since it's less likely to go backwards"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n--- a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n+++ b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n@@ -564,7 +564,7 @@ static class EstimatedTimeThread extends Thread {\n         EstimatedTimeThread(String name, long interval) {\n             super(name);\n             this.interval = interval;\n-            this.estimatedTimeInMillis = System.currentTimeMillis();\n+            this.estimatedTimeInMillis = TimeValue.nsecToMSec(System.nanoTime());\n             this.counter = new TimeCounter();\n             setDaemon(true);\n         }\n@@ -576,7 +576,7 @@ public long estimatedTimeInMillis() {\n         @Override\n         public void run() {\n             while (running) {\n-                estimatedTimeInMillis = System.currentTimeMillis();\n+                estimatedTimeInMillis = TimeValue.nsecToMSec(System.nanoTime());\n                 try {\n                     Thread.sleep(interval);\n                 } catch (InterruptedException e) {",
    "output": "Use System.nanoTime for ThreadPool's estimated time, since it's less likely to go backwards"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/integration/ClusterPrivilegeTests.java b/src/test/java/org/elasticsearch/integration/ClusterPrivilegeTests.java\n--- a/src/test/java/org/elasticsearch/integration/ClusterPrivilegeTests.java\n+++ b/src/test/java/org/elasticsearch/integration/ClusterPrivilegeTests.java\n@@ -8,7 +8,7 @@\n import com.google.common.collect.ImmutableMap;\n import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.action.admin.cluster.snapshots.status.SnapshotsStatusResponse;\n-import org.elasticsearch.cluster.metadata.SnapshotMetaData;\n+import org.elasticsearch.cluster.SnapshotsInProgress;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.node.Node;\n import org.elasticsearch.test.junit.annotations.TestLogging;\n@@ -180,6 +180,6 @@ private void waitForSnapshotToFinish(String repo, String snapshot) {\n             } catch (InterruptedException e) {}\n             i++;\n             if (i >= 20) { throw new ElasticsearchException(\"Snapshot should have been successfully created after four seconds, was \" + snapshotsStatusResponse.getSnapshots().get(0).getState()); }\n-        } while (snapshotsStatusResponse.getSnapshots().get(0).getState() != SnapshotMetaData.State.SUCCESS);\n+        } while (snapshotsStatusResponse.getSnapshots().get(0).getState() != SnapshotsInProgress.State.SUCCESS);\n     }\n }",
    "output": "Fix compilation due to change in snapshot state enum"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n--- a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n+++ b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n@@ -318,7 +318,7 @@ public List<PendingClusterTask> pendingTasks() {\n                 timeInQueue = runnable.timeSinceCreatedInMillis();\n             } else {\n                 assert false : \"expected TimedPrioritizedRunnable got \" + task.getClass();\n-                source = \"unknown\";\n+                source = \"unknown [\" + task.getClass() + \"]\";\n                 timeInQueue = 0;\n             }\n ",
    "output": "Use task's class name if not a TimedPrioritizeRunnable This is helpful to track down the origin of pending_tasks that aren't expected. In tests we catch this with an assert, but in production asserts may not be enabled so we should at least add the class name"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n--- a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n+++ b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n@@ -65,7 +65,6 @@ public QueryPhase(AggregationPhase aggregationPhase, SuggestPhase suggestPhase,\n                 .put(\"query\", new QueryParseElement())\n                 .put(\"queryBinary\", new QueryBinaryParseElement())\n                 .put(\"query_binary\", new QueryBinaryParseElement())\n-                .put(\"filter\", new PostFilterParseElement()) // For bw comp reason, should be removed in version 1.1\n                 .put(\"post_filter\", new PostFilterParseElement())\n                 .put(\"postFilter\", new PostFilterParseElement())\n                 .put(\"filterBinary\", new FilterBinaryParseElement())",
    "output": "Remove top-level filter parameter from search API"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java\n@@ -304,6 +304,10 @@ public Query toQuery(QueryParseContext parseContext) throws QueryParsingExceptio\n         }\n \n         if (query == null) {\n+            if (this.timeZone != null) {\n+                throw new QueryParsingException(parseContext, \"[range] time_zone can not be applied to non date field [\"\n+                        + fieldName + \"]\");\n+            }\n             query = new TermRangeQuery(this.fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);\n         }\n ",
    "output": "Fix edge case in RangeQueryBuilder when using time zone"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java\n@@ -304,6 +304,10 @@ public Query toQuery(QueryParseContext parseContext) throws QueryParsingExceptio\n         }\n \n         if (query == null) {\n+            if (this.timeZone != null) {\n+                throw new QueryParsingException(parseContext, \"[range] time_zone can not be applied to non date field [\"\n+                        + fieldName + \"]\");\n+            }\n             query = new TermRangeQuery(this.fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);\n         }\n ",
    "output": "Fix edge case in RangeQueryBuilder when using time zone When specifying a time zone, RangeQueryBuilder currently throws an exeption when the field does not use DateFieldMapper, but if there are no mappers at all for that field it doesn't complain. To be consistent we also throw expection now"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/WatcherVersion.java b/src/main/java/org/elasticsearch/watcher/WatcherVersion.java\n--- a/src/main/java/org/elasticsearch/watcher/WatcherVersion.java\n+++ b/src/main/java/org/elasticsearch/watcher/WatcherVersion.java\n@@ -26,6 +26,8 @@ public class WatcherVersion implements Serializable {\n \n     public static final int V_1_0_0_Beta1_ID = /*00*/1000001;\n     public static final WatcherVersion V_1_0_0_Beta1 = new WatcherVersion(V_1_0_0_Beta1_ID, false, Version.V_1_5_0, LicenseVersion.V_1_0_0);\n+    public static final int V_1_0_0_Beta2_ID = /*00*/1000002;\n+    public static final WatcherVersion V_1_0_0_Beta2 = new WatcherVersion(V_1_0_0_Beta2_ID, false, Version.V_1_5_0, LicenseVersion.V_1_0_0);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n     public static final WatcherVersion V_2_0_0 = new WatcherVersion(V_2_0_0_ID, false, Version.V_1_5_0, LicenseVersion.V_1_0_0);\n \n@@ -39,6 +41,8 @@ public static WatcherVersion fromId(int id) {\n         switch (id) {\n             case V_1_0_0_Beta1_ID:\n                 return V_1_0_0_Beta1;\n+            case V_1_0_0_Beta2_ID:\n+                return V_1_0_0_Beta2;\n             case V_2_0_0_ID:\n                 return V_2_0_0;\n             default:",
    "output": "Add version 1.0.0-Beta2"
  },
  {
    "input": "diff --git a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n--- a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n+++ b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n@@ -358,14 +358,14 @@ void assertBasicSearchWorks(String indexName) {\n         ElasticsearchAssertions.assertNoFailures(searchReq.get());\n \n         logger.info(\"--> testing exists filter\");\n-        searchReq = client().prepareSearch(indexName).setQuery(QueryBuilders.filteredQuery(QueryBuilders.matchAllQuery(), QueryBuilders.existsQuery(\"string\")));\n+        searchReq = client().prepareSearch(indexName).setQuery(QueryBuilders.existsQuery(\"string\"));\n         searchRsp = searchReq.get();\n         ElasticsearchAssertions.assertNoFailures(searchRsp);\n         assertEquals(numDocs, searchRsp.getHits().getTotalHits());\n \n         logger.info(\"--> testing missing filter\");\n         // the field for the missing filter here needs to be different than the exists filter above, to avoid being found in the cache\n-        searchReq = client().prepareSearch(indexName).setQuery(QueryBuilders.filteredQuery(QueryBuilders.matchAllQuery(), QueryBuilders.missingQuery(\"long_sort\")));\n+        searchReq = client().prepareSearch(indexName).setQuery(QueryBuilders.missingQuery(\"long_sort\"));\n         searchRsp = searchReq.get();\n         ElasticsearchAssertions.assertNoFailures(searchRsp);\n         assertEquals(0, searchRsp.getHits().getTotalHits());",
    "output": "Remove deprecated API"
  },
  {
    "input": "diff --git a/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java\n--- a/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java\n+++ b/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java\n@@ -69,7 +69,7 @@ public boolean equals(Object o) {\n \n     @Override\n     public int hashCode() {\n-        return Integer.hashCode(limit);\n+        return this.limit;\n     }\n \n     @Override",
    "output": "Fix using java 8 method in LimitQueryBuilder"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/authz/InternalAuthorizationServiceTests.java b/src/test/java/org/elasticsearch/shield/authz/InternalAuthorizationServiceTests.java\n--- a/src/test/java/org/elasticsearch/shield/authz/InternalAuthorizationServiceTests.java\n+++ b/src/test/java/org/elasticsearch/shield/authz/InternalAuthorizationServiceTests.java\n@@ -30,9 +30,12 @@\n import org.junit.Before;\n import org.junit.Test;\n \n-import static org.hamcrest.Matchers.contains;\n import static org.hamcrest.Matchers.*;\n-import static org.mockito.Mockito.*;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n \n public class InternalAuthorizationServiceTests extends ElasticsearchTestCase {\n ",
    "output": "Fix JDK7 compilation"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/ssl/SSLSettingsTests.java b/src/test/java/org/elasticsearch/shield/ssl/SSLSettingsTests.java\n--- a/src/test/java/org/elasticsearch/shield/ssl/SSLSettingsTests.java\n+++ b/src/test/java/org/elasticsearch/shield/ssl/SSLSettingsTests.java\n@@ -135,7 +135,7 @@ public void testThatProfileSettingsOverrideServiceSettings() {\n         assertThat(sslSettings.trustStoreAlgorithm, is(equalTo(\"trusted\")));\n         assertThat(sslSettings.sslProtocol, is(equalTo(\"ssl\")));\n         assertThat(sslSettings.sessionCacheSize, is(equalTo(3)));\n-        assertThat(sslSettings.sessionCacheTimeout, is(equalTo(TimeValue.parseTimeValue(\"10m\", null))));\n+        assertThat(sslSettings.sessionCacheTimeout, is(equalTo(TimeValue.timeValueMinutes(10L))));\n     }\n \n     @Test",
    "output": "Fix compilation issue with parsing TimeValue"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java b/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n--- a/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/MinimumMasterNodesTests.java\n@@ -31,6 +31,7 @@\n import org.elasticsearch.index.query.QueryBuilders;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.ElasticsearchIntegrationTest.ClusterScope;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.junit.Test;\n \n import java.util.concurrent.ExecutionException;\n@@ -163,6 +164,7 @@ public void run() {\n     }\n \n     @Test @Slow\n+    @TestLogging(\"cluster.routing.allocation.allocator:TRACE\")\n     public void multipleNodesShutdownNonMasterNodes() throws Exception {\n         Settings settings = settingsBuilder()\n                 .put(\"discovery.type\", \"zen\")",
    "output": "Add more logging to allocation decision"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java b/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java\n--- a/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java\n+++ b/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java\n@@ -172,7 +172,7 @@ public boolean allocateUnassigned(RoutingAllocation allocation) {\n             }\n             AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId()));\n             if (shardState.hasData() == false) {\n-                logger.trace(\"{}: ignoring allocation, still fetching shard started state\");\n+                logger.trace(\"{}: ignoring allocation, still fetching shard started state\", shard);\n                 unassignedIterator.remove();\n                 routingNodes.ignoredUnassigned().add(shard);\n                 continue;\n@@ -396,7 +396,7 @@ public int compare(DiscoveryNode o1, DiscoveryNode o2) {\n             }\n \n             if (!canBeAllocatedToAtLeastOneNode) {\n-                logger.trace(\"{}: ignoring allocation, can't be allocated on any node\");\n+                logger.trace(\"{}: ignoring allocation, can't be allocated on any node\", shard);\n                 unassignedIterator.remove();\n                 routingNodes.ignoredUnassigned().add(shard);\n                 continue;\n@@ -409,7 +409,7 @@ public int compare(DiscoveryNode o1, DiscoveryNode o2) {\n             }\n             AsyncShardFetch.FetchResult<TransportNodesListShardStoreMetaData.NodeStoreFilesMetaData> shardStores = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId()));\n             if (shardStores.hasData() == false) {\n-                logger.trace(\"{}: ignoring allocation, still fetching shard stores\");\n+                logger.trace(\"{}: ignoring allocation, still fetching shard stores\", shard);\n                 unassignedIterator.remove();\n                 routingNodes.ignoredUnassigned().add(shard);\n                 continue; // still fetching",
    "output": "Add missing `shard` object in trace logging statement"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java b/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java\n--- a/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java\n@@ -786,7 +786,7 @@ public void addListener(Listener listener) {\n             fail(\"should not have been able to reroute the shard\");\n         } catch (IllegalArgumentException e) {\n             assertThat(\"can't allocated because there isn't enough room: \" + e.getMessage(),\n-                    e.getMessage().contains(\"less than required [30.0%] free disk on node, free: [26.0%]\"), equalTo(true));\n+                    e.getMessage().contains(\"more than allowed [70.0%] used disk on node, free: [26.0%]\"), equalTo(true));\n         }\n \n     }",
    "output": "Fix incorrect message in DiskThresholdDeciderTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java b/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java\n--- a/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java\n+++ b/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java\n@@ -381,7 +381,7 @@ public void handleResponse(PreSyncedFlushResponse response) {\n \n                 @Override\n                 public void handleException(TransportException exp) {\n-                    logger.trace(\"{} error while performing pre synced flush on [{}], skipping\", shardId, exp, shard);\n+                    logger.trace(\"{} error while performing pre synced flush on [{}], skipping\", exp, shardId, shard);\n                     if (countDown.countDown()) {\n                         listener.onResponse(commitIds);\n                     }",
    "output": "Fix log message. exception first, parameters later"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/SearchWithRejectionsTests.java b/src/test/java/org/elasticsearch/search/SearchWithRejectionsTests.java\n--- a/src/test/java/org/elasticsearch/search/SearchWithRejectionsTests.java\n+++ b/src/test/java/org/elasticsearch/search/SearchWithRejectionsTests.java\n@@ -70,18 +70,12 @@ public void testOpenContextsAfterRejections() throws InterruptedException {\n                     .setSearchType(searchType)\n                     .execute();\n         }\n-        int failures = 0;\n         for (int i = 0; i < numSearches; i++) {\n             try {\n-                SearchResponse searchResponse = responses[i].get();\n-                if (searchResponse.getFailedShards() > 0) {\n-                    failures++;\n-                }\n+                responses[i].get();\n             } catch (Throwable t) {\n-                failures++;\n             }\n         }\n-        assertThat(failures, greaterThanOrEqualTo(1));\n         awaitBusy(new Predicate<Object>() {\n             @Override\n             public boolean apply(Object input) {",
    "output": "Remove check for failure, might rarely not fail at all"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsTests.java b/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsTests.java\n--- a/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/settings/ClusterSettingsTests.java\n@@ -198,13 +198,15 @@ public void testMissingUnitsLenient() {\n         try {\n             createNode(Settings.builder().put(Settings.SETTINGS_REQUIRE_UNITS, \"false\").build());\n             assertAcked(prepareCreate(\"test\"));\n+            ensureGreen();\n             client().admin().indices().prepareUpdateSettings(\"test\").setSettings(Settings.builder().put(\"index.refresh_interval\", \"10\")).execute().actionGet();\n         } finally {\n             // Restore the default so subsequent tests require units:\n             assertFalse(Settings.getSettingsRequireUnits());\n             Settings.setSettingsRequireUnits(true);\n         }\n     }\n+\n     private void createNode(Settings settings) {\n         internalCluster().startNode(Settings.builder()\n                         .put(ClusterName.SETTING, \"ClusterSettingsTests\")\n@@ -213,10 +215,7 @@ private void createNode(Settings settings) {\n                         .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)\n                         .put(EsExecutors.PROCESSORS, 1) // limit the number of threads created\n                         .put(\"http.enabled\", false)\n-                        .put(\"index.store.type\", \"ram\")\n                         .put(\"config.ignore_system_properties\", true) // make sure we get what we set :)\n-                        .put(\"gateway.type\", \"none\")\n-                        .put(\"indices.memory.interval\", \"100ms\")\n                         .put(settings)\n         );\n     }",
    "output": "Fix test bugs"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/suggest/SuggestShardModule.java b/src/main/java/org/elasticsearch/index/suggest/SuggestShardModule.java\n--- a/src/main/java/org/elasticsearch/index/suggest/SuggestShardModule.java\n+++ b/src/main/java/org/elasticsearch/index/suggest/SuggestShardModule.java\n@@ -1,33 +0,0 @@\n-/*\n- * Licensed to Elasticsearch under one or more contributor\n- * license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright\n- * ownership. Elasticsearch licenses this file to you under\n- * the Apache License, Version 2.0 (the \"License\"); you may\n- * not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.elasticsearch.index.suggest;\n-\n-import org.elasticsearch.common.inject.AbstractModule;\n-import org.elasticsearch.index.suggest.stats.ShardSuggestService;\n-\n-/**\n- *\n- */\n-public class SuggestShardModule extends AbstractModule {\n-    @Override\n-    protected void configure() {\n-        bind(ShardSuggestService.class).asEagerSingleton();\n-    }\n-}",
    "output": "Remove leftover class, not needed anymore"
  },
  {
    "input": "diff --git a/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesMetaDataSerializationTests.java b/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesMetaDataSerializationTests.java\n--- a/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesMetaDataSerializationTests.java\n+++ b/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesMetaDataSerializationTests.java\n@@ -6,10 +6,7 @@\n package org.elasticsearch.license.plugin;\n \n import org.elasticsearch.common.unit.TimeValue;\n-import org.elasticsearch.common.xcontent.ToXContent;\n-import org.elasticsearch.common.xcontent.XContentBuilder;\n-import org.elasticsearch.common.xcontent.XContentFactory;\n-import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.*;\n import org.elasticsearch.license.core.License;\n import org.elasticsearch.license.plugin.core.LicensesMetaData;\n import org.elasticsearch.license.plugin.core.TrialLicenseUtils;\n@@ -144,7 +141,7 @@ public void testXContentSerializationManyTrialAndSignedLicenses() throws Excepti\n     }\n \n     private static LicensesMetaData getLicensesMetaDataFromXContent(byte[] bytes) throws Exception {\n-        final XContentParser parser = XContentFactory.xContent(bytes).createParser(bytes);\n+        final XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(bytes);\n         parser.nextToken(); // consume null\n         parser.nextToken(); // consume \"licensesMetaData\"\n         LicensesMetaData licensesMetaDataFromXContent = LicensesMetaData.PROTO.fromXContent(parser);",
    "output": "Fix XContextSerialization test failure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java b/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java\n--- a/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java\n+++ b/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java\n@@ -42,7 +42,7 @@ public abstract class AbstractSSLService extends AbstractComponent {\n     static final String[] DEFAULT_CIPHERS = new String[] { \"TLS_RSA_WITH_AES_128_CBC_SHA256\", \"TLS_RSA_WITH_AES_128_CBC_SHA\", \"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\" };\n     static final TimeValue DEFAULT_SESSION_CACHE_TIMEOUT = TimeValue.timeValueHours(24);\n     static final int DEFAULT_SESSION_CACHE_SIZE = 1000;\n-    static final String DEFAULT_PROTOCOL = \"TLS\";\n+    static final String DEFAULT_PROTOCOL = \"TLSv1.2\";\n \n     protected final Environment env;\n     protected final LoadingCache<SSLSettings, SSLContext> sslContexts = CacheBuilder.newBuilder().build(new SSLContextCacheLoader());",
    "output": "Make TLSv1.2 the default protocol This commit makes TLSv1.2 the default protocol for better security. The old value of TLS would only pick a TLSv1.0 supporting context and cause client connections to be negotiated using that protocol when TLSv1.2 is supported and considered an improved protocol. Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java b/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java\n--- a/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java\n+++ b/src/main/java/org/elasticsearch/shield/ssl/AbstractSSLService.java\n@@ -39,7 +39,7 @@ public abstract class AbstractSSLService extends AbstractComponent {\n \n     public static final String[] DEFAULT_SUPPORTED_PROTOCOLS = new String[] { \"TLSv1\", \"TLSv1.1\", \"TLSv1.2\" };\n \n-    static final String[] DEFAULT_CIPHERS = new String[] { \"TLS_RSA_WITH_AES_128_CBC_SHA256\", \"TLS_RSA_WITH_AES_128_CBC_SHA\", \"TLS_DHE_RSA_WITH_AES_128_CBC_SHA\", \"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\" };\n+    static final String[] DEFAULT_CIPHERS = new String[] { \"TLS_RSA_WITH_AES_128_CBC_SHA256\", \"TLS_RSA_WITH_AES_128_CBC_SHA\", \"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\" };\n     static final TimeValue DEFAULT_SESSION_CACHE_TIMEOUT = TimeValue.timeValueHours(24);\n     static final int DEFAULT_SESSION_CACHE_SIZE = 1000;\n     static final String DEFAULT_PROTOCOL = \"TLS\";",
    "output": "Remove DHE cipher from default list This commit removes the DHE cipher from our list of enabled ciphers due to the recently published Logjam attack. The default configuration is not susceptible to the Logjam attack, but since we support Java 7 the maximum prime size (768 bit) is considered too weak. Java 8 supports 1024 bit primes, but these are also not ideal and this cipher should not be used with a prime smaller than 2048 bits. Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java b/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java\n--- a/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java\n+++ b/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java\n@@ -67,6 +67,7 @@ public void testAlternateConfigFileSuffixes() {\n         // test that we can read config files with .yaml, .json, and .properties suffixes\n         Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(settingsBuilder()\n                 .put(\"config.ignore_system_properties\", true)\n+                .put(\"path.home\", createTempDir().toString())\n                 .build(), true);\n \n         assertThat(tuple.v1().get(\"yaml.config.exists\"), equalTo(\"true\"));",
    "output": "Add path.home to settings"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java b/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java\n@@ -251,7 +251,7 @@ public void testUnderscoreInAnalyzerName() {\n             fail(\"This should fail with IllegalArgumentException because the analyzers name starts with _\");\n         } catch (ProvisionException e) {\n             assertTrue(e.getCause() instanceof IllegalArgumentException);\n-            assertThat(e.getCause().getMessage(), equalTo(\"analyzer name must not start with _. got \\\"_invalid_name\\\"\"));\n+            assertThat(e.getCause().getMessage(), equalTo(\"analyzer name must not start with '_'. got \\\"_invalid_name\\\"\"));\n         }\n     }\n \n@@ -268,7 +268,7 @@ public void testUnderscoreInAnalyzerNameAlias() {\n             fail(\"This should fail with IllegalArgumentException because the analyzers alias starts with _\");\n         } catch (ProvisionException e) {\n             assertTrue(e.getCause() instanceof IllegalArgumentException);\n-            assertThat(e.getCause().getMessage(), equalTo(\"analyzer name must not start with _. got \\\"_invalid_name\\\"\"));\n+            assertThat(e.getCause().getMessage(), equalTo(\"analyzer name must not start with '_'. got \\\"_invalid_name\\\"\"));\n         }\n     }\n }",
    "output": "Fix epected error message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/QueryBuilder.java b/src/main/java/org/elasticsearch/index/query/QueryBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/QueryBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/QueryBuilder.java\n@@ -35,7 +35,7 @@\n  * Base class for all classes producing lucene queries.\n  * Supports conversion to BytesReference and creation of lucene Query objects.\n  */\n-public abstract class QueryBuilder<QB> extends ToXContentToBytes implements Writeable<QB> {\n+public abstract class QueryBuilder<QB extends QueryBuilder> extends ToXContentToBytes implements Writeable<QB> {\n \n     protected QueryBuilder() {\n         super(XContentType.JSON);",
    "output": "Fix generic usage in QUeryBUilder, readFrom returns a QueryBuilder too, rather than just an Object"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java b/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java\n--- a/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java\n@@ -29,7 +29,7 @@ public void testCreate_Json() throws Exception {\n         Attachment attachment = DataAttachment.JSON.create(data);\n         InputStream input = attachment.bodyPart().getDataHandler().getInputStream();\n         String content = Streams.copyToString(new InputStreamReader(input, Charsets.UTF_8));\n-        assertThat(content, is(\"{\\n  \\\"key\\\" : \\\"value\\\"\" + System.lineSeparator() + \"}\"));\n+        assertThat(content, is(\"{\" + System.lineSeparator() + \"  \\\"key\\\" : \\\"value\\\"\" + System.lineSeparator() + \"}\"));\n     }\n \n     @Test\n@@ -38,6 +38,6 @@ public void testCreate_Yaml() throws Exception {\n         Attachment attachment = DataAttachment.YAML.create(data);\n         InputStream input = attachment.bodyPart().getDataHandler().getInputStream();\n         String content = Streams.copyToString(new InputStreamReader(input, Charsets.UTF_8));\n-        assertThat(content, is(\"---\\nkey: \\\"value\\\"\" + System.lineSeparator()));\n+        assertThat(content, is(\"---\" + System.lineSeparator() + \"key: \\\"value\\\"\" + System.lineSeparator()));\n     }\n }",
    "output": "Fix failing test on windows... now for realz"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n--- a/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n@@ -547,7 +547,7 @@ public FieldMapper smartNameFieldMapper(String smartName) {\n     }\n \n     public FieldMapper smartNameFieldMapper(String smartName, @Nullable String[] types) {\n-        if (types == null || types.length == 0) {\n+        if (types == null || types.length == 0 || types.length == 1 && types[0].equals(\"_all\")) {\n             return smartNameFieldMapper(smartName);\n         }\n         for (String type : types) {",
    "output": "Add back accidentally removed support for _all as a type alias. dd4f48"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java b/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java\n--- a/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/actions/email/DataAttachmentTests.java\n@@ -29,7 +29,7 @@ public void testCreate_Json() throws Exception {\n         Attachment attachment = DataAttachment.JSON.create(data);\n         InputStream input = attachment.bodyPart().getDataHandler().getInputStream();\n         String content = Streams.copyToString(new InputStreamReader(input, Charsets.UTF_8));\n-        assertThat(content, is(\"{\\n  \\\"key\\\" : \\\"value\\\"\\n}\"));\n+        assertThat(content, is(\"{\\n  \\\"key\\\" : \\\"value\\\"\" + System.lineSeparator() + \"}\"));\n     }\n \n     @Test\n@@ -38,6 +38,6 @@ public void testCreate_Yaml() throws Exception {\n         Attachment attachment = DataAttachment.YAML.create(data);\n         InputStream input = attachment.bodyPart().getDataHandler().getInputStream();\n         String content = Streams.copyToString(new InputStreamReader(input, Charsets.UTF_8));\n-        assertThat(content, is(\"---\\nkey: \\\"value\\\"\\n\"));\n+        assertThat(content, is(\"---\\nkey: \\\"value\\\"\" + System.lineSeparator()));\n     }\n }",
    "output": "Fix failing test on windows"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/StoreTest.java b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n--- a/src/test/java/org/elasticsearch/index/store/StoreTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n@@ -34,6 +34,7 @@\n import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.common.io.stream.InputStreamStreamInput;\n import org.elasticsearch.common.io.stream.OutputStreamStreamOutput;\n+import org.elasticsearch.common.lucene.Lucene;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n@@ -1234,6 +1235,7 @@ public void testMarkCorruptedOnTruncatedSegmentsFile() throws IOException {\n             // expected\n         }\n         assertTrue(store.isMarkedCorrupted());\n+        Lucene.cleanLuceneIndex(store.directory()); // we have to remove the index since it's corrupted and might fail the MocKDirWrapper checkindex call\n         store.close();\n     }\n ",
    "output": "Remove corrupted index before checkindex goes wild"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/compress/CompressedString.java b/src/main/java/org/elasticsearch/common/compress/CompressedString.java\n--- a/src/main/java/org/elasticsearch/common/compress/CompressedString.java\n+++ b/src/main/java/org/elasticsearch/common/compress/CompressedString.java\n@@ -47,7 +47,7 @@ public CompressedString(BytesReference data) throws IOException {\n         } else {\n             BytesArray bytesArray = data.toBytesArray();\n             this.bytes = CompressorFactory.defaultCompressor().compress(bytesArray.array(), bytesArray.arrayOffset(), bytesArray.length());\n-            assert CompressorFactory.compressor(bytes) == CompressorFactory.defaultCompressor();\n+            assert CompressorFactory.compressor(bytes) != null;\n         }\n \n     }",
    "output": "Fix abusive assertion"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n--- a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n@@ -514,6 +514,7 @@ public void testCorruptFileThenSnapshotAndRestore() throws ExecutionException, I\n      * replica.\n      */\n     @Test\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/11226\")\n     public void testReplicaCorruption() throws Exception {\n         int numDocs = scaledRandomIntBetween(100, 1000);\n         internalCluster().ensureAtLeastNumDataNodes(2);",
    "output": "Add await fix for"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n@@ -750,7 +750,6 @@ public CommitId flush(boolean force, boolean waitIfOngoing) throws EngineExcepti\n             try {\n                 if (flushNeeded || force) {\n                     flushNeeded = false;\n-                    final long translogId;\n                     try {\n                         translog.prepareCommit();\n                         logger.trace(\"starting commit for flush; commitTranslog=true\");\n@@ -759,7 +758,6 @@ public CommitId flush(boolean force, boolean waitIfOngoing) throws EngineExcepti\n                         translog.commit();\n                         // we need to refresh in order to clear older version values\n                         refresh(\"version_table_flush\");\n-\n                     } catch (Throwable e) {\n                         throw new FlushFailedEngineException(shardId, e);\n                     }",
    "output": "Add some words about the purpose of a seal etc"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java b/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java\n--- a/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java\n@@ -93,7 +93,6 @@ public void testBasics() throws IOException {\n         QueryUtils.checkUnequal(rewritten, rewritten2);\n     }\n \n-    @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/LUCENE-6483\")\n     public void testCache() throws IOException {\n         Directory dir = newDirectory();\n         LRUQueryCache cache = new LRUQueryCache(10000, Long.MAX_VALUE);",
    "output": "Upgrade to lucene-5.2.0-snapshot-1680200"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java b/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java\n--- a/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/IndexCacheableQueryTests.java\n@@ -93,7 +93,6 @@ public void testBasics() throws IOException {\n         QueryUtils.checkUnequal(rewritten, rewritten2);\n     }\n \n-    @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/LUCENE-6483\")\n     public void testCache() throws IOException {\n         Directory dir = newDirectory();\n         LRUQueryCache cache = new LRUQueryCache(10000, Long.MAX_VALUE);",
    "output": "Upgrade to lucene-5.2.0-snapshot-1680200"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/Engine.java b/src/main/java/org/elasticsearch/index/engine/Engine.java\n--- a/src/main/java/org/elasticsearch/index/engine/Engine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/Engine.java\n@@ -1147,7 +1147,9 @@ public void close() throws IOException {\n     public abstract boolean hasUncommittedChanges();\n \n     public static class CommitId implements Writeable {\n-        private byte[] id;\n+\n+        private final byte[] id;\n+\n         public CommitId(byte[] id) {\n             assert id != null;\n             this.id = Arrays.copyOf(id, id.length);\n@@ -1165,8 +1167,7 @@ public String toString() {\n \n         @Override\n         public CommitId readFrom(StreamInput in) throws IOException {\n-            byte[] bytes = in.readByteArray();\n-            return new CommitId(bytes);\n+            return new CommitId(in);\n         }\n \n         @Override",
    "output": "Make commitID byte[] final"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsDirectoryService.java b/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsDirectoryService.java\n--- a/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsDirectoryService.java\n+++ b/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsDirectoryService.java\n@@ -43,6 +43,6 @@ public SmbMmapFsDirectoryService(@IndexSettings Settings indexSettings, IndexSto\n     @Override\n     protected Directory newFSDirectory(Path location, LockFactory lockFactory) throws IOException {\n         logger.debug(\"wrapping MMapDirectory for SMB\");\n-        return new SmbDirectoryWrapper(new MMapDirectory(location, buildLockFactory()));\n+        return new SmbDirectoryWrapper(new MMapDirectory(location, buildLockFactory(indexSettings)));\n     }\n }",
    "output": "Fix compilation for latest ES versions This fixes a change that recently landed in 1.x and master that prevents the plugin from being compiled"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/Engine.java b/src/main/java/org/elasticsearch/index/engine/Engine.java\n--- a/src/main/java/org/elasticsearch/index/engine/Engine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/Engine.java\n@@ -534,31 +534,10 @@ protected Throwable wrapIfClosed(Throwable t) {\n         return t;\n     }\n \n-    public static interface FailedEngineListener {\n+    public interface FailedEngineListener {\n         void onFailedEngine(ShardId shardId, String reason, @Nullable Throwable t);\n     }\n \n-    /**\n-     * Recovery allow to start the recovery process. It is built of three phases.\n-     * <p/>\n-     * <p>The first phase allows to take a snapshot of the master index. Once this\n-     * is taken, no commit operations are effectively allowed on the index until the recovery\n-     * phases are through.\n-     * <p/>\n-     * <p>The seconds phase takes a snapshot of the current transaction log.\n-     * <p/>\n-     * <p>The last phase returns the remaining transaction log. During this phase, no dirty\n-     * operations are allowed on the index.\n-     */\n-    public static interface RecoveryHandler {\n-\n-        void phase1(SnapshotIndexCommit snapshot);\n-\n-        void phase2(Translog.Snapshot snapshot);\n-\n-        void phase3(Translog.Snapshot snapshot);\n-    }\n-\n     public static class Searcher implements Releasable {\n \n         private final String source;",
    "output": "Remove dead code / unused class"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n@@ -764,9 +764,9 @@ public void testPhraseBoundaryCases() throws IOException {\n     public void testDifferentShardSize() throws Exception {\n         createIndex(\"test\");\n         ensureGreen();\n-        indexRandom(true, client().prepareIndex(\"text\", \"type1\", \"1\").setSource(\"field1\", \"foobar1\").setRouting(\"1\"),\n-                client().prepareIndex(\"text\", \"type1\", \"2\").setSource(\"field1\", \"foobar2\").setRouting(\"2\"),\n-                client().prepareIndex(\"text\", \"type1\", \"3\").setSource(\"field1\", \"foobar3\").setRouting(\"3\"));\n+        indexRandom(true, client().prepareIndex(\"test\", \"type1\", \"1\").setSource(\"field1\", \"foobar1\").setRouting(\"1\"),\n+                client().prepareIndex(\"test\", \"type1\", \"2\").setSource(\"field1\", \"foobar2\").setRouting(\"2\"),\n+                client().prepareIndex(\"test\", \"type1\", \"3\").setSource(\"field1\", \"foobar3\").setRouting(\"3\"));\n \n         Suggest suggest = searchSuggest( \"foobar\",\n                 termSuggestion(\"simple\")",
    "output": "Use correct index name created for this test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayTests.java b/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayTests.java\n--- a/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayTests.java\n+++ b/src/test/java/org/elasticsearch/gateway/RecoveryFromGatewayTests.java\n@@ -56,7 +56,7 @@\n  */\n @ClusterScope(numDataNodes = 0, scope = Scope.TEST)\n @Slow\n-public class RecoveryFromGatewayTesTermVectorsFields.javats extends ElasticsearchIntegrationTest {\n+public class RecoveryFromGatewayTests extends ElasticsearchIntegrationTest {\n \n     @Test\n     @Slow",
    "output": "Remove accidential modification"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/WatcherVersion.java b/src/main/java/org/elasticsearch/watcher/WatcherVersion.java\n--- a/src/main/java/org/elasticsearch/watcher/WatcherVersion.java\n+++ b/src/main/java/org/elasticsearch/watcher/WatcherVersion.java\n@@ -25,7 +25,7 @@ public class WatcherVersion implements Serializable {\n     // the (internal) format of the id is there so we can easily do after/before checks on the id\n \n     public static final int V_1_0_0_Beta1_ID = /*00*/1000001;\n-    public static final WatcherVersion V_1_0_0_Beta1 = new WatcherVersion(V_1_0_0_Beta1_ID, true, Version.V_1_4_0, LicenseVersion.V_1_0_0);\n+    public static final WatcherVersion V_1_0_0_Beta1 = new WatcherVersion(V_1_0_0_Beta1_ID, true, Version.V_1_5_0, LicenseVersion.V_1_0_0);\n \n     public static final WatcherVersion CURRENT = V_1_0_0_Beta1;\n ",
    "output": "Upgrade `WatcherVersion` with min es compatibility to 1.5"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n@@ -1253,6 +1253,18 @@ public void testPhraseSuggesterCollate() throws InterruptedException, ExecutionE\n         assertSuggestionSize(searchSuggest, 0, 10, \"title\");\n         assertSuggestionPhraseCollateMatchExists(searchSuggest, \"title\", 2);\n \n+        collateWithParams = XContentFactory.jsonBuilder()\n+                .startObject()\n+                .startObject(\"query\")\n+                .startObject(\"{{query_type}}\")\n+                .field(\"{{query_field}}\", \"{{suggestion}}\")\n+                .endObject()\n+                .endObject()\n+                .endObject().string();\n+\n+        params.clear();\n+        params.put(\"query_type\", \"match_phrase\");\n+        params.put(\"query_field\", \"title\");\n         // collate filter request with prune set to true\n         phraseSuggestWithParamsAndReturn = suggest.collateFilter(collateWithParams).collateQuery(null).collateParams(params).collatePrune(true);\n         searchSuggest = searchSuggest(\"united states house of representatives elections in washington 2006\", phraseSuggestWithParamsAndReturn);",
    "output": "Improve Phrase Collate filter test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/MultiValueMode.java b/src/main/java/org/elasticsearch/search/MultiValueMode.java\n--- a/src/main/java/org/elasticsearch/search/MultiValueMode.java\n+++ b/src/main/java/org/elasticsearch/search/MultiValueMode.java\n@@ -20,7 +20,6 @@\n \n package org.elasticsearch.search;\n \n-import javafx.collections.transformation.SortedList;\n import org.apache.lucene.index.*;\n import org.apache.lucene.search.DocIdSet;\n import org.apache.lucene.search.DocIdSetIterator;",
    "output": "Fix a broken import in MultiValueMode"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/KuromojiAnalysisTests.java b/src/test/java/org/elasticsearch/index/analysis/KuromojiAnalysisTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/KuromojiAnalysisTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/KuromojiAnalysisTests.java\n@@ -245,4 +245,24 @@ private String readFully(Reader reader) throws IOException {\n         return buffer.toString();\n     }\n \n+    @Test\n+    public void testKuromojiUserDict() throws IOException {\n+        AnalysisService analysisService = createAnalysisService();\n+        TokenizerFactory tokenizerFactory = analysisService.tokenizer(\"kuromoji_user_dict\");\n+        String source = \"\";\n+        String[] expected = new String[]{\"\", \"\", \"\", \"\", \"\"};\n+\n+        Tokenizer tokenizer = tokenizerFactory.create();\n+        tokenizer.setReader(new StringReader(source));\n+        assertSimpleTSOutput(tokenizer, expected);\n+    }\n+\n+    // fix #59\n+    @Test\n+    public void testKuromojiEmptyUserDict() {\n+        AnalysisService analysisService = createAnalysisService();\n+        TokenizerFactory tokenizerFactory = analysisService.tokenizer(\"kuromoji_empty_user_dict\");\n+        assertThat(tokenizerFactory, instanceOf(KuromojiTokenizerFactory.class));\n+    }\n+\n }",
    "output": "Add user dictionary test case"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -243,6 +243,26 @@ public abstract class ElasticsearchIntegrationTest extends ElasticsearchTestCase\n     public @interface Integration {\n     }\n \n+    /**\n+     * Property that controls whether ThirdParty Integration tests are run (not the default).\n+     */\n+    public static final String SYSPROP_THIRDPARTY = \"tests.thirdparty\";\n+\n+    /**\n+     * Annotation for third-party integration tests.\n+     * <p>\n+     * These are tests the require a third-party service in order to run. They\n+     * may require the user to manually configure an external process (such as rabbitmq),\n+     * or may additionally require some external configuration (e.g. AWS credentials)\n+     * via the {@code tests.config} system property.\n+     */\n+    @Inherited\n+    @Retention(RetentionPolicy.RUNTIME)\n+    @Target(ElementType.TYPE)\n+    @TestGroup(enabled = false, sysProperty = ElasticsearchIntegrationTest.SYSPROP_THIRDPARTY)\n+    public @interface ThirdParty {\n+    }\n+\n     /** node names of the corresponding clusters will start with these prefixes */\n     public static final String SUITE_CLUSTER_NODE_PREFIX = \"node_s\";\n     public static final String TEST_CLUSTER_NODE_PREFIX = \"node_t\";",
    "output": "Add test group for third-party tests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -243,6 +243,26 @@ public abstract class ElasticsearchIntegrationTest extends ElasticsearchTestCase\n     public @interface Integration {\n     }\n \n+    /**\n+     * Property that controls whether ThirdParty Integration tests are run (not the default).\n+     */\n+    public static final String SYSPROP_THIRDPARTY = \"tests.thirdparty\";\n+\n+    /**\n+     * Annotation for third-party integration tests.\n+     * <p>\n+     * These are tests the require a third-party service in order to run. They\n+     * may require the user to manually configure an external process (such as rabbitmq),\n+     * or may additionally require some external configuration (e.g. AWS credentials)\n+     * via the {@code tests.config} system property.\n+     */\n+    @Inherited\n+    @Retention(RetentionPolicy.RUNTIME)\n+    @Target(ElementType.TYPE)\n+    @TestGroup(enabled = false, sysProperty = ElasticsearchIntegrationTest.SYSPROP_THIRDPARTY)\n+    public @interface ThirdParty {\n+    }\n+\n     /** node names of the corresponding clusters will start with these prefixes */\n     public static final String SUITE_CLUSTER_NODE_PREFIX = \"node_s\";\n     public static final String TEST_CLUSTER_NODE_PREFIX = \"node_t\";",
    "output": "Add test group for third-party tests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java b/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java\n@@ -60,7 +60,7 @@ public static UserDictionary getUserDictionary(Environment env, Settings setting\n                 return null;\n             } else {\n                 try {\n-                    return new UserDictionary(reader);\n+                    return UserDictionary.open(reader);\n                 } finally {\n                     reader.close();\n                 }",
    "output": "Fix compilation (use the new UserDictionary.open) Relates to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -23,8 +23,10 @@\n import org.elasticsearch.bootstrap.Bootstrap;\n import org.elasticsearch.bootstrap.ESPolicy;\n import org.elasticsearch.bootstrap.Security;\n+import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.io.PathUtils;\n \n+import java.io.FilePermission;\n import java.nio.file.Path;\n import java.security.Permissions;\n import java.security.Policy;\n@@ -68,6 +70,10 @@ public class BootstrapForTesting {\n                 Path javaTmpDir = PathUtils.get(Objects.requireNonNull(System.getProperty(\"java.io.tmpdir\"), \n                                                                       \"please set ${java.io.tmpdir} in pom.xml\"));\n                 Security.addPath(perms, javaTmpDir, \"read,readlink,write,delete\");\n+                // custom test config file\n+                if (Strings.hasLength(System.getProperty(\"tests.config\"))) {\n+                    perms.add(new FilePermission(System.getProperty(\"tests.config\"), \"read,readlink\"));\n+                }\n                 Policy.setPolicy(new ESPolicy(perms));\n                 System.setSecurityManager(new TestSecurityManager());\n                 Security.selfTest();",
    "output": "Add tests.config support to BootstrapForTesting"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/transport/actions/service/TransportWatcherServiceAction.java b/src/main/java/org/elasticsearch/watcher/transport/actions/service/TransportWatcherServiceAction.java\n--- a/src/main/java/org/elasticsearch/watcher/transport/actions/service/TransportWatcherServiceAction.java\n+++ b/src/main/java/org/elasticsearch/watcher/transport/actions/service/TransportWatcherServiceAction.java\n@@ -35,7 +35,8 @@ public TransportWatcherServiceAction(Settings settings, TransportService transpo\n \n     @Override\n     protected String executor() {\n-        return ThreadPool.Names.MANAGEMENT;\n+        // We should always be able to stop or restart the watcher service, even if the a TP is exhausted, so don't fork into another thread:\n+        return ThreadPool.Names.SAME;\n     }\n \n     @Override\n\ndiff --git a/src/main/java/org/elasticsearch/watcher/transport/actions/stats/TransportWatcherStatsAction.java b/src/main/java/org/elasticsearch/watcher/transport/actions/stats/TransportWatcherStatsAction.java\n--- a/src/main/java/org/elasticsearch/watcher/transport/actions/stats/TransportWatcherStatsAction.java\n+++ b/src/main/java/org/elasticsearch/watcher/transport/actions/stats/TransportWatcherStatsAction.java\n@@ -42,7 +42,8 @@ public TransportWatcherStatsAction(Settings settings, TransportService transport\n \n     @Override\n     protected String executor() {\n-        return ThreadPool.Names.MANAGEMENT;\n+        // cheap operation, no need to fork into another thread\n+        return ThreadPool.Names.SAME;\n     }\n \n     @Override",
    "output": "Use ThreadPool.Names.SAME executor in stats and service apis"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n--- a/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n+++ b/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java\n@@ -23,8 +23,10 @@\n import org.elasticsearch.bootstrap.Bootstrap;\n import org.elasticsearch.bootstrap.ESPolicy;\n import org.elasticsearch.bootstrap.Security;\n+import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.io.PathUtils;\n \n+import java.io.FilePermission;\n import java.nio.file.Path;\n import java.security.Permissions;\n import java.security.Policy;\n@@ -68,6 +70,10 @@ public class BootstrapForTesting {\n                 Path javaTmpDir = PathUtils.get(Objects.requireNonNull(System.getProperty(\"java.io.tmpdir\"), \n                                                                       \"please set ${java.io.tmpdir} in pom.xml\"));\n                 Security.addPath(perms, javaTmpDir, \"read,readlink,write,delete\");\n+                // custom test config file\n+                if (Strings.hasLength(System.getProperty(\"tests.config\"))) {\n+                    perms.add(new FilePermission(System.getProperty(\"tests.config\"), \"read,readlink\"));\n+                }\n                 Policy.setPolicy(new ESPolicy(perms));\n                 System.setSecurityManager(new TestSecurityManager());\n                 Security.selfTest();",
    "output": "Add tests.config support to BootstrapForTesting Several plugins (e.g. elasticsearch-cloud-aws, elasticsearch-cloud-azure, elasticsearch-cloud-gce) have integration tests that run with actual credentials to a remote service, so test runs need access to this file. These all require the tester (or jenkins) to supply the file with -Dtests.config"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/execution/Wid.java b/src/main/java/org/elasticsearch/watcher/execution/Wid.java\n--- a/src/main/java/org/elasticsearch/watcher/execution/Wid.java\n+++ b/src/main/java/org/elasticsearch/watcher/execution/Wid.java\n@@ -23,7 +23,7 @@ public class Wid {\n \n     public Wid(String watchId, long nonce, DateTime executionTime) {\n         this.watchId = watchId;\n-        this.value = watchId + \"_\" + String.valueOf(nonce) + \"#\" +  formatter.print(executionTime);\n+        this.value = watchId + \"_\" + String.valueOf(nonce) + \"-\" +  formatter.print(executionTime);\n     }\n \n     public Wid(String value) {",
    "output": "Use a different separator in `Wid` `#` is a reserved character in the URL spec and must be escaped to be used. This change uses `-` instead. Fixes: elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n@@ -642,19 +642,11 @@ private Map<String, Set<String>> resolveSearchRoutingAllIndices(String routing)\n      * @param indicesOptions   how the aliases or indices need to be resolved to concrete indices\n      * @param aliasesOrIndices the aliases or indices to be resolved to concrete indices\n      * @return the obtained concrete indices\n-<<<<<<< HEAD\n      * @throws IndexMissingException if one of the aliases or indices is missing and the provided indices options\n      * don't allow such a case, or if the final result of the indices resolution is no indices and the indices options\n      * don't allow such a case.\n      * @throws IllegalArgumentException if one of the aliases resolve to multiple indices and the provided\n      * indices options don't allow such a case.\n-=======\n-     * @throws IndexMissingException                 if one of the aliases or indices is missing and the provided indices options\n-     *                                               don't allow such a case, or if the final result of the indices resolution is no indices and the indices options\n-     *                                               don't allow such a case.\n-     * @throws ElasticsearchIllegalArgumentException if one of the aliases resolve to multiple indices and the provided\n-     *                                               indices options don't allow such a case.\n->>>>>>> Add support for cluster state diffs\n      */\n     public String[] concreteIndices(IndicesOptions indicesOptions, String... aliasesOrIndices) throws IndexMissingException, IllegalArgumentException {\n         if (indicesOptions.expandWildcardsOpen() || indicesOptions.expandWildcardsClosed()) {",
    "output": "Fix merge conflict in javadoc"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java b/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java\n@@ -23,7 +23,6 @@\n \n import org.apache.lucene.queries.TermsQuery;\n import org.apache.lucene.search.Query;\n-import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.io.stream.Streamable;\n@@ -52,6 +51,10 @@ public class IdsQueryBuilder extends BaseQueryBuilder implements Streamable, Boo\n \n     private String queryName;\n \n+    public IdsQueryBuilder() {\n+        //for serialization only\n+    }\n+\n     public IdsQueryBuilder(String... types) {\n         this.types = (types == null || types.length == 0) ? new ArrayList<String>() : Arrays.asList(types);\n     }\n\ndiff --git a/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java b/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java\n@@ -121,7 +121,7 @@ public TermQueryBuilder(String fieldName, Object value) {\n         }\n     }\n \n-    TermQueryBuilder() {\n+    public TermQueryBuilder() {\n         // for serialization only\n     }\n ",
    "output": "Make default constructors (needed for serialization) public"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java b/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java\n--- a/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java\n+++ b/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java\n@@ -69,8 +69,9 @@ protected void assertLuceneQuery(IdsQueryBuilder queryBuilder, Query query, Quer\n         }\n     }\n \n-    public IdsQueryBuilder createTestQueryBuilder() {\n-        IdsQueryBuilder query = new IdsQueryBuilder();\n+    @Override\n+    protected IdsQueryBuilder createTestQueryBuilder() {\n+        IdsQueryBuilder query;\n         int numberOfTypes = randomIntBetween(1, 10);\n         String[] types = new String[numberOfTypes];\n         for (int i = 0; i < numberOfTypes; i++) {\n\ndiff --git a/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java b/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java\n--- a/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java\n+++ b/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java\n@@ -38,6 +38,7 @@ protected TermQueryBuilder createEmptyQueryBuilder() {\n     /**\n      * @return a TermQuery with random field name and value, optional random boost and queryname\n      */\n+    @Override\n     protected TermQueryBuilder createTestQueryBuilder() {\n         Object value = null;\n         switch (randomIntBetween(0, 3)) {",
    "output": "Add missing @Override annotations to query builder tests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/jna/NativesTests.java b/src/test/java/org/elasticsearch/common/jna/NativesTests.java\n--- a/src/test/java/org/elasticsearch/common/jna/NativesTests.java\n+++ b/src/test/java/org/elasticsearch/common/jna/NativesTests.java\n@@ -29,11 +29,10 @@ public class NativesTests extends ElasticsearchTestCase {\n \n     @Test\n     public void testMlockall() {\n-        if (Constants.WINDOWS) {\n-            assertFalse(\"Memory locking is not available on Windows platforms\", Natives.LOCAL_MLOCKALL);\n-        }\n         if (Constants.MAC_OS_X) {\n             assertFalse(\"Memory locking is not available on OS X platforms\", Natives.LOCAL_MLOCKALL);\n+        } else {\n+            assertTrue(Natives.LOCAL_MLOCKALL);\n         }\n     }\n     ",
    "output": "Fix mlockall test when running on Windows"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/CorruptedTranslogTests.java b/src/test/java/org/elasticsearch/index/store/CorruptedTranslogTests.java\n--- a/src/test/java/org/elasticsearch/index/store/CorruptedTranslogTests.java\n+++ b/src/test/java/org/elasticsearch/index/store/CorruptedTranslogTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.index.store;\n \n import com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.Lists;\n+import com.carrotsearch.randomizedtesting.annotations.Repeat;\n import com.carrotsearch.randomizedtesting.generators.RandomPicks;\n \n import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n@@ -33,6 +34,7 @@\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.translog.Translog;\n import org.elasticsearch.monitor.fs.FsStats;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.engine.MockEngineSupport;\n@@ -80,7 +82,7 @@ public void testCorruptTranslogFiles() throws Exception {\n                 .put(\"index.refresh_interval\", \"-1\")\n                 .put(MockEngineSupport.FLUSH_ON_CLOSE_RATIO, 0.0d) // never flush - always recover from translog\n                 .put(IndexShard.INDEX_FLUSH_ON_CLOSE, false) // never flush - always recover from translog\n-                .put(\"index.gateway.local.sync\", \"1s\") // fsync the translog every second\n+                .put(Translog.INDEX_TRANSLOG_SYNC_INTERVAL, \"1s\") // fsync the translog every second\n         ));\n         ensureYellow();\n ",
    "output": "Use the correct translog setting"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/StoreTest.java b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n--- a/src/test/java/org/elasticsearch/index/store/StoreTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n@@ -45,6 +45,7 @@\n \n import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.nio.file.Files;\n import java.nio.file.NoSuchFileException;\n import java.util.*;\n import java.util.concurrent.atomic.AtomicBoolean;\n@@ -1033,9 +1034,13 @@ public void testStoreStats() throws IOException {\n         DirectoryService directoryService = new LuceneManagedDirectoryService(random());\n         Settings settings = ImmutableSettings.builder().put(Store.INDEX_STORE_STATS_REFRESH_INTERVAL, TimeValue.timeValueMinutes(0)).build();\n         Store store = new Store(shardId, settings, directoryService, new DummyShardLock(shardId));\n-\n+        long initialStoreSize = 0;\n+        for (String extraFiles : store.directory().listAll()) {\n+            assertTrue(\"expected extraFS file but got: \" + extraFiles, extraFiles.startsWith(\"extra\"));\n+            initialStoreSize += store.directory().fileLength(extraFiles);\n+        }\n         StoreStats stats = store.stats();\n-        assertEquals(stats.getSize().bytes(), 0);\n+        assertEquals(stats.getSize().bytes(), initialStoreSize);\n \n         Directory dir = store.directory();\n         final long length;\n@@ -1050,7 +1055,7 @@ public void testStoreStats() throws IOException {\n \n         assertTrue(numNonExtraFiles(store) > 0);\n         stats = store.stats();\n-        assertEquals(stats.getSizeInBytes(), length);\n+        assertEquals(stats.getSizeInBytes(), length + initialStoreSize);\n \n         deleteContent(store.directory());\n         IOUtils.close(store);",
    "output": "Fix storeStats tests if extraFS is involved"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/QueryParseContext.java b/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n--- a/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n+++ b/src/main/java/org/elasticsearch/index/query/QueryParseContext.java\n@@ -267,7 +267,10 @@ public QueryBuilder parseInnerQueryBuilder() throws IOException {\n     @Deprecated\n     public Query parseInnerQuery() throws IOException, QueryParsingException {\n         QueryBuilder builder = parseInnerQueryBuilder();\n-        Query result = builder.toQuery(this);\n+        Query result = null;\n+        if (builder != null) {\n+            result = builder.toQuery(this);\n+        }\n         return result;\n     }\n ",
    "output": "Add missing null check to QueryParseContext#parseInnerQuery to fix test failure"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java b/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java\n--- a/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java\n+++ b/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java\n@@ -19,8 +19,6 @@\n \n package org.elasticsearch.index.query;\n \n-import com.carrotsearch.randomizedtesting.annotations.Repeat;\n-\n import org.apache.lucene.search.MatchAllDocsQuery;\n import org.apache.lucene.search.Query;\n \n@@ -29,7 +27,6 @@\n import static org.hamcrest.Matchers.instanceOf;\n import static org.hamcrest.Matchers.is;\n \n-@Repeat(iterations=20)\n public class MatchAllQueryBuilderTest extends BaseQueryTestCase<MatchAllQueryBuilder> {\n \n     @Override",
    "output": "Remove @Repeat from MatchAllQueryBuilderTest, handled in BaseQueryBuilderTest now"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/rest/action/RestGetWatchAction.java b/src/main/java/org/elasticsearch/watcher/rest/action/RestGetWatchAction.java\n--- a/src/main/java/org/elasticsearch/watcher/rest/action/RestGetWatchAction.java\n+++ b/src/main/java/org/elasticsearch/watcher/rest/action/RestGetWatchAction.java\n@@ -38,9 +38,11 @@ public RestResponse buildResponse(GetWatchResponse response, XContentBuilder bui\n                 builder.startObject()\n                         .field(\"found\", response.isFound())\n                         .field(\"_id\", response.getId())\n-                        .field(\"_version\", response.getVersion())\n-                        .field(\"watch\", response.getSource(), ToXContent.EMPTY_PARAMS)\n-                        .endObject();\n+                        .field(\"_version\", response.getVersion());\n+                        if (response.isFound()) {\n+                            builder.field(\"watch\", response.getSource(), ToXContent.EMPTY_PARAMS);\n+                        }\n+                        builder.endObject();\n \n                 RestStatus status = response.isFound() ? OK : NOT_FOUND;\n                 return new BytesRestResponse(status, builder);",
    "output": "Fix NPE in Rest Layer when GET missing watch. The REST GET API was trying to render a null watch on GET which was causing an NPE. Don't render the watch if it's not found and add a test for this case. Fixes: elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n@@ -101,7 +101,7 @@ public static SearchRequest parseSearchRequest(RestRequest request) {\n         String searchType = request.param(\"search_type\");\n         if (SearchType.fromString(searchType).equals(SearchType.QUERY_AND_FETCH) ||\n                 SearchType.fromString(searchType).equals(SearchType.DFS_QUERY_AND_FETCH)) {\n-            throw new ElasticsearchIllegalArgumentException(\"Unsupported search type [\" + searchType + \"]\");\n+            throw new IllegalArgumentException(\"Unsupported search type [\" + searchType + \"]\");\n         } else {\n             searchRequest.searchType(searchType);\n         }",
    "output": "Fix the build, remove usage of old ES specific IAE"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n@@ -21,6 +21,7 @@\n \n import org.elasticsearch.action.search.SearchRequest;\n import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.search.SearchType;\n import org.elasticsearch.action.support.IndicesOptions;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.Strings;\n@@ -94,8 +95,18 @@ public static SearchRequest parseSearchRequest(RestRequest request) {\n             }\n         }\n \n+        // do not allow 'query_and_fetch' or 'dfs_query_and_fetch' search types\n+        // from the REST layer. these modes are an internal optimization and should\n+        // not be specified explicitly by the user.\n+        String searchType = request.param(\"search_type\");\n+        if (SearchType.fromString(searchType).equals(SearchType.QUERY_AND_FETCH) ||\n+                SearchType.fromString(searchType).equals(SearchType.DFS_QUERY_AND_FETCH)) {\n+            throw new ElasticsearchIllegalArgumentException(\"Unsupported search type [\" + searchType + \"]\");\n+        } else {\n+            searchRequest.searchType(searchType);\n+        }\n+\n         searchRequest.extraSource(parseSearchSource(request));\n-        searchRequest.searchType(request.param(\"search_type\"));\n         searchRequest.queryCache(request.paramAsBoolean(\"query_cache\", null));\n \n         String scroll = request.param(\"scroll\");",
    "output": "Remove (dfs_)query_and_fetch from the REST API"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java b/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n--- a/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n+++ b/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n@@ -189,7 +189,7 @@ public static SearchRequest readSearchRequest(XContentParser parser, SearchType\n                                 throw new SearchRequestParseException(\"could not read search request. unexpected template field [\" + currentFieldName + \"]\");\n                             }\n                         } else if (token == XContentParser.Token.START_OBJECT) {\n-                            if (TEMPLATE_TYPE_FIELD.getPreferredName().equals(currentFieldName)) {\n+                            if (TEMPLATE_PARAMS_FIELD.getPreferredName().equals(currentFieldName)) {\n                                 searchRequest.templateParams(flattenModel(parser.map()));\n                             }\n                         } else {",
    "output": "Fix wrong parse field"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java b/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n--- a/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n+++ b/src/main/java/org/elasticsearch/watcher/support/WatcherUtils.java\n@@ -189,7 +189,7 @@ public static SearchRequest readSearchRequest(XContentParser parser, SearchType\n                                 throw new SearchRequestParseException(\"could not read search request. unexpected template field [\" + currentFieldName + \"]\");\n                             }\n                         } else if (token == XContentParser.Token.START_OBJECT) {\n-                            if (\"params\".equals(currentFieldName)) {\n+                            if (TEMPLATE_TYPE_FIELD.getPreferredName().equals(currentFieldName)) {\n                                 searchRequest.templateParams(flattenModel(parser.map()));\n                             }\n                         } else {",
    "output": "Use parse field instead of a plain string"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/transform/search/ExecutableSearchTransform.java b/src/main/java/org/elasticsearch/watcher/transform/search/ExecutableSearchTransform.java\n--- a/src/main/java/org/elasticsearch/watcher/transform/search/ExecutableSearchTransform.java\n+++ b/src/main/java/org/elasticsearch/watcher/transform/search/ExecutableSearchTransform.java\n@@ -51,27 +51,4 @@ public SearchTransform.Result execute(WatchExecutionContext ctx, Payload payload\n         return new SearchTransform.Result(req, new Payload.XContent(resp));\n     }\n \n-    SearchRequest createRequest(SearchRequest requestPrototype, WatchExecutionContext ctx, Payload payload) throws IOException {\n-        SearchRequest request = new SearchRequest(requestPrototype)\n-                .indicesOptions(requestPrototype.indicesOptions())\n-                .indices(requestPrototype.indices())\n-                .searchType(requestPrototype.searchType());\n-\n-\n-        if (Strings.hasLength(requestPrototype.source())) {\n-            String requestSource = XContentHelper.convertToJson(requestPrototype.source(), false);\n-            ExecutableScript script = scriptService.executable(\"mustache\", requestSource, ScriptService.ScriptType.INLINE, createCtxModel(ctx, payload));\n-            request.source((BytesReference) script.unwrap(script.run()), false);\n-        } else if (requestPrototype.templateName() != null) {\n-            MapBuilder<String, Object> templateParams = MapBuilder.newMapBuilder(requestPrototype.templateParams())\n-                    .putAll(flattenModel(createCtxModel(ctx, payload)));\n-            request.templateParams(templateParams.map());\n-            request.templateName(requestPrototype.templateName());\n-            request.templateType(requestPrototype.templateType());\n-        } else {\n-            throw new TransformException(\"search requests needs either source or template name\");\n-        }\n-        return request;\n-    }\n-\n }",
    "output": "Remove unused method"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/FilterParser.java b/src/main/java/org/elasticsearch/index/query/FilterParser.java\n--- a/src/main/java/org/elasticsearch/index/query/FilterParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/FilterParser.java\n@@ -40,7 +40,6 @@ public interface FilterParser {\n      * it exists within a must clause or a must_not bool clause (that is why returning MATCH_ALL will\n      * not be good, since it will not match anything when returned within a must_not clause).\n      */\n-    //norelease can be removed in favour of fromXContent once search requests can be parsed on the coordinating node\n     @Nullable\n     Filter parse(QueryParseContext parseContext) throws IOException, QueryParsingException;\n }\n\\ No newline at end of file",
    "output": "Remove //norelease comment, FilterParser will go away with"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java b/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java\n--- a/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java\n+++ b/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java\n@@ -130,7 +130,7 @@ private ExecuteWatchRequest parseRequest(RestRequest request, WatcherClient clie\n         if (triggerEvent == null) {\n             throw new WatcherException(\"[{}] is a required field.\",TRIGGER_EVENT_FIELD.getPreferredName());\n         }\n-\n+        executeWatchRequestBuilder.setTriggerEvent(triggerEvent);\n         return executeWatchRequestBuilder.request();\n     }\n ",
    "output": "Fix execute REST API call We weren't assigning the trigger event in the execute REST API"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/ssl/ClientSSLServiceTests.java b/src/test/java/org/elasticsearch/shield/ssl/ClientSSLServiceTests.java\n--- a/src/test/java/org/elasticsearch/shield/ssl/ClientSSLServiceTests.java\n+++ b/src/test/java/org/elasticsearch/shield/ssl/ClientSSLServiceTests.java\n@@ -171,7 +171,7 @@ public void testThatSSLContextWithoutSettingsWorks() throws Exception {\n             // Execute a GET on a site known to have a valid certificate signed by a trusted public CA\n             // This will result in a SSLHandshakeException if the SSLContext does not trust the CA, but the default\n             // truststore trusts all common public CAs so the handshake will succeed\n-            client.execute(new HttpGet(\"https://www.elasticsearch.com/\"));\n+            client.execute(new HttpGet(\"https://www.elastic.co/\"));\n         }\n     }\n \n@@ -187,7 +187,7 @@ public void testThatSSLContextWithKeystoreDoesNotTrustAllPublicCAs() throws Exce\n             // Execute a GET on a site known to have a valid certificate signed by a trusted public CA\n             // This will result in a SSLHandshakeException because the truststore is the testnodestore, which doesn't\n             // trust any public CAs\n-            client.execute(new HttpGet(\"https://www.elasticsearch.com/\"));\n+            client.execute(new HttpGet(\"https://www.elastic.co/\"));\n             fail(\"A SSLHandshakeException should have been thrown here\");\n         } catch (Exception e) {\n             assertThat(e, instanceOf(SSLHandshakeException.class));",
    "output": "Use elastic.co instead of elasticsearch.com The elasticsearch.com SSL cert expired causing these tests to fail. Just use elastic.co instead"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java b/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java\n--- a/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java\n@@ -203,7 +203,7 @@ public void testPruneUnreferencedFiles() throws IOException {\n         assertEquals(s.search(new TermQuery(new Term(\"id\", \"4\")), 1).totalHits, 0);\n \n         for (String file : dir.listAll()) {\n-            assertFalse(\"unexpected file: \" + file, file.equals(\"segments_3\") || file.startsWith(\"_2\") || file.startsWith(\"extra\"));\n+            assertFalse(\"unexpected file: \" + file, file.equals(\"segments_3\") || file.startsWith(\"_2\"));\n         }\n         open.close();\n         dir.close();",
    "output": "Remove unexpected extraFS file check - this was wrongly added before"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java b/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java\n--- a/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java\n+++ b/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java\n@@ -24,7 +24,6 @@\n import org.apache.lucene.search.QueryWrapperFilter;\n import org.apache.lucene.search.TermQuery;\n import org.elasticsearch.common.lucene.BytesRefs;\n-import org.elasticsearch.index.search.child.CustomQueryWrappingFilter;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -83,9 +82,7 @@ protected void assertLuceneQuery(TermQueryBuilder queryBuilder, Query query, Que\n         if (queryBuilder.queryName() != null) {\n             Filter namedQuery = context.copyNamedFilters().get(queryBuilder.queryName());\n             assertNotNull(namedQuery);\n-            if (namedQuery instanceof CustomQueryWrappingFilter) {\n-                assertThat(query, is(((CustomQueryWrappingFilter) namedQuery).getQuery()));\n-            } else if (namedQuery instanceof QueryWrapperFilter) {\n+            if (namedQuery instanceof QueryWrapperFilter) {\n                 assertThat(query, is(((QueryWrapperFilter) namedQuery).getQuery()));\n             } else {\n                 fail(\"Expected either a QueryWrapperFilter or a CustomQueryWrappingFilter to be registered under \" + queryBuilder.queryName() +",
    "output": "Remove deleted lucene CustomQueryWrappingFilter"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/translog/Translog.java b/src/main/java/org/elasticsearch/index/translog/Translog.java\n--- a/src/main/java/org/elasticsearch/index/translog/Translog.java\n+++ b/src/main/java/org/elasticsearch/index/translog/Translog.java\n@@ -152,10 +152,10 @@ private Translog(ShardId shardId, @IndexSettings Settings indexSettings, @Nullab\n \n         syncInterval = indexSettings.getAsTime(INDEX_TRANSLOG_SYNC_INTERVAL, TimeValue.timeValueSeconds(5));\n         if (syncInterval.millis() > 0 && threadPool != null) {\n-            syncOnEachOperation(false);\n+            this.syncOnEachOperation = false;\n             syncScheduler = threadPool.schedule(syncInterval, ThreadPool.Names.SAME, new Sync());\n         } else if (syncInterval.millis() == 0) {\n-            syncOnEachOperation(true);\n+            this.syncOnEachOperation = true;\n         }\n \n         if (indexSettingsService != null) {\n@@ -507,15 +507,6 @@ public boolean syncNeeded() {\n         }\n     }\n \n-    public void syncOnEachOperation(boolean syncOnEachOperation) {\n-        this.syncOnEachOperation = syncOnEachOperation;\n-        if (syncOnEachOperation) {\n-            type = TranslogFile.Type.SIMPLE;\n-        } else {\n-            type = TranslogFile.Type.BUFFERED;\n-        }\n-    }\n-\n     /** package private for testing */\n     String getFilename(long translogId) {\n         return TRANSLOG_FILE_PREFIX + translogId;",
    "output": "Use buffered tanslog type also when sync is set to 0"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/translog/Translog.java b/src/main/java/org/elasticsearch/index/translog/Translog.java\n--- a/src/main/java/org/elasticsearch/index/translog/Translog.java\n+++ b/src/main/java/org/elasticsearch/index/translog/Translog.java\n@@ -152,10 +152,10 @@ private Translog(ShardId shardId, @IndexSettings Settings indexSettings, @Nullab\n \n         syncInterval = indexSettings.getAsTime(INDEX_TRANSLOG_SYNC_INTERVAL, TimeValue.timeValueSeconds(5));\n         if (syncInterval.millis() > 0 && threadPool != null) {\n-            syncOnEachOperation(false);\n+            this.syncOnEachOperation = false;\n             syncScheduler = threadPool.schedule(syncInterval, ThreadPool.Names.SAME, new Sync());\n         } else if (syncInterval.millis() == 0) {\n-            syncOnEachOperation(true);\n+            this.syncOnEachOperation = true;\n         }\n \n         if (indexSettingsService != null) {\n@@ -507,15 +507,6 @@ public boolean syncNeeded() {\n         }\n     }\n \n-    public void syncOnEachOperation(boolean syncOnEachOperation) {\n-        this.syncOnEachOperation = syncOnEachOperation;\n-        if (syncOnEachOperation) {\n-            type = TranslogFile.Type.SIMPLE;\n-        } else {\n-            type = TranslogFile.Type.BUFFERED;\n-        }\n-    }\n-\n     /** package private for testing */\n     String getFilename(long translogId) {\n         return TRANSLOG_FILE_PREFIX + translogId;",
    "output": "Use buffered tanslog type also when sync is set to 0 When settings sync to 0, we benefit from using the buffered type, no need to change to simple, since we get a chance to fsync multiple operations (for that single operation) and not have to sync for the other ones before returning each one"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -278,9 +278,6 @@ protected void responseWithFailure(Throwable t) {\n         protected void doRun() throws Exception {\n             try (Releasable shardReference = getIndexShardOperationsCounter(request.internalShardId)) {\n                 shardOperationOnReplica(request.internalShardId, request);\n-            } catch (Throwable t) {\n-                failReplicaIfNeeded(request.internalShardId.index().name(), request.internalShardId.id(), t);\n-                throw t;\n             }\n             channel.sendResponse(TransportResponse.Empty.INSTANCE);\n         }",
    "output": "Remove double exceptin handling that causes false replica failures we already fail the shard in the `onFailure` method if the replica operation barfs. This additional check has been added lately that bypasses the clusterstate observer which causes replicas to fail if the mappings are not yet present"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n@@ -417,7 +417,7 @@ public void run() throws InterruptedException {\n                     try {\n                         final Store.MetadataSnapshot remainingFilesAfterCleanup = recoverWithSyncId? request.metadataSnapshot(): recoverySourceMetadata;\n                         transportService.submitRequest(request.targetNode(), RecoveryTarget.Actions.CLEAN_FILES,\n-                                new RecoveryCleanFilesRequest(request.recoveryId(), shard.shardId(), recoverySourceMetadata, translogView.totalOperations()),\n+                                new RecoveryCleanFilesRequest(request.recoveryId(), shard.shardId(), remainingFilesAfterCleanup, translogView.totalOperations()),\n                                 TransportRequestOptions.options().withTimeout(recoverySettings.internalActionTimeout()),\n                                 EmptyTransportResponseHandler.INSTANCE_SAME).txGet();\n                     } catch (RemoteTransportException remoteException) {",
    "output": "Fix after merge with master"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java b/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n--- a/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n+++ b/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java\n@@ -73,6 +73,7 @@ public abstract class BaseQueryTestCase<QB extends BaseQueryBuilder & Streamable\n     public static void init() throws IOException {\n         Settings settings = ImmutableSettings.settingsBuilder()\n                 .put(\"name\", BaseQueryTestCase.class.toString())\n+                .put(\"path.home\", createTempDir())\n                 .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)\n                 .build();\n \n\ndiff --git a/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java b/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java\n--- a/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java\n+++ b/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java\n@@ -19,6 +19,8 @@\n \n package org.elasticsearch.index.query;\n \n+import com.carrotsearch.randomizedtesting.annotations.Repeat;\n+\n import org.apache.lucene.search.MatchAllDocsQuery;\n import org.apache.lucene.search.Query;\n \n@@ -27,6 +29,7 @@\n import static org.hamcrest.Matchers.instanceOf;\n import static org.hamcrest.Matchers.is;\n \n+@Repeat(iterations=20)\n public class MatchAllQueryBuilderTest extends BaseQueryTestCase<MatchAllQueryBuilder> {\n \n     @Override",
    "output": "Add path.home setting to BaseQueryTestCase setup, this seems to be enforeced now"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -30,6 +30,7 @@\n import org.elasticsearch.common.io.PathUtils;\n import org.elasticsearch.common.jna.Kernel32Library;\n import org.elasticsearch.common.jna.Natives;\n+import org.elasticsearch.common.lease.Releasables;\n import org.elasticsearch.common.logging.ESLogger;\n import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.common.logging.log4j.LogConfigurator;\n@@ -177,9 +178,7 @@ private void start() {\n \n     private void stop() {\n         try {\n-            if (node != null) {\n-                node.close();\n-            }\n+            Releasables.close(node);\n         } finally {\n             keepAliveLatch.countDown();\n         }",
    "output": "Use Releasables.close here"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -177,7 +177,9 @@ private void start() {\n \n     private void stop() {\n         try {\n-            node.close();\n+            if (node != null) {\n+                node.close();\n+            }\n         } finally {\n             keepAliveLatch.countDown();\n         }",
    "output": "Add a null check for safety"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -216,15 +216,6 @@ public static void main(String[] args) {\n             // fail if using broken version\n             JVMCheck.check();\n \n-            bootstrap.setup(true, settings, environment);\n-\n-            stage = \"Startup\";\n-            bootstrap.start();\n-\n-            if (!foreground) {\n-                closeSysError();\n-            }\n-\n             keepAliveLatch = new CountDownLatch(1);\n             // keep this thread alive (non daemon thread) until we shutdown\n             Runtime.getRuntime().addShutdownHook(new Thread() {\n@@ -234,6 +225,15 @@ public void run() {\n                 }\n             });\n \n+            bootstrap.setup(true, settings, environment);\n+\n+            stage = \"Startup\";\n+            bootstrap.start();\n+\n+            if (!foreground) {\n+                closeSysError();\n+            }\n+\n             keepAliveThread = new Thread(new Runnable() {\n                 @Override\n                 public void run() {",
    "output": "Remove shutdownHooks permission"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -216,15 +216,6 @@ public static void main(String[] args) {\n             // fail if using broken version\n             JVMCheck.check();\n \n-            bootstrap.setup(true, settings, environment);\n-\n-            stage = \"Startup\";\n-            bootstrap.start();\n-\n-            if (!foreground) {\n-                closeSysError();\n-            }\n-\n             keepAliveLatch = new CountDownLatch(1);\n             // keep this thread alive (non daemon thread) until we shutdown\n             Runtime.getRuntime().addShutdownHook(new Thread() {\n@@ -234,6 +225,15 @@ public void run() {\n                 }\n             });\n \n+            bootstrap.setup(true, settings, environment);\n+\n+            stage = \"Startup\";\n+            bootstrap.start();\n+\n+            if (!foreground) {\n+                closeSysError();\n+            }\n+\n             keepAliveThread = new Thread(new Runnable() {\n                 @Override\n                 public void run() {",
    "output": "Remove shutdownHooks permission"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java b/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java\n--- a/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/LuceneTest.java\n@@ -144,8 +144,11 @@ public void testCleanIndex() throws IOException {\n         }\n         Lucene.cleanLuceneIndex(dir);\n         if (dir.listAll().length > 0) {\n-            assertEquals(dir.listAll().length, 1);\n-            assertEquals(dir.listAll()[0], \"write.lock\");\n+            for (String file : dir.listAll()) {\n+                if (file.startsWith(\"extra\") == false) {\n+                    assertEquals(file, \"write.lock\");\n+                }\n+            }\n         }\n         dir.close();\n     }\n@@ -200,7 +203,7 @@ public void testPruneUnreferencedFiles() throws IOException {\n         assertEquals(s.search(new TermQuery(new Term(\"id\", \"4\")), 1).totalHits, 0);\n \n         for (String file : dir.listAll()) {\n-            assertFalse(\"unexpected file: \" + file, file.equals(\"segments_3\") || file.startsWith(\"_2\"));\n+            assertFalse(\"unexpected file: \" + file, file.equals(\"segments_3\") || file.startsWith(\"_2\") || file.startsWith(\"extra\"));\n         }\n         open.close();\n         dir.close();",
    "output": "Make LuceneTest extraFS proof"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/actions/email/service/HtmlSanitizeTests.java b/src/test/java/org/elasticsearch/watcher/actions/email/service/HtmlSanitizeTests.java\n--- a/src/test/java/org/elasticsearch/watcher/actions/email/service/HtmlSanitizeTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/actions/email/service/HtmlSanitizeTests.java\n@@ -66,5 +66,12 @@ public void test_HtmlSanitizer_Script() {\n         assertThat(sanitizedHtml, equalTo(\"This was a dangerous script\"));\n     }\n \n+    @Test\n+    public void test_HtmlSanitizer_FullHtmlWithMetaString() {\n+        String needsSanitation = \"<html><head></head><body><h1>Hello {{ctx.metadata.name}}</h1> meta <a href='https://www.google.com/search?q={{ctx.metadata.name}}'>Testlink</a>meta</body></html>\";\n+        byte[] bytes = new byte[0];\n+        String sanitizedHtml = Profile.sanitizeHtml(ImmutableMap.of(\"foo\", (Attachment) new Attachment.Bytes(\"foo\", bytes, \"\")), needsSanitation);\n+        assertThat(sanitizedHtml, equalTo(\"<head></head><body><h1>Hello {{ctx.metadata.name}}</h1> meta <a href=\\\"https://www.google.com/search?q&#61;{{ctx.metadata.name}}\\\" rel=\\\"nofollow\\\">Testlink</a>meta</body>\"));\n+    }\n \n }",
    "output": "Add html found during testing to cause problems for the sanitizer. This change adds a html string that was found to cause problems for the sanitizer during testing"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java b/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java\n--- a/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java\n@@ -57,7 +57,7 @@ public void testTimeFields() throws Exception {\n \n         // the action should fail as no email server is available\n         assertWatchWithMinimumActionsCount(\"_id\", WatchRecord.State.EXECUTED, 1);\n-\n+        refresh();\n         GetMappingsResponse mappingsResponse = client().admin().indices().prepareGetMappings().get();\n         assertThat(mappingsResponse, notNullValue());\n         assertThat(mappingsResponse.getMappings().isEmpty(), is(false));",
    "output": "Add refresh to make sure watch record is in the index before checking the mappings"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java b/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java\n--- a/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/test/integration/HistoryTemplateTimeMappingsTests.java\n@@ -8,9 +8,7 @@\n import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;\n import org.elasticsearch.cluster.metadata.MappingMetaData;\n import org.elasticsearch.common.collect.ImmutableOpenMap;\n-import org.elasticsearch.common.hppc.cursors.ObjectCursor;\n import org.elasticsearch.common.hppc.cursors.ObjectObjectCursor;\n-import org.elasticsearch.common.xcontent.support.XContentMapValues;\n import org.elasticsearch.watcher.history.WatchRecord;\n import org.elasticsearch.watcher.test.AbstractWatcherIntegrationTests;\n import org.elasticsearch.watcher.transport.actions.put.PutWatchResponse;\n@@ -70,6 +68,7 @@ public void testTimeFields() throws Exception {\n             MappingMetaData metadata = metadatas.value.get(\"watch_record\");\n             assertThat(metadata, notNullValue());\n             Map<String, Object> source = metadata.getSourceAsMap();\n+            logger.info(\"metadata : [{}]\", metadata.source().toString());\n             assertThat(extractValue(\"properties.trigger_event.properties.schedule.properties.scheduled_time.type\", source), is((Object) \"date\"));\n             assertThat(extractValue(\"properties.trigger_event.properties.schedule.properties.triggered_time.type\", source), is((Object) \"date\"));\n             assertThat(extractValue(\"properties.watch_execution.properties.execution_time.type\", source), is((Object) \"date\"));",
    "output": "Add logging to see why test is failing. Log the metadata we get back to see why this test is failing on jenkins"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Security.java b/src/main/java/org/elasticsearch/bootstrap/Security.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Security.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Security.java\n@@ -71,12 +71,14 @@ static void configure(Environment environment) throws IOException {\n         }\n         PermissionCollection permissions = policy.getPermissions(Security.class.getProtectionDomain());\n         log.trace(\"generated permissions: {}\", permissions);\n-        \n+        log.info(\"java.io.tmpdir: {}\", System.getProperty(\"java.io.tmpdir\"));\n+\n         System.setSecurityManager(new SecurityManager());\n         try {\n             // don't hide securityexception here, it means java.io.tmpdir is not accessible!\n             Files.delete(newConfig);\n         } catch (SecurityException broken) {\n+            log.info(\"java.io.tmpdir: {}\", System.getProperty(\"java.io.tmpdir\"));\n             log.error(\"unable to properly access temporary files, permissions: {}\", permissions);\n             throw broken;\n         } catch (IOException ignore) {",
    "output": "Add 2 more x"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java b/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n--- a/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n@@ -1863,6 +1863,7 @@ public void testParentChildQueriesViaScrollApi() throws Exception {\n     }\n \n     @Test\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/pull/10897\")\n     public void testValidateThatHasChildAndHasParentFilterAreNeverCached() throws Exception {\n         assertAcked(prepareCreate(\"test\")\n                 .setSettings(builder().put(indexSettings())\n\ndiff --git a/src/test/java/org/elasticsearch/search/scriptfilter/ScriptFilterSearchTests.java b/src/test/java/org/elasticsearch/search/scriptfilter/ScriptFilterSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/scriptfilter/ScriptFilterSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/scriptfilter/ScriptFilterSearchTests.java\n@@ -118,6 +118,7 @@ public static int incrementScriptCounter() {\n     }\n \n     @Test\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/pull/10897\")\n     public void testCustomScriptCache() throws Exception {\n         assertAcked(prepareCreate(\"test\").setSettings(\n             ImmutableSettings.settingsBuilder()",
    "output": "Upgrade lucene snapshot to r1677039"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java b/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java\n--- a/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java\n+++ b/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java\n@@ -223,7 +223,12 @@ public void testChangingAByte() {\n         assertThat(Arrays.equals(encrypted, bytes), is(false));\n \n         int tamperedIndex = randomIntBetween(0, encrypted.length - 1);\n-        encrypted[tamperedIndex] = randomByte();\n+        final byte untamperedByte = encrypted[tamperedIndex];\n+        byte tamperedByte = randomByte();\n+        while (tamperedByte == untamperedByte) {\n+            tamperedByte = randomByte();\n+        }\n+        encrypted[tamperedIndex] = tamperedByte;\n         final byte[] decrypted = service.decrypt(encrypted);\n         assertThat(Arrays.equals(bytes, decrypted), is(false));\n     }",
    "output": "Fix bug where random byte may be the same as the byte being changed"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapperTests.java b/src/test/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapperTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapperTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapperTests.java\n@@ -65,7 +65,7 @@ public void testExtractFieldNames() {\n \n     public void testFieldType() throws Exception {\n         String mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type\")\n-            .startObject(\"_field_names\").field(\"store\", \"yes\").endObject()\n+            .startObject(\"_field_names\").endObject()\n             .endObject().endObject().string();\n \n         DocumentMapper docMapper = createIndex(\"test\").mapperService().documentMapperParser().parse(mapping);",
    "output": "Fix dumb test copy/paste mistake"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/support/init/proxy/ClientProxy.java b/src/main/java/org/elasticsearch/watcher/support/init/proxy/ClientProxy.java\n--- a/src/main/java/org/elasticsearch/watcher/support/init/proxy/ClientProxy.java\n+++ b/src/main/java/org/elasticsearch/watcher/support/init/proxy/ClientProxy.java\n@@ -63,17 +63,17 @@ public IndexResponse index(IndexRequest request) {\n \n     public BulkResponse bulk(BulkRequest request) {\n         request.listenerThreaded(true);\n-        return client.bulk(request).actionGet();\n+        return client.bulk(preProcess(request)).actionGet();\n     }\n \n     public void index(IndexRequest request, ActionListener<IndexResponse> listener) {\n         request.listenerThreaded(true);\n-        client.index(request, listener);\n+        client.index(preProcess(request), listener);\n     }\n \n     public void bulk(BulkRequest request, ActionListener<BulkResponse> listener) {\n         request.listenerThreaded(true);\n-        client.bulk(request, listener);\n+        client.bulk(preProcess(request), listener);\n     }\n \n     public ActionFuture<DeleteResponse> delete(DeleteRequest request) {",
    "output": "Fix fixed shield integration - updated Shield version to 1.2.1 (final) - Not all requests sent via the client proxy where set with the `__watcher_user` Fixes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/trigger/schedule/ScheduleModule.java b/src/main/java/org/elasticsearch/watcher/trigger/schedule/ScheduleModule.java\n--- a/src/main/java/org/elasticsearch/watcher/trigger/schedule/ScheduleModule.java\n+++ b/src/main/java/org/elasticsearch/watcher/trigger/schedule/ScheduleModule.java\n@@ -75,7 +75,7 @@ protected Class<? extends TriggerEngine> engineType() {\n         protected abstract Class<? extends TriggerEngine> engineType();\n \n         public static Engine resolve(Settings settings) {\n-            String engine = settings.getComponentSettings(ScheduleModule.class).get(\"engine\", \"scheduler\");\n+            String engine = settings.getComponentSettings(ScheduleModule.class).get(\"engine\", \"ticker\");\n             switch (engine.toLowerCase(Locale.ROOT)) {\n                 case \"ticker\"    : return TICKER;\n                 case \"scheduler\" : return SCHEDULER;",
    "output": "Make the `ticker` engine the default engine"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTestCase.java b/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTestCase.java\n--- a/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTestCase.java\n+++ b/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTestCase.java\n@@ -20,8 +20,6 @@\n package org.elasticsearch.test.rest;\n \n import com.carrotsearch.randomizedtesting.RandomizedTest;\n-import com.carrotsearch.randomizedtesting.annotations.Name;\n-import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n import com.carrotsearch.randomizedtesting.annotations.TestGroup;\n import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;\n import com.google.common.collect.Lists;\n@@ -221,9 +219,6 @@ private static void validateSpec(RestSpec restSpec) {\n                     if (!restApi.getMethods().contains(\"POST\")) {\n                         errorMessage.append(\"\\n- \").append(restApi.getName()).append(\" supports GET with a body but doesn't support POST\");\n                     }\n-                    if (!restApi.getParams().contains(\"source\")) {\n-                        errorMessage.append(\"\\n- \").append(restApi.getName()).append(\" supports GET with a body but doesn't support the source query string parameter\");\n-                    }\n                 }\n             }\n             if (errorMessage.length() > 0) {",
    "output": "Remove source parameter validation from REST tests runner source parameter is implicitly supported and doesn't need to be declared in rest spec. It is tested though, as every api that supports get with body can also get requests using POST with body or get with source query_string parameter"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java b/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n--- a/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n+++ b/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n@@ -28,7 +28,6 @@\n import com.google.api.services.compute.model.Instance;\n import com.google.api.services.compute.model.InstanceList;\n import org.elasticsearch.ElasticsearchException;\n-import org.elasticsearch.ElasticsearchIllegalArgumentException;\n import org.elasticsearch.common.base.Function;\n import org.elasticsearch.common.collect.Iterables;\n import org.elasticsearch.common.collect.Lists;\n@@ -141,7 +140,7 @@ public synchronized Compute client() {\n                     .build();\n         } catch (Exception e) {\n             logger.warn(\"unable to start GCE discovery service: {} : {}\", e.getClass().getName(), e.getMessage());\n-            throw new ElasticsearchIllegalArgumentException(\"unable to start GCE discovery service\", e);\n+            throw new IllegalArgumentException(\"unable to start GCE discovery service\", e);\n         }\n \n         return this.client;",
    "output": "Remove `ElasticsearchIllegalArgumentException` and `ElasticsearchIllegalStateException` in favor of the JDK one Related to https://github.com/elastic/elasticsearch/issues/10794"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java b/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n@@ -21,6 +21,7 @@\n \n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.ClusterService;\n+import org.elasticsearch.cluster.settings.ClusterDynamicSettings;\n import org.elasticsearch.cluster.settings.DynamicSettings;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.Settings;\n@@ -42,7 +43,7 @@ public class AzureDiscovery extends ZenDiscovery {\n     @Inject\n     public AzureDiscovery(Settings settings, ClusterName clusterName, ThreadPool threadPool, TransportService transportService,\n                           ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n-                          DiscoverySettings discoverySettings, ElectMasterService electMasterService, DynamicSettings dynamicSettings) {\n+                          DiscoverySettings discoverySettings, ElectMasterService electMasterService, @ClusterDynamicSettings DynamicSettings dynamicSettings) {\n         super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n                 pingService, electMasterService, discoverySettings, dynamicSettings);\n     }",
    "output": "Fix non working update dynamic settings Described in https://github.com/elastic/elasticsearch/issues/10614, it's not possible with cloud discovery plugin to update dynamic settings anymore. ```sh curl -XPUT localhost:9200/_cluster/settings -d '{ \"persistent\" : { \"discovery.zen.minimum_master_nodes\" : 3 }, \"transient\" : { \"discovery.zen.minimum_master_nodes\" : 3 } }' ``` gives ```json {\"acknowledged\":true,\"persistent\":{},\"transient\":{}} ``` . (cherry picked from commit 7749055) (cherry picked from commit 82bea69ef0f24c5f60a68bd823f638890b984691) Conflicts: src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/azure/AzureServiceDisableException.java b/src/main/java/org/elasticsearch/cloud/azure/AzureServiceDisableException.java\n--- a/src/main/java/org/elasticsearch/cloud/azure/AzureServiceDisableException.java\n+++ b/src/main/java/org/elasticsearch/cloud/azure/AzureServiceDisableException.java\n@@ -19,13 +19,7 @@\n \n package org.elasticsearch.cloud.azure;\n \n-import org.elasticsearch.ElasticsearchIllegalStateException;\n-\n-public class AzureServiceDisableException extends ElasticsearchIllegalStateException {\n-    public AzureServiceDisableException() {\n-        super(null);\n-    }\n-\n+public class AzureServiceDisableException extends IllegalStateException {\n     public AzureServiceDisableException(String msg) {\n         super(msg);\n     }\n\ndiff --git a/src/main/java/org/elasticsearch/cloud/azure/AzureServiceRemoteException.java b/src/main/java/org/elasticsearch/cloud/azure/AzureServiceRemoteException.java\n--- a/src/main/java/org/elasticsearch/cloud/azure/AzureServiceRemoteException.java\n+++ b/src/main/java/org/elasticsearch/cloud/azure/AzureServiceRemoteException.java\n@@ -19,13 +19,7 @@\n \n package org.elasticsearch.cloud.azure;\n \n-import org.elasticsearch.ElasticsearchIllegalStateException;\n-\n-public class AzureServiceRemoteException extends ElasticsearchIllegalStateException {\n-    public AzureServiceRemoteException() {\n-        super(null);\n-    }\n-\n+public class AzureServiceRemoteException extends IllegalStateException {\n     public AzureServiceRemoteException(String msg) {\n         super(msg);\n     }",
    "output": "Remove `ElasticsearchIllegalArgumentException` and `ElasticsearchIllegalStateException` in favor of the JDK one Related to https://github.com/elastic/elasticsearch/issues/10794"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java\n@@ -93,7 +93,7 @@ public static long ipToLong(String ip) {\n             }\n             return (Long.parseLong(octets[0]) << 24) + (Integer.parseInt(octets[1]) << 16) +\n                     (Integer.parseInt(octets[2]) << 8) + Integer.parseInt(octets[3]);\n-        } catch (Exception e)\n+        } catch (Exception e) {\n             if (e instanceof IllegalArgumentException) {\n                 throw (IllegalArgumentException) e;\n             }",
    "output": "Add missing {"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/DeleteByQueryFailedEngineException.java b/src/main/java/org/elasticsearch/index/engine/DeleteByQueryFailedEngineException.java\n--- a/src/main/java/org/elasticsearch/index/engine/DeleteByQueryFailedEngineException.java\n+++ b/src/main/java/org/elasticsearch/index/engine/DeleteByQueryFailedEngineException.java\n@@ -21,6 +21,8 @@\n \n import org.elasticsearch.index.shard.ShardId;\n \n+/** @deprecated Delete-by-query is removed in 2.0, but we keep this so translog can replay on upgrade. */\n+@Deprecated\n public class DeleteByQueryFailedEngineException extends EngineException {\n \n     public DeleteByQueryFailedEngineException(ShardId shardId, Engine.DeleteByQuery deleteByQuery, Throwable cause) {",
    "output": "Add another delete-by-query deprecation"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n@@ -22,6 +22,7 @@\n import org.elasticsearch.ElasticsearchIllegalArgumentException;\n import org.elasticsearch.action.search.SearchRequest;\n import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.search.SearchType;\n import org.elasticsearch.action.support.IndicesOptions;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.Strings;\n@@ -96,8 +97,18 @@ public static SearchRequest parseSearchRequest(RestRequest request) {\n             }\n         }\n \n+        // do not allow 'query_and_fetch' or 'dfs_query_and_fetch' search types\n+        // from the REST layer. these modes are an internal optimization and should\n+        // not be specified explicitly by the user.\n+        String searchType = request.param(\"search_type\");\n+        if (SearchType.fromString(searchType).equals(SearchType.QUERY_AND_FETCH) ||\n+                SearchType.fromString(searchType).equals(SearchType.DFS_QUERY_AND_FETCH)) {\n+            throw new ElasticsearchIllegalArgumentException(\"Unsupported search type [\" + searchType + \"]\");\n+        } else {\n+            searchRequest.searchType(searchType);\n+        }\n+\n         searchRequest.extraSource(parseSearchSource(request));\n-        searchRequest.searchType(request.param(\"search_type\"));\n         searchRequest.queryCache(request.paramAsBoolean(\"query_cache\", null));\n \n         String scroll = request.param(\"scroll\");",
    "output": "Remove (dfs_)query_and_fetch from the REST API Remove the ability to specify search type query_and_fetch and df_query_and_fetch from the REST API. - Adds REST tests - Updates REST API spec to remove query_and_fetch and df_query_and_fetch as options - Removes documentation for these options"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java b/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java\n--- a/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java\n+++ b/src/test/java/org/elasticsearch/plugins/PluginManagerTests.java\n@@ -422,7 +422,7 @@ private void singlePluginInstallAndRemove(String pluginShortName, String pluginC\n     @Test\n     @Network\n     public void testInstallPluginWithElasticsearchDownloadService() throws IOException {\n-        assumeTrue(\"download.elasticsearch.org is accessible\", isDownloadServiceWorking(\"download.elasticsearch.org\", 80, \"/elasticsearch/ci-test.txt\"));\n+        assumeTrue(\"download.elastic.co is accessible\", isDownloadServiceWorking(\"download.elastic.co\", 80, \"/elasticsearch/ci-test.txt\"));\n         singlePluginInstallAndRemove(\"elasticsearch/elasticsearch-transport-thrift/2.4.0\", null);\n     }\n ",
    "output": "Fix more download URLs"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java b/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java\n--- a/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java\n+++ b/src/test/java/org/elasticsearch/shield/crypto/InternalCryptoServiceTests.java\n@@ -216,7 +216,8 @@ public void testEncryptionAndDecryptionBytesWithoutKey() {\n     @Test\n     public void testChangingAByte() {\n         InternalCryptoService service = new InternalCryptoService(settings, env, watcherService).start();\n-        final byte[] bytes = randomByteArray();\n+        // We need at least one byte to test changing a byte, otherwise output is always the same\n+        final byte[] bytes = randomByteArray(1);\n         final byte[] encrypted = service.encrypt(bytes);\n         assertThat(encrypted, notNullValue());\n         assertThat(Arrays.equals(encrypted, bytes), is(false));\n@@ -262,7 +263,11 @@ public void onKeyRefresh() {\n     }\n \n     private static byte[] randomByteArray() {\n-        int count = randomIntBetween(0, 1000);\n+        return randomByteArray(0);\n+    }\n+\n+    private static byte[] randomByteArray(int min) {\n+        int count = randomIntBetween(min, 1000);\n         byte[] bytes = new byte[count];\n         for (int i = 0; i < count; i++) {\n             bytes[i] = randomByte();",
    "output": "Fix bug in creating a byte array for tampered encryption test The testChangingAByte method was requesting a random length byte array ranging from 0-1000. The issue is that a byte array with length of 0 cannot be changed and therefore this test is not valid in this case. It now requests a range of 1-1000"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/AnalysisFactoryTests.java b/src/test/java/org/elasticsearch/index/analysis/AnalysisFactoryTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/AnalysisFactoryTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/AnalysisFactoryTests.java\n@@ -164,6 +164,8 @@ public void testTokenizers() {\n         put(\"hyphenatedwords\",           Void.class);\n         // repeats anything marked as keyword\n         put(\"keywordrepeat\",             Void.class);\n+        // like limittokencount, but by offset\n+        put(\"limittokenoffset\",          Void.class);\n         // like limittokencount, but by position\n         put(\"limittokenposition\",        Void.class);\n         // ???",
    "output": "Upgrade to lucene-5.2-snapshot-1675927"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -92,8 +92,14 @@ public boolean handle(int code) {\n         }\n     }\n     \n+    /** \n+     * option for elasticsearch.yml etc to turn off our security manager completely,\n+     * for example if you want to have your own configuration or just disable.\n+     */\n+    static final String SECURITY_SETTING = \"security.manager.enabled\";\n+\n     private void setupSecurity(Settings settings, Environment environment) throws Exception {\n-        if (settings.getAsBoolean(\"security.manager.enabled\", true)) {\n+        if (settings.getAsBoolean(SECURITY_SETTING, true)) {\n             Security.configure(environment);\n         }\n     }",
    "output": "Add constant only used once to make it harder to read the code"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -247,8 +247,8 @@ public void messageReceived(final ReplicaOperationRequest request, final Transpo\n     }\n \n     protected class PrimaryOperationRequest {\n-        public ShardId shardId;\n-        public Request request;\n+        public final ShardId shardId;\n+        public final Request request;\n \n         public PrimaryOperationRequest(int shardId, String index, Request request) {\n             this.shardId = new ShardId(index, shardId);\n@@ -283,15 +283,9 @@ public IndicesOptions indicesOptions() {\n         @Override\n         public void readFrom(StreamInput in) throws IOException {\n             super.readFrom(in);\n-            int shard = -1;\n             shardId = ShardId.readShardId(in);\n             request = newReplicaRequestInstance();\n             request.readFrom(in);\n-            if (in.getVersion().before(Version.V_1_4_0_Beta1)) {\n-                assert shard >= 0;\n-                //older nodes will send the concrete index as part of the request\n-                shardId = new ShardId(request.index(), shard);\n-            }\n         }\n \n         @Override",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/IndexLookupTests.java b/src/test/java/org/elasticsearch/script/IndexLookupTests.java\n--- a/src/test/java/org/elasticsearch/script/IndexLookupTests.java\n+++ b/src/test/java/org/elasticsearch/script/IndexLookupTests.java\n@@ -581,8 +581,8 @@ private void checkExceptions(String script) {\n             }\n         } catch (SearchPhaseExecutionException ex) {\n             assertThat(\n-                    \"got \" + ex.getDetailedMessage(),\n-                    ex.getDetailedMessage().indexOf(\"Cannot iterate twice! If you want to iterate more that once, add _CACHE explicitly.\"),\n+                    \"got \" + ex.toString(),\n+                    ex.toString().indexOf(\"Cannot iterate twice! If you want to iterate more that once, add _CACHE explicitly.\"),\n                     Matchers.greaterThan(-1));\n         }\n     }",
    "output": "Use toString rather than getDetailedMessage()"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/reducers/movavg/MovAvgReducer.java b/src/main/java/org/elasticsearch/search/aggregations/reducers/movavg/MovAvgReducer.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/reducers/movavg/MovAvgReducer.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/reducers/movavg/MovAvgReducer.java\n@@ -115,10 +115,9 @@ public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext\n             Double thisBucketValue = resolveBucketValue(histo, bucket, bucketsPaths()[0], gapPolicy);\n             currentKey = bucket.getKey();\n \n-            if (thisBucketValue != null) {\n+            if (!(thisBucketValue == null || thisBucketValue.equals(Double.NaN))) {\n                 values.offer(thisBucketValue);\n \n-                // TODO handle \"edge policy\"\n                 double movavg = model.next(values);\n \n                 List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(), FUNCTION));",
    "output": "Fix bug where MovAvgReducer would allow NaN's to \"corrupt\" the moving avg"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Security.java b/src/main/java/org/elasticsearch/bootstrap/Security.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Security.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Security.java\n@@ -76,7 +76,6 @@ static Path processTemplate(Path template, Environment environment) throws IOExc\n             paths.add(environment.workFile());\n             paths.add(environment.workWithClusterFile());\n             for (Path path : environment.dataFiles()) {\n-                System.out.println(\"datapath=\" + path);\n                 paths.add(path);\n             }\n             for (Path path : environment.dataWithClusterFiles()) {",
    "output": "Remove stray sop"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java b/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java\n--- a/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java\n+++ b/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java\n@@ -8,7 +8,6 @@\n import org.elasticsearch.ElasticsearchIllegalStateException;\n import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.ActionListener;\n-import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.common.component.AbstractComponent;\n import org.elasticsearch.common.inject.Inject;\n@@ -46,21 +45,19 @@ public class ExecutionService extends AbstractComponent {\n     private final HistoryStore historyStore;\n     private final WatchExecutor executor;\n     private final WatchStore watchStore;\n-    private final ClusterService clusterService;\n     private final WatchLockService watchLockService;\n     private final Clock clock;\n \n     private final AtomicBoolean started = new AtomicBoolean(false);\n \n     @Inject\n     public ExecutionService(Settings settings, HistoryStore historyStore, WatchExecutor executor, WatchStore watchStore,\n-                            WatchLockService watchLockService, ClusterService clusterService, Clock clock) {\n+                            WatchLockService watchLockService, Clock clock) {\n         super(settings);\n         this.historyStore = historyStore;\n         this.executor = executor;\n         this.watchStore = watchStore;\n         this.watchLockService = watchLockService;\n-        this.clusterService = clusterService;\n         this.clock = clock;\n     }\n ",
    "output": "Remove unused field"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/InternalEngine.java\n@@ -1214,7 +1214,7 @@ protected void recoverFromTranslog(long translogId, TranslogRecoveryPerformer ha\n                 }\n             }\n         } catch (FileNotFoundException ex) {\n-            logger.info(\"no translog file found for ID: \" + translogId);\n+            logger.debug(\"no translog file found for ID: \" + translogId);\n         } catch (TruncatedTranslogException e) {\n             // file is empty or header has been half-written and should be ignored\n             logger.trace(\"ignoring truncation exception, the translog is either empty or half-written\", e);",
    "output": "Use debug logging if no translog file is found"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java b/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.node.DiscoveryNodeService;\n+import org.elasticsearch.cluster.settings.ClusterDynamicSettings;\n import org.elasticsearch.cluster.settings.DynamicSettings;\n import org.elasticsearch.common.collect.ImmutableList;\n import org.elasticsearch.common.inject.Inject;\n@@ -49,7 +50,7 @@ public GceDiscovery(Settings settings, ClusterName clusterName, ThreadPool threa\n                         ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n                         DiscoveryNodeService discoveryNodeService, GceComputeService gceComputeService,\n                         NetworkService networkService, DiscoverySettings discoverySettings,\n-                        ElectMasterService electMasterService, DynamicSettings dynamicSettings,\n+                        ElectMasterService electMasterService, @ClusterDynamicSettings DynamicSettings dynamicSettings,\n                         Version version) {\n         super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n                 discoveryNodeService, pingService, electMasterService, discoverySettings, dynamicSettings);",
    "output": "Fix non working update dynamic settings Described in https://github.com/elastic/elasticsearch/issues/10614, it's not possible with cloud discovery plugin to update dynamic settings anymore. ```sh curl -XPUT localhost:9200/_cluster/settings -d '{ \"persistent\" : { \"discovery.zen.minimum_master_nodes\" : 3 }, \"transient\" : { \"discovery.zen.minimum_master_nodes\" : 3 } }' ``` gives ```json {\"acknowledged\":true,\"persistent\":{},\"transient\":{}} ``` . (cherry picked from commit 9df33a3) (cherry picked from commit a40016e)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n--- a/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n+++ b/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n@@ -300,12 +300,26 @@ private static FileStore getFileStore(Path path) throws IOException {\n \n         try {\n             String mount = getMountPoint(store);\n-            // find the \"matching\" FileStore from system list, it's the one we want.\n+            FileStore sameMountPoint = null;\n             for (FileStore fs : path.getFileSystem().getFileStores()) {\n                 if (mount.equals(getMountPoint(fs))) {\n-                    return fs;\n+                    if (sameMountPoint == null) {\n+                        sameMountPoint = fs;\n+                    } else {\n+                        // more than one filesystem has the same mount point; something is wrong!\n+                        // fall back to crappy one we got from Files.getFileStore\n+                        return store;\n+                    }\n                 }\n             }\n+\n+            if (sameMountPoint != null) {\n+                // ok, we found only one, use it:\n+                return sameMountPoint;\n+            } else {\n+                // fall back to crappy one we got from Files.getFileStore\n+                return store;    \n+            }\n         } catch (Exception e) {\n             // ignore\n         }\n@@ -319,7 +333,12 @@ private static FileStore getFileStore(Path path) throws IOException {\n     // these are hacks that are not guaranteed\n     private static String getMountPoint(FileStore store) {\n         String desc = store.toString();\n-        return desc.substring(0, desc.lastIndexOf('(') - 1);\n+        int index = desc.lastIndexOf(\" (\");\n+        if (index != -1) {\n+            return desc.substring(0, index);\n+        } else {\n+            return desc;\n+        }\n     }\n \n     /**",
    "output": "Make NodeEnvironment.getFileStore a bit more defensive This improves the NodeEnvironment code that walks through all mount points looking for the one matching the file store for a specified path, to make it a bit more defensive. We currently rely on this to log the correct file system type of the path.data paths"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/StoreTest.java b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n--- a/src/test/java/org/elasticsearch/index/store/StoreTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n@@ -45,6 +45,7 @@\n \n import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.nio.file.Files;\n import java.nio.file.NoSuchFileException;\n import java.util.*;\n import java.util.concurrent.atomic.AtomicBoolean;\n@@ -697,7 +698,7 @@ public long throttleTimeInNanos() {\n \n     public static void assertConsistent(Store store, Store.MetadataSnapshot metadata) throws IOException {\n         for (String file : store.directory().listAll()) {\n-            if (!IndexWriter.WRITE_LOCK_NAME.equals(file) && !IndexFileNames.OLD_SEGMENTS_GEN.equals(file) && !Store.isChecksum(file)) {\n+            if (!IndexWriter.WRITE_LOCK_NAME.equals(file) && !IndexFileNames.OLD_SEGMENTS_GEN.equals(file) && !Store.isChecksum(file) && file.startsWith(\"extra\") == false) {\n                 assertTrue(file + \" is not in the map: \" + metadata.asMap().size() + \" vs. \" + store.directory().listAll().length, metadata.asMap().containsKey(file));\n             } else {\n                 assertFalse(file + \" is not in the map: \" + metadata.asMap().size() + \" vs. \" + store.directory().listAll().length, metadata.asMap().containsKey(file));",
    "output": "Make sure extraFS files are not in the metadata"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java b/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java\n--- a/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/watch/WatchLockServiceTests.java\n@@ -11,6 +11,7 @@\n \n import java.util.ArrayList;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.atomic.AtomicInteger;\n \n import static org.hamcrest.Matchers.*;\n@@ -66,13 +67,15 @@ public void testLocking_fair() throws Exception {\n         class FairRunner implements Runnable {\n \n             final int expectedValue;\n+            final CountDownLatch startLatch = new CountDownLatch(1);\n \n             FairRunner(int expectedValue) {\n                 this.expectedValue = expectedValue;\n             }\n \n             @Override\n             public void run() {\n+                startLatch.countDown();\n                 WatchLockService.Lock lock = lockService.acquire(\"_name\");\n                 try {\n                     int actualValue = value.getAndIncrement();\n@@ -85,13 +88,17 @@ public void run() {\n             }\n         }\n \n+        List<FairRunner> runners = new ArrayList<>();\n+\n         for(int i = 0; i < 100; ++i) {\n             FairRunner f = new FairRunner(i);\n+            runners.add(f);\n             threads.add(new Thread(f));\n         }\n \n-        for(Thread t : threads) {\n-            t.start();\n+        for(int i = 0; i < threads.size(); ++i) {\n+            threads.get(i).start();\n+            runners.get(i).startLatch.await();\n             Thread.sleep(10);\n         }\n ",
    "output": "Add CountDownLatches to ensure order of operation. This change adds countdownlatches to the `FairKeyedLock` tests on `WatchLockService`"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java b/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java\n--- a/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java\n@@ -68,7 +68,7 @@ String getErrorMessage() {\n             if (workAround != null) {\n                 sb.append(System.lineSeparator());\n                 sb.append(\"If you absolutely cannot upgrade, please add \").append(workAround);\n-                sb.append(\" to the JVM_OPTS environment variable.\");\n+                sb.append(\" to the JAVA_OPTS environment variable.\");\n                 sb.append(System.lineSeparator());\n                 sb.append(\"Upgrading is preferred, this workaround will result in degraded performance.\");\n             }",
    "output": "Fix typo in JVM checker user help. When checking the JVM we provide the user with help on which environment variable to use to disable the check in case the check fails. Fixing the variable we point the user to - should be JAVA_OPTS"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/test/VersionUtilsTests.java b/src/test/java/org/elasticsearch/test/test/VersionUtilsTests.java\n--- a/src/test/java/org/elasticsearch/test/test/VersionUtilsTests.java\n+++ b/src/test/java/org/elasticsearch/test/test/VersionUtilsTests.java\n@@ -18,14 +18,12 @@\n  */\n package org.elasticsearch.test.test;\n \n-import com.carrotsearch.randomizedtesting.annotations.Seed;\n import org.elasticsearch.Version;\n import org.elasticsearch.test.ElasticsearchTestCase;\n import org.elasticsearch.test.VersionUtils;\n \n import java.util.List;\n \n-@Seed(\"E619863BE07FF5CB\")\n public class VersionUtilsTests extends ElasticsearchTestCase {\n \n     public void testAllVersionsSorted() {",
    "output": "Remove fixed seed for version util tests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ESTestCase.java b/src/test/java/org/elasticsearch/test/ESTestCase.java\n--- a/src/test/java/org/elasticsearch/test/ESTestCase.java\n+++ b/src/test/java/org/elasticsearch/test/ESTestCase.java\n@@ -76,8 +76,7 @@\n @LuceneTestCase.SuppressSysoutChecks(bugUrl = \"we log a lot on purpose\")\n @Ignore\n @SuppressCodecs({\"SimpleText\", \"Memory\", \"CheapBastard\", \"Direct\"}) // slow ones\n-// LUCENE-6432\n-//@LuceneTestCase.SuppressReproduceLine\n+@LuceneTestCase.SuppressReproduceLine\n public abstract class ESTestCase extends LuceneTestCase {\n     static {\n         SecurityHack.ensureInitialized();",
    "output": "Upgrade to lucene 5.2 r1674278"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java b/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n--- a/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n+++ b/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n@@ -33,6 +33,7 @@\n import java.nio.file.Files;\n import java.nio.file.Path;\n import java.util.HashSet;\n+import java.util.Locale;\n import java.util.Set;\n \n import static org.elasticsearch.test.ElasticsearchIntegrationTest.*;\n@@ -81,10 +82,10 @@ protected int numberOfReplicas() {\n \n     @Test\n     public void testThatLoadingTemplateFromFileWorks() throws Exception {\n-        final int iters = scaledRandomIntBetween(5, 20);\n+        final int iters = scaledRandomIntBetween(1, 5);\n         Set<String> indices = new HashSet<>();\n         for (int i = 0; i < iters; i++) {\n-            String indexName = \"foo\" + randomRealisticUnicodeOfLengthBetween(0, 5);\n+            String indexName = \"foo\" + randomAsciiOfLengthBetween(0, 5).toLowerCase(Locale.ROOT);\n             if (indices.contains(indexName)) {\n                 continue;\n             }",
    "output": "Use lowercase index names in test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java b/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java\n--- a/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java\n+++ b/src/main/java/org/elasticsearch/watcher/execution/ExecutionService.java\n@@ -310,7 +310,7 @@ public void triggered(String name, TriggerEvent event) {\n                 if (started()) {\n                     logger.error(\"failed to execute watch from SchedulerListener [{}]\", e, name);\n                 } else {\n-                    logger.error(\"failed to execute watch from SchedulerListener [{}] after shutdown\", e, name);\n+                    logger.debug(\"failed to execute watch from SchedulerListener [{}] after shutdown\", e, name);\n                 }\n             }\n         }",
    "output": "Upgrade after review. Change log level of message at shutdown"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java b/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java\n--- a/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java\n+++ b/src/main/java/org/elasticsearch/watcher/rest/action/RestExecuteWatchAction.java\n@@ -58,6 +58,11 @@ public RestResponse buildResponse(ExecuteWatchResponse response, XContentBuilder\n     private static ExecuteWatchRequest parseRequest(RestRequest request, WatcherClient client) throws IOException {\n         ExecuteWatchRequestBuilder executeWatchRequestBuilder = client.prepareExecuteWatch(request.param(\"id\"));\n \n+        if (request.content() == null || request.content().length() == 0) {\n+            //If there isn't any content just return the default request\n+            return executeWatchRequestBuilder.request();\n+        }\n+\n         XContentParser parser = XContentHelper.createParser(request.content());\n         parser.nextToken();\n ",
    "output": "Fix REST execute API call with empty body. Execute with an empty body will now just use the defaults. Add REST test for empty body. Fixes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java b/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n--- a/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n+++ b/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n@@ -68,7 +68,7 @@ public void testFailure(Failure failure) throws Exception {\n         final Description d = failure.getDescription();\n         final StringBuilder b = new StringBuilder();\n         b.append(\"FAILURE  : \").append(d.getDisplayName()).append(\"\\n\");\n-        b.append(\"REPRODUCE WITH  : mvn clean test\");\n+        b.append(\"REPRODUCE WITH  : mvn test -Pdev\");\n         MavenMessageBuilder mavenMessageBuilder = new MavenMessageBuilder(b);\n         mavenMessageBuilder.appendAllOpts(failure.getDescription());\n ",
    "output": "Improve REPRODUCE WITH"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/watch/WatchService.java b/src/main/java/org/elasticsearch/watcher/watch/WatchService.java\n--- a/src/main/java/org/elasticsearch/watcher/watch/WatchService.java\n+++ b/src/main/java/org/elasticsearch/watcher/watch/WatchService.java\n@@ -77,9 +77,9 @@ public void onFailure(Throwable e) {\n     public void stop() {\n         if (state.compareAndSet(State.STARTED, State.STOPPING)) {\n             logger.info(\"stopping watch service...\");\n-            watchLockService.stop();\n-            executionService.stop();\n             triggerService.stop();\n+            executionService.stop();\n+            watchLockService.stop();\n             watchStore.stop();\n             state.set(State.STOPPED);\n             logger.info(\"watch service has stopped\");",
    "output": "Change the order in which the interval services are stopped when watcher stops"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/actions/email/service/EmailTemplate.java b/src/main/java/org/elasticsearch/watcher/actions/email/service/EmailTemplate.java\n--- a/src/main/java/org/elasticsearch/watcher/actions/email/service/EmailTemplate.java\n+++ b/src/main/java/org/elasticsearch/watcher/actions/email/service/EmailTemplate.java\n@@ -94,15 +94,15 @@ public Email.Builder render(TemplateEngine engine, Map<String, Object> model) th\n             builder.priority(Email.Priority.resolve(engine.render(priority, model)));\n         }\n         if (to != null) {\n-            Email.AddressList addresses = templatesToAddressList(engine, replyTo, model);\n+            Email.AddressList addresses = templatesToAddressList(engine, to, model);\n             builder.to(addresses);\n         }\n         if (cc != null) {\n-            Email.AddressList addresses = templatesToAddressList(engine, replyTo, model);\n+            Email.AddressList addresses = templatesToAddressList(engine, cc, model);\n             builder.cc(addresses);\n         }\n         if (bcc != null) {\n-            Email.AddressList addresses = templatesToAddressList(engine, replyTo, model);\n+            Email.AddressList addresses = templatesToAddressList(engine, bcc, model);\n             builder.bcc(addresses);\n         }\n         if (subject != null) {",
    "output": "Fix NPE in EmailTemplate EmailTemplate was passing replyTo to all calls to templatesToAddressList"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/reducers/Reducer.java b/src/main/java/org/elasticsearch/search/aggregations/reducers/Reducer.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/reducers/Reducer.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/reducers/Reducer.java\n@@ -45,7 +45,7 @@ public abstract class Reducer implements Streamable {\n      */\n     public static interface Parser {\n \n-        public static final ParseField BUCKETS_PATH = new ParseField(\"bucketsPath\");\n+        public static final ParseField BUCKETS_PATH = new ParseField(\"buckets_path\");\n \n         /**\n          * @return The reducer type this parser is associated with.",
    "output": "Change `bucketsPaths` to `buckets_paths`"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/watcher/execution/ManualExecutionTests.java b/src/test/java/org/elasticsearch/watcher/execution/ManualExecutionTests.java\n--- a/src/test/java/org/elasticsearch/watcher/execution/ManualExecutionTests.java\n+++ b/src/test/java/org/elasticsearch/watcher/execution/ManualExecutionTests.java\n@@ -40,6 +40,7 @@ protected boolean enableShield() {\n     @Test\n     @Repeat(iterations = 10)\n     public void testExecuteWatch() throws Exception {\n+        ensureWatcherStarted();\n         boolean ignoreCondition = randomBoolean();\n         boolean persistRecord = randomBoolean();\n         boolean conditionAlwaysTrue = randomBoolean();",
    "output": "Make sure watcher is started before running the test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/watch/Watch.java b/src/main/java/org/elasticsearch/watcher/watch/Watch.java\n--- a/src/main/java/org/elasticsearch/watcher/watch/Watch.java\n+++ b/src/main/java/org/elasticsearch/watcher/watch/Watch.java\n@@ -529,7 +529,7 @@ public static Status parse(XContentParser parser) throws IOException {\n                                 } else if (REASON_FIELD.match(currentFieldName)) {\n                                     reason = parser.text();\n                                 } else {\n-                                    throw new WatcherException(\"unknown filed [\" + currentFieldName + \"] in watch status throttle entry\");\n+                                    throw new WatcherException(\"unknown field [\" + currentFieldName + \"] in watch status throttle entry\");\n                                 }\n                             }\n                         }\n@@ -550,7 +550,7 @@ public static Status parse(XContentParser parser) throws IOException {\n                                 } else if (STATE_FIELD.match(currentFieldName)) {\n                                     state = AckStatus.State.valueOf(parser.text().toUpperCase(Locale.ROOT));\n                                 } else {\n-                                    throw new WatcherException(\"unknown filed [\" + currentFieldName + \"] in watch status throttle entry\");\n+                                    throw new WatcherException(\"unknown field [\" + currentFieldName + \"] in watch status throttle entry\");\n                                 }\n                             }\n                         }",
    "output": "Fix minor spelling errors in exception messages"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/watch/Watch.java b/src/main/java/org/elasticsearch/watcher/watch/Watch.java\n--- a/src/main/java/org/elasticsearch/watcher/watch/Watch.java\n+++ b/src/main/java/org/elasticsearch/watcher/watch/Watch.java\n@@ -529,7 +529,7 @@ public static Status parse(XContentParser parser) throws IOException {\n                                 } else if (REASON_FIELD.match(currentFieldName)) {\n                                     reason = parser.text();\n                                 } else {\n-                                    throw new WatcherException(\"unknown filed [\" + currentFieldName + \"] in watch status throttle entry\");\n+                                    throw new WatcherException(\"unknown field [\" + currentFieldName + \"] in watch status throttle entry\");\n                                 }\n                             }\n                         }\n@@ -550,7 +550,7 @@ public static Status parse(XContentParser parser) throws IOException {\n                                 } else if (STATE_FIELD.match(currentFieldName)) {\n                                     state = AckStatus.State.valueOf(parser.text().toUpperCase(Locale.ROOT));\n                                 } else {\n-                                    throw new WatcherException(\"unknown filed [\" + currentFieldName + \"] in watch status throttle entry\");\n+                                    throw new WatcherException(\"unknown field [\" + currentFieldName + \"] in watch status throttle entry\");\n                                 }\n                             }\n                         }",
    "output": "Fix minor spelling errors in exception messages"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java b/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java\n--- a/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/JVMCheck.java\n@@ -68,7 +68,7 @@ String getErrorMessage() {\n             if (workAround != null) {\n                 sb.append(System.lineSeparator());\n                 sb.append(\"If you absolutely cannot upgrade, please add \").append(workAround);\n-                sb.append(\" to the JVM_OPTS environment variable.\");\n+                sb.append(\" to the JAVA_OPTS environment variable.\");\n                 sb.append(System.lineSeparator());\n                 sb.append(\"Upgrading is preferred, this workaround will result in degraded performance.\");\n             }",
    "output": "Fix typo in JVM checker user help. When checking the JVM currently running ES we provide the user with help on which environment variable to use to disable the check in case the check fails. The variable we point to however is the wrong one"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java b/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java\n@@ -69,10 +69,4 @@ public static void forceDefaultCodec() {\n     public static int scaledRandomIntBetween(int min, int max) {\n         return RandomizedTest.scaledRandomIntBetween(min, max);\n     }\n-\n-    @AfterClass\n-    public static void clearDefaultQueryCache() {\n-        // TODO: remove me when https://issues.apache.org/jira/browse/LUCENE-6406 is fixed\n-        IndexSearcher.setDefaultQueryCache(null);\n-    }\n }",
    "output": "Upgrade to lucene-5.1.0-snapshot-1671894"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java b/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchLuceneTestCase.java\n@@ -69,10 +69,4 @@ public static void forceDefaultCodec() {\n     public static int scaledRandomIntBetween(int min, int max) {\n         return RandomizedTest.scaledRandomIntBetween(min, max);\n     }\n-\n-    @AfterClass\n-    public static void clearDefaultQueryCache() {\n-        // TODO: remove me when https://issues.apache.org/jira/browse/LUCENE-6406 is fixed\n-        IndexSearcher.setDefaultQueryCache(null);\n-    }\n }",
    "output": "Upgrade to lucene-5.1.0-snapshot-1671894. This includes a fix for LUCENE-6406"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/watcher/input/search/SearchInput.java b/src/main/java/org/elasticsearch/watcher/input/search/SearchInput.java\n--- a/src/main/java/org/elasticsearch/watcher/input/search/SearchInput.java\n+++ b/src/main/java/org/elasticsearch/watcher/input/search/SearchInput.java\n@@ -47,7 +47,7 @@ public class SearchInput extends Input<SearchInput.Result> {\n \n     public static final String TYPE = \"search\";\n \n-    public static final SearchType DEFAULT_SEARCH_TYPE = SearchType.COUNT;\n+    public static final SearchType DEFAULT_SEARCH_TYPE = SearchType.QUERY_THEN_FETCH;\n \n     private final Set<String> extractKeys;\n     private final SearchRequest searchRequest;\n\ndiff --git a/src/main/java/org/elasticsearch/watcher/transform/SearchTransform.java b/src/main/java/org/elasticsearch/watcher/transform/SearchTransform.java\n--- a/src/main/java/org/elasticsearch/watcher/transform/SearchTransform.java\n+++ b/src/main/java/org/elasticsearch/watcher/transform/SearchTransform.java\n@@ -40,7 +40,7 @@ public class SearchTransform extends Transform<SearchTransform.Result> {\n \n     public static final String TYPE = \"search\";\n \n-    public static final SearchType DEFAULT_SEARCH_TYPE = SearchType.DFS_QUERY_AND_FETCH;\n+    public static final SearchType DEFAULT_SEARCH_TYPE = SearchType.QUERY_THEN_FETCH;\n \n     protected final ESLogger logger;\n     protected final ScriptServiceProxy scriptService;",
    "output": "Change SearchTypes to be `QUERY_THEN_FETCH` This closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n--- a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n+++ b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n@@ -21,7 +21,9 @@\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n+\n import org.apache.log4j.PropertyConfigurator;\n+import org.apache.log4j.rolling.SizeBasedTriggeringPolicy;\n import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.common.collect.MapBuilder;\n import org.elasticsearch.common.settings.ImmutableSettings;\n@@ -69,6 +71,7 @@ public class LogConfigurator {\n             .put(\"telnet\", \"org.apache.log4j.net.TelnetAppender\")\n                     // policies\n             .put(\"timeBased\", \"org.apache.log4j.rolling.TimeBasedRollingPolicy\")\n+            .put(\"sizeBased\", \"org.apache.log4j.rolling.SizeBasedTriggeringPolicy\")\n                     // layouts\n             .put(\"simple\", \"org.apache.log4j.SimpleLayout\")\n             .put(\"html\", \"org.apache.log4j.HTMLLayout\")",
    "output": "Add ability to specify a SizeBasedTriggeringPolicy for log configuration"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n--- a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n+++ b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n@@ -21,7 +21,9 @@\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n+\n import org.apache.log4j.PropertyConfigurator;\n+import org.apache.log4j.rolling.SizeBasedTriggeringPolicy;\n import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.common.collect.MapBuilder;\n import org.elasticsearch.common.settings.ImmutableSettings;\n@@ -69,6 +71,7 @@ public class LogConfigurator {\n             .put(\"telnet\", \"org.apache.log4j.net.TelnetAppender\")\n                     // policies\n             .put(\"timeBased\", \"org.apache.log4j.rolling.TimeBasedRollingPolicy\")\n+            .put(\"sizeBased\", \"org.apache.log4j.rolling.SizeBasedTriggeringPolicy\")\n                     // layouts\n             .put(\"simple\", \"org.apache.log4j.SimpleLayout\")\n             .put(\"html\", \"org.apache.log4j.HTMLLayout\")",
    "output": "Add ability to specify a SizeBasedTriggeringPolicy for log configuration"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/metadata/MetaDataTests.java b/src/test/java/org/elasticsearch/cluster/metadata/MetaDataTests.java\n--- a/src/test/java/org/elasticsearch/cluster/metadata/MetaDataTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/metadata/MetaDataTests.java\n@@ -21,7 +21,6 @@\n \n import com.google.common.collect.Sets;\n \n-import org.apache.tools.ant.taskdefs.condition.IsTrue;\n import org.elasticsearch.ElasticsearchIllegalArgumentException;\n import org.elasticsearch.Version;\n import org.elasticsearch.action.support.IndicesOptions;",
    "output": "Remove unused import"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/GatewayService.java b/src/main/java/org/elasticsearch/gateway/GatewayService.java\n--- a/src/main/java/org/elasticsearch/gateway/GatewayService.java\n+++ b/src/main/java/org/elasticsearch/gateway/GatewayService.java\n@@ -151,7 +151,7 @@ protected void checkStateMeetsSettingsAndMaybeRecover(ClusterState state, boolea\n             if (expectedNodes == -1 && expectedMasterNodes == -1 && expectedDataNodes == -1) {\n                 // no expected is set, honor the setting if they are there\n                 enforceRecoverAfterTime = true;\n-                reason = \"recovery_after_time was set to [\" + recoverAfterTime + \"]\";\n+                reason = \"recover_after_time was set to [\" + recoverAfterTime + \"]\";\n             } else {\n                 // one of the expected is set, see if all of them meet the need, and ignore the timeout in this case\n                 enforceRecoverAfterTime = false;\n@@ -181,7 +181,7 @@ private void performStateRecovery(boolean asyncRecovery, boolean enforceRecoverA\n                     @Override\n                     public void run() {\n                         if (recovered.compareAndSet(false, true)) {\n-                            logger.info(\"recovery_after_time [{}] elapsed. performing state recovery...\", recoverAfterTime);\n+                            logger.info(\"recover_after_time [{}] elapsed. performing state recovery...\", recoverAfterTime);\n                             gateway.performStateRecovery(recoveryListener);\n                         }\n                     }",
    "output": "Fix typos for gateway.recover_after_time"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/GatewayService.java b/src/main/java/org/elasticsearch/gateway/GatewayService.java\n--- a/src/main/java/org/elasticsearch/gateway/GatewayService.java\n+++ b/src/main/java/org/elasticsearch/gateway/GatewayService.java\n@@ -151,7 +151,7 @@ protected void checkStateMeetsSettingsAndMaybeRecover(ClusterState state, boolea\n             if (expectedNodes == -1 && expectedMasterNodes == -1 && expectedDataNodes == -1) {\n                 // no expected is set, honor the setting if they are there\n                 enforceRecoverAfterTime = true;\n-                reason = \"recovery_after_time was set to [\" + recoverAfterTime + \"]\";\n+                reason = \"recover_after_time was set to [\" + recoverAfterTime + \"]\";\n             } else {\n                 // one of the expected is set, see if all of them meet the need, and ignore the timeout in this case\n                 enforceRecoverAfterTime = false;\n@@ -181,7 +181,7 @@ private void performStateRecovery(boolean asyncRecovery, boolean enforceRecoverA\n                     @Override\n                     public void run() {\n                         if (recovered.compareAndSet(false, true)) {\n-                            logger.info(\"recovery_after_time [{}] elapsed. performing state recovery...\", recoverAfterTime);\n+                            logger.info(\"recover_after_time [{}] elapsed. performing state recovery...\", recoverAfterTime);\n                             gateway.performStateRecovery(recoveryListener);\n                         }\n                     }",
    "output": "Fix typos for gateway.recover_after_time There were a few references to the setting `gateway.recovery_after_time`, which should instead be `gateway.recover_after_time`"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/cache/query/IndicesQueryCacheTests.java b/src/test/java/org/elasticsearch/indices/cache/query/IndicesQueryCacheTests.java\n--- a/src/test/java/org/elasticsearch/indices/cache/query/IndicesQueryCacheTests.java\n+++ b/src/test/java/org/elasticsearch/indices/cache/query/IndicesQueryCacheTests.java\n@@ -50,7 +50,7 @@ public void testCacheAggs() throws Exception {\n         // see #9500\n         final SearchResponse r1 = client().prepareSearch(\"index\").setSize(0).setSearchType(SearchType.QUERY_THEN_FETCH)\n             .addAggregation(dateHistogram(\"histo\").field(\"f\").timeZone(\"+01:00\").minDocCount(0).interval(DateHistogramInterval.MONTH)).get();\n-        assertSearchResponse(r1);System.out.println(r1);\n+        assertSearchResponse(r1);\n \n         // The cached is actually used\n         assertThat(client().admin().indices().prepareStats(\"index\").setQueryCache(true).get().getTotal().getQueryCache().getMemorySizeInBytes(), greaterThan(0l));",
    "output": "Remove leftover println"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java b/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java\n--- a/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java\n+++ b/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java\n@@ -62,7 +62,7 @@ public static String buildScrollId(SearchType searchType, AtomicArray<? extends\n         } else if (searchType == SearchType.SCAN) {\n             return buildScrollId(ParsedScrollId.SCAN, searchPhaseResults, attributes);\n         } else {\n-            throw new ElasticsearchIllegalStateException();\n+            throw new ElasticsearchIllegalStateException(\"search_type [\" + searchType + \"] not supported\");\n         }\n     }\n \n\ndiff --git a/src/test/java/org/elasticsearch/search/scroll/SearchScrollTests.java b/src/test/java/org/elasticsearch/search/scroll/SearchScrollTests.java\n--- a/src/test/java/org/elasticsearch/search/scroll/SearchScrollTests.java\n+++ b/src/test/java/org/elasticsearch/search/scroll/SearchScrollTests.java\n@@ -427,7 +427,7 @@ public void testDeepPaginationWithOneDocIndexAndDoNotBlowUp() throws Exception {\n                     .setQuery(QueryBuilders.matchAllQuery())\n                     .setSize(Integer.MAX_VALUE);\n \n-            if (searchType == SearchType.SCAN || randomBoolean()) {\n+            if (searchType == SearchType.SCAN || searchType != SearchType.COUNT && randomBoolean()) {\n                 builder.setScroll(\"1m\");\n             }\n ",
    "output": "Fix SearchScrollTests, scroll doesn't support searchType count"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/util/BigLongArray.java b/src/main/java/org/elasticsearch/common/util/BigLongArray.java\n--- a/src/main/java/org/elasticsearch/common/util/BigLongArray.java\n+++ b/src/main/java/org/elasticsearch/common/util/BigLongArray.java\n@@ -94,6 +94,9 @@ public void resize(long newSize) {\n     @Override\n     public void fill(long fromIndex, long toIndex, long value) {\n         Preconditions.checkArgument(fromIndex <= toIndex);\n+        if (fromIndex == toIndex) {\n+            return; // empty range\n+        }\n         final int fromPage = pageIndex(fromIndex);\n         final int toPage = pageIndex(toIndex - 1);\n         if (fromPage == toPage) {",
    "output": "Fix BigLongArray.fill to account for an empty range"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugin/python/PythonPlugin.java b/src/main/java/org/elasticsearch/plugin/python/PythonPlugin.java\n--- a/src/main/java/org/elasticsearch/plugin/python/PythonPlugin.java\n+++ b/src/main/java/org/elasticsearch/plugin/python/PythonPlugin.java\n@@ -35,7 +35,7 @@ public String name() {\n \n     @Override\n     public String description() {\n-        return \"Python plugin allowing to add javascript scripting support\";\n+        return \"Adds support for writing scripts in Python\";\n     }\n \n     public void onModule(ScriptModule module) {",
    "output": "Upgrade plugin description Updates wording to (hopefully) better reflect what it does and removes reference to Javascript"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java b/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java\n--- a/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java\n+++ b/src/test/java/org/elasticsearch/shield/authc/ldap/LdapSessionFactoryTests.java\n@@ -42,13 +42,11 @@ public void testBindWithReadTimeout() throws Exception {\n         SecuredString userPass = SecuredStringTests.build(\"pass\");\n \n         ldapServer.setProcessingDelayMillis(500L);\n-        long start = System.currentTimeMillis();\n         try (LdapSession session = sessionFactory.session(user, userPass)) {\n             fail(\"expected connection timeout error here\");\n         } catch (Throwable t) {\n-            long time = System.currentTimeMillis() - start;\n-            assertThat(time, lessThan(1000l));\n             assertThat(t, instanceOf(ShieldLdapException.class));\n+            assertThat(t.getCause().getMessage(), containsString(\"A client-side timeout was encountered while waiting \"));\n         } finally {\n             ldapServer.setProcessingDelayMillis(0L);\n         }",
    "output": "Remove timing assertion from timeout test The timeout test times an operation that involves much more than a simple socket connect. There is overheard from the UnboundID library and its asynchronous nature that could cause delay in a response. This removes the assertion that the call to session took less than one second and adds an assertion about the exceptions cause. Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/authc/InternalAuthenticationService.java b/src/main/java/org/elasticsearch/shield/authc/InternalAuthenticationService.java\n--- a/src/main/java/org/elasticsearch/shield/authc/InternalAuthenticationService.java\n+++ b/src/main/java/org/elasticsearch/shield/authc/InternalAuthenticationService.java\n@@ -7,6 +7,7 @@\n \n import org.apache.commons.codec.binary.Base64;\n import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.bytes.BytesArray;\n import org.elasticsearch.common.component.AbstractComponent;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.io.stream.BytesStreamInput;\n@@ -116,7 +117,7 @@ public void attachUserHeaderIfMissing(TransportMessage message, User user) {\n     static User decodeUser(String text) {\n         byte[] bytes = Base64.decodeBase64(text);\n         try {\n-            BytesStreamInput input = new BytesStreamInput(bytes, true);\n+            BytesStreamInput input = new BytesStreamInput(new BytesArray(bytes));\n             return User.readFrom(input);\n         } catch (IOException ioe) {\n             throw new AuthenticationException(\"could not read authenticated user\", ioe);",
    "output": "Use the BytesStreamInput with BytesArray This resolves a compatibility issue with the current builds of elasticsearch 1.6.0. Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java b/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n@@ -33,12 +33,18 @@\n import java.util.Map;\n \n import static org.elasticsearch.client.Requests.updateSettingsRequest;\n+import com.google.common.collect.ImmutableSet;\n \n /**\n  *\n  */\n public class RestUpdateSettingsAction extends BaseRestHandler {\n \n+    private static final ImmutableSet<String> VALUES_TO_EXCLUDE = ImmutableSet.<String>builder()\n+            .add(\"pretty\").add(\"timeout\").add(\"master_timeout\").add(\"index\")\n+            .add(\"expand_wildcards\").add(\"ignore_unavailable\").add(\"allow_no_indices\")\n+            .build();\n+\n     @Inject\n     public RestUpdateSettingsAction(Settings settings, RestController controller, Client client) {\n         super(settings, controller, client);\n@@ -69,7 +75,7 @@ public void handleRequest(final RestRequest request, final RestChannel channel,\n             }\n         }\n         for (Map.Entry<String, String> entry : request.params().entrySet()) {\n-            if (entry.getKey().equals(\"pretty\") || entry.getKey().equals(\"timeout\") || entry.getKey().equals(\"master_timeout\") || entry.getKey().equals(\"index\")) {\n+            if (VALUES_TO_EXCLUDE.contains(entry.getKey())) {\n                 continue;\n             }\n             updateSettings.put(entry.getKey(), entry.getValue());",
    "output": "Upgrade Settings api: fix handling of IndicesOptions parameters in REST layer The Update Settings API tries to merge the query_string params with the settings sent as body and excluding some \"well known params\" such as `pretty`, `timeout` etc. Those well known params do not include the params used by IndicesOptions though, so they get merged resulting in invalid settings that get rejected"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java b/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java\n@@ -86,7 +86,6 @@ public RecoveryStatus(IndexShard indexShard, DiscoveryNode sourceNode, RecoveryT\n         // make sure the store is not released until we are done.\n         store.incRef();\n         indexShard.recoveryStats().incCurrentAsTarget();\n-        logger.info(\"--> incremented recoveries {}\", indexShard.recoveryStats());\n     }\n \n     private final Map<String, String> tempFileNames = ConcurrentCollections.newConcurrentMap();",
    "output": "Remove left over recovery log"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/recovery/TruncatedRecoveryTests.java b/src/test/java/org/elasticsearch/recovery/TruncatedRecoveryTests.java\n--- a/src/test/java/org/elasticsearch/recovery/TruncatedRecoveryTests.java\n+++ b/src/test/java/org/elasticsearch/recovery/TruncatedRecoveryTests.java\n@@ -124,7 +124,8 @@ public void testCancelRecoveryAndResume() throws Exception {\n                 public void sendRequest(DiscoveryNode node, long requestId, String action, TransportRequest request, TransportRequestOptions options) throws IOException, TransportException {\n                     if (action.equals(RecoveryTarget.Actions.FILE_CHUNK)) {\n                         RecoveryFileChunkRequest req = (RecoveryFileChunkRequest) request;\n-                        if ((req.name().endsWith(\"cfs\") || req.name().endsWith(\"fdt\"))&& req.lastChunk() && truncate.get()) {\n+                        logger.debug(\"file chunk [\" + req.toString() + \"] lastChunk: \" + req.lastChunk());\n+                        if ((req.name().endsWith(\"cfs\") || req.name().endsWith(\"fdt\")) && req.lastChunk() && truncate.get()) {\n                             latch.countDown();\n                             throw new RuntimeException(\"Caused some truncated files for fun and profit\");\n                         }",
    "output": "Add more logging to TruncatedRecoveryTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/ClusterStateObserver.java b/src/main/java/org/elasticsearch/cluster/ClusterStateObserver.java\n--- a/src/main/java/org/elasticsearch/cluster/ClusterStateObserver.java\n+++ b/src/main/java/org/elasticsearch/cluster/ClusterStateObserver.java\n@@ -147,13 +147,6 @@ public void waitForNextChange(Listener listener, ChangePredicate changePredicate\n         }\n     }\n \n-    public void close() {\n-        if (observingContext.getAndSet(null) != null) {\n-            clusterService.remove(clusterStateListener);\n-            logger.trace(\"cluster state observer closed\");\n-        }\n-    }\n-\n     /**\n      * reset this observer to the give cluster state. Any pending waits will be canceled.\n      *",
    "output": "Remove unused method. close() is neither needed nor called anywhere"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/support/Features.java b/src/test/java/org/elasticsearch/test/rest/support/Features.java\n--- a/src/test/java/org/elasticsearch/test/rest/support/Features.java\n+++ b/src/test/java/org/elasticsearch/test/rest/support/Features.java\n@@ -34,7 +34,7 @@\n  */\n public final class Features {\n \n-    private static final List<String> SUPPORTED = Lists.newArrayList(\"gtelte\", \"stash_in_path\", \"groovy_scripting\");\n+    private static final List<String> SUPPORTED = Lists.newArrayList(\"stash_in_path\", \"groovy_scripting\");\n \n     private Features() {\n ",
    "output": "Remove 'gtelte' feature from yaml tests Some yaml tests still used the 'gtelte' feature in their skip section. Since all language clients support this, the feature skip can be removed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -386,7 +386,7 @@ protected void doStart() throws ElasticsearchException {\n                 }\n                 if (!shard.active() || !observer.observedState().nodes().nodeExists(shard.currentNodeId())) {\n                     logger.trace(\"primary shard [{}] is not yet active or we do not know the node it is assigned to [{}], scheduling a retry.\", shard.shardId(), shard.currentNodeId());\n-                    retryBecauseUnavailable(shardIt.shardId(), \"Primary shard is not active or isn't assigned is a known node.\");\n+                    retryBecauseUnavailable(shardIt.shardId(), \"Primary shard is not active or isn't assigned to a known node.\");\n                     return;\n                 }\n ",
    "output": "Fix typo in UnavailableShardsException message"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n@@ -787,8 +787,8 @@ public void testShardFailures() throws IOException, InterruptedException {\n                 .put(\"index.analysis.filter.shingler.min_shingle_size\", 2)\n                 .put(\"index.analysis.filter.shingler.max_shingle_size\", 5)\n                 .put(\"index.analysis.filter.shingler.output_unigrams\", true));\n-        \n-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type1\")\n+\n+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject(\"type2\")\n                 .startObject(\"properties\")\n                     .startObject(\"name\")\n                         .field(\"type\", \"multi_field\")\n@@ -801,7 +801,7 @@ public void testShardFailures() throws IOException, InterruptedException {\n                     .endObject()\n                 .endObject()\n                 .endObject().endObject();\n-        assertAcked(builder.addMapping(\"type1\", mapping));\n+        assertAcked(builder.addMapping(\"type2\", mapping));\n         ensureGreen();\n \n         index(\"test\", \"type2\", \"1\", \"foo\", \"bar\");",
    "output": "Fix test to use correct type in the mapping"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n--- a/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n+++ b/src/main/java/org/elasticsearch/index/shard/IndexShard.java\n@@ -222,7 +222,7 @@ public IndexShard(ShardId shardId, @IndexSettings Settings indexSettings, IndexS\n         this.codecService = codecService;\n         this.shardSuggestService = shardSuggestService;\n         this.shardBitsetFilterCache = shardBitsetFilterCache;\n-        assert clusterService.lifecycleState() == Lifecycle.State.STARTED; // otherwise localNode is still none;\n+        assert clusterService.lifecycleState() == Lifecycle.State.STARTED : \"expected lifecycle to be started but was: \" + clusterService.lifecycleState() ; // otherwise localNode is still none;\n         this.localNode = clusterService.localNode();\n         state = IndexShardState.CREATED;\n         this.refreshInterval = indexSettings.getAsTime(INDEX_REFRESH_INTERVAL, EngineConfig.DEFAULT_REFRESH_INTERVAL);",
    "output": "Improve reporting of assert in IndexShard"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java\n@@ -435,7 +435,7 @@ public void run() throws InterruptedException {\n         stopWatch.stop();\n         response.startTime = stopWatch.totalTime().millis();\n         logger.trace(\"{} recovery [phase2] to {}: start took [{}]\",\n-                request.shardId(), request.targetNode(), request.targetNode(), stopWatch.totalTime());\n+                request.shardId(), request.targetNode(), stopWatch.totalTime());\n \n \n         logger.trace(\"{} recovery [phase2] to {}: updating current mapping to master\", request.shardId(), request.targetNode());",
    "output": "Fix extra logging parameter in RecoverySourceHandler"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/store/IndicesStoreIntegrationTests.java b/src/test/java/org/elasticsearch/indices/store/IndicesStoreIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/indices/store/IndicesStoreIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/indices/store/IndicesStoreIntegrationTests.java\n@@ -151,6 +151,10 @@ public ClusterState execute(ClusterState currentState) throws Exception {\n                         .build();\n             }\n \n+            public boolean runOnlyOnMaster() {\n+                return false;\n+            }\n+\n             @Override\n             public void onFailure(String source, Throwable t) {\n             }",
    "output": "Make sure update task is actually executed The update task that was submitted in this test never got executed if node_2 was not master"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/alerts/actions/email/service/ManualPublicSmtpServersTests.java b/src/test/java/org/elasticsearch/alerts/actions/email/service/ManualPublicSmtpServersTests.java\n--- a/src/test/java/org/elasticsearch/alerts/actions/email/service/ManualPublicSmtpServersTests.java\n+++ b/src/test/java/org/elasticsearch/alerts/actions/email/service/ManualPublicSmtpServersTests.java\n@@ -83,7 +83,7 @@ public static void main(String[] args) throws Exception {\n                             .put(\"alerts.actions.email.service.account.ses.smtp.starttls.enable\", true)\n                             .put(\"alerts.actions.email.service.account.ses.smtp.starttls.required\", true)\n                             .put(\"alerts.actions.email.service.account.ses.smtp.host\", \"email-smtp.us-east-1.amazonaws.com\")\n-                            .put(\"alerts.actions.email.service.account.ses.smtp.port\", 25)\n+                            .put(\"alerts.actions.email.service.account.ses.smtp.port\", 587)\n                             .put(\"alerts.actions.email.service.account.ses.smtp.user\", terminal.readText(\"user: \"))\n                             .put(\"alerts.actions.email.service.account.ses.smtp.password\", new String(terminal.readSecret(\"password: \")))\n                             .put(\"alerts.actions.email.service.account.ses.email_defaults.from\", \"dummy.user@elasticsearch.com\")",
    "output": "Change the SES email port to 587"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/NamingConventionTests.java b/src/test/java/org/elasticsearch/NamingConventionTests.java\n--- a/src/test/java/org/elasticsearch/NamingConventionTests.java\n+++ b/src/test/java/org/elasticsearch/NamingConventionTests.java\n@@ -110,8 +110,7 @@ private Class<?> loadClass(String filename) throws ClassNotFoundException {\n                         pkg.append(p.getFileName().toString()).append(\".\");\n                     }\n                     pkg.append(filename.substring(0, filename.length() - 6));\n-\n-                    return Class.forName(pkg.toString());\n+                    return Thread.currentThread().getContextClassLoader().loadClass(pkg.toString());\n                 }\n \n                 @Override",
    "output": "Use context classloader to load testclasses"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java b/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java\n--- a/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java\n+++ b/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.indices.memory.breaker;\n \n-import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n@@ -108,7 +107,6 @@ private boolean noopBreakerUsed() {\n     }\n \n     @Test\n-    @LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elasticsearch/elasticsearch/issues/8710\")\n     public void testMemoryBreaker() throws Exception {\n         if (noopBreakerUsed()) {\n             logger.info(\"--> noop breakers used, skipping test\");\n@@ -154,7 +152,6 @@ public void testMemoryBreaker() throws Exception {\n     }\n \n     @Test\n-    @LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elasticsearch/elasticsearch/issues/9270\")\n     public void testRamAccountingTermsEnum() throws Exception {\n         if (noopBreakerUsed()) {\n             logger.info(\"--> noop breakers used, skipping test\");",
    "output": "Remove AwaitsFix from CircuitBreakerServiceTests I beasted these tests for a while without failure, I would like to re-enable them to see if they still fail"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bwcompat/ClusterStateBackwardsCompatTests.java b/src/test/java/org/elasticsearch/bwcompat/ClusterStateBackwardsCompatTests.java\n--- a/src/test/java/org/elasticsearch/bwcompat/ClusterStateBackwardsCompatTests.java\n+++ b/src/test/java/org/elasticsearch/bwcompat/ClusterStateBackwardsCompatTests.java\n@@ -30,7 +30,7 @@\n import org.junit.Test;\n import static org.hamcrest.Matchers.*;\n \n-public class ClusterStateBackwardsCompat extends ElasticsearchBackwardsCompatIntegrationTest {\n+public class ClusterStateBackwardsCompatTests extends ElasticsearchBackwardsCompatIntegrationTest {\n \n     @Test\n     public void testClusterState() throws Exception {\n\ndiff --git a/src/test/java/org/elasticsearch/bwcompat/NodesStatsBasicBackwardsCompatTests.java b/src/test/java/org/elasticsearch/bwcompat/NodesStatsBasicBackwardsCompatTests.java\n--- a/src/test/java/org/elasticsearch/bwcompat/NodesStatsBasicBackwardsCompatTests.java\n+++ b/src/test/java/org/elasticsearch/bwcompat/NodesStatsBasicBackwardsCompatTests.java\n@@ -34,7 +34,7 @@\n \n \n @ElasticsearchIntegrationTest.ClusterScope(scope= ElasticsearchIntegrationTest.Scope.SUITE,  numClientNodes = 0)\n-public class NodesStatsBasicBackwardsCompat extends ElasticsearchBackwardsCompatIntegrationTest {\n+public class NodesStatsBasicBackwardsCompatTests extends ElasticsearchBackwardsCompatIntegrationTest {\n \n     @Test\n     public void testNodeStatsSetIndices() throws Exception {",
    "output": "Add Tests suffix"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsTests.java b/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsTests.java\n--- a/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsTests.java\n+++ b/src/test/java/org/elasticsearch/discovery/DiscoveryWithServiceDisruptionsTests.java\n@@ -75,7 +75,7 @@\n  */\n @LuceneTestCase.Slow\n @ClusterScope(scope = Scope.TEST, numDataNodes = 0, transportClientRatio = 0)\n-public class DiscoveryWithServiceDisruptions extends ElasticsearchIntegrationTest {\n+public class DiscoveryWithServiceDisruptionsTests extends ElasticsearchIntegrationTest {\n \n     private static final TimeValue DISRUPTION_HEALING_OVERHEAD = TimeValue.timeValueSeconds(40); // we use 30s as timeout in many places.\n ",
    "output": "Add Tests suffix"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n@@ -53,7 +53,7 @@ public class JavaScriptScriptEngineService extends AbstractComponent implements\n     public JavaScriptScriptEngineService(Settings settings) {\n         super(settings);\n \n-        this.optimizationLevel = componentSettings.getAsInt(\"optimization_level\", 1);\n+        this.optimizationLevel = settings.getAsInt(\"script.javascript.optimization_level\", 1);\n \n         Context ctx = Context.enter();\n         try {",
    "output": "Remove component settings from AbstractComponent Related to elasticsearch/elasticsearch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/get/GetActionTests.java b/src/test/java/org/elasticsearch/get/GetActionTests.java\n--- a/src/test/java/org/elasticsearch/get/GetActionTests.java\n+++ b/src/test/java/org/elasticsearch/get/GetActionTests.java\n@@ -964,7 +964,6 @@ public void testUngeneratedFieldsThatAreNeverStored() throws IOException {\n \n     @Test\n     public void testUngeneratedFieldsThatAreAlwaysStored() throws IOException {\n-        String storedString = randomBoolean() ? \"yes\" : \"no\";\n         String createIndexSource = \"{\\n\" +\n                 \"  \\\"settings\\\": {\\n\" +\n                 \"    \\\"index.translog.disable_flush\\\": true,\\n\" +\n@@ -980,8 +979,7 @@ public void testUngeneratedFieldsThatAreAlwaysStored() throws IOException {\n                 \"        \\\"type\\\": \\\"parentdoc\\\"\\n\" +\n                 \"      },\\n\" +\n                 \"      \\\"_ttl\\\": {\\n\" +\n-                \"        \\\"enabled\\\": true,\\n\" +\n-                \"        \\\"store\\\": \\\"\" + storedString + \"\\\"\\n\" +\n+                \"        \\\"enabled\\\": true\\n\" +\n                 \"      }\\n\" +\n                 \"    }\\n\" +\n                 \"  }\\n\" +",
    "output": "Fix test bug leftover from"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -69,12 +69,15 @@\n import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.collect.ImmutableOpenMap;\n import org.elasticsearch.common.collect.Tuple;\n import org.elasticsearch.common.io.FileSystemUtils;\n import org.elasticsearch.common.regex.Regex;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.transport.InetSocketTransportAddress;\n+import org.elasticsearch.common.transport.TransportAddress;\n import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.unit.TimeValue;",
    "output": "Fix compilation issue from forward port of"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bwcompat/BasicBackwardsCompatibilityTest.java b/src/test/java/org/elasticsearch/bwcompat/BasicBackwardsCompatibilityTest.java\n--- a/src/test/java/org/elasticsearch/bwcompat/BasicBackwardsCompatibilityTest.java\n+++ b/src/test/java/org/elasticsearch/bwcompat/BasicBackwardsCompatibilityTest.java\n@@ -22,6 +22,7 @@\n import org.apache.lucene.index.Fields;\n import org.apache.lucene.util.English;\n import org.elasticsearch.ElasticsearchIllegalArgumentException;\n+import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.Version;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n import org.elasticsearch.action.admin.indices.alias.Alias;\n@@ -396,7 +397,7 @@ public void testUnsupportedFeatures() throws IOException {\n                     .addMapping(\"type\", mapping));\n         } catch (MapperParsingException ex) {\n             assertThat(ex.getCause(), instanceOf(ElasticsearchIllegalArgumentException.class));\n-            assertThat(ex.getCause().getMessage(), equalTo(\"type=_field_names is not supported on indices created before version 1.3.0 is your cluster running multiple datanode versions?\"));\n+            assertThat(ExceptionsHelper.detailedMessage(ex).contains(\"type=_field_names is not supported on indices created before version 1.3.0\"), equalTo(true));\n         }\n \n     }",
    "output": "Fix bwc test to be more lenient on error message when _field_names is not supported"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationTests.java b/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.search.geo;\n \n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.get.GetResponse;\n import org.elasticsearch.action.search.SearchResponse;\n import org.elasticsearch.test.geo.RandomShapeGenerator;\n@@ -380,6 +381,7 @@ public void testThatShapeIsReturnedEvenWhenExclusionsAreSet() throws Exception {\n         assertThat(locationMap.size(), equalTo(2));\n     }\n \n+    @LuceneTestCase.AwaitsFix(bugUrl = \"https://github.com/elasticsearch/elasticsearch/issues/9904\")\n     @Test\n     public void testShapeFilterWithRandomGeoCollection() throws Exception {\n         // Create a random geometry collection.",
    "output": "Add 'AwaitsFix' annotation to randomGeoCollection test Random geo shape testing periodically fails on a known issue within Spatial4j core. A simple patch in ES will fix the issue. For now this random test will be disabled until the patch can be applied"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java b/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java\n@@ -21,7 +21,6 @@\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Maps;\n-import org.elasticsearch.ElasticsearchIllegalArgumentException;\n import org.elasticsearch.action.ActionResponse;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n@@ -66,15 +65,12 @@ public class ClusterHealthResponse extends ActionResponse implements Iterable<Cl\n     ClusterHealthResponse() {\n     }\n \n-    public ClusterHealthResponse(String clusterName, List<String> validationFailures) {\n-        this.clusterName = clusterName;\n-        this.validationFailures = validationFailures;\n+    /** needed for plugins BWC */\n+    public ClusterHealthResponse(String clusterName, String[] concreteIndices, ClusterState clusterState) {\n+        this(clusterName, concreteIndices, clusterState, -1);\n     }\n \n     public ClusterHealthResponse(String clusterName, String[] concreteIndices, ClusterState clusterState, int numberOfPendingTasks) {\n-        if (numberOfPendingTasks < 0) {\n-            throw new ElasticsearchIllegalArgumentException(\"pending task should be non-negative. got [\" + numberOfPendingTasks + \"]\");\n-        }\n         this.clusterName = clusterName;\n         this.numberOfPendingTasks = numberOfPendingTasks;\n         RoutingTableValidation validation = clusterState.routingTable().validate(clusterState.metaData());",
    "output": "Add ClusterHealthResponse constructor needed for plugin BWC"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java b/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java\n@@ -175,6 +175,22 @@ public String prettyPrint() {\n         return sb.toString();\n     }\n \n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(\"routingNode ([\");\n+        sb.append(node.getName());\n+        sb.append(\"][\");\n+        sb.append(node.getId());\n+        sb.append(\"][\");\n+        sb.append(node.getHostName());\n+        sb.append(\"][\");\n+        sb.append(node.getHostAddress());\n+        sb.append(\"], [\");\n+        sb.append(shards.size());\n+        sb.append(\" assigned shards])\");\n+        return sb.toString();\n+    }\n+\n     public MutableShardRouting get(int i) {\n         return shards.get(i) ;\n     }",
    "output": "Add a .toString() method to RoutingNode Previously this would log: ``` [2015-02-24 11:13:45,105][TRACE][cluster.routing.allocation.allocator] [Poltergeist] Try moving shard [ [2], node[HFn4dJ7fQAyfSAB8BquaSQ], [R], s[STARTED]] from [org.elasticsearch.cluster.routing.RoutingNode@6df2c498] ``` Now it will log: ``` [2015-02-25 11:32:45,182][TRACE][cluster.routing.allocation.allocator] [Solarr] Try moving shard [[my_index][2], node[HDhbU4D9Rx27MSr_72bmWQ], [P], s[STARTED]] from [routingNode ([Solarr][HDhbU4D9Rx27MSr_72bmWQ][Xanadu.domain][192.168.0.4], [5 assigned shards])] ```"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java b/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java\n--- a/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java\n+++ b/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java\n@@ -92,6 +92,7 @@ public GroovySandboxExpressionChecker(Settings settings, Set<String> blacklistAd\n     private final static String[] defaultReceiverWhitelist = new String [] {\n             groovy.util.GroovyCollections.class.getName(),\n             java.lang.Math.class.getName(),\n+            java.lang.String.class.getName(),\n             java.lang.Integer.class.getName(), \"[I\", \"[[I\", \"[[[I\",\n             java.lang.Float.class.getName(), \"[F\", \"[[F\", \"[[[F\",\n             java.lang.Double.class.getName(), \"[D\", \"[[D\", \"[[[D\",\n\ndiff --git a/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java b/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java\n--- a/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java\n+++ b/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java\n@@ -60,6 +60,8 @@ public void testSandboxedGroovyScript() throws Exception {\n         testSuccess(\"def t = Instant.now().getMillis()\");\n         // GroovyCollections\n         testSuccess(\"def n = [1,2,3]; GroovyCollections.max(n)\");\n+        // String\n+        testSuccess(\"def s = String.format(\\\\\\\"%d\\\\\\\", 4)\");\n \n         // Fail cases\n         testFailure(\"pr = Runtime.getRuntime().exec(\\\\\\\"touch /tmp/gotcha\\\\\\\"); pr.waitFor()\",",
    "output": "Add String to the default whitelisted receivers"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/Store.java b/src/main/java/org/elasticsearch/index/store/Store.java\n--- a/src/main/java/org/elasticsearch/index/store/Store.java\n+++ b/src/main/java/org/elasticsearch/index/store/Store.java\n@@ -657,11 +657,6 @@ public String toString() {\n \n     }\n \n-    /** Log that we are about to delete this file, to the index.store.deletes component. */\n-    public void deleteFile(String msg, String storeFile) throws IOException {\n-        directory.deleteFile(msg, storeFile);\n-    }\n-\n     /**\n      * Represents a snapshot of the current directory build from the latest Lucene commit.\n      * Only files that are part of the last commit are considered in this datastrucutre.",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/attachment/test/unit/VariousDocTest.java b/src/test/java/org/elasticsearch/index/mapper/attachment/test/unit/VariousDocTest.java\n--- a/src/test/java/org/elasticsearch/index/mapper/attachment/test/unit/VariousDocTest.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/attachment/test/unit/VariousDocTest.java\n@@ -27,7 +27,7 @@\n import org.elasticsearch.index.mapper.ParseContext;\n import org.elasticsearch.index.mapper.attachment.AttachmentMapper;\n import org.elasticsearch.index.mapper.attachment.test.MapperTestUtils;\n-import org.junit.BeforeClass;\n+import org.junit.Before;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -46,10 +46,10 @@\n  */\n public class VariousDocTest extends AttachmentUnitTestCase {\n \n-    protected static DocumentMapper docMapper;\n+    protected DocumentMapper docMapper;\n \n-    @BeforeClass\n-    public static void createMapper() throws IOException {\n+    @Before\n+    public void createMapper() throws IOException {\n         DocumentMapperParser mapperParser = MapperTestUtils.newMapperParser(ImmutableSettings.builder().build());\n         mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE, new AttachmentMapper.TypeParser());\n ",
    "output": "Fix remaining static objects after running tests Test framework detects when static objects are not released when running tests. This commit remove usage of static objects when possible"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java b/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n--- a/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n+++ b/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n@@ -322,7 +322,7 @@ public void testOpenCloseWithDocs() throws IOException, ExecutionException, Inte\n         int docs = between(10, 100);\n         IndexRequestBuilder[] builder = new IndexRequestBuilder[docs];\n         for (int i = 0; i < docs ; i++) {\n-            builder[i] = client().prepareIndex(\"test\", \"initial\", \"\" + i).setSource(\"test\", \"init\");\n+            builder[i] = client().prepareIndex(\"test\", \"type\", \"\" + i).setSource(\"test\", \"init\");\n         }\n         indexRandom(true, builder);\n         if (randomBoolean()) {\n@@ -333,7 +333,7 @@ public void testOpenCloseWithDocs() throws IOException, ExecutionException, Inte\n         // check the index still contains the records that we indexed\n         client().admin().indices().prepareOpen(\"test\").execute().get();\n         ensureGreen();\n-        SearchResponse searchResponse = client().prepareSearch().setTypes(\"initial\").setQuery(QueryBuilders.matchQuery(\"test\", \"init\")).get();\n+        SearchResponse searchResponse = client().prepareSearch().setTypes(\"type\").setQuery(QueryBuilders.matchQuery(\"test\", \"init\")).get();\n         assertNoFailures(searchResponse);\n         assertHitCount(searchResponse, docs);\n     }",
    "output": "Use same type in mapping and for indexing"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/env/NodeEnvironmentTests.java b/src/test/java/org/elasticsearch/env/NodeEnvironmentTests.java\n--- a/src/test/java/org/elasticsearch/env/NodeEnvironmentTests.java\n+++ b/src/test/java/org/elasticsearch/env/NodeEnvironmentTests.java\n@@ -121,7 +121,7 @@ public void testShardLock() throws IOException {\n \n         List<ShardLock> locks = env.lockAllForIndex(new Index(\"foo\"), settings, randomIntBetween(0, 10));\n         try {\n-            env.shardLock(new ShardId(\"foo\", randomIntBetween(0, 1)));\n+            env.shardLock(new ShardId(\"foo\", 0));\n             fail(\"shard is locked\");\n         } catch (LockObtainFailedException ex) {\n             // expected",
    "output": "Fix test bug"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java b/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java\n--- a/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java\n@@ -28,13 +28,12 @@\n import org.apache.lucene.codecs.PostingsFormat;\n import org.apache.lucene.document.Document;\n import org.apache.lucene.index.DirectoryReader;\n-import org.apache.lucene.index.DocsAndPositionsEnum;\n-import org.apache.lucene.index.DocsEnum;\n import org.apache.lucene.index.Fields;\n import org.apache.lucene.index.IndexWriter;\n import org.apache.lucene.index.IndexWriterConfig;\n import org.apache.lucene.index.IndexableField;\n import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PostingsEnum;\n import org.apache.lucene.index.Terms;\n import org.apache.lucene.index.TermsEnum;\n import org.apache.lucene.search.suggest.InputIterator;",
    "output": "Add missing import"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java b/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n--- a/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n+++ b/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java\n@@ -110,9 +110,9 @@ public S3Repository(RepositoryName name, RepositorySettings repositorySettings,\n                 } else if (\"ap-northeast-1\".equals(regionSetting)) {\n                     region = \"ap-northeast-1\";\n                 } else if (\"eu-west\".equals(regionSetting)) {\n-                    region = \"EU\";\n+                    region = \"eu-west-1\";\n                 } else if (\"eu-west-1\".equals(regionSetting)) {\n-                    region = \"EU\";\n+                    region = \"eu-west-1\";\n                 } else if (\"eu-central\".equals(regionSetting)) {\n                     region = \"eu-central-1\";\n                 } else if (\"eu-central-1\".equals(regionSetting)) {",
    "output": "Fix region settings for s3 snapshot repository in eu-west-1"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java b/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobStore.java\n@@ -67,7 +67,7 @@ public S3BlobStore(Settings settings, AmazonS3 client, String bucket, @Nullable\n \n         this.bufferSize = (bufferSize != null) ? bufferSize : MIN_BUFFER_SIZE;\n         if (this.bufferSize.getBytes() < MIN_BUFFER_SIZE.getBytes()) {\n-            throw new BlobStoreException(\"\\\"Detected a buffer_size for the S3 storage lower than [\" + MIN_BUFFER_SIZE + \"]\");\n+            throw new BlobStoreException(\"Detected a buffer_size for the S3 storage lower than [\" + MIN_BUFFER_SIZE + \"]\");\n         }\n \n         this.numberOfRetries = maxRetries;",
    "output": "Remove an excess quote character in an exception message"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java b/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n--- a/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n+++ b/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n@@ -89,11 +89,13 @@ public class OldIndexBackwardsCompatibilityTests extends StaticIndexBackwardComp\n         \"index-1.3.6.zip\",\n         \"index-1.3.7.zip\",\n         \"index-1.3.8.zip\",\n+        \"index-1.3.9.zip\",\n         \"index-1.4.0.Beta1.zip\",\n         \"index-1.4.0.zip\",\n         \"index-1.4.1.zip\",\n         \"index-1.4.2.zip\",\n-        \"index-1.4.3.zip\"\n+        \"index-1.4.3.zip\",\n+        \"index-1.4.4.zip\"\n     );\n     \n     public void testAllVersionsTested() throws Exception {",
    "output": "Add static bwc indexes for 1.3.9 and 1.4.4"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/IndicesService.java b/src/main/java/org/elasticsearch/indices/IndicesService.java\n--- a/src/main/java/org/elasticsearch/indices/IndicesService.java\n+++ b/src/main/java/org/elasticsearch/indices/IndicesService.java\n@@ -535,7 +535,7 @@ public void deleteShardStore(String reason, ShardId shardId, IndexMetaData metaD\n      * @return true if the index can be deleted on this node\n      */\n     public boolean canDeleteIndexContents(Index index, Settings indexSettings) {\n-        final Tuple<IndexService, Injector> indexServiceInjectorTuple = this.indices.get(index);\n+        final Tuple<IndexService, Injector> indexServiceInjectorTuple = this.indices.get(index.name());\n         if (IndexMetaData.isOnSharedFilesystem(indexSettings) == false) {\n             if (indexServiceInjectorTuple == null && nodeEnv.hasNodeFile()) {\n                 return true;",
    "output": "Use index name rather than Index.java to lookup IndexService"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/SimpleAttachmentIntegrationTests.java b/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/SimpleAttachmentIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/SimpleAttachmentIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/SimpleAttachmentIntegrationTests.java\n@@ -141,8 +141,8 @@ public void testContentTypeAndName() throws Exception {\n         refresh();\n \n         SearchResponse response = client().prepareSearch(\"test\")\n-                .addField(\"content_type\")\n-                .addField(\"name\")\n+                .addField(\"file.content_type\")\n+                .addField(\"file.name\")\n                 .execute().get();\n         String contentType = response.getHits().getAt(0).getFields().get(\"file.content_type\").getValue();\n         String name = response.getHits().getAt(0).getFields().get(\"file.name\").getValue();",
    "output": "Use now full qualified names for fields We were asking for short name fields but elasticsearch does not allow anymore using short names but full qualified names. ```java SearchResponse response = client().prepareSearch(\"test\") .addField(\"content_type\") .addField(\"name\") .execute().get(); ``` We need to use now: ```java SearchResponse response = client().prepareSearch(\"test\") .addField(\"file.content_type\") .addField(\"file.name\") .execute().get(); ```"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java b/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java\n--- a/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java\n+++ b/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java\n@@ -150,7 +150,7 @@ public void deleteBlob(String container, String blob) throws URISyntaxException,\n         // Container name must be lower case.\n         CloudBlobContainer blob_container = client.getContainerReference(container);\n         if (blob_container.exists()) {\n-            logger.trace(\"blob found. removing.\", container, blob);\n+            logger.trace(\"container [{}]: blob [{}] found. removing.\", container, blob);\n             CloudBlockBlob azureBlob = blob_container.getBlockBlobReference(blob);\n             azureBlob.delete();\n         }",
    "output": "Fix log parameters"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java b/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n@@ -66,7 +66,7 @@ protected int numberOfShards() {\n     @Slow\n     public void testRestartNodePercolator1() throws Exception {\n         internalCluster().startNode();\n-        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", \"field1\", \"type=string\"));\n+        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", \"field1\", \"type=string\").addMapping(PercolatorService.TYPE_NAME, \"color\", \"type=string\"));\n \n         logger.info(\"--> register a query\");\n         client().prepareIndex(\"test\", PercolatorService.TYPE_NAME, \"kuku\")",
    "output": "Add percolate type to the mapping"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java b/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java\n--- a/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java\n+++ b/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java\n@@ -153,7 +153,7 @@ public List<DiscoveryNode> buildDynamicNodes() {\n                         address = instance.getPublicDnsName();\n                         break;\n                     case PUBLIC_IP:\n-                        address = instance.getPublicDnsName();\n+                        address = instance.getPublicIpAddress();\n                         break;\n                 }\n                 if (address != null) {",
    "output": "Fix address resolution"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/StoreTest.java b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n--- a/src/test/java/org/elasticsearch/index/store/StoreTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/StoreTest.java\n@@ -1064,15 +1064,13 @@ public void testStoreStats() throws IOException {\n         assertEquals(stats.getSize().bytes(), 0);\n \n         Directory dir = store.directory();\n-        long length = 0;\n+        final long length;\n         try (IndexOutput output = dir.createOutput(\"foo.bar\", IOContext.DEFAULT)) {\n             int iters = scaledRandomIntBetween(10, 100);\n             for (int i = 0; i < iters; i++) {\n                 BytesRef bytesRef = new BytesRef(TestUtil.randomRealisticUnicodeString(random(), 10, 1024));\n                 output.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n             }\n-            stats = store.stats();\n-            assertEquals(stats.getSize().bytes(), 0);\n             length = output.getFilePointer();\n         }\n ",
    "output": "Remove wrong assertion - stream must be closed to assert the size"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java b/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n@@ -157,7 +157,7 @@ public Builder addReducer(ReducerFactory reducerFactory) {\n         }\n \n         public AggregatorFactories build() {\n-            if (factories.isEmpty()) {\n+            if (factories.isEmpty() && reducerFactories.isEmpty()) {\n                 return EMPTY;\n             }\n             List<ReducerFactory> orderedReducers = resolveReducerOrder(this.reducerFactories, this.factories);\n@@ -212,7 +212,7 @@ private void resolveReducerOrder(Set<String> aggFactoryNames, Map<String, Reduce\n                 String[] bucketsPaths = factory.getBucketsPaths();\n                 for (String bucketsPath : bucketsPaths) {\n                     ReducerFactory matchingFactory = reducerFactoriesMap.get(bucketsPath);\n-                    if (aggFactoryNames.contains(bucketsPath)) {\n+                    if (bucketsPath.equals(\"_count\") || bucketsPath.equals(\"_key\") || aggFactoryNames.contains(bucketsPath)) {\n                         continue;\n                     } else if (matchingFactory != null) {\n                         resolveReducerOrder(aggFactoryNames, reducerFactoriesMap, orderedReducers, unmarkedFactories, temporarilyMarked,",
    "output": "Add support for _count and _key as bucketsPaths"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java b/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n@@ -161,7 +161,6 @@ public AggregatorFactories build() {\n                 return EMPTY;\n             }\n             List<ReducerFactory> orderedReducers = resolveReducerOrder(this.reducerFactories, this.factories);\n-            // NOCOMMIT work out dependency order of reducer factories\n             return new AggregatorFactories(factories.toArray(new AggregatorFactory[factories.size()]), orderedReducers);\n         }\n \n@@ -200,7 +199,6 @@ private List<ReducerFactory> resolveReducerOrder(List<ReducerFactory> reducerFac\n             for (ReducerFactory reducerFactory : orderedReducers) {\n                 orderedReducerNames.add(reducerFactory.getName());\n             }\n-            System.out.println(\"ORDERED REDUCERS: \" + orderedReducerNames);\n             return orderedReducers;\n         }\n ",
    "output": "Remove obselete NOCOMMIT and left over sysout call"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/Store.java b/src/main/java/org/elasticsearch/index/store/Store.java\n--- a/src/main/java/org/elasticsearch/index/store/Store.java\n+++ b/src/main/java/org/elasticsearch/index/store/Store.java\n@@ -665,8 +665,6 @@ public void deleteFile(String msg, String storeFile) throws IOException {\n     public final static class MetadataSnapshot implements Iterable<StoreFileMetaData>, Streamable {\n         private static final ESLogger logger = Loggers.getLogger(MetadataSnapshot.class);\n         private static final Version FIRST_LUCENE_CHECKSUM_VERSION = Version.LUCENE_4_8;\n-        // we stopped writing legacy checksums in 1.3.0 so all segments here must use the new CRC32 version\n-        private static final Version FIRST_ES_CRC32_VERSION = org.elasticsearch.Version.V_1_3_0.luceneVersion;\n \n         private Map<String, StoreFileMetaData> metadata;\n ",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/Store.java b/src/main/java/org/elasticsearch/index/store/Store.java\n--- a/src/main/java/org/elasticsearch/index/store/Store.java\n+++ b/src/main/java/org/elasticsearch/index/store/Store.java\n@@ -556,7 +556,6 @@ public void cleanupAndVerify(String reason, MetadataSnapshot sourceMetaData) thr\n                 if (!sourceMetaData.contains(existingFile) && !Store.isChecksum(existingFile)) {\n                     try {\n                         dir.deleteFile(reason, existingFile);\n-                        dir.deleteFile(existingFile);\n                     } catch (Exception e) {\n                         // ignore, we don't really care, will get deleted later on\n                     }",
    "output": "Remove obsolet deleteFile call in Store"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ShieldVersion.java b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n--- a/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n+++ b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n@@ -26,6 +26,8 @@ public class ShieldVersion implements Serializable {\n \n     public static final int V_1_0_0_ID = /*00*/1000099;\n     public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, false, Version.V_1_4_2, LicenseVersion.V_1_0_0);\n+    public static final int V_1_0_1_ID = /*00*/1000199;\n+    public static final ShieldVersion V_1_0_1 = new ShieldVersion(V_1_0_1_ID, false, Version.V_1_4_2, LicenseVersion.V_1_0_0);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n     public static final ShieldVersion V_2_0_0 = new ShieldVersion(V_2_0_0_ID, true, Version.V_1_4_2, LicenseVersion.V_1_0_0);\n \n@@ -38,6 +40,7 @@ public static ShieldVersion readVersion(StreamInput in) throws IOException {\n     public static ShieldVersion fromId(int id) {\n         switch (id) {\n             case V_1_0_0_ID:    return V_1_0_0;\n+            case V_1_0_1_ID:    return V_1_0_1;\n             case V_2_0_0_ID:    return V_2_0_0;\n \n             default:",
    "output": "Upgrade ShieldVersion with version 1.0.1"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java b/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n--- a/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n+++ b/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.nested;\n \n+import com.carrotsearch.randomizedtesting.annotations.Seed;\n import org.apache.lucene.search.Explanation;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n import org.elasticsearch.action.admin.cluster.stats.ClusterStatsResponse;\n@@ -1211,7 +1212,7 @@ public void testCheckFixedBitSetCache() throws Exception {\n \n             // only when querying with nested the fixed bitsets are loaded\n             SearchResponse searchResponse = client().prepareSearch(\"test\")\n-                    .setQuery(nestedQuery(\"array1\", termQuery(\"field1\", \"value1\")))\n+                    .setQuery(nestedQuery(\"array1\", termQuery(\"array1.field1\", \"value1\")))\n                     .get();\n             assertNoFailures(searchResponse);\n             assertThat(searchResponse.getHits().totalHits(), equalTo(5l));",
    "output": "Fix test failure resulting from #8872 change"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/reducers/derivative/DerivativeReducer.java b/src/main/java/org/elasticsearch/search/aggregations/reducers/derivative/DerivativeReducer.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/reducers/derivative/DerivativeReducer.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/reducers/derivative/DerivativeReducer.java\n@@ -96,9 +96,9 @@ public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext\n                 double diff = thisBucketValue - lastBucketValue;\n \n                 List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(), FUNCTION));\n-                aggs.add(new InternalSimpleValue(bucketsPath, diff, null, new ArrayList<Reducer>(), metaData())); // NOCOMMIT implement formatter for derivative reducer\n+                aggs.add(new InternalSimpleValue(name(), diff, null, new ArrayList<Reducer>(), metaData())); // NOCOMMIT implement formatter for derivative reducer\n                 InternalHistogram.Bucket newBucket = factory.createBucket(((DateTime) bucket.getKey()).getMillis(), bucket.getDocCount(),\n-                        new InternalAggregations(aggs), bucket.getKeyed(), bucket.getFormatter()); // NOCOMMIT fix key resolution for dates\n+                        new InternalAggregations(aggs), bucket.getKeyed(), bucket.getFormatter()); // NOCOMMIT fix key resolution to deal with numbers and dates\n                 newBuckets.add(newBucket);\n             } else {\n                 newBuckets.add(bucket);",
    "output": "Fix to the name of the injected aggregation for derivatives"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java b/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n@@ -455,6 +455,10 @@ public void parse(ParseContext context) throws IOException {\n             // Set the maximum length of strings returned by the parseToString method, -1 sets no limit\n             parsedContent = tika().parseToString(new BytesStreamInput(content, false), metadata, indexedChars);\n         } catch (Throwable e) {\n+            // It could happen that Tika adds a System property `sun.font.fontmanager` which should not happen\n+            // TODO Remove when this will be fixed in Tika. See https://issues.apache.org/jira/browse/TIKA-1548\n+            System.clearProperty(\"sun.font.fontmanager\");\n+\n             // #18: we could ignore errors when Tika does not parse data\n             if (!ignoreErrors) {\n                 throw new MapperParsingException(\"Failed to extract [\" + indexedChars + \"] characters of text for [\" + name + \"]\", e);",
    "output": "Upgrade Tika to 1.7 . (cherry picked from commit 0ab38f3) (cherry picked from commit 96c7bb1)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java b/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java\n--- a/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java\n+++ b/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java\n@@ -136,7 +136,7 @@ public void testThatDefaultProfilePortOverridesGeneralConfiguration() throws Exc\n     public void testThatBindingOnDifferentHostsWorks() throws Exception {\n         int[] ports = getRandomPorts(2);\n         InetAddress firstNonLoopbackAddress = NetworkUtils.getFirstNonLoopbackAddress(NetworkUtils.StackType.IPv4);\n-\n+        assumeTrue(\"No IP-v4 non-loopback address available - are you on a plane?\", firstNonLoopbackAddress != null);\n         Settings settings = settingsBuilder()\n                 .put(\"network.host\", \"127.0.0.1\")\n                 .put(\"transport.tcp.port\", ports[0])",
    "output": "Make tests pass while flying"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java b/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java\n--- a/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java\n+++ b/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java\n@@ -42,11 +42,8 @@\n import java.net.Socket;\n \n import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;\n-import static org.elasticsearch.test.ElasticsearchIntegrationTest.ClusterScope;\n-import static org.elasticsearch.test.ElasticsearchIntegrationTest.Scope;\n import static org.hamcrest.Matchers.is;\n \n-@ClusterScope(scope = Scope.TEST, numDataNodes = 1)\n public class NettyTransportMultiPortTests extends ElasticsearchTestCase {\n \n     private NettyTransport nettyTransport;",
    "output": "Remove needless ClusterScope annotation from NettyTransportMultiPortTests NettyTransportMultiPortTests is not an integration test, it doesn't rely on the test cluster thus the ClusterScope annotation doesn't have any effect"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java b/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java\n--- a/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java\n+++ b/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java\n@@ -25,6 +25,7 @@\n \n import static org.elasticsearch.test.hamcrest.RegexMatcher.matches;\n import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.instanceOf;\n import static org.hamcrest.Matchers.notNullValue;\n import static org.junit.Assert.assertThat;\n \n@@ -49,10 +50,12 @@ protected void doAssert(Object actualValue, Object expectedValue) {\n         if (expectedValue instanceof String) {\n             String expValue = ((String) expectedValue).trim();\n             if (expValue.length() > 2 && expValue.startsWith(\"/\") && expValue.endsWith(\"/\")) {\n+                assertThat(\"field [\" + getField() + \"] was expected to be of type String but is an instanceof [\" + actualValue.getClass() + \"]\", actualValue, instanceOf(String.class));\n+                String stringValue = (String) actualValue;\n                 String regex = expValue.substring(1, expValue.length() - 1);\n-                logger.trace(\"assert that [{}] matches [{}]\", actualValue, regex);\n+                logger.trace(\"assert that [{}] matches [{}]\", stringValue, regex);\n                 assertThat(\"field [\" + getField() + \"] was expected to match the provided regex but didn't\",\n-                        actualValue.toString(), matches(regex, Pattern.COMMENTS));\n+                        stringValue, matches(regex, Pattern.COMMENTS));\n                 return;\n             }\n         }",
    "output": "Make sure that match assertion throws error if run against an object We had a REST test that relied on matching a json response against a regex. It worked but the match wasn't done against the actual json object, but its java map representation converted into a string by calling `toString`. Since all other clients test runners don't work in this case, as they try to match a json object against a regex, we should do the same and prevent it from working"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java b/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n--- a/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n+++ b/src/test/java/org/elasticsearch/shield/VersionCompatibilityTests.java\n@@ -40,7 +40,7 @@ public void testCompatibility() {\n         /**\n          * see https://github.com/elasticsearch/elasticsearch/pull/9134 {@link org.elasticsearch.shield.transport.netty.ShieldMessageChannelHandler}\n          */\n-        assertThat(\"Cleanup SecuredMessageChannelHandler class and remove needless code, fixed in es core 1.5\", Version.CURRENT.onOrBefore(Version.V_1_4_2), is(true));\n+        assertThat(\"Cleanup ShieldMessageChannelHandler class and remove needless code, fixed in es core 1.5\", Version.CURRENT.onOrBefore(Version.V_1_4_2), is(true));\n \n         /**\n          * see https://github.com/elasticsearch/elasticsearch/pull/9273 {@link org.elasticsearch.action.admin.indices.create.CreateIndexRequestHelper}",
    "output": "Upgrade naming of assert message relates to elastic/x-pack@22ca864cd1d4a241e554517b6b765f4fb0b3816b"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/plugin/AlertsPlugin.java b/src/main/java/org/elasticsearch/alerts/plugin/AlertsPlugin.java\n--- a/src/main/java/org/elasticsearch/alerts/plugin/AlertsPlugin.java\n+++ b/src/main/java/org/elasticsearch/alerts/plugin/AlertsPlugin.java\n@@ -18,7 +18,7 @@\n public class AlertsPlugin extends AbstractPlugin {\n \n     public static final String ALERT_THREAD_POOL_NAME = \"alerts\";\n-    public static final String SCHEDULER_THREAD_POOL_NAME = \"alerts\";\n+    public static final String SCHEDULER_THREAD_POOL_NAME = \"alerts_scheduler\";\n \n     @Override public String name() {\n         return ALERT_THREAD_POOL_NAME;",
    "output": "Fix thread pool name"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/authz/IndexAliasesTests.java b/src/test/java/org/elasticsearch/shield/authz/IndexAliasesTests.java\n--- a/src/test/java/org/elasticsearch/shield/authz/IndexAliasesTests.java\n+++ b/src/test/java/org/elasticsearch/shield/authz/IndexAliasesTests.java\n@@ -205,7 +205,7 @@ public void testCreateIndexThenAliasesCreateAndAliasesPermission() {\n \n         try {\n             //fails: user doesn't have manage_aliases on alias_1\n-            client().admin().indices().prepareAliases().addAlias(\"test_1\", \"alias_1\", \"test_alias\")\n+            client().admin().indices().prepareAliases().addAlias(\"test_1\", \"alias_1\").addAlias(\"test_1\", \"test_alias\")\n                     .putHeader(BASIC_AUTH_HEADER, basicAuthHeaderValue(\"create_test_aliases_test\", new SecuredString(\"test123\".toCharArray()))).get();\n             fail(\"add alias should have failed due to missing manage_aliases privileges on alias_1\");\n         } catch(AuthorizationException e) {",
    "output": "Fix minor bug in IndexAliasesTests Two aliases were supposed to be created, while only one was, which was also associated with a broken filter"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/deleteByQuery/DeleteByQueryTests.java b/src/test/java/org/elasticsearch/deleteByQuery/DeleteByQueryTests.java\n--- a/src/test/java/org/elasticsearch/deleteByQuery/DeleteByQueryTests.java\n+++ b/src/test/java/org/elasticsearch/deleteByQuery/DeleteByQueryTests.java\n@@ -19,7 +19,6 @@\n \n package org.elasticsearch.deleteByQuery;\n \n-import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.ActionWriteResponse;\n import org.elasticsearch.action.admin.indices.alias.Alias;\n import org.elasticsearch.action.deletebyquery.DeleteByQueryRequestBuilder;\n@@ -52,7 +51,6 @@ public void testDeleteAllNoIndices() {\n     }\n \n     @Test\n-    @LuceneTestCase.AwaitsFix(bugUrl=\"https://github.com/elasticsearch/elasticsearch/issues/9421\")\n     public void testDeleteAllOneIndex() {\n         String json = \"{\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elastic Search\\\"\" + \"}\";\n         final long iters = randomIntBetween(1, 50);",
    "output": "Remove AwaitsFix from DeleteByQuery test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsTests.java\n@@ -115,6 +115,7 @@ public void setupSuiteScopeCluster() throws Exception {\n                     .endObject()\n                 .endObject()\n                 .endObject().endObject().endObject()));\n+        ensureGreen(\"idx\", \"empty\", \"articles\");\n \n         List<IndexRequestBuilder> builders = new ArrayList<>();\n         for (int i = 0; i < 50; i++) {",
    "output": "Add `ensureGreen` to indices created in TopHitsTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/action/ShieldActionFilter.java b/src/main/java/org/elasticsearch/shield/action/ShieldActionFilter.java\n--- a/src/main/java/org/elasticsearch/shield/action/ShieldActionFilter.java\n+++ b/src/main/java/org/elasticsearch/shield/action/ShieldActionFilter.java\n@@ -45,7 +45,7 @@ public class ShieldActionFilter extends AbstractComponent implements ActionFilte\n     private final AuditTrail auditTrail;\n     private final ShieldActionMapper actionMapper;\n \n-    private volatile boolean licenseEnabled;\n+    private volatile boolean licenseEnabled = true;\n \n     @Inject\n     public ShieldActionFilter(Settings settings, AuthenticationService authcService, AuthorizationService authzService, SignatureService signatureService,",
    "output": "Fix sets treats the license as enabled by default We need to assume the license is enabled until we're told otherwise by the license plugin. It's required as we should allow the execution of APIs (like cluster health) on a node that just started and didn't receive the cluster state yet"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java b/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n--- a/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n+++ b/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n@@ -162,8 +162,9 @@ protected void afterMerge(OnGoingMerge merge) {\n         }\n \n         @Override\n-        protected void maybeStall(IndexWriter writer) {\n+        protected boolean maybeStall(IndexWriter writer) {\n             // Don't stall here, because we do our own index throttling (in InternalEngine.IndexThrottle) when merges can't keep up\n+            return true;\n         }\n     }\n ",
    "output": "Upgrade to lucene r1654549 snapshot. . Squashed commit of the following: commit 85c71b6478441a73738c81f02257193f9837f3ba Author: Robert Muir <rmuir@apache.org> Date: Sat Jan 24 11:24:36 2015 -0500 upgrade to lucene r1654549 snapshot"
  },
  {
    "input": "diff --git a/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesClientServiceTests.java b/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesClientServiceTests.java\n--- a/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesClientServiceTests.java\n+++ b/plugin/src/test/java/org/elasticsearch/license/plugin/LicensesClientServiceTests.java\n@@ -137,7 +137,7 @@ public void testMultipleEventNotification() throws Exception {\n         final AtomicInteger triggerCount1 = new AtomicInteger(0);\n         callbacks.add(preCallbackLatch(TimeValue.timeValueMillis(500), TimeValue.timeValueSeconds(1), TimeValue.timeValueMillis(100), triggerCount1));\n         final AtomicInteger triggerCount2 = new AtomicInteger(0);\n-        callbacks.add(postCallbackLatch(TimeValue.timeValueMillis(0), null, TimeValue.timeValueMillis(200), triggerCount2));\n+        callbacks.add(postCallbackLatch(TimeValue.timeValueMillis(10), null, TimeValue.timeValueMillis(200), triggerCount2));\n         final AtomicInteger triggerCount3 = new AtomicInteger(0);\n         callbacks.add(preCallbackLatch(TimeValue.timeValueSeconds(1), TimeValue.timeValueSeconds(2), TimeValue.timeValueMillis(500), triggerCount3));\n ",
    "output": "Change notification event time"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ShieldRestTests.java b/src/test/java/org/elasticsearch/test/ShieldRestTests.java\n--- a/src/test/java/org/elasticsearch/test/ShieldRestTests.java\n+++ b/src/test/java/org/elasticsearch/test/ShieldRestTests.java\n@@ -23,7 +23,6 @@\n import org.junit.Test;\n \n import java.io.IOException;\n-import java.util.Locale;\n \n import static org.elasticsearch.shield.authc.support.UsernamePasswordToken.basicAuthHeaderValue;\n \n@@ -67,7 +66,6 @@ public static void close() {\n \n     @Test\n     public void test() throws IOException {\n-        logger.info(\"current default locale is [{}]\", Locale.getDefault());\n         delegate.test();\n     }\n ",
    "output": "Remove current locale log line from ShieldRestTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptTests.java b/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptTests.java\n--- a/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptTests.java\n+++ b/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptTests.java\n@@ -45,8 +45,8 @@\n import static org.elasticsearch.client.Requests.searchRequest;\n import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;\n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+import static org.elasticsearch.index.query.FilterBuilders.termFilter;\n import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;\n-import static org.elasticsearch.index.query.QueryBuilders.termQuery;\n import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;\n import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;\n import static org.elasticsearch.test.ElasticsearchIntegrationTest.ClusterScope;\n@@ -77,7 +77,7 @@ public void testNativeExplainScript() throws InterruptedException, IOException,\n         client().admin().indices().prepareRefresh().execute().actionGet();\n         ensureYellow();\n         SearchResponse response = client().search(searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(\n-                searchSource().explain(true).query(functionScoreQuery(termQuery(\"text\", \"text\")).add(scriptFunction(\"native_explainable_script\", \"native\")).boostMode(\"sum\")))).actionGet();\n+                searchSource().explain(true).query(functionScoreQuery(termFilter(\"text\", \"text\")).add(scriptFunction(\"native_explainable_script\", \"native\")).boostMode(\"sum\")))).actionGet();\n \n         ElasticsearchAssertions.assertNoFailures(response);\n         SearchHits hits = response.getHits();",
    "output": "Fix scores in ExplainableScriptTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java b/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java\n@@ -26,7 +26,7 @@\n \n public class SmtpAlertActionFactory implements AlertActionFactory, ConfigurableComponentListener {\n \n-    private static final String PORT_SETTING = \"alerts.action.smpt.server.port\";\n+    private static final String PORT_SETTING = \"alerts.action.email.server.port\";\n     private static final String SERVER_SETTING = \"alerts.action.email.server.name\";\n     private static final String FROM_SETTING = \"alerts.action.email.from.address\";\n     private static final String PASSWD_SETTING = \"alerts.action.email.from.passwd\";",
    "output": "Fix email port setting"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/integration/ClearRealmsCacheTests.java b/src/test/java/org/elasticsearch/integration/ClearRealmsCacheTests.java\n--- a/src/test/java/org/elasticsearch/integration/ClearRealmsCacheTests.java\n+++ b/src/test/java/org/elasticsearch/integration/ClearRealmsCacheTests.java\n@@ -41,7 +41,7 @@ public class ClearRealmsCacheTests extends ShieldIntegrationTest {\n     public static void init() throws Exception {\n         usernames = new String[randomIntBetween(5, 10)];\n         for (int i = 0; i < usernames.length; i++) {\n-            usernames[i] = \"user_\" + i;\n+            usernames[i] = randomAsciiOfLength(6) + \"_\" + i;\n         }\n     }\n \n@@ -63,6 +63,9 @@ public void assertEviction(User prevUser, User newUser) {\n         EVICT_SOME() {\n \n             private final String[] evicted_usernames = randomSelection(usernames);\n+            {\n+                Arrays.sort(evicted_usernames);\n+            }\n \n             @Override\n             public ClearRealmCacheRequest createRequest() {\n@@ -194,11 +197,13 @@ public void onFailure(Throwable e) {\n \n     // selects a random sub-set of the give values\n     private static String[] randomSelection(String[] values) {\n-        double base = randomDouble();\n         List<String> list = new ArrayList<>();\n-        for (String value : values) {\n-            if (randomDouble() < base) {\n-                list.add(value);\n+        while (list.isEmpty()) {\n+            double base = randomDouble();\n+            for (String value : values) {\n+                if (randomDouble() < base) {\n+                    list.add(value);\n+                }\n             }\n         }\n         return list.toArray(new String[list.size()]);",
    "output": "Fix a bug in ClearRealmCacheTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -159,7 +159,7 @@ public class Version {\n     public static final int V_1_0_0_Beta1_ID = 1000001;\n     public static final Version V_1_0_0_Beta1 = new Version(V_1_0_0_Beta1_ID, false, org.apache.lucene.util.Version.LUCENE_4_5);\n     public static final int V_1_0_0_Beta2_ID = 1000002;\n-    public static final Version V_1_0_0_Beta2 = new Version(V_1_0_0_Beta2_ID, true, org.apache.lucene.util.Version.LUCENE_4_6);\n+    public static final Version V_1_0_0_Beta2 = new Version(V_1_0_0_Beta2_ID, false, org.apache.lucene.util.Version.LUCENE_4_6);\n     public static final int V_1_0_0_RC1_ID = 1000051;\n     public static final Version V_1_0_0_RC1 = new Version(V_1_0_0_RC1_ID, false, org.apache.lucene.util.Version.LUCENE_4_6);\n     public static final int V_1_0_0_RC2_ID = 1000052;",
    "output": "Fix snapshot flag accidentally switched for 1.0 beta2"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java b/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n--- a/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n+++ b/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityTests.java\n@@ -54,7 +54,6 @@ public class OldIndexBackwardsCompatibilityTests extends StaticIndexBackwardComp\n     // We have a 0.20.6.zip etc for this.\n     \n     List<String> indexes = Arrays.asList(\n-        /* skipping 0.90.0.Beta1...fails to load with \"java.lang.IllegalArgumentException: An SPI class of type org.apache.lucene.codecs.PostingsFormat with name 'XBloomFilter' does not exist\" */\n         \"index-0.90.0.Beta1.zip\",\n         \"index-0.90.0.RC1.zip\",\n         \"index-0.90.0.RC2.zip\",",
    "output": "Remove irrelevant bwc comment"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java b/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/SmtpAlertActionFactory.java\n@@ -26,7 +26,7 @@\n \n public class SmtpAlertActionFactory implements AlertActionFactory, ConfigurableComponentListener {\n \n-    private static final String PORT_SETTING = \"alerts.action.smpt.server.port\";\n+    private static final String PORT_SETTING = \"alerts.action.email.server.port\";\n     private static final String SERVER_SETTING = \"alerts.action.email.server.name\";\n     private static final String FROM_SETTING = \"alerts.action.email.from.address\";\n     private static final String PASSWD_SETTING = \"alerts.action.email.from.passwd\";",
    "output": "Fix email port setting The setting was mistyped as 'smpt' when it should have been 'smtp', but it is better to change it to 'email' to be consistent with the other settings"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java b/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java\n--- a/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java\n+++ b/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java\n@@ -87,8 +87,8 @@ public ClusterDynamicSettingsModule() {\n         clusterDynamicSettings.addDynamicSetting(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES, Validator.INTEGER);\n         clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK);\n         clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK);\n-        clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED);\n-        clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS);\n+        clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED, Validator.BOOLEAN);\n+        clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS, Validator.BOOLEAN);\n         clusterDynamicSettings.addDynamicSetting(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_REROUTE_INTERVAL, Validator.TIME_NON_NEGATIVE);\n         clusterDynamicSettings.addDynamicSetting(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL, Validator.TIME_NON_NEGATIVE);\n         clusterDynamicSettings.addDynamicSetting(SnapshotInProgressAllocationDecider.CLUSTER_ROUTING_ALLOCATION_SNAPSHOT_RELOCATION_ENABLED);",
    "output": "Add validator for `cluster.routing.allocation.disk` boolean settings `cluster.routing.allocation.disk.include_relocations` and `cluster.routing.allocation.disk.reroute_interval` are both boolean settings, so they should have the `Validator.BOOLEAN` applied"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -222,7 +222,7 @@ public class Version implements Serializable {\n     public static final int V_1_4_3_ID = /*00*/1040399;\n     public static final Version V_1_4_3 = new Version(V_1_4_3_ID, false, org.apache.lucene.util.Version.LUCENE_4_10_2);\n     public static final int V_1_5_0_ID = /*00*/1050099;\n-    public static final Version V_1_5_0 = new Version(V_1_5_0_ID, false, org.apache.lucene.util.Version.fromBits(4, 10, 3)); // TODO change this to a constant once we update the snapshot\n+    public static final Version V_1_5_0 = new Version(V_1_5_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_10_3);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n     public static final Version V_2_0_0 = new Version(V_2_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_0_0);\n ",
    "output": "Use Lucene's 4.10.3 version constant"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java b/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n--- a/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n+++ b/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n@@ -366,7 +366,7 @@ private static void assign(Edge[] holes, Coordinate[][] points, int numHoles, Ed\n             final int pos;\n             if (intersections == 0 ||\n                (pos = Arrays.binarySearch(edges, 0, intersections, current, INTERSECTION_ORDER)) >= 0) {\n-                throw new ElasticsearchParseException(\"Invaild shape: Hole is not within polygon\");\n+                throw new ElasticsearchParseException(\"Invalid shape: Hole is not within polygon\");\n             }\n             final int index = -(pos+2);\n             final int component = -edges[index].component - numHoles - 1;",
    "output": "Fix typo in geoshape exception Invaild -> Invalid"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java b/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java\n--- a/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java\n+++ b/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java\n@@ -362,8 +362,8 @@ public void testNonExistingRepo_86() {\n     @Test\n     public void testGetDeleteNonExistingSnapshot_86() {\n         ClusterAdminClient client = client().admin().cluster();\n-        logger.info(\"-->  creating azure repository without any path\");\n-        PutRepositoryResponse putRepositoryResponse = client.preparePutRepository(\"test-repo\").setType(\"azure\")\n+        logger.info(\"-->  creating s3 repository without any path\");\n+        PutRepositoryResponse putRepositoryResponse = client.preparePutRepository(\"test-repo\")\n                 .setType(\"s3\").setSettings(ImmutableSettings.settingsBuilder()\n                                 .put(\"base_path\", basePath)\n                 ).get();",
    "output": "Fix typo (azure -> s3)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/transport/netty/HandshakeWaitingHandlerTests.java b/src/test/java/org/elasticsearch/shield/transport/netty/HandshakeWaitingHandlerTests.java\n--- a/src/test/java/org/elasticsearch/shield/transport/netty/HandshakeWaitingHandlerTests.java\n+++ b/src/test/java/org/elasticsearch/shield/transport/netty/HandshakeWaitingHandlerTests.java\n@@ -217,7 +217,7 @@ private static class WriteBeforeHandshakeCompletedCallable implements Callable<C\n         @Override\n         public ChannelFuture call() throws Exception {\n             ChannelBuffer buffer = ChannelBuffers.buffer(8);\n-            buffer.writeLong(SecureRandom.getInstanceStrong().nextLong());\n+            buffer.writeLong(SecureRandom.getInstance(\"SHA1PRNG\").nextLong());\n \n             // Connect and wait, then immediately start writing\n             ChannelFuture future = bootstrap.connect(new InetSocketAddress(\"localhost\", port));",
    "output": "Fix compilation error by removing use of SecureRandom.getInstanceStrong()"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/GroovyScriptTests.java b/src/test/java/org/elasticsearch/script/GroovyScriptTests.java\n--- a/src/test/java/org/elasticsearch/script/GroovyScriptTests.java\n+++ b/src/test/java/org/elasticsearch/script/GroovyScriptTests.java\n@@ -140,8 +140,10 @@ public void testScoreAccess() {\n         assertSearchHits(resp, \"3\", \"1\");\n \n         // _score is comparable\n+        // NOTE: it is important to use 0.0 instead of 0 instead Groovy will do an integer comparison\n+        // and if the score if between 0 and 1 it will be considered equal to 0 due to the cast\n         resp = client().prepareSearch(\"test\").setQuery(functionScoreQuery(matchQuery(\"foo\", \"dog\"))\n-            .add(scriptFunction(\"_score > 0 ? _score : 0\", \"groovy\"))\n+            .add(scriptFunction(\"_score > 0.0 ? _score : 0\", \"groovy\"))\n             .boostMode(CombineFunction.REPLACE)).get();\n         assertNoFailures(resp);\n         assertSearchHits(resp, \"3\", \"1\");",
    "output": "Fix GroovyScriptTests failures"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n--- a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n+++ b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n@@ -1998,6 +1998,7 @@ public void testIndicesQueryMissingIndices() throws IOException, ExecutionExcept\n     public void testIndicesFilterMissingIndices() throws IOException, ExecutionException, InterruptedException {\n         createIndex(\"index1\");\n         createIndex(\"index2\");\n+        createIndex(\"index3\");\n         ensureGreen();\n         indexRandom(true,\n                 client().prepareIndex(\"index1\", \"type1\", \"1\").setSource(\"field\", \"match\"),",
    "output": "Make sure to wait for all shards to be allocated before running the test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java b/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java\n--- a/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java\n+++ b/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java\n@@ -38,6 +38,8 @@\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.cache.filter.AutoFilterCachingPolicy;\n+import org.elasticsearch.index.cache.filter.FilterCacheModule;\n+import org.elasticsearch.index.cache.filter.weighted.WeightedFilterCache;\n import org.elasticsearch.index.merge.policy.TieredMergePolicyProvider;\n import org.elasticsearch.index.merge.scheduler.ConcurrentMergeSchedulerProvider;\n import org.elasticsearch.index.query.FilterBuilders;\n@@ -76,6 +78,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 .put(\"indices.cache.filter.clean_interval\", \"1ms\")\n                 .put(IndicesQueryCache.INDICES_CACHE_QUERY_CLEAN_INTERVAL, \"1ms\")\n                 .put(AutoFilterCachingPolicy.AGGRESSIVE_CACHING_SETTINGS)\n+                .put(FilterCacheModule.FilterCacheSettings.FILTER_CACHE_TYPE, WeightedFilterCache.class)\n                 .build();\n     }\n ",
    "output": "Fix IndexStatsTests failures"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java b/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n--- a/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n+++ b/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n@@ -404,7 +404,8 @@ private static int merge(Edge[] intersections, int offset, int length, Edge[] ho\n             // The connect method creates a new edge for these paired edges in the linked list. \n             // For boundary conditions (e.g., intersect but not crossing) there is no sibling edge \n             // to connect. Thus the following enforces the pairwise rule \n-            if (e1.intersect != Edge.MAX_COORDINATE && e2.intersect != Edge.MAX_COORDINATE) {\n+            if (e1.intersect != Edge.MAX_COORDINATE && e2.intersect != Edge.MAX_COORDINATE \n+                    && (e1.next.next.coordinate != e2.coordinate) ) {\n                 connect(e1, e2);\n             }\n         }\n@@ -431,7 +432,7 @@ private static void connect(Edge in, Edge out) {\n                 in.next = new Edge(in.intersect, out.next, in.intersect);\n             }\n             out.next = new Edge(out.intersect, e1, out.intersect);\n-        } else if (in.next != out){\n+        } else if (in.next != out && in.coordinate != out.intersect) {\n             // first edge intersects with dateline\n             Edge e2 = new Edge(out.intersect, in.next, out.intersect);\n ",
    "output": "Upgrade connect method to prevent duplicate edges"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -1709,11 +1709,10 @@ protected double getPerTestTransportClientRatio() {\n     }\n \n     /**\n-     * Returns a random numeric field data format from the choices of \"array\",\n-     * \"compressed\", or \"doc_values\".\n+     * Returns a random numeric field data format from the choices of \"array\" or \"doc_values\".\n      */\n     public static String randomNumericFieldDataFormat() {\n-        return randomFrom(Arrays.asList(\"array\", \"compressed\", \"doc_values\"));\n+        return randomFrom(Arrays.asList(\"array\", \"doc_values\"));\n     }\n \n     /**",
    "output": "Remove \"compressed\" field data from numeric formats The \"compressed\" format was removed, so this caused warnings in the log like: ``` [WARN ][index.fielddata ] [node_0] failed to find format [compressed] for field [test-num], will use default ```"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/gateway/IndexShardGateway.java b/src/main/java/org/elasticsearch/index/gateway/IndexShardGateway.java\n--- a/src/main/java/org/elasticsearch/index/gateway/IndexShardGateway.java\n+++ b/src/main/java/org/elasticsearch/index/gateway/IndexShardGateway.java\n@@ -356,4 +356,9 @@ public void run() {\n             }\n         }\n     }\n+\n+    @Override\n+    public String toString() {\n+        return \"shard_gateway\";\n+    }\n }",
    "output": "Add toString() to IndexShardGateway"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java b/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java\n--- a/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java\n+++ b/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java\n@@ -207,11 +207,9 @@ public void run() {\n         logger.info(\"--> parent tripped: {}, total trip count: {} (expecting 1-2 for each)\", parentTripped.get(), tripped.get());\n         assertThat(\"no other exceptions were thrown\", lastException.get(), equalTo(null));\n         assertThat(\"breaker should be reset back to the parent limit after parent breaker trips\",\n-                breaker.getUsed(), equalTo((long)parentLimit));\n+                breaker.getUsed(), greaterThanOrEqualTo((long)parentLimit - NUM_THREADS));\n         assertThat(\"parent breaker was tripped at least once\", parentTripped.get(), greaterThanOrEqualTo(1));\n         assertThat(\"total breaker was tripped at least once\", tripped.get(), greaterThanOrEqualTo(1));\n-        assertThat(\"breaker total is expected value: \" + parentLimit, breaker.getUsed(), equalTo((long)\n-                parentLimit));\n     }\n \n     @Test",
    "output": "Make parent breaker check less strict In cases of heavy contention, it's possible for more than 2 threads to race to a circuit breaking exception. Essentially this means that if we have 3 threads all trying to add 3 and simultaneously cause a circuit breaking exception (due to retry), when adjusting after circuit breaking we can \"rewind\" past what this test expects the child breaker to be at. This adds leeway into the check, where it's okay to be within NUM_THREADS from the parentLimit, because each thread should only add 1 to the breaker at a time"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java b/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n--- a/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n+++ b/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n@@ -548,4 +548,24 @@ private void corruptTranslogs(Path directory) throws Exception {\n     private Term newUid(String id) {\n         return new Term(\"_uid\", id);\n     }\n+\n+\n+    @Test\n+    public void testVerifyTranslogIsNotDeleted() throws IOException {\n+        Path path = translogFileDirectory();\n+        assertTrue(Files.exists(path.resolve(\"translog-1\")));\n+        translog.add(new Translog.Create(\"test\", \"1\", new byte[]{1}));\n+        Translog.Snapshot snapshot = translog.snapshot();\n+        MatcherAssert.assertThat(snapshot, TranslogSizeMatcher.translogSize(1));\n+        assertThat(snapshot.estimatedTotalOperations(), equalTo(1));\n+        if (randomBoolean()) {\n+            translog.close();\n+            snapshot.close();\n+        } else {\n+            snapshot.close();\n+            translog.close();\n+        }\n+\n+        assertTrue(Files.exists(path.resolve(\"translog-1\")));\n+    }\n }",
    "output": "Add test to ensure master is not prone to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/test/TestScopeClusterTests.java b/src/test/java/org/elasticsearch/test/test/TestScopeClusterTests.java\n--- a/src/test/java/org/elasticsearch/test/test/TestScopeClusterTests.java\n+++ b/src/test/java/org/elasticsearch/test/test/TestScopeClusterTests.java\n@@ -18,7 +18,6 @@\n  */\n package org.elasticsearch.test.test;\n \n-import com.carrotsearch.randomizedtesting.annotations.Repeat;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.TestCluster;\n import org.junit.Test;\n@@ -38,7 +37,6 @@ public class TestScopeClusterTests extends ElasticsearchIntegrationTest {\n     private static Long CLUSTER_SEED = null;\n \n     @Test\n-    @Repeat(iterations = 10, useConstantSeed = true)\n     public void testReproducible() throws IOException {\n         if (ITER++ == 0) {\n             CLUSTER_SEED = cluster().seed();",
    "output": "Remove debug leftover"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineTests.java b/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineTests.java\n--- a/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineTests.java\n+++ b/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineTests.java\n@@ -357,10 +357,8 @@ public void testSegments() throws Exception {\n     }\n \n     public void testStartAndAcquireConcurrently() throws IOException {\n-        // Close engine from setUp (we create our own):\n-        engine.close();\n-\n         ConcurrentMergeSchedulerProvider mergeSchedulerProvider = new ConcurrentMergeSchedulerProvider(shardId, EMPTY_SETTINGS, threadPool, new IndexSettingsService(shardId.index(), EMPTY_SETTINGS));\n+        final Store store = createStore();\n         final Engine engine = createEngine(engineSettingsService, store, createTranslog(), mergeSchedulerProvider);\n         final AtomicBoolean startPending = new AtomicBoolean(true);\n         Thread thread = new Thread() {\n@@ -384,6 +382,7 @@ public void run() {\n             }\n         }\n         engine.close();\n+        store.close();\n     }\n \n ",
    "output": "Use private store for a test private engine The test was using the same store as the suite level engine which caused problems with write locks in some cases"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java b/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n@@ -82,11 +82,7 @@ public void handleRequest(final RestRequest request, RestChannel channel, final\n                 .field(\"build_hash\", Build.CURRENT.hash())\n                 .field(\"build_timestamp\", Build.CURRENT.timestamp())\n                 .field(\"build_snapshot\", version.snapshot)\n-                        // We use the lucene version from lucene constants since\n-                        // this includes bugfix release version as well and is already in\n-                        // the right format. We can also be sure that the format is maitained\n-                        // since this is also recorded in lucene segments and has BW compat\n-                .field(\"lucene_version\", Constants.LUCENE_MAIN_VERSION)\n+                .field(\"lucene_version\", version.luceneVersion.toString())\n                 .endObject();\n         builder.field(\"tagline\", \"You Know, for Search\");\n         builder.endObject();",
    "output": "Use Lucene version string in main rest action This commit removes the deprecated constant for the main version and uses the real lucene version we are running instead. Behind the scenes the same value was used and is now obsolet"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/index/ElasticsearchLeafReader.java b/src/main/java/org/elasticsearch/common/lucene/index/ElasticsearchLeafReader.java\n--- a/src/main/java/org/elasticsearch/common/lucene/index/ElasticsearchLeafReader.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/index/ElasticsearchLeafReader.java\n@@ -49,4 +49,14 @@ public final class ElasticsearchLeafReader extends FilterLeafReader {\n     public ShardId shardId() {\n         return this.shardId;\n     }\n+\n+    @Override\n+    public Object getCoreCacheKey() {\n+        return in.getCoreCacheKey();\n+    }\n+\n+    @Override\n+    public Object getCombinedCoreAndDeletesKey() {\n+        return in.getCombinedCoreAndDeletesKey();\n+    }\n }",
    "output": "Fix cache key methods on leaf reader"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersToolTests.java b/src/test/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersToolTests.java\n--- a/src/test/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersToolTests.java\n+++ b/src/test/java/org/elasticsearch/shield/authc/esusers/tool/ESUsersToolTests.java\n@@ -648,7 +648,7 @@ public void testListUsersAndRoles_Cmd_NoUsers() throws Exception {\n         assertThat(status, is(CliTool.ExitStatus.OK));\n         List<String> output = terminal.getTerminalOutput();\n         assertThat(output, hasSize(1));\n-        assertThat(output.get(0), equalTo(\"No users found\\n\"));\n+        assertThat(output.get(0), equalTo(\"No users found\" + System.lineSeparator()));\n     }\n \n     @Test",
    "output": "Use operating system specific line ending The line endings differ between operating systems and the existing test failed on Windows systems. This change uses the OS specific line ending. Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/transport/actions/config/TransportConfigAlertAction.java b/src/main/java/org/elasticsearch/alerts/transport/actions/config/TransportConfigAlertAction.java\n--- a/src/main/java/org/elasticsearch/alerts/transport/actions/config/TransportConfigAlertAction.java\n+++ b/src/main/java/org/elasticsearch/alerts/transport/actions/config/TransportConfigAlertAction.java\n@@ -12,7 +12,6 @@\n import org.elasticsearch.action.support.master.TransportMasterNodeOperationAction;\n import org.elasticsearch.alerts.AlertsStore;\n import org.elasticsearch.alerts.ConfigurationManager;\n-import org.elasticsearch.client.Client;\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.block.ClusterBlockException;\n@@ -28,15 +27,12 @@\n public class TransportConfigAlertAction extends TransportMasterNodeOperationAction<ConfigAlertRequest, ConfigAlertResponse> {\n \n     private final ConfigurationManager configManager;\n-    private final Client client;\n \n     @Inject\n     public TransportConfigAlertAction(Settings settings, TransportService transportService, ClusterService clusterService,\n-                                      ThreadPool threadPool, ActionFilters actionFilters, ConfigurationManager configManager,\n-                                      Client client) {\n+                                      ThreadPool threadPool, ActionFilters actionFilters, ConfigurationManager configManager) {\n         super(settings, ConfigAlertAction.NAME, transportService, clusterService, threadPool, actionFilters);\n         this.configManager = configManager;\n-        this.client = client;\n     }\n \n     @Override",
    "output": "Remove unused field"
  },
  {
    "input": "diff --git a/plugin/src/main/java/org/elasticsearch/license/plugin/core/LicensesService.java b/plugin/src/main/java/org/elasticsearch/license/plugin/core/LicensesService.java\n--- a/plugin/src/main/java/org/elasticsearch/license/plugin/core/LicensesService.java\n+++ b/plugin/src/main/java/org/elasticsearch/license/plugin/core/LicensesService.java\n@@ -354,7 +354,7 @@ protected void doStop() throws ElasticsearchException {\n \n         // notify features to be disabled\n         for (ListenerHolder holder : registeredListeners) {\n-            holder.disableFeatureIfNeeded();\n+            holder.disableFeatureIfNeeded(false);\n         }\n         // clear all handlers\n         registeredListeners.clear();\n@@ -468,7 +468,7 @@ private long notifyFeatures(final LicensesMetaData currentLicensesMetaData) {\n                     nextScheduleFrequency = Math.min(expiryDuration, nextScheduleFrequency);\n                 }\n             } else {\n-                listenerHolder.disableFeatureIfNeeded();\n+                listenerHolder.disableFeatureIfNeeded(true);\n             }\n \n             if (logger.isDebugEnabled()) {\n@@ -740,10 +740,12 @@ private void enableFeatureIfNeeded() {\n             }\n         }\n \n-        private void disableFeatureIfNeeded() {\n+        private void disableFeatureIfNeeded(boolean log) {\n             if (enabled.compareAndSet(true, false)) {\n                 listener.onDisabled();\n-                logger.info(\"license for [\" + feature + \"] - expired\");\n+                if (log) {\n+                    logger.info(\"license for [\" + feature + \"] - expired\");\n+                }\n             }\n         }\n ",
    "output": "Fix Do not emit feature license status on shutdown closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertManager.java b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n@@ -265,22 +265,19 @@ private void internalStart(ClusterState initialState) {\n                 if (configurationManager.start(initialState)) {\n                     break;\n                 }\n-                logger.error(\"CONFIG NOT STARTED\");\n                 clusterState = newClusterState(clusterState);\n             }\n             // Try to load alert store before the action manager, b/c action depends on alert store\n             while (true) {\n                 if (alertsStore.start(clusterState)) {\n                     break;\n                 }\n-                logger.error(\"STORE NOT STARTED\");\n                 clusterState = newClusterState(clusterState);\n             }\n             while (true) {\n                 if (actionManager.start(clusterState)) {\n                     break;\n                 }\n-                logger.error(\"ACTION NOT STARTED\");\n                 clusterState = newClusterState(clusterState);\n             }\n ",
    "output": "Remove log statements"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertManager.java b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n@@ -265,19 +265,22 @@ private void internalStart(ClusterState initialState) {\n                 if (configurationManager.start(initialState)) {\n                     break;\n                 }\n+                logger.error(\"CONFIG NOT STARTED\");\n                 clusterState = newClusterState(clusterState);\n             }\n             // Try to load alert store before the action manager, b/c action depends on alert store\n             while (true) {\n                 if (alertsStore.start(clusterState)) {\n                     break;\n                 }\n+                logger.error(\"STORE NOT STARTED\");\n                 clusterState = newClusterState(clusterState);\n             }\n             while (true) {\n                 if (actionManager.start(clusterState)) {\n                     break;\n                 }\n+                logger.error(\"ACTION NOT STARTED\");\n                 clusterState = newClusterState(clusterState);\n             }\n \n\ndiff --git a/src/main/java/org/elasticsearch/alerts/AlertsStore.java b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n@@ -152,10 +152,6 @@ public boolean start(ClusterState state) {\n             return true;\n         }\n \n-        if (!configurationManager.start(state)) {\n-            return false;\n-        }\n-\n         IndexMetaData alertIndexMetaData = state.getMetaData().index(ALERT_INDEX);\n         if (alertIndexMetaData != null) {\n             logger.debug(\"Previous alerting index\");",
    "output": "Remove redundant if statement"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/alerts/AlertSerializationTest.java b/src/test/java/org/elasticsearch/alerts/AlertSerializationTest.java\n--- a/src/test/java/org/elasticsearch/alerts/AlertSerializationTest.java\n+++ b/src/test/java/org/elasticsearch/alerts/AlertSerializationTest.java\n@@ -7,7 +7,7 @@\n \n import org.elasticsearch.action.search.SearchRequest;\n import org.elasticsearch.alerts.actions.AlertAction;\n-import org.elasticsearch.alerts.actions.SntpAlertAction;\n+import org.elasticsearch.alerts.actions.SmtpAlertAction;\n import org.elasticsearch.alerts.triggers.ScriptedTrigger;\n import org.elasticsearch.common.joda.time.DateTime;\n import org.elasticsearch.common.unit.TimeValue;\n@@ -34,7 +34,7 @@ public void testAlertSerialization() throws Exception {\n         SearchRequest payloadRequest = createTriggerSearchRequest(\"my-payload-index\").source(searchSource().query(matchAllQuery()));\n \n         List<AlertAction> actions = new ArrayList<>();\n-        actions.add(new SntpAlertAction(\"message\", \"foo@bar.com\"));\n+        actions.add(new SmtpAlertAction(\"message\", \"foo@bar.com\"));\n         Alert alert = new Alert(\"test-serialization\",\n                 triggerRequest,\n                 new ScriptedTrigger(\"return true\", ScriptService.ScriptType.INLINE, \"groovy\"),",
    "output": "Change to support name change of email alert action"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java b/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n--- a/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n+++ b/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.ToXContent;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.InternalTestCluster;\n import org.elasticsearch.test.TestCluster;\n@@ -181,7 +182,7 @@ public void run() {\n                         .get();\n                 assertThat(searchResponse.getHits().getTotalHits(), greaterThanOrEqualTo(minimumExpectedAlertActionsWithActionPerformed));\n                 if (assertTriggerSearchMatched) {\n-                    assertThat(searchResponse.getHits().totalHits(), greaterThanOrEqualTo(1L));\n+                    assertThat((Integer) XContentMapValues.extractValue(\"trigger_response.hits.total\", searchResponse.getHits().getAt(0).sourceAsMap()), greaterThanOrEqualTo(1));\n                 }\n             }\n         });",
    "output": "Fix tests differently"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n@@ -373,8 +373,8 @@ public void run() {\n                     } else if (entry.getState() != AlertActionState.THROTTLED) {\n                         entry.setState(AlertActionState.ACTION_PERFORMED);\n                     }\n-                    entry.setPayloadRequest(trigger.getPayloadRequest());\n-                    entry.setPayloadResponse(trigger.getPayloadResponse());\n+                    entry.setPayloadRequest(result.getPayloadRequest());\n+                    entry.setPayloadResponse(result.getPayloadResponse());\n                 } else {\n                     entry.setState(AlertActionState.NO_ACTION_NEEDED);\n                 }",
    "output": "Fix Fixes after merge fail"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ShieldVersion.java b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n--- a/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n+++ b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n@@ -24,7 +24,7 @@ public class ShieldVersion implements Serializable {\n     // the (internal) format of the id is there so we can easily do after/before checks on the id\n \n     public static final int V_1_0_0_ID = /*00*/1000099;\n-    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0_Beta1);\n+    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0);\n \n     public static final ShieldVersion CURRENT = V_1_0_0;\n ",
    "output": "Upgrade the min es compatibility to 1.4.0"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/VerifyingIndexOutput.java b/src/main/java/org/elasticsearch/index/store/VerifyingIndexOutput.java\n--- a/src/main/java/org/elasticsearch/index/store/VerifyingIndexOutput.java\n+++ b/src/main/java/org/elasticsearch/index/store/VerifyingIndexOutput.java\n@@ -33,7 +33,7 @@ public abstract class VerifyingIndexOutput extends IndexOutput {\n     \n     /** Sole constructor */\n     VerifyingIndexOutput(IndexOutput out) {\n-        super(\"VerifyingIndexOutput(in=\" + out + \")\");\n+        super(\"VerifyingIndexOutput(out=\" + out + \")\");\n         this.out = out;\n     }\n     ",
    "output": "Fix resource description of VerifyingIndexOutput"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ShieldSettingsSource.java b/src/test/java/org/elasticsearch/test/ShieldSettingsSource.java\n--- a/src/test/java/org/elasticsearch/test/ShieldSettingsSource.java\n+++ b/src/test/java/org/elasticsearch/test/ShieldSettingsSource.java\n@@ -99,8 +99,10 @@ public Settings node(int nodeOrdinal) {\n                 .put(\"shield.authz.store.files.roles\", writeFile(folder, \"roles.yml\", configRoles()))\n                 .put(getNodeSSLSettings());\n \n+        //the random call has to happen all the time for repeatability\n+        String networkHost = RandomizedTest.randomBoolean() ? \"127.0.0.1\" : \"::1\";\n         if (OsUtils.MAC) {\n-            builder.put(\"network.host\", RandomizedTest.randomBoolean() ? \"127.0.0.1\" : \"::1\");\n+            builder.put(\"network.host\", networkHost);\n         }\n \n         setUser(builder, nodeClientUsername(), nodeClientPassword());",
    "output": "Fix tests repeatability issue Every random call should happen all the time on all platforms (unless randomized!), otherwise tests won't reproduce on different platforms"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n--- a/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n@@ -305,7 +305,7 @@ public InternalTestCluster(long clusterSeed,\n             builder.put(RecoverySettings.INDICES_RECOVERY_CONCURRENT_SMALL_FILE_STREAMS, RandomInts.randomIntBetween(random, 10, 15));\n             builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES, RandomInts.randomIntBetween(random, 5, 10));\n             builder.put(RecoverySettings.INDICES_RECOVERY_RETRY_DELAY, TimeValue.timeValueMillis(RandomInts.randomIntBetween(random, 10, 25))); // more shared - we need to retry more often\n-        } else if (frequently()) {\n+        } else if (random.nextInt(100) <= 90) {\n             builder.put(RecoverySettings.INDICES_RECOVERY_CONCURRENT_STREAMS, RandomInts.randomIntBetween(random, 3, 6));\n             builder.put(RecoverySettings.INDICES_RECOVERY_CONCURRENT_SMALL_FILE_STREAMS, RandomInts.randomIntBetween(random, 3, 6));\n             builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES, RandomInts.randomIntBetween(random, 2, 5));",
    "output": "Use private randomness in InternalTestCluster"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java b/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java\n--- a/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java\n+++ b/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java\n@@ -480,7 +480,7 @@ public SearchContext docIdsToLoad(int[] docIdsToLoad, int docsIdsToLoadFrom, int\n \n     @Override\n     public void accessed(long accessTime) {\n-        accessed(accessTime);\n+        in.accessed(accessTime);\n     }\n \n     @Override",
    "output": "Fix forgotten delegation"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n--- a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n@@ -325,6 +325,7 @@ public void testCorruptionOnNetworkLayer() throws ExecutionException, Interrupte\n \n         assertAcked(prepareCreate(\"test\").setSettings(ImmutableSettings.builder()\n                 .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, \"0\")\n+                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, between(1, 4)) // don't go crazy here it must recovery fast\n                 .put(InternalEngine.INDEX_FAIL_ON_CORRUPTION, true)\n                 // This does corrupt files on the replica, so we can't check:\n                 .put(MockFSDirectoryService.CHECK_INDEX_ON_CLOSE, false)",
    "output": "Make sure number of shard is low in network corruption tests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/client/RestClient.java b/src/test/java/org/elasticsearch/test/rest/client/RestClient.java\n--- a/src/test/java/org/elasticsearch/test/rest/client/RestClient.java\n+++ b/src/test/java/org/elasticsearch/test/rest/client/RestClient.java\n@@ -21,8 +21,10 @@\n import com.carrotsearch.randomizedtesting.RandomizedTest;\n import com.google.common.collect.Lists;\n import com.google.common.collect.Maps;\n+import org.apache.http.conn.HttpClientConnectionManager;\n import org.apache.http.impl.client.CloseableHttpClient;\n import org.apache.http.impl.client.HttpClients;\n+import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;\n import org.elasticsearch.client.support.Headers;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.logging.ESLogger;\n@@ -38,6 +40,7 @@\n import java.net.InetSocketAddress;\n import java.util.List;\n import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n \n /**\n  * REST client used to test the elasticsearch REST layer\n@@ -46,6 +49,7 @@\n public class RestClient implements Closeable {\n \n     private static final ESLogger logger = Loggers.getLogger(RestClient.class);\n+    private static final HttpClientConnectionManager connectionPool = new PoolingHttpClientConnectionManager(15, TimeUnit.SECONDS);\n \n     private final RestSpec restSpec;\n     private final CloseableHttpClient httpClient;\n@@ -218,7 +222,7 @@ protected HttpRequestBuilder httpRequestBuilder() {\n     }\n \n     protected CloseableHttpClient createHttpClient() {\n-        return HttpClients.createDefault();\n+        return HttpClients.createMinimal(connectionPool);\n     }\n \n     public InetSocketAddress[] httpAddresses() {",
    "output": "Use a pooling connection manager for REST tests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/authz/Privilege.java b/src/main/java/org/elasticsearch/shield/authz/Privilege.java\n--- a/src/main/java/org/elasticsearch/shield/authz/Privilege.java\n+++ b/src/main/java/org/elasticsearch/shield/authz/Privilege.java\n@@ -111,10 +111,9 @@ public static class Index extends AutomatonPrivilege<Index> {\n         public static final Index INDEX =           new Index(\"index\",          \"indices:data/write/index*\", \"indices:data/write/update\");\n         public static final Index DELETE =          new Index(\"delete\",         \"indices:data/write/delete*\");\n         public static final Index WRITE =           new Index(\"write\",          \"indices:data/write/*\");\n-        public static final Index BENCHMARK =       new Index(\"benchmark\",      \"indices:data/benchmark\");\n \n         private static final Index[] values = new Index[] {\n-            NONE, ALL, MANAGE, CREATE_INDEX, MONITOR, DATA_ACCESS, CRUD, READ, SEARCH, GET, INDEX, DELETE, WRITE, BENCHMARK\n+            NONE, ALL, MANAGE, CREATE_INDEX, MONITOR, DATA_ACCESS, CRUD, READ, SEARCH, GET, INDEX, DELETE, WRITE\n         };\n \n         public static final Predicate<String> ACTION_MATCHER = Privilege.Index.ALL.predicate();",
    "output": "Remove benchmark privileges and actions from codebase and docs Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/recovery/RelocationTests.java b/src/test/java/org/elasticsearch/recovery/RelocationTests.java\n--- a/src/test/java/org/elasticsearch/recovery/RelocationTests.java\n+++ b/src/test/java/org/elasticsearch/recovery/RelocationTests.java\n@@ -61,6 +61,7 @@\n import org.elasticsearch.test.BackgroundIndexer;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.ElasticsearchIntegrationTest.ClusterScope;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.elasticsearch.test.transport.MockTransportService;\n import org.elasticsearch.transport.*;\n import org.junit.Test;\n@@ -87,6 +88,7 @@\n /**\n  */\n @ClusterScope(scope = Scope.TEST, numDataNodes = 0)\n+@TestLogging(\"indices.recovery:TRACE,index.shard.service:TRACE\")\n public class RelocationTests extends ElasticsearchIntegrationTest {\n     private final TimeValue ACCEPTABLE_RELOCATION_TIME = new TimeValue(5, TimeUnit.MINUTES);\n ",
    "output": "Add back accidetially removed test logging"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java b/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java\n@@ -57,6 +57,7 @@ public void testSetIndexCompoundOnFlush() {\n \n     private void assertTotalCompoundSegments(int i, int t, String index) {\n         IndicesSegmentResponse indicesSegmentResponse = client().admin().indices().prepareSegments(index).get();\n+        assertNotNull(\"indices segments response should contain indices\", indicesSegmentResponse.getIndices());\n         IndexSegments indexSegments = indicesSegmentResponse.getIndices().get(index);\n         assertNotNull(indexSegments);\n         assertNotNull(indexSegments.getShards());",
    "output": "Add an assert for null indices in InternalEngineIntegrationTest"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n--- a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n+++ b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n@@ -138,7 +138,7 @@ public void testScriptFieldUsingSource() throws Exception {\n         assertThat(sObj2Arr2.get(0).toString(), equalTo(\"arr_value1\"));\n         assertThat(sObj2Arr2.get(1).toString(), equalTo(\"arr_value2\"));\n \n-        sObj2Arr2 = (List) response.getHits().getAt(0).field(\"s_obj2_arr2\").value();\n+        sObj2Arr2 = (List) response.getHits().getAt(0).field(\"s_obj2_arr2\").values();\n         assertThat(sObj2Arr2.size(), equalTo(2));\n         assertThat(sObj2Arr2.get(0).toString(), equalTo(\"arr_value1\"));\n         assertThat(sObj2Arr2.get(1).toString(), equalTo(\"arr_value2\"));",
    "output": "Fix expectations around script fields as a consequence of https://github.com/elasticsearch/elasticsearch/pull/8592"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/actions/AlertActionEntry.java b/src/main/java/org/elasticsearch/alerts/actions/AlertActionEntry.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/AlertActionEntry.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/AlertActionEntry.java\n@@ -195,7 +195,9 @@ public XContentBuilder toXContent(XContentBuilder historyEntry, Params params) t\n         historyEntry.endObject();\n         historyEntry.field(\"request\");\n         AlertUtils.writeSearchRequest(searchRequest, historyEntry, params);\n-        historyEntry.field(\"response\", searchResponse);\n+        if (searchResponse != null) {\n+            historyEntry.field(\"response\", searchResponse);\n+        }\n \n         historyEntry.startObject(\"actions\");\n         for (AlertAction action : actions) {\n\ndiff --git a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n@@ -240,11 +240,7 @@ AlertActionEntry parseHistory(String historyId, BytesReference source, long vers\n                             throw new ElasticsearchIllegalArgumentException(\"Unexpected field [\" + currentFieldName + \"]\");\n                     }\n                 } else {\n-                    if (token == XContentParser.Token.VALUE_NULL) {\n-                        logger.warn(\"Got null value for [{}]\", currentFieldName);\n-                    } else {\n-                        throw new ElasticsearchIllegalArgumentException(\"Unexpected token [\" + token + \"] for [\" + currentFieldName + \"]\");\n-                    }\n+                    throw new ElasticsearchIllegalArgumentException(\"Unexpected token [\" + token + \"] for [\" + currentFieldName + \"]\");\n                 }\n             }\n         } catch (IOException e) {",
    "output": "Remove error log for null values"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java b/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n--- a/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n+++ b/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n@@ -83,10 +83,6 @@ public void clearAlerts() throws Exception {\n         // Clear all internal alerting state for the next test method:\n         logger.info(\"[{}#{}]: clearing alerts\", getTestClass().getSimpleName(), getTestName());\n         stopAlerting();\n-        client().admin().indices().prepareDelete(AlertsStore.ALERT_INDEX, AlertActionManager.ALERT_HISTORY_INDEX_PREFIX + \"*\")\n-                .setIndicesOptions(IndicesOptions.lenientExpandOpen())\n-                .get();\n-        startAlerting();\n     }\n \n     protected BytesReference createAlertSource(String cron, SearchRequest request, String scriptTrigger) throws IOException {\n@@ -122,7 +118,6 @@ protected AlertsClient alertClient() {\n         return internalTestCluster().getInstance(AlertsClient.class);\n     }\n \n-\n     protected void assertAlertTriggered(final String alertName, final long minimumExpectedAlertActionsWithActionPerformed) throws Exception {\n         assertAlertTriggered(alertName, minimumExpectedAlertActionsWithActionPerformed, true);\n     }",
    "output": "Remove explicit delete index calls, because it redundant and the test framework wipes the clusters between tests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n@@ -22,9 +22,7 @@\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n import org.elasticsearch.common.bytes.BytesReference;\n-import org.elasticsearch.common.collect.ImmutableOpenMap;\n import org.elasticsearch.common.component.AbstractComponent;\n-import org.elasticsearch.common.hppc.cursors.ObjectCursor;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.joda.time.DateTime;\n import org.elasticsearch.common.joda.time.format.DateTimeFormat;\n@@ -148,11 +146,6 @@ public boolean started() {\n \n     /**\n      * Calculates the correct alert history index name for a given time using alertHistoryIndexTimeFormat\n-<<<<<<< HEAD\n-=======\n-     * @param time\n-     * @return\n->>>>>>> 7462f14f6d6a8c1529fc4f4203184f30c83057d7\n      */\n     public static String getAlertHistoryIndexNameForTime(DateTime time) {\n         StringBuffer sb = new StringBuffer(ALERT_HISTORY_INDEX_PREFIX);",
    "output": "Remove merge conflict in comment"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/transport/actions/stats/TransportAlertStatsAction.java b/src/main/java/org/elasticsearch/alerts/transport/actions/stats/TransportAlertStatsAction.java\n--- a/src/main/java/org/elasticsearch/alerts/transport/actions/stats/TransportAlertStatsAction.java\n+++ b/src/main/java/org/elasticsearch/alerts/transport/actions/stats/TransportAlertStatsAction.java\n@@ -14,6 +14,7 @@\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.threadpool.ThreadPool;\n@@ -64,7 +65,7 @@ protected void masterOperation(AlertsStatsRequest request, ClusterState state, A\n \n     @Override\n     protected ClusterBlockException checkBlock(AlertsStatsRequest request, ClusterState state) {\n-        return null;\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA);\n     }\n \n ",
    "output": "Add forgotten cluster block check"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java b/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java\n--- a/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java\n+++ b/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceTests.java\n@@ -34,6 +34,7 @@\n import org.elasticsearch.search.sort.SortOrder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.ElasticsearchIntegrationTest.ClusterScope;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.junit.After;\n import org.junit.Before;\n import org.junit.Test;\n@@ -103,7 +104,7 @@ private boolean noopBreakerUsed() {\n     }\n \n     @Test\n-    //@TestLogging(\"indices.breaker:TRACE,index.fielddata:TRACE,common.breaker:TRACE\")\n+    @TestLogging(\"indices.breaker:TRACE,index.fielddata:TRACE,common.breaker:TRACE\")\n     public void testMemoryBreaker() throws Exception {\n         if (noopBreakerUsed()) {\n             logger.info(\"--> noop breakers used, skipping test\");",
    "output": "Add additional logging to memoryCircuitBreaker test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java b/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java\n--- a/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java\n+++ b/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java\n@@ -192,8 +192,8 @@ public void testEncryption() {\n \tSettings settings = internalCluster().getInstance(Settings.class);\n \tSettings bucket = settings.getByPrefix(\"repositories.s3.\");\n \tAmazonS3 s3Client = internalCluster().getInstance(AwsS3Service.class).client(\n-\t\tbucket.get(\"endpoint\", settings.get(\"repositories.s3.endpoint\")),\n-\t\tbucket.get(\"protocol\", settings.get(\"repositories.s3.protocol\")),\n+\t\tnull,\n+\t\tnull,\n \t\tbucket.get(\"region\", settings.get(\"repositories.s3.region\")),\n \t\tbucket.get(\"access_key\", settings.get(\"cloud.aws.access_key\")),\n \t\tbucket.get(\"secret_key\", settings.get(\"cloud.aws.secret_key\")));",
    "output": "Remove unnecessary settings in test method"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java b/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n--- a/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n+++ b/src/test/java/org/elasticsearch/alerts/AbstractAlertingTests.java\n@@ -36,6 +36,7 @@\n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.elasticsearch.index.query.QueryBuilders.boolQuery;\n import static org.elasticsearch.index.query.QueryBuilders.matchQuery;\n+import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n import static org.hamcrest.Matchers.notNullValue;\n import static org.hamcrest.core.Is.is;\n@@ -275,11 +276,16 @@ public void close() throws IOException {\n             // First manually stop alerting on non elected master node, this will prevent that alerting becomes active\n             // on these nodes\n             for (String node : nodes) {\n-                _testCluster.getInstance(AlertManager.class, node).stop();\n+                AlertManager alertManager = _testCluster.getInstance(AlertManager.class, node);\n+                assertThat(alertManager.getState(), equalTo(State.STOPPED));\n+                alertManager.stop(); // Prevents these nodes from starting alerting when new elected master node is picked.\n             }\n \n             // Then stop alerting on elected master node and wait until alerting has stopped on it.\n             AlertManager alertManager = _testCluster.getInstance(AlertManager.class, masterNode);\n+            if (alertManager.getState() == State.STARTING) {\n+                while (alertManager.getState() != State.STARTED) {}\n+            }\n             alertManager.stop();\n             while (alertManager.getState() != State.STOPPED) {}\n ",
    "output": "Change the way alerting gets shut down when the test cluster gets closed"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/search/geo/GeoHashUtilsTests.java b/src/test/java/org/elasticsearch/index/search/geo/GeoHashUtilsTests.java\n--- a/src/test/java/org/elasticsearch/index/search/geo/GeoHashUtilsTests.java\n+++ b/src/test/java/org/elasticsearch/index/search/geo/GeoHashUtilsTests.java\n@@ -134,5 +134,20 @@ public void testNeighbours() {\n         neighbors = new ArrayList<>();\n         GeoHashUtils.addNeighbors(geohash, neighbors );\n         assertEquals(expectedNeighbors, neighbors);\n+\n+        // Border even and odd geohash\n+        geohash = \"ezzzz\";\n+        expectedNeighbors = new ArrayList<>();\n+        expectedNeighbors.add(\"gbpbn\");\n+        expectedNeighbors.add(\"gbpbp\");\n+        expectedNeighbors.add(\"u0000\");\n+        expectedNeighbors.add(\"ezzzy\");\n+        expectedNeighbors.add(\"spbpb\");\n+        expectedNeighbors.add(\"ezzzw\");\n+        expectedNeighbors.add(\"ezzzx\");\n+        expectedNeighbors.add(\"spbp8\");\n+        neighbors = new ArrayList<>();\n+        GeoHashUtils.addNeighbors(geohash, neighbors );\n+        assertEquals(expectedNeighbors, neighbors);\n     }\n }",
    "output": "Add unit test for even / odd boundary condition"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/scroll/SearchScrollWithFailingNodesTests.java b/src/test/java/org/elasticsearch/search/scroll/SearchScrollWithFailingNodesTests.java\n--- a/src/test/java/org/elasticsearch/search/scroll/SearchScrollWithFailingNodesTests.java\n+++ b/src/test/java/org/elasticsearch/search/scroll/SearchScrollWithFailingNodesTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.search.scroll;\n \n+import com.google.common.base.Predicate;\n import org.elasticsearch.action.index.IndexRequestBuilder;\n import org.elasticsearch.action.search.SearchResponse;\n import org.elasticsearch.cluster.routing.allocation.decider.ShardsLimitAllocationDecider;\n@@ -108,7 +109,6 @@ public void testScanScrollWithShardExceptions() throws Exception {\n             assertThat(searchResponse.getSuccessfulShards(), equalTo(numberOfSuccessfulShards));\n         } while (searchResponse.getHits().hits().length > 0);\n         assertThat(numHits, greaterThan(0l));\n-        clearScroll(\"_all\");\n     }\n \n }",
    "output": "Remove unnecessary clearScroll call - these contexts are released by delete index now"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java b/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java\n--- a/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java\n+++ b/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.action.support.broadcast.BroadcastOperationRequestBuilder;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.index.query.QueryBuilder;\n \n /**\n@@ -98,6 +99,14 @@ public CountRequestBuilder setQuery(BytesReference queryBinary) {\n         sourceBuilder().setQuery(queryBinary);\n         return this;\n     }\n+    \n+    /**\n+     * Constructs a new builder with a raw search query.\n+     */\n+    public CountRequestBuilder setQuery(XContentBuilder query) {\n+        return setQuery(query.bytes());\n+    }\n+\n \n     /**\n      * The source to execute.",
    "output": "Add utility method to CountRequestBuilder Allows to add a query to CountRequestBuilder as a XContentBuilder"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java b/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java\n--- a/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java\n@@ -34,7 +34,7 @@\n import java.util.Map;\n \n /**\n- * Same ad {@link MatchQueryParser} but has support for multiple fields.\n+ * Same as {@link MatchQueryParser} but has support for multiple fields.\n  */\n public class MultiMatchQueryParser implements QueryParser {\n \n@@ -142,11 +142,11 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n         }\n \n         if (value == null) {\n-            throw new QueryParsingException(parseContext.index(), \"No text specified for match_all query\");\n+            throw new QueryParsingException(parseContext.index(), \"No text specified for multi_match query\");\n         }\n \n         if (fieldNameWithBoosts.isEmpty()) {\n-            throw new QueryParsingException(parseContext.index(), \"No fields specified for match_all query\");\n+            throw new QueryParsingException(parseContext.index(), \"No fields specified for multi_match query\");\n         }\n         if (type == null) {\n             type = MultiMatchQueryBuilder.Type.BEST_FIELDS;\n@@ -198,4 +198,4 @@ private void extractFieldAndBoost(QueryParseContext parseContext, XContentParser\n             fieldNameWithBoosts.put(fField, fBoost);\n         }\n     }\n-}\n\\ No newline at end of file\n+}",
    "output": "Fix wrong error messages in MultiMatchQueryParser. Also fix a typo in the comment"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n@@ -355,13 +355,8 @@ public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower\n \n     private Query innerRangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, @Nullable DateTimeZone timeZone, @Nullable DateMathParser forcedDateParser) {\n         return NumericRangeQuery.newLongRange(names.indexName(), precisionStep,\n-<<<<<<< HEAD\n-                lowerTerm == null ? null : parseToMilliseconds(lowerTerm, false, timeZone, forcedDateParser == null ? dateMathParser : forcedDateParser),\n+                lowerTerm == null ? null : parseToMilliseconds(lowerTerm, !includeLower, timeZone, forcedDateParser == null ? dateMathParser : forcedDateParser),\n                 upperTerm == null ? null : parseToMilliseconds(upperTerm, includeUpper, timeZone, forcedDateParser == null ? dateMathParser : forcedDateParser),\n-=======\n-                lowerTerm == null ? null : parseToMilliseconds(lowerTerm, context, !includeLower, timeZone, forcedDateParser == null ? dateMathParser : forcedDateParser),\n-                upperTerm == null ? null : parseToMilliseconds(upperTerm, context, includeUpper, timeZone, forcedDateParser == null ? dateMathParser : forcedDateParser),\n->>>>>>> DateMath: Fix semantics of rounding with inclusive/exclusive ranges.\n                 includeLower, includeUpper);\n     }\n ",
    "output": "Fix compile error from bad merge in"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n--- a/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/actions/AlertActionManager.java\n@@ -245,7 +245,7 @@ public void addAlertAction(Alert alert, DateTime scheduledFireTime, DateTime fir\n                 .setSource(XContentFactory.jsonBuilder().value(entry))\n                 .setOpType(IndexRequest.OpType.CREATE)\n                 .get();\n-        logger.info(\"Adding alert action for alert [{}]\", alert.alertName());\n+        logger.debug(\"Adding alert action for alert [{}]\", alert.alertName());\n         entry.setVersion(response.getVersion());\n         long currentSize = actionsToBeProcessed.size() + 1;\n         actionsToBeProcessed.add(entry);\n@@ -311,7 +311,7 @@ public void run() {\n                     return;\n                 }\n                 updateHistoryEntry(entry, AlertActionState.SEARCH_UNDERWAY);\n-                logger.info(\"Running an alert action entry for [{}]\", entry.getAlertName());\n+                logger.debug(\"Running an alert action entry for [{}]\", entry.getAlertName());\n                 TriggerResult trigger = alertManager.executeAlert(entry);\n                 if (trigger.isTriggered()) {\n                     if (entry.getState() != AlertActionState.THROTTLED) {",
    "output": "Change info log into debug log"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertsStore.java b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n@@ -230,7 +230,6 @@ private Alert parseAlert(String alertId, SearchHit sh) {\n     protected Alert parseAlert(String alertName, BytesReference source) {\n         Alert alert = new Alert();\n         alert.alertName(alertName);\n-        logger.error(\"Source : [{}]\", source.toUtf8());\n         try (XContentParser parser = XContentHelper.createParser(source)) {\n             String currentFieldName = null;\n             XContentParser.Token token = parser.nextToken();",
    "output": "Remove error log statement"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertsStore.java b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n@@ -179,7 +179,7 @@ public boolean started() {\n     }\n \n     public void stop() {\n-        if (started.compareAndSet(false, true)) {\n+        if (started.compareAndSet(true, false)) {\n             clear();\n             logger.info(\"Stopped alert store\");\n         }",
    "output": "Fix bug, expected and update was swapped"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java b/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java\n@@ -529,16 +529,20 @@ public void onFailure(Throwable t) {\n         for (DocumentMapper documentMapper : documentMappersToUpdate) {\n             mappingUpdatedAction.updateMappingOnMaster(indexService.index().getName(), documentMapper, indexService.indexUUID(), listener);\n         }\n-        try {\n-            if (!updatedOnMaster.await(internalActionTimeout.millis(), TimeUnit.MILLISECONDS)) {\n-                logger.debug(\"[{}][{}] recovery [phase2] to {}: waiting on pending mapping update timed out. waited [{}]\",\n-                        indexName, shardId, request.targetNode(), internalActionTimeout);\n+        cancelableThreads.run(new Interruptable() {\n+            @Override\n+            public void run() throws InterruptedException {\n+                try {\n+                    if (!updatedOnMaster.await(internalActionTimeout.millis(), TimeUnit.MILLISECONDS)) {\n+                        logger.debug(\"[{}][{}] recovery [phase2] to {}: waiting on pending mapping update timed out. waited [{}]\",\n+                                indexName, shardId, request.targetNode(), internalActionTimeout);\n+                    }\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                    logger.debug(\"interrupted while waiting for mapping to update on master\");\n+                }\n             }\n-        } catch (InterruptedException e) {\n-            Thread.currentThread().interrupt();\n-            logger.debug(\"interrupted while waiting for mapping to update on master\");\n-        }\n-\n+        });\n     }\n \n     /**",
    "output": "Add missing await into an interruptable block"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertManager.java b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n@@ -200,10 +200,9 @@ public void run() {\n                 });\n             } else {\n                 if (event.state().blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)) {\n-                    return; // wait until the gateway has recovered from disk\n-                }\n-                if (isStarted()) {\n-                    return; // We're already started\n+                    // wait until the gateway has recovered from disk, otherwise we think may not have .alerts and\n+                    // a .alertshistory index, but they may not have been restored from the cluster state on disk\n+                    return;\n                 }\n                 if (state.compareAndSet(State.STOPPED, State.LOADING)) {\n                     initialize(event.state());",
    "output": "Remove useless if check"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertManager.java b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertManager.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertManager.java\n@@ -151,7 +151,11 @@ public TriggerResult executeAlert(AlertActionEntry entry) throws IOException {\n     }\n \n \n-    public void stop() {\n+    // This is synchronized, because this may first be called from the cluster changed event and then from before close\n+    // when a node closes. The stop also stops the scheduler which has several background threads. If this method is\n+    // invoked in that order that node closes and the test framework complains then about the fact that there are still\n+    // threads alive.\n+    public synchronized void stop() {\n         if (state.compareAndSet(State.LOADING, State.STOPPED) || state.compareAndSet(State.STARTED, State.STOPPED)) {\n             logger.info(\"Stopping alert manager...\");\n             scheduler.stop();",
    "output": "Make AlertManager#stop() synchronized so that the call from beforeClose waits if an stop is being performed already. This prevents the test framework to complain about the fact that threads are lingering around when the test cluster has been shutdown"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java b/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java\n--- a/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java\n+++ b/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java\n@@ -27,6 +27,7 @@\n import org.elasticsearch.client.Client;\n import org.elasticsearch.search.SearchHits;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.hamcrest.Matchers;\n import org.junit.Test;\n \n@@ -51,17 +52,20 @@ public class SearchWhileRelocatingTests extends ElasticsearchIntegrationTest {\n //   we just make sure if we get a partial result without a failure that the postsearch is ok!\n     @Test\n     @Nightly\n+    @TestLogging(\"action.search:TRACE\")\n     public void testSearchAndRelocateConcurrently0Replicas() throws Exception {\n         testSearchAndRelocateConcurrently(0);\n     }\n \n     @Test\n     @Nightly\n+    @TestLogging(\"action.search:TRACE\")\n     public void testSearchAndRelocateConcurrently1Replicas() throws Exception {\n         testSearchAndRelocateConcurrently(1);\n     }\n \n     @Test\n+    @TestLogging(\"action.search:TRACE\")\n     public void testSearchAndRelocateConcurrentlyRanodmReplicas() throws Exception {\n         testSearchAndRelocateConcurrently(randomIntBetween(0, 1));\n     }",
    "output": "Add search trace logging for debugging"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n--- a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n+++ b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n@@ -62,12 +62,13 @@ public class LogConfigurator {\n             .put(\"null\", \"org.apache.log4j.NullAppender\")\n             .put(\"rollingFile\", \"org.apache.log4j.RollingFileAppender\")\n             .put(\"extrasRollingFile\", \"org.apache.log4j.rolling.RollingFileAppender\")\n-            .put(\"timeBased\", \"org.apache.log4j.rolling.TimeBasedRollingPolicy\")\n             .put(\"smtp\", \"org.apache.log4j.net.SMTPAppender\")\n             .put(\"socket\", \"org.apache.log4j.net.SocketAppender\")\n             .put(\"socketHub\", \"org.apache.log4j.net.SocketHubAppender\")\n             .put(\"syslog\", \"org.apache.log4j.net.SyslogAppender\")\n             .put(\"telnet\", \"org.apache.log4j.net.TelnetAppender\")\n+                    // policies\n+            .put(\"timeBased\", \"org.apache.log4j.rolling.TimeBasedRollingPolicy\")\n                     // layouts\n             .put(\"simple\", \"org.apache.log4j.SimpleLayout\")\n             .put(\"html\", \"org.apache.log4j.HTMLLayout\")",
    "output": "Fix example in logging daily rotate configuration PR #8464 come with a bug in the example provided. First, the current log file is not compressed so it should not end with `.gz`. Second, conversion pattern was removing all the log content but was printing only the log date. Then, the current log filename was hardcoded to `elasticsearch` instead of the cluster name"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java b/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoveryStatus.java\n@@ -117,6 +117,7 @@ public Store store() {\n \n     /** set a thread that should be interrupted if the recovery is canceled */\n     public void setWaitingRecoveryThread(Thread thread) {\n+        ensureRefCount();\n         waitingRecoveryThread.set(thread);\n     }\n \n@@ -160,6 +161,7 @@ public void cancel(String reason) {\n \n             final Thread thread = waitingRecoveryThread.get();\n             if (thread != null) {\n+                logger.debug(\"interrupting recovery thread on canceled recovery\");\n                 thread.interrupt();\n             }\n         }",
    "output": "Add more debug logging if recovery thread got iterrupted"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java b/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java\n--- a/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java\n+++ b/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java\n@@ -19,6 +19,8 @@\n \n package org.elasticsearch.action.bulk;\n \n+import org.elasticsearch.action.RoutingMissingException;\n+\n import com.google.common.collect.Lists;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n@@ -285,7 +287,8 @@ private void executeBulk(final BulkRequest bulkRequest, final long startTime, fi\n                 String concreteIndex = concreteIndices.getConcreteIndex(updateRequest.index());\n                 MappingMetaData mappingMd = clusterState.metaData().index(concreteIndex).mappingOrDefault(updateRequest.type());\n                 if (mappingMd != null && mappingMd.routing().required() && updateRequest.routing() == null) {\n-                    continue; // What to do?\n+                    //Bulk update child doc, NPE error message when parent is not specified #8365 \n+                    throw new RoutingMissingException(concreteIndex, updateRequest.type(), updateRequest.id());\n                 }\n                 ShardId shardId = clusterService.operationRouting().indexShards(clusterState, concreteIndex, updateRequest.type(), updateRequest.id(), updateRequest.routing()).shardId();\n                 List<BulkItemRequest> list = requestsByShard.get(shardId);",
    "output": "Fix of Bulk update child doc, NPE error message when parent is not specified - Throw an RoutingMissingException instead of NPE"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n--- a/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n+++ b/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n@@ -270,7 +270,7 @@ protected void closeInternal() {\n      * Returns all currently lock shards\n      */\n     public Set<ShardId> lockedShards() {\n-        synchronized (this) {\n+        synchronized (shardLocks) {\n             ImmutableSet.Builder<ShardId> builder = ImmutableSet.builder();\n             return builder.addAll(shardLocks.keySet()).build();\n         }",
    "output": "Fix synchronization - leftover from refactoring"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/license/plugin/core/ExpiredLicenseException.java b/src/main/java/org/elasticsearch/license/plugin/core/ExpiredLicenseException.java\n--- a/src/main/java/org/elasticsearch/license/plugin/core/ExpiredLicenseException.java\n+++ b/src/main/java/org/elasticsearch/license/plugin/core/ExpiredLicenseException.java\n@@ -0,0 +1,24 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.license.plugin.core;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.rest.RestStatus;\n+\n+/**\n+ * Exception to be thrown when a feature action requires a valid license\n+ */\n+public class ExpiredLicenseException extends ElasticsearchException {\n+\n+    public ExpiredLicenseException(String feature) {\n+        super(feature + \" license has expired\");\n+    }\n+\n+    @Override\n+    public RestStatus status() {\n+        return RestStatus.UNAUTHORIZED;\n+    }\n+}",
    "output": "Add Generic ExpiredLicenseException closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java b/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java\n--- a/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java\n+++ b/src/main/java/org/elasticsearch/cloud/azure/blobstore/AzureBlobContainer.java\n@@ -95,10 +95,9 @@ public OutputStream createOutput(String blobName) throws IOException {\n     }\n \n     @Override\n-    public boolean deleteBlob(String blobName) throws IOException {\n+    public void deleteBlob(String blobName) throws IOException {\n         try {\n             blobStore.client().deleteBlob(blobStore.container(), buildKey(blobName));\n-            return true;\n         } catch (URISyntaxException e) {\n             logger.warn(\"can not access [{}] in container {{}}: {}\", blobName, blobStore.container(), e.getMessage());\n             throw new IOException(e);",
    "output": "Change in BlobContainer deleteBlob does not return boolean Due to this change: https://github.com/elasticsearch/elasticsearch/pull/8366"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobContainer.java b/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobContainer.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobContainer.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/blobstore/S3BlobContainer.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.cloud.aws.blobstore;\n \n+import com.amazonaws.AmazonClientException;\n import com.amazonaws.services.s3.model.AmazonS3Exception;\n import com.amazonaws.services.s3.model.ObjectListing;\n import com.amazonaws.services.s3.model.S3Object;\n@@ -68,9 +69,12 @@ public boolean blobExists(String blobName) {\n     }\n \n     @Override\n-    public boolean deleteBlob(String blobName) throws IOException {\n-        blobStore.client().deleteObject(blobStore.bucket(), buildKey(blobName));\n-        return true;\n+    public void deleteBlob(String blobName) throws IOException {\n+        try {\n+            blobStore.client().deleteObject(blobStore.bucket(), buildKey(blobName));\n+        } catch (AmazonClientException e) {\n+            throw new IOException(\"Exception when deleting blob [\" + blobName + \"]\", e);\n+        }\n     }\n \n     @Override",
    "output": "Upgrade S3BlobContainer because BlobContainer changed See elasticsearch/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java b/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.node.DiscoveryNodeService;\n+import org.elasticsearch.cluster.settings.DynamicSettings;\n import org.elasticsearch.common.collect.ImmutableList;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.network.NetworkService;\n@@ -48,9 +49,9 @@ public class AzureDiscovery extends ZenDiscovery {\n     public AzureDiscovery(Settings settings, ClusterName clusterName, ThreadPool threadPool, TransportService transportService,\n                           ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n                           DiscoveryNodeService discoveryNodeService, AzureComputeService azureService, NetworkService networkService,\n-                          DiscoverySettings discoverySettings, ElectMasterService electMasterService) {\n+                          DiscoverySettings discoverySettings, ElectMasterService electMasterService, DynamicSettings dynamicSettings) {\n         super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n-                discoveryNodeService, pingService, electMasterService, discoverySettings);\n+                discoveryNodeService, pingService, electMasterService, discoverySettings, dynamicSettings);\n         if (settings.getAsBoolean(\"cloud.enabled\", true)) {\n             ImmutableList<? extends ZenPing> zenPings = pingService.zenPings();\n             UnicastZenPing unicastZenPing = null;",
    "output": "Fix constructor for ZenDiscovery's subclass"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java b/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n@@ -19,11 +19,11 @@\n \n package org.elasticsearch.discovery.gce;\n \n-import org.elasticsearch.Version;\n import org.elasticsearch.cloud.gce.GceComputeService;\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.node.DiscoveryNodeService;\n+import org.elasticsearch.cluster.settings.DynamicSettings;\n import org.elasticsearch.common.collect.ImmutableList;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.network.NetworkService;\n@@ -48,9 +48,9 @@ public GceDiscovery(Settings settings, ClusterName clusterName, ThreadPool threa\n                         ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n                         DiscoveryNodeService discoveryNodeService, GceComputeService gceComputeService,\n                         NetworkService networkService, DiscoverySettings discoverySettings,\n-                        ElectMasterService electMasterService) {\n+                        ElectMasterService electMasterService, DynamicSettings dynamicSettings) {\n         super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n-                discoveryNodeService, pingService, electMasterService, Version.CURRENT, discoverySettings);\n+                discoveryNodeService, pingService, electMasterService, discoverySettings, dynamicSettings);\n         if (settings.getAsBoolean(\"cloud.enabled\", true)) {\n             ImmutableList<? extends ZenPing> zenPings = pingService.zenPings();\n             UnicastZenPing unicastZenPing = null;",
    "output": "Fix constructor for ZenDiscovery's subclass"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/SmartChineseTokenizerTokenizerFactory.java b/src/main/java/org/elasticsearch/index/analysis/SmartChineseTokenizerTokenizerFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/SmartChineseTokenizerTokenizerFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/SmartChineseTokenizerTokenizerFactory.java\n@@ -37,7 +37,7 @@ public SmartChineseTokenizerTokenizerFactory(Index index, @IndexSettings Setting\n     }\n \n     @Override\n-    public Tokenizer create(Reader reader) {\n-        return new HMMChineseTokenizer(reader);\n+    public Tokenizer create() {\n+        return new HMMChineseTokenizer();\n     }\n }\n\ndiff --git a/src/main/java/org/elasticsearch/indices/analysis/smartcn/SmartChineseIndicesAnalysis.java b/src/main/java/org/elasticsearch/indices/analysis/smartcn/SmartChineseIndicesAnalysis.java\n--- a/src/main/java/org/elasticsearch/indices/analysis/smartcn/SmartChineseIndicesAnalysis.java\n+++ b/src/main/java/org/elasticsearch/indices/analysis/smartcn/SmartChineseIndicesAnalysis.java\n@@ -52,8 +52,8 @@ public String name() {\n             }\n \n             @Override\n-            public Tokenizer create(Reader reader) {\n-                return new HMMChineseTokenizer(reader);\n+            public Tokenizer create() {\n+                return new HMMChineseTokenizer();\n             }\n         }));\n \n@@ -65,8 +65,8 @@ public String name() {\n             }\n \n             @Override\n-            public Tokenizer create(Reader reader) {\n-                return new HMMChineseTokenizer(reader);\n+            public Tokenizer create() {\n+                return new HMMChineseTokenizer();\n             }\n         }));\n ",
    "output": "Upgrade to lucene 5 snapshot"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java b/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n@@ -19,7 +19,7 @@\n \n package org.elasticsearch.script.python;\n \n-import org.apache.lucene.index.AtomicReaderContext;\n+import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.search.Scorer;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.component.AbstractComponent;\n@@ -171,7 +171,7 @@ public void setScorer(Scorer scorer) {\n         }\n \n         @Override\n-        public void setNextReader(AtomicReaderContext context) {\n+        public void setNextReader(LeafReaderContext context) {\n             lookup.setNextReader(context);\n         }\n ",
    "output": "Upgrade to lucene 5 snapshot"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n@@ -19,7 +19,7 @@\n \n package org.elasticsearch.script.javascript;\n \n-import org.apache.lucene.index.AtomicReaderContext;\n+import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.search.Scorer;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.component.AbstractComponent;\n@@ -230,7 +230,7 @@ public void setScorer(Scorer scorer) {\n         }\n \n         @Override\n-        public void setNextReader(AtomicReaderContext context) {\n+        public void setNextReader(LeafReaderContext context) {\n             lookup.setNextReader(context);\n         }\n ",
    "output": "Upgrade to lucene 5 snapshot"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/query/TemplateQueryTest.java b/src/test/java/org/elasticsearch/index/query/TemplateQueryTest.java\n--- a/src/test/java/org/elasticsearch/index/query/TemplateQueryTest.java\n+++ b/src/test/java/org/elasticsearch/index/query/TemplateQueryTest.java\n@@ -264,7 +264,7 @@ public void testIndexedTemplateClient() throws Exception {\n         templateParams.put(\"fieldParam\", \"foo\");\n \n         SearchResponse searchResponse = client().prepareSearch(\"test\").setTypes(\"type\").\n-                setTemplateName(\"testTemplate\").setTemplateType(ScriptService.ScriptType.INDEXED).setTemplateType(ScriptService.ScriptType.INDEXED).setTemplateParams(templateParams).get();\n+                setTemplateName(\"testTemplate\").setTemplateType(ScriptService.ScriptType.INDEXED).setTemplateParams(templateParams).get();\n         assertHitCount(searchResponse, 4);\n \n         DeleteIndexedScriptResponse deleteResponse = client().prepareDeleteIndexedScript(\"mustache\",\"testTemplate\").get();",
    "output": "Remove redundant call to setTemplateType()"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java b/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java\n--- a/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java\n+++ b/src/test/java/org/elasticsearch/indices/stats/IndexStatsTests.java\n@@ -321,7 +321,6 @@ public void nonThrottleStats() throws Exception {\n     }\n \n     @Test\n-    @LuceneTestCase.AwaitsFix(bugUrl = \"This test intermittently fails with no throttling happening.\")\n     public void throttleStats() throws Exception {\n         assertAcked(prepareCreate(\"test\")\n                 .setSettings(ImmutableSettings.builder()\n@@ -363,7 +362,9 @@ public void throttleStats() throws Exception {\n             }\n         }\n         stats = client().admin().indices().prepareStats().execute().actionGet();\n-        assertThat(stats.getPrimaries().getIndexing().getTotal().getThrottleTimeInMillis(), greaterThan(0l));\n+        if (done) {\n+            assertThat(stats.getPrimaries().getIndexing().getTotal().getThrottleTimeInMillis(), greaterThan(0l));\n+        }\n     }\n \n     @Test",
    "output": "Fix the throttle test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java b/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java\n--- a/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.node.DiscoveryNodeService;\n+import org.elasticsearch.cluster.settings.DynamicSettings;\n import org.elasticsearch.common.collect.ImmutableList;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.Settings;\n@@ -45,9 +46,9 @@ public class Ec2Discovery extends ZenDiscovery {\n     public Ec2Discovery(Settings settings, ClusterName clusterName, ThreadPool threadPool, TransportService transportService,\n                         ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n                         DiscoveryNodeService discoveryNodeService, AwsEc2Service ec2Service, DiscoverySettings discoverySettings,\n-                        ElectMasterService electMasterService) {\n+                        ElectMasterService electMasterService, DynamicSettings dynamicSettings) {\n         super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n-                discoveryNodeService, pingService, electMasterService, discoverySettings);\n+                discoveryNodeService, pingService, electMasterService, discoverySettings, dynamicSettings);\n         if (settings.getAsBoolean(\"cloud.enabled\", true)) {\n             ImmutableList<? extends ZenPing> zenPings = pingService.zenPings();\n             UnicastZenPing unicastZenPing = null;",
    "output": "Fix constructors of ZenDiscovery's sub classes"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java b/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java\n--- a/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java\n+++ b/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java\n@@ -58,7 +58,8 @@ public class UpgradeTest extends ElasticsearchBackwardsCompatIntegrationTest {\n \n     @BeforeClass\n     public static void checkUpgradeVersion() {\n-        boolean luceneVersionMatches = globalCompatibilityVersion().luceneVersion.equals(Version.CURRENT.luceneVersion);\n+        final boolean luceneVersionMatches = (globalCompatibilityVersion().luceneVersion.major == Version.CURRENT.luceneVersion.major\n+                && globalCompatibilityVersion().luceneVersion.minor == Version.CURRENT.luceneVersion.minor);\n         assumeFalse(\"lucene versions must be different to run upgrade test\", luceneVersionMatches);\n     }\n ",
    "output": "Upgrade test can only run if major or minor version differs"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java b/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java\n--- a/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java\n+++ b/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java\n@@ -21,7 +21,6 @@\n \n import org.apache.log4j.Appender;\n import org.apache.log4j.Logger;\n-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;\n import org.elasticsearch.common.logging.log4j.Log4jESLogger;\n import org.elasticsearch.common.logging.log4j.Log4jESLoggerFactory;\n import org.elasticsearch.common.logging.log4j.LogConfigurator;\n@@ -40,10 +39,11 @@\n  */\n public class LoggingConfigurationTests extends ElasticsearchTestCase {\n \n-    @AwaitsFix(bugUrl = \"relates to commit 4ebbb657\")\n+    // @AwaitsFix(bugUrl = \"relates to commit 4ebbb657\")\n     @Test\n     public void testMultipleConfigs() throws Exception {\n         File configDir = resolveConfigDir();\n+        logger.info(\"Using config directory: {}\", configDir.getAbsolutePath());\n         Settings settings = ImmutableSettings.builder()\n                 .put(\"path.conf\", configDir.getAbsolutePath())\n                 .build();",
    "output": "Add additional logging to LoggingConfigurationTests This is to try to determine why the test passes locally but not on the CI builds"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/alerts/AlertsStore.java b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n--- a/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n+++ b/src/main/java/org/elasticsearch/alerts/AlertsStore.java\n@@ -185,7 +185,7 @@ private void loadAlerts() {\n                 .setTypes(AlertManager.ALERT_TYPE)\n                 .setIndices(AlertManager.ALERT_INDEX).get();\n         try {\n-            for (; response.getHits().hits().length != 0; response = client.prepareSearchScroll(response.getScrollId()).setScroll(scrollTimeout).get()) {\n+            while (response.getHits().hits().length != 0) {\n                 for (SearchHit sh : response.getHits()) {\n                     String alertId = sh.getId();\n                     Alert alert = parseAlert(alertId, sh);",
    "output": "Make more readable"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java b/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java\n--- a/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java\n+++ b/src/test/java/org/elasticsearch/common/logging/LoggingConfigurationTests.java\n@@ -21,6 +21,7 @@\n \n import org.apache.log4j.Appender;\n import org.apache.log4j.Logger;\n+import org.apache.lucene.util.LuceneTestCase.AwaitsFix;\n import org.elasticsearch.common.logging.log4j.Log4jESLogger;\n import org.elasticsearch.common.logging.log4j.Log4jESLoggerFactory;\n import org.elasticsearch.common.logging.log4j.LogConfigurator;\n@@ -39,6 +40,7 @@\n  */\n public class LoggingConfigurationTests extends ElasticsearchTestCase {\n \n+    @AwaitsFix(bugUrl = \"relates to commit 4ebbb657\")\n     @Test\n     public void testMultipleConfigs() throws Exception {\n         File configDir = resolveConfigDir();",
    "output": "Add awaits fix to failing LoggingConfigurationTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java b/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java\n--- a/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java\n+++ b/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java\n@@ -115,7 +115,7 @@ public ExitStatus execute(Settings settings, Environment env) throws Exception {\n \n             terminal.println(\"## Extracted text\");\n             terminal.println(\"--------------------- BEGIN -----------------------\");\n-            terminal.println(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()));\n+            terminal.println(\"%s\", doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()));\n             terminal.println(\"---------------------- END ------------------------\");\n             terminal.println(\"## Metadata\");\n             printMetadataContent(doc, AttachmentMapper.FieldNames.AUTHOR);",
    "output": "Fix test Related to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java b/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java\n--- a/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java\n+++ b/src/test/java/org/elasticsearch/plugin/mapper/attachments/test/StandaloneTest.java\n@@ -106,7 +106,7 @@ public ExitStatus execute(Settings settings, Environment env) throws Exception {\n             }\n \n             if (size >= 0) {\n-                builder.field(\"_indexed_chars\", 10);\n+                builder.field(\"_indexed_chars\", size);\n             }\n \n             BytesReference json = builder.endObject().endObject().bytes();",
    "output": "Fix test Related to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/authz/store/FileRolesStoreTests.java b/src/test/java/org/elasticsearch/shield/authz/store/FileRolesStoreTests.java\n--- a/src/test/java/org/elasticsearch/shield/authz/store/FileRolesStoreTests.java\n+++ b/src/test/java/org/elasticsearch/shield/authz/store/FileRolesStoreTests.java\n@@ -103,14 +103,16 @@ public void testDefaultRolesFile() throws Exception {\n         Path path = Paths.get(getClass().getResource(\"default_roles.yml\").toURI());\n         Map<String, Permission.Global> roles = FileRolesStore.parseFile(path, logger, mock(AuthorizationService.class));\n         assertThat(roles, notNullValue());\n-        assertThat(roles.size(), is(6));\n+        assertThat(roles.size(), is(8));\n \n         assertThat(roles, hasKey(\"admin\"));\n         assertThat(roles, hasKey(\"power_user\"));\n         assertThat(roles, hasKey(\"user\"));\n         assertThat(roles, hasKey(\"kibana3\"));\n         assertThat(roles, hasKey(\"kibana4\"));\n         assertThat(roles, hasKey(\"logstash\"));\n+        assertThat(roles, hasKey(\"marvel_user\"));\n+        assertThat(roles, hasKey(\"marvel_agent\"));\n     }\n \n     @Test",
    "output": "Add intro text to Clients page, general fixes elsewhere"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java b/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java\n@@ -27,11 +27,7 @@\n import org.elasticsearch.index.shard.ShardId;\n import org.elasticsearch.index.shard.service.IndexShard;\n import org.elasticsearch.index.shard.service.InternalIndexShard;\n-import org.elasticsearch.index.store.Store;\n \n-import java.io.IOException;\n-import java.sql.Timestamp;\n-import java.util.Map;\n import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.atomic.AtomicBoolean;\n ",
    "output": "Remove unused imports"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -58,6 +58,9 @@\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.metadata.MappingMetaData;\n import org.elasticsearch.cluster.metadata.MetaData;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.Priority;",
    "output": "Add missing imports"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n--- a/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n+++ b/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java\n@@ -67,6 +67,7 @@ public class LogConfigurator {\n             .put(\"html\", \"org.apache.log4j.HTMLLayout\")\n             .put(\"pattern\", \"org.apache.log4j.PatternLayout\")\n             .put(\"consolePattern\", \"org.apache.log4j.PatternLayout\")\n+            .put(\"enhancedPattern\", \"org.apache.log4j.EnhancedPatternLayout\")\n             .put(\"ttcc\", \"org.apache.log4j.TTCCLayout\")\n             .put(\"xml\", \"org.apache.log4j.XMLLayout\")\n             .immutableMap();",
    "output": "Add EnhancedPatternLayout to logging.yml options"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/transport/SecuredTransportModule.java b/src/main/java/org/elasticsearch/shield/transport/SecuredTransportModule.java\n--- a/src/main/java/org/elasticsearch/shield/transport/SecuredTransportModule.java\n+++ b/src/main/java/org/elasticsearch/shield/transport/SecuredTransportModule.java\n@@ -53,6 +53,7 @@ protected void configure(boolean clientMode) {\n         if (clientMode) {\n             // no ip filtering on the client\n             bind(N2NNettyUpstreamHandler.class).toProvider(Providers.<N2NNettyUpstreamHandler>of(null));\n+            bind(TransportFilter.class).toInstance(TransportFilter.NOOP);\n             return;\n         }\n \n\ndiff --git a/src/main/java/org/elasticsearch/shield/transport/TransportFilter.java b/src/main/java/org/elasticsearch/shield/transport/TransportFilter.java\n--- a/src/main/java/org/elasticsearch/shield/transport/TransportFilter.java\n+++ b/src/main/java/org/elasticsearch/shield/transport/TransportFilter.java\n@@ -13,6 +13,8 @@\n  */\n public interface TransportFilter {\n \n+    static final TransportFilter NOOP = new Base();\n+\n     /**\n      * Called just before the given request is about to be sent. Any exception thrown\n      * by this method will stop the request from being sent.",
    "output": "Fix Transport Client that start up with shield in the classpath Now a NOOP transport filter is bound by to the secured transport service in a transport client Fixes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/IndexPrimaryShardNotAllocatedException.java b/src/main/java/org/elasticsearch/indices/IndexPrimaryShardNotAllocatedException.java\n--- a/src/main/java/org/elasticsearch/indices/IndexPrimaryShardNotAllocatedException.java\n+++ b/src/main/java/org/elasticsearch/indices/IndexPrimaryShardNotAllocatedException.java\n@@ -35,6 +35,6 @@ public IndexPrimaryShardNotAllocatedException(Index index) {\n \n     @Override\n     public RestStatus status() {\n-        return RestStatus.CONFLICT;\n+        return RestStatus.INTERNAL_SERVER_ERROR;\n     }\n }",
    "output": "Change IndexPrimaryShardNotAllocatedException from 409 (RestStatus.CONFLICT) to 500 (RestStatus.INTERNAL_SERVER_ERROR) ,"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/authc/ldap/LdapGroupToRoleMapper.java b/src/main/java/org/elasticsearch/shield/authc/ldap/LdapGroupToRoleMapper.java\n--- a/src/main/java/org/elasticsearch/shield/authc/ldap/LdapGroupToRoleMapper.java\n+++ b/src/main/java/org/elasticsearch/shield/authc/ldap/LdapGroupToRoleMapper.java\n@@ -33,7 +33,7 @@\n  */\n public class LdapGroupToRoleMapper extends AbstractComponent {\n \n-    public static final String DEFAULT_FILE_NAME = \"role_mapping\";\n+    public static final String DEFAULT_FILE_NAME = \"role_mapping.yml\";\n     public static final String ROLE_MAPPING_FILE_SETTING = \"files.role_mapping\";\n     public static final String USE_UNMAPPED_GROUPS_AS_ROLES_SETTING = \"unmapped_groups_as_roles\";\n ",
    "output": "Fix default ldap group to role mapping file Description: This fixes the name of the default file for group to role mapping. It was missing the extension"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/SearchRequest.java b/src/main/java/org/elasticsearch/action/search/SearchRequest.java\n--- a/src/main/java/org/elasticsearch/action/search/SearchRequest.java\n+++ b/src/main/java/org/elasticsearch/action/search/SearchRequest.java\n@@ -371,7 +371,7 @@ public SearchRequest extraSource(Map extraSource) {\n             builder.map(extraSource);\n             return extraSource(builder);\n         } catch (IOException e) {\n-            throw new ElasticsearchGenerationException(\"Failed to generate [\" + source + \"]\", e);\n+            throw new ElasticsearchGenerationException(\"Failed to generate [\" + extraSource + \"]\", e);\n         }\n     }\n ",
    "output": "Fix copy/paste mistake in SearchRequest.extraSource's exception message"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java b/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java\n--- a/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java\n+++ b/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeTest.java\n@@ -65,7 +65,6 @@ protected int minExternalNodes() {\n     }\n \n     public void testUpgrade() throws Exception {\n-        Loggers.getLogger(UpgradeTest.class).setLevel(\"DEBUG\");\n \n         int numIndexes = randomIntBetween(2, 4);\n         String[] indexNames = new String[numIndexes];\n@@ -152,12 +151,7 @@ public boolean apply(Object o) {\n         logSegmentsState(null);\n         assertUpgraded(httpClient, null);\n     }\n-    \n-    @After\n-    void restLogLevel() {\n-        Loggers.getLogger(UpgradeTest.class).setLevel(\"INFO\");\n-    }\n-    \n+\n     void logSegmentsState(String index) throws Exception {\n         // double check using the segments api that all segments are actually upgraded\n         IndicesSegmentResponse segsRsp;",
    "output": "Remove unnecessary log level setting in upgrade test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeReallyOldIndexTest.java b/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeReallyOldIndexTest.java\n--- a/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeReallyOldIndexTest.java\n+++ b/src/test/java/org/elasticsearch/rest/action/admin/indices/upgrade/UpgradeReallyOldIndexTest.java\n@@ -67,7 +67,6 @@ public void testUpgrade_0_20() throws Exception {\n         File dataDir = prepareBackwardsDataDir(new File(getClass().getResource(\"index-0.20.zip\").toURI()));\n         internalCluster().startNode(ImmutableSettings.builder()\n                 .put(\"path.data\", dataDir.getPath())\n-                .put(\"node.mode\", \"network\")\n                 .put(\"gateway.type\", \"local\") // this is important we need to recover from gateway\n                 .put(InternalNode.HTTP_ENABLED, true)\n                 .build());",
    "output": "Remove explicit network mode - not needed here"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesResolver.java b/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesResolver.java\n--- a/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesResolver.java\n+++ b/src/main/java/org/elasticsearch/shield/authz/indicesresolver/DefaultIndicesResolver.java\n@@ -71,6 +71,9 @@ private Set<String> resolveIndices(User user, String action, IndicesRequest indi\n                 //If we can't replace because we got an empty set, we can only throw exception.\n                 //Downside of this is that a single item exception is going to its composite requests fail as a whole.\n                 if (indices == null || indices.isEmpty()) {\n+                    if (MetaData.isAllIndices(indicesRequest.indices())) {\n+                        throw new IndexMissingException(new Index(MetaData.ALL));\n+                    }\n                     throw new IndexMissingException(new Index(Arrays.toString(indicesRequest.indices())));\n                 }\n                 ((IndicesRequest.Replaceable)indicesRequest).indices(indices.toArray(new String[indices.size()]));",
    "output": "Improve error message when the cluster has no indices When the indices are empty, replaced the error message `IndexMissingException[[[]] missing]` with `IndexMissingException[[[_all]] missing]` Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/xcontent/XContentBuilder.java b/src/main/java/org/elasticsearch/common/xcontent/XContentBuilder.java\n--- a/src/main/java/org/elasticsearch/common/xcontent/XContentBuilder.java\n+++ b/src/main/java/org/elasticsearch/common/xcontent/XContentBuilder.java\n@@ -1272,7 +1272,7 @@ private void writeValue(Object value) throws IOException {\n             generator.writeEndArray();\n         } else if (value instanceof short[]) {\n             generator.writeStartArray();\n-            for (float v : (short[]) value) {\n+            for (short v : (short[]) value) {\n                 generator.writeNumber(v);\n             }\n             generator.writeEndArray();",
    "output": "Fix serialization of short[] arays. short[] were mistakenly encoded as a float[]. This is not an issue for the text-based xcontents that we have (yaml, json) since floats can represent any short value and are serialized as strings. However, this will make the binary xcontents serialize shorts as int instead of floats"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/license/plugin/action/delete/TransportDeleteLicenseAction.java b/src/main/java/org/elasticsearch/license/plugin/action/delete/TransportDeleteLicenseAction.java\n--- a/src/main/java/org/elasticsearch/license/plugin/action/delete/TransportDeleteLicenseAction.java\n+++ b/src/main/java/org/elasticsearch/license/plugin/action/delete/TransportDeleteLicenseAction.java\n@@ -56,11 +56,6 @@ protected ClusterBlockException checkBlock(DeleteLicenseRequest request, Cluster\n \n     @Override\n     protected void masterOperation(final DeleteLicenseRequest request, ClusterState state, final ActionListener<DeleteLicenseResponse> listener) throws ElasticsearchException {\n-        MetaData metaData = state.metaData();\n-        LicensesMetaData licenses = metaData.custom(LicensesMetaData.TYPE);\n-        //listener.onResponse(new DeleteLicenseResponse(licenses));\n-\n-        //TODO:: add features of the license to be deleted\n         licensesService.unregisteredLicenses(\"delete_licenses []\", request, new ActionListener<ClusterStateUpdateResponse>() {\n             @Override\n             public void onResponse(ClusterStateUpdateResponse clusterStateUpdateResponse) {",
    "output": "Remove redundant code"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java b/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java\n--- a/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java\n+++ b/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java\n@@ -2460,7 +2460,7 @@ public void testEmptyBoolSubClausesIsMatchAll() throws ElasticsearchException, I\n         assertThat(parsedQuery, instanceOf(XConstantScoreQuery.class));\n         assertThat(((XConstantScoreQuery) parsedQuery).getFilter(), instanceOf(CustomQueryWrappingFilter.class));\n         assertThat(((CustomQueryWrappingFilter) ((XConstantScoreQuery) parsedQuery).getFilter()).getQuery(), instanceOf(ParentConstantScoreQuery.class));\n-        assertThat(((CustomQueryWrappingFilter) ((XConstantScoreQuery) parsedQuery).getFilter()).getQuery().toString(), equalTo(\"parent_filter[foo](*:*)\"));\n+        assertThat(((CustomQueryWrappingFilter) ((XConstantScoreQuery) parsedQuery).getFilter()).getQuery().toString(), equalTo(\"parent_filter[foo](filtered(*:*)->cache(_type:foo))\"));\n         SearchContext.removeCurrent();\n     }\n }",
    "output": "Fix test after pr"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/CurrentTestFailedMarker.java b/src/test/java/org/elasticsearch/test/CurrentTestFailedMarker.java\n--- a/src/test/java/org/elasticsearch/test/CurrentTestFailedMarker.java\n+++ b/src/test/java/org/elasticsearch/test/CurrentTestFailedMarker.java\n@@ -39,7 +39,7 @@ public void testFailure(Failure failure) throws Exception {\n     }\n \n     @Override\n-    public void testRunStarted(Description description) throws Exception {\n+    public void testStarted(Description description) throws Exception {\n         failed.set(false);\n     }\n ",
    "output": "Fix CurrentTestFailedMarker to reset its state after each test The currently used method `testRunStarted` is only called before any tests have been run, we need to reset that state before each test, that's why we need to use `testStarted`"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java b/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java\n--- a/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java\n+++ b/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java\n@@ -26,6 +26,7 @@\n import org.junit.Test;\n \n import java.io.File;\n+import java.io.IOException;\n \n import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;\n import static org.hamcrest.Matchers.is;\n@@ -36,7 +37,7 @@\n public class PluginManagerUnitTests extends ElasticsearchTestCase {\n \n     @Test\n-    public void testThatConfigDirectoryCanBeOutsideOfElasticsearchHomeDirectory() {\n+    public void testThatConfigDirectoryCanBeOutsideOfElasticsearchHomeDirectory() throws IOException {\n         String pluginName = randomAsciiOfLength(10);\n         File homeFolder = newTempDir();\n         File genericConfigFolder = newTempDir();\n@@ -48,9 +49,8 @@ public void testThatConfigDirectoryCanBeOutsideOfElasticsearchHomeDirectory() {\n         Environment environment = new Environment(settings);\n \n         PluginManager.PluginHandle pluginHandle = new PluginManager.PluginHandle(pluginName, \"version\", \"user\", \"repo\");\n-\n-        String configDirPath = Files.simplifyPath(pluginHandle.configDir(environment).getAbsolutePath());\n-        String expectedDirPath = Files.simplifyPath(new File(genericConfigFolder, pluginName).getAbsolutePath());\n+        String configDirPath = Files.simplifyPath(pluginHandle.configDir(environment).getCanonicalPath());\n+        String expectedDirPath = Files.simplifyPath(new File(genericConfigFolder, pluginName).getCanonicalPath());\n \n         assertThat(configDirPath, is(expectedDirPath));\n     }",
    "output": "Use canonical path for comparison rather than absolute path"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ExternalNode.java b/src/test/java/org/elasticsearch/test/ExternalNode.java\n--- a/src/test/java/org/elasticsearch/test/ExternalNode.java\n+++ b/src/test/java/org/elasticsearch/test/ExternalNode.java\n@@ -20,6 +20,7 @@\n \n import com.google.common.base.Predicate;\n import org.apache.lucene.util.Constants;\n+import org.elasticsearch.Version;\n import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;\n import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;\n import org.elasticsearch.client.Client;\n@@ -215,8 +216,10 @@ synchronized void stop(boolean forceKill) {\n         if (running()) {\n             try {\n                 if (forceKill == false && nodeInfo != null && random.nextBoolean()) {\n-                    // sometimes shut down gracefully\n-                    getClient().admin().cluster().prepareNodesShutdown(this.nodeInfo.getNode().id()).setExit(random.nextBoolean()).setDelay(\"0s\").get();\n+                    if (nodeInfo.getVersion().onOrAfter(Version.V_1_3_3)) {\n+                        // sometimes shut down gracefully\n+                        getClient().admin().cluster().prepareNodesShutdown(this.nodeInfo.getNode().id()).setExit(random.nextBoolean()).setDelay(\"0s\").get();\n+                    }\n                 }\n                 if (this.client != null) {\n                     client.close();",
    "output": "Use Shutdown API only if nodes are on 1.3.3 or newer to prevent shutdown problems"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n@@ -1735,7 +1735,7 @@ public Releasable acquireThrottle() {\n         }\n \n         @Override\n-        public void beforeMerge(OnGoingMerge merge) {\n+        public synchronized void beforeMerge(OnGoingMerge merge) {\n             if (numMergesInFlight.incrementAndGet() > maxNumMerges) {\n                 if (isThrottling.getAndSet(true) == false) {\n                     logger.info(\"now throttling indexing: numMergesInFlight={}, maxNumMerges={}\", numMergesInFlight, maxNumMerges);\n@@ -1745,7 +1745,7 @@ public void beforeMerge(OnGoingMerge merge) {\n         }\n \n         @Override\n-        public void afterMerge(OnGoingMerge merge) {\n+        public synchronized void afterMerge(OnGoingMerge merge) {\n             if (numMergesInFlight.decrementAndGet() < maxNumMerges) {\n                 if (isThrottling.getAndSet(false)) {\n                     logger.info(\"stop throttling indexing: numMergesInFlight={}, maxNumMerges={}\", numMergesInFlight, maxNumMerges);",
    "output": "Fix concurrency bug in index throttling"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/key/InternalKeyService.java b/src/main/java/org/elasticsearch/shield/key/InternalKeyService.java\n--- a/src/main/java/org/elasticsearch/shield/key/InternalKeyService.java\n+++ b/src/main/java/org/elasticsearch/shield/key/InternalKeyService.java\n@@ -27,7 +27,6 @@\n import java.nio.file.Files;\n import java.nio.file.Path;\n import java.nio.file.Paths;\n-import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n \n /**\n@@ -96,7 +95,7 @@ public String sign(String text) {\n         }\n         Mac mac = createMac(key);\n         byte[] sig = mac.doFinal(text.getBytes(Charsets.UTF_8));\n-        String sigStr = Base64.encodeBase64String(sig);\n+        String sigStr = Base64.encodeBase64URLSafeString(sig);\n         return \"$$\" + sigStr.length() + \"$$\" + sigStr + text;\n     }\n \n@@ -121,7 +120,9 @@ public String unsignAndVerify(String signedText) {\n             String text = signedText.substring(i + 2 + length);\n             Mac mac = createMac(key);\n             byte[] sig = mac.doFinal(text.getBytes(Charsets.UTF_8));\n-            if (!Base64.encodeBase64String(sig).equals(sigStr)) {\n+\n+\n+            if (!Base64.encodeBase64URLSafeString(sig).equals(sigStr)) {\n                 throw new SignatureException(\"tampered signed text\");\n             }\n             return text;",
    "output": "Change the base64 encoding of the signatures to be URL safe In InternalKeyService, we encode the signatures with base64. For things like scroll id, that need to be placed in URLs it's important that the signature will be URL safe"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/ScrollIdSigningTests.java b/src/test/java/org/elasticsearch/shield/ScrollIdSigningTests.java\n--- a/src/test/java/org/elasticsearch/shield/ScrollIdSigningTests.java\n+++ b/src/test/java/org/elasticsearch/shield/ScrollIdSigningTests.java\n@@ -19,6 +19,8 @@\n import org.junit.Test;\n \n import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;\n+import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.notNullValue;\n \n@@ -54,16 +56,22 @@ public void testSearchAndClearScroll() throws Exception {\n                 .setScroll(TimeValue.timeValueMinutes(2))\n                 .setSize(randomIntBetween(1, 10)).get();\n \n+        assertHitCount(response, docs.length);\n+        int hits = response.getHits().hits().length;\n+\n         try {\n             assertSigned(response.getScrollId());\n             while (true) {\n                 response = client().prepareSearchScroll(response.getScrollId())\n                         .setScroll(TimeValue.timeValueMinutes(2)).get();\n                 assertSigned(response.getScrollId());\n+                assertHitCount(response, docs.length);\n+                hits += response.getHits().hits().length;\n                 if (response.getHits().getHits().length == 0) {\n                     break;\n                 }\n             }\n+            assertThat(hits, equalTo(docs.length));\n         } finally {\n             clearScroll(response.getScrollId());\n         }",
    "output": "Add docs check to ScrollIdSigningTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreTests.java b/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreTests.java\n--- a/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreTests.java\n+++ b/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreTests.java\n@@ -22,7 +22,6 @@\n import com.carrotsearch.randomizedtesting.LifecycleScope;\n import com.google.common.base.Predicate;\n import com.google.common.collect.ImmutableList;\n-import org.apache.lucene.util.LuceneTestCase;\n import org.apache.lucene.util.LuceneTestCase.Slow;\n import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.action.ListenableActionFuture;\n@@ -1069,8 +1068,8 @@ public void throttlingTest() throws Exception {\n                         .put(\"location\", repositoryLocation)\n                         .put(\"compress\", randomBoolean())\n                         .put(\"chunk_size\", randomIntBetween(1000, 10000))\n-                        .put(\"max_restore_bytes_per_sec\", throttleRestore ? \"2.5k\" : \"0\")\n-                        .put(\"max_snapshot_bytes_per_sec\", throttleSnapshot ? \"2.5k\" : \"0\")));\n+                        .put(\"max_restore_bytes_per_sec\", throttleRestore ? \"0.5k\" : \"0\")\n+                        .put(\"max_snapshot_bytes_per_sec\", throttleSnapshot ? \"0.5k\" : \"0\")));\n \n         createIndex(\"test-idx\");\n         ensureGreen();",
    "output": "Make sure test actually throttles"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ShieldVersion.java b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n--- a/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n+++ b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n@@ -24,7 +24,7 @@ public class ShieldVersion implements Serializable {\n     // the (internal) format of the id is there so we can easily do after/before checks on the id\n \n     public static final int V_1_0_0_ID = /*00*/1000099;\n-    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0_Beta);\n+    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0_Beta1);\n \n     public static final ShieldVersion CURRENT = V_1_0_0;\n ",
    "output": "Upgrade es core version to 1.4.0.Beta1-SNAPSHOT"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ShieldVersion.java b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n--- a/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n+++ b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n@@ -24,7 +24,7 @@ public class ShieldVersion implements Serializable {\n     // the (internal) format of the id is there so we can easily do after/before checks on the id\n \n     public static final int V_1_0_0_ID = /*00*/1000099;\n-    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0);\n+    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0_Beta);\n \n     public static final ShieldVersion CURRENT = V_1_0_0;\n ",
    "output": "Upgrade es core version to 1.4.0.Beta-SNAPSHOT"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java b/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java\n--- a/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java\n+++ b/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java\n@@ -52,6 +52,14 @@ public void addScrollId(String scrollId) {\n         scrollIds.add(scrollId);\n     }\n \n+    public List<String> scrollIds() {\n+        return scrollIds;\n+    }\n+\n+    public void scrollIds(List<String> scrollIds) {\n+        this.scrollIds = scrollIds;\n+    }\n+\n     @Override\n     public ActionRequestValidationException validate() {\n         ActionRequestValidationException validationException = null;\n\ndiff --git a/src/main/java/org/elasticsearch/action/search/SearchResponse.java b/src/main/java/org/elasticsearch/action/search/SearchResponse.java\n--- a/src/main/java/org/elasticsearch/action/search/SearchResponse.java\n+++ b/src/main/java/org/elasticsearch/action/search/SearchResponse.java\n@@ -171,6 +171,10 @@ public String getScrollId() {\n         return scrollId;\n     }\n \n+    public void scrollId(String scrollId) {\n+        this.scrollId = scrollId;\n+    }\n+\n     static final class Fields {\n         static final XContentBuilderString _SCROLL_ID = new XContentBuilderString(\"_scroll_id\");\n         static final XContentBuilderString _SHARDS = new XContentBuilderString(\"_shards\");",
    "output": "Add scrollId/s setters to the different scroll requests/responses"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java b/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java\n--- a/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java\n@@ -47,7 +47,7 @@ public double evaluate(double value, double scale) {\n         public Explanation explainFunction(String valueExpl, double value, double scale) {\n             ComplexExplanation ce = new ComplexExplanation();\n             ce.setValue((float) evaluate(value, scale));\n-            ce.setDescription(\"-exp(-0.5*pow(\" + valueExpl + \",2.0)/\" + -1 * scale + \")\");\n+            ce.setDescription(\"exp(-0.5*pow(\" + valueExpl + \",2.0)/\" + -1 * scale + \")\");\n             return ce;\n         }\n ",
    "output": "Fix explanation for GaussDecayFunction The explanation now gives the correct value instead of the negative"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java b/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java\n@@ -36,6 +36,7 @@\n import org.elasticsearch.search.sort.SortBuilders;\n import org.elasticsearch.search.sort.SortOrder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.junit.Test;\n \n import java.util.ArrayList;\n@@ -54,6 +55,7 @@\n  *\n  */\n @ElasticsearchIntegrationTest.SuiteScopeTest\n+@TestLogging(\"org.elasticsearch.indices.recovery:TRACE\")\n public class GeoBoundsTests extends ElasticsearchIntegrationTest {\n \n     private static final String SINGLE_VALUED_FIELD_NAME = \"geo_value\";",
    "output": "Add trace logging for index recovery in GeoBoundsTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java b/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java\n--- a/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java\n+++ b/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java\n@@ -257,7 +257,7 @@ protected double computeExpectedScore(float[] weights, float[] scores, String sc\n         }\n \n         for (int i = 0; i < weights.length; i++) {\n-            float functionScore = weights[i] * scores[i];\n+            double functionScore = (double) weights[i] * scores[i];\n \n             if (\"avg\".equals(scoreMode)) {\n                 expectedScore += functionScore;",
    "output": "Fix another rounding issue"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchTests.java b/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchTests.java\n@@ -73,7 +73,7 @@ private Set<String> prepareData() throws Exception {\n     }\n \n     private Set<String> prepareData(int numShards) throws Exception {\n-        Set<String> fullExpectedIds = Sets.newHashSet();\n+        Set<String> fullExpectedIds = Sets.newTreeSet();\n \n         ImmutableSettings.Builder settingsBuilder = settingsBuilder()\n                 .put(indexSettings())\n@@ -209,7 +209,7 @@ public void testQueryThenFetchWithFrom() throws Exception {\n                 .query(matchAllQuery())\n                 .explain(true);\n \n-        Set<String> collectedIds = Sets.newHashSet();\n+        Set<String> collectedIds = Sets.newTreeSet();\n \n         SearchResponse searchResponse = client().search(searchRequest(\"test\").source(source.from(0).size(60)).searchType(QUERY_THEN_FETCH)).actionGet();\n         assertNoFailures(searchResponse);",
    "output": "Use a sorted set since sets are compared and compare is order specific"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java b/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java\n--- a/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java\n+++ b/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java\n@@ -21,6 +21,7 @@\n \n import com.google.common.collect.ImmutableMap;\n import org.elasticsearch.Version;\n+import org.elasticsearch.action.admin.indices.get.GetIndexAction;\n import org.elasticsearch.action.bench.AbortBenchmarkAction;\n import org.elasticsearch.action.bench.BenchmarkAction;\n import org.elasticsearch.action.bench.BenchmarkService;\n@@ -123,6 +124,7 @@ private static boolean isActionNotFoundExpected(Version version, String action)\n         actionsVersions.put(BenchmarkAction.NAME, Version.V_1_4_0);\n         actionsVersions.put(BenchmarkStatusAction.NAME, Version.V_1_4_0);\n         actionsVersions.put(AbortBenchmarkAction.NAME, Version.V_1_4_0);\n+        actionsVersions.put(GetIndexAction.NAME, Version.V_1_4_0);\n \n         actionsVersions.put(ExistsAction.NAME, Version.V_1_4_0);\n         actionsVersions.put(ExistsAction.NAME + \"[s]\", Version.V_1_4_0);",
    "output": "Add exception for GET index API to bwc tests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java b/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/metrics/GeoBoundsTests.java\n@@ -24,6 +24,9 @@\n import org.elasticsearch.common.geo.GeoPoint;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.SearchHitField;\n import org.elasticsearch.search.aggregations.bucket.terms.Terms;\n@@ -156,6 +159,8 @@ public void setupSuiteScopeCluster() throws Exception {\n         SearchResponse response = client().prepareSearch(\"high_card_idx\").addField(NUMBER_FIELD_NAME).addSort(SortBuilders.fieldSort(NUMBER_FIELD_NAME).order(SortOrder.ASC)).setSize(5000).get();\n         assertSearchResponse(response);\n         long totalHits = response.getHits().totalHits();\n+        XContentBuilder builder = response.toXContent(XContentBuilder.builder(JsonXContent.jsonXContent), ToXContent.EMPTY_PARAMS);\n+        logger.info(\"Full high_card_idx Response Content:\\n{ {} }\", builder.string());\n         for (int i = 0; i < totalHits; i++) {\n             SearchHit searchHit = response.getHits().getAt(i);\n             assertThat(\"Hit \" + i + \" with id: \" + searchHit.getId(), searchHit.getIndex(), equalTo(\"high_card_idx\"));",
    "output": "Add logging of response to aid debugging"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java\n@@ -1152,17 +1152,16 @@ public void singleValuedField_OrderedByNonMetricsOrMultiBucketSubAggregation() t\n     @Test\n     public void singleValuedField_OrderedByMultiValuedSubAggregation_WithUknownMetric() throws Exception {\n         try {\n-            client().prepareSearch(\"idx\").setTypes(\"type\")\n+            SearchResponse response = client().prepareSearch(\"idx\").setTypes(\"type\")\n                     .addAggregation(terms(\"terms\")\n                             .executionHint(randomExecutionHint())\n                             .field(SINGLE_VALUED_FIELD_NAME)\n                             .collectMode(randomFrom(SubAggCollectionMode.values()))\n                             .order(Terms.Order.aggregation(\"stats.foo\", true))\n                             .subAggregation(stats(\"stats\").field(\"i\"))\n                     ).execute().actionGet();\n-\n             fail(\"Expected search to fail when trying to sort terms aggregation by multi-valued sug-aggregation \" +\n-                    \"with an unknown specified metric to order by\");\n+                    \"with an unknown specified metric to order by. response had \" + response.getFailedShards() + \" failed shards.\");\n \n         } catch (ElasticsearchException e) {\n             // expected",
    "output": "Add more information to fail message for a test to debug test failure"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java b/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java\n--- a/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java\n+++ b/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreTests.java\n@@ -244,13 +244,13 @@ public void simpleWeightedFunctionsTestWithRandomWeightsAndRandomCombineMode() t\n \n     }\n \n-    protected float computeExpectedScore(float[] weights, float[] scores, String scoreMode) {\n-        float expectedScore = 0.0f;\n+    protected double computeExpectedScore(float[] weights, float[] scores, String scoreMode) {\n+        double expectedScore = 0.0;\n         if (\"multiply\".equals(scoreMode)) {\n-            expectedScore = 1.0f;\n+            expectedScore = 1.0;\n         }\n         if (\"max\".equals(scoreMode)) {\n-            expectedScore = Float.MAX_VALUE * -1.0f;\n+            expectedScore = Float.MAX_VALUE * -1.0;\n         }\n         if (\"min\".equals(scoreMode)) {\n             expectedScore = Float.MAX_VALUE;",
    "output": "Fix rounding issue"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/aliases/IndexAliasesTests.java b/src/test/java/org/elasticsearch/aliases/IndexAliasesTests.java\n--- a/src/test/java/org/elasticsearch/aliases/IndexAliasesTests.java\n+++ b/src/test/java/org/elasticsearch/aliases/IndexAliasesTests.java\n@@ -153,7 +153,7 @@ public void testEmptyFilter() throws Exception {\n     @Test\n     public void testSearchingFilteringAliasesSingleIndex() throws Exception {\n         logger.info(\"--> creating index [test]\");\n-        createIndex(\"test\");\n+        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", \"id\", \"type=string\", \"name\", \"type=string\"));\n \n         ensureGreen();\n ",
    "output": "Add explicit mappings to IndexAliasesTests.testSearchingFilteringAliasesSingleIndex This makes sure that all shards know about the `_uid` field"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/gateway/local/RecoveryBackwardsCompatibilityTests.java b/src/test/java/org/elasticsearch/gateway/local/RecoveryBackwardsCompatibilityTests.java\n--- a/src/test/java/org/elasticsearch/gateway/local/RecoveryBackwardsCompatibilityTests.java\n+++ b/src/test/java/org/elasticsearch/gateway/local/RecoveryBackwardsCompatibilityTests.java\n@@ -47,7 +47,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n                 .put(super.nodeSettings(nodeOrdinal))\n                 .put(\"action.admin.cluster.node.shutdown.delay\", \"10ms\")\n                 .put(\"gateway.recover_after_nodes\", 2)\n-                .put(BalancedShardsAllocator.SETTING_THRESHOLD, 1.1f).build(); // use less aggressive settings\n+                .put(BalancedShardsAllocator.SETTING_THRESHOLD, 100.0f).build(); // use less aggressive settings\n     }\n \n     protected int minExternalNodes() {",
    "output": "Use a large threshold to prevent relocations in RecoveryBackwardsCompatibilityTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/ClusterDiscoveryConfiguration.java b/src/test/java/org/elasticsearch/discovery/ClusterDiscoveryConfiguration.java\n--- a/src/test/java/org/elasticsearch/discovery/ClusterDiscoveryConfiguration.java\n+++ b/src/test/java/org/elasticsearch/discovery/ClusterDiscoveryConfiguration.java\n@@ -108,7 +108,8 @@ public UnicastZen(int numOfNodes, Settings extraSettings, int[] unicastHostOrdin\n         }\n \n         private final static int calcBasePort() {\n-            return 10000 +\n+            // note that this has properly co-exist with the port logic at InternalTestCluster's constructor\n+            return 30000 +\n                     1000 * (ElasticsearchIntegrationTest.CHILD_JVM_ID % 60) + // up to 60 jvms\n                     100 * portRangeCounter.incrementAndGet(); // up to 100 nodes\n         }",
    "output": "Change the default port base for ClusterDiscoveryConfiguration.UnicastZen to 30000 The previous value of 10000 collided with the standard test cluster ports when 6 or more JVMs are used"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -1569,11 +1569,8 @@ public Settings transportClient() {\n             case SUITE:\n                 nodePrefix = SUITE_CLUSTER_NODE_PREFIX;\n                 break;\n-            case GLOBAL:\n-                nodePrefix = GLOBAL_CLUSTER_NODE_PREFIX;\n-                break;\n             default:\n-                throw new ElasticsearchException(\"Unknown scope: \" + scope);\n+                throw new ElasticsearchException(\"Scope not supported: \" + scope);\n         }\n \n         return new InternalTestCluster(currentClusterSeed, minNumDataNodes, maxNumDataNodes,",
    "output": "Remove global scope mention from ElasticsearchIntegrationTest#buildTestCluster The global cluster gets created from a static block and shared through all tests in the same jvm. The `buildTestCluster` method can't get called passing in `Scope.GLOBAL`, hence removed its mention from it as it might be misleading. The only two scopes supported within the `buildTestCluster` method are `SUITE` and `TEST`"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/shield/authz/KnownActionsSanityCheckTests.java b/src/test/java/org/elasticsearch/shield/authz/KnownActionsSanityCheckTests.java\n--- a/src/test/java/org/elasticsearch/shield/authz/KnownActionsSanityCheckTests.java\n+++ b/src/test/java/org/elasticsearch/shield/authz/KnownActionsSanityCheckTests.java\n@@ -7,7 +7,6 @@\n \n import com.google.common.collect.ImmutableSet;\n import com.google.common.reflect.ClassPath;\n-import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.ElasticsearchIllegalStateException;\n import org.elasticsearch.action.Action;\n import org.elasticsearch.common.io.Streams;\n@@ -21,9 +20,7 @@\n import java.lang.reflect.Field;\n import java.lang.reflect.Modifier;\n \n-import static org.apache.lucene.util.LuceneTestCase.AwaitsFix;\n import static org.hamcrest.Matchers.hasItem;\n-import static org.hamcrest.Matchers.is;\n \n /**\n  *\n@@ -63,13 +60,6 @@ public void testAllShieldActionsAreKnown() throws Exception {\n         }\n     }\n \n-    @Test @AwaitsFix(bugUrl = \"waiting for core to change the action names\")\n-    public void testIndexTemplateActionIsIndicesAction() throws Exception {\n-        assertThat(knownActions.contains(\"indices:admin/template/delete\"), is(true));\n-        assertThat(knownActions.contains(\"indices:admin/template/get\"), is(true));\n-        assertThat(knownActions.contains(\"indices:admin/template/put\"), is(true));\n-    }\n-\n     private String extractActionName(Class clazz) throws Exception {\n         if (Modifier.isAbstract(clazz.getModifiers())) {\n             return null;",
    "output": "Upgrade known actions names test Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java b/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingOnClusterTests.java\n@@ -34,7 +34,7 @@\n import static org.hamcrest.Matchers.equalTo;\n \n \n-public class UpdateMappingOnCusterTests extends ElasticsearchIntegrationTest {\n+public class UpdateMappingOnClusterTests extends ElasticsearchIntegrationTest {\n \n     private static final String INDEX = \"index\";\n     private static final String TYPE = \"type\";",
    "output": "Fix typo in class name"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/authz/AuthorizationException.java b/src/main/java/org/elasticsearch/shield/authz/AuthorizationException.java\n--- a/src/main/java/org/elasticsearch/shield/authz/AuthorizationException.java\n+++ b/src/main/java/org/elasticsearch/shield/authz/AuthorizationException.java\n@@ -22,6 +22,6 @@ public AuthorizationException(String msg, Throwable cause) {\n \n     @Override\n     public RestStatus status() {\n-        return RestStatus.UNAUTHORIZED;\n+        return RestStatus.FORBIDDEN;\n     }\n }",
    "output": "Change http status of AuthorizationException to 403 Closes elastic/elasticsearch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n--- a/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n@@ -357,7 +357,6 @@ private static Settings getRandomNodeSettings(long seed) {\n                 }\n             }\n         }\n-        builder.put(\"plugins.isolation\", random.nextBoolean());\n         if (random.nextInt(10) == 0) {\n             builder.put(EsExecutors.PROCESSORS, 1 + random.nextInt(AbstractRandomizedTest.TESTS_PROCESSORS));\n         } else {",
    "output": "Remove unused plugin isolation leftover"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/util/BigArraysTests.java b/src/test/java/org/elasticsearch/common/util/BigArraysTests.java\n--- a/src/test/java/org/elasticsearch/common/util/BigArraysTests.java\n+++ b/src/test/java/org/elasticsearch/common/util/BigArraysTests.java\n@@ -336,7 +336,7 @@ public void testMaxSizeExceededOnNew() throws Exception {\n         for (String type : Arrays.asList(\"Byte\", \"Int\", \"Long\", \"Float\", \"Double\", \"Object\")) {\n             HierarchyCircuitBreakerService hcbs = new HierarchyCircuitBreakerService(\n                     ImmutableSettings.builder()\n-                            .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING, size)\n+                            .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING, size - 1)\n                             .build(),\n                     new NodeSettingsService(ImmutableSettings.EMPTY));\n             BigArrays bigArrays = new BigArrays(ImmutableSettings.EMPTY, null, hcbs).withCircuitBreaking();",
    "output": "Fix off-by-one error in BigArrays tests Comparisons for the BigArrays breaker use \"greater than\" instead of \"greater than or equal\", which was never an issue before because the test size was not right on a page boundary. A test with an exactly divisible page boundary (4mb exactly in this case) caused the sizes to be equal to, but not exceed, the limit, and never break. The limit should be smaller than the test increments the breaker anyway"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -965,6 +965,8 @@ private DiscoveryNode findMaster() {\n                 return null;\n             }\n         } else {\n+\n+            assert !pingMasters.contains(localNode) : \"local node should never be elected as master when other nodes indicate an active master\";\n             // lets tie break between discovered nodes\n             return electMaster.electMaster(pingMasters);\n         }",
    "output": "Add an assertion to ZenDiscovery checking that local node is never elected if pings indicate an active master"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n--- a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n@@ -464,10 +464,10 @@ private ShardRouting corruptRandomFile(final boolean includePerCommitFiles) thro\n             files.addAll(Arrays.asList(file.listFiles(new FileFilter() {\n                 @Override\n                 public boolean accept(File pathname) {\n-                    return pathname.isFile() && !\"write.lock\".equals(pathname.getName()) &&\n-                            (includePerCommitFiles == true // .del and segments_N are per commit files and might change after corruption\n-                                    || pathname.getName().startsWith(\"segments\") == false\n-                                    || pathname.getName().endsWith(\".del\") == false);\n+                    if (pathname.isFile() && \"write.lock\".equals(pathname.getName()) == false) {\n+                        return (includePerCommitFiles || isPerSegmentFile(pathname.getName()));\n+                    }\n+                    return false; // no dirs no write.locks\n                 }\n             })));\n         }\n@@ -514,6 +514,15 @@ public boolean accept(File pathname) {\n         return shardRouting;\n     }\n \n+    private static final boolean isPerCommitFile(String fileName) {\n+        // .del and segments_N are per commit files and might change after corruption\n+        return fileName.startsWith(\"segments\") || fileName.endsWith(\".del\");\n+    }\n+\n+    private static final boolean isPerSegmentFile(String fileName) {\n+        return isPerCommitFile(fileName) == false;\n+    }\n+\n     /**\n      * prunes the list of index files such that only the latest del generation files are contained.\n      */",
    "output": "Fix per-segment / per-commit exclude logic in CorruptFileTest"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java b/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n--- a/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n+++ b/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.index.translog;\n \n import org.apache.lucene.index.Term;\n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.common.bytes.BytesArray;\n import org.elasticsearch.common.io.stream.BytesStreamInput;\n@@ -413,6 +414,7 @@ public void run() {\n     }\n \n     @Test\n+    @LuceneTestCase.AwaitsFix(bugUrl = \"corrupting size can cause OOME\")\n     public void testTranslogChecksums() throws Exception {\n         List<Translog.Location> locations = newArrayList();\n ",
    "output": "Add AwaitsFix for testTranslogChecksums since it may cause OOME if the size is corrupted"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ExternalNode.java b/src/test/java/org/elasticsearch/test/ExternalNode.java\n--- a/src/test/java/org/elasticsearch/test/ExternalNode.java\n+++ b/src/test/java/org/elasticsearch/test/ExternalNode.java\n@@ -25,6 +25,8 @@\n import org.elasticsearch.client.Client;\n import org.elasticsearch.client.transport.TransportClient;\n import org.elasticsearch.cluster.ClusterName;\n+import org.elasticsearch.common.logging.ESLogger;\n+import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.transport.TransportAddress;\n@@ -53,6 +55,9 @@ final class ExternalNode implements Closeable {\n     private final String clusterName;\n     private TransportClient client;\n \n+    private final ESLogger logger = Loggers.getLogger(getClass());\n+\n+\n     ExternalNode(File path, long seed, SettingsSource settingsSource) {\n         this(path, null, seed, settingsSource);\n     }\n@@ -109,6 +114,7 @@ synchronized void startInternal(Client client, Settings settings, String nodeNam\n         builder.inheritIO();\n         boolean success = false;\n         try {\n+            logger.debug(\"starting external node [{}] with: {}\", nodeName, builder.command());\n             process = builder.start();\n             this.nodeInfo = null;\n             if (waitForNode(client, nodeName)) {",
    "output": "Add a debug logging message when starting an external node"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java b/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java\n--- a/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java\n@@ -21,6 +21,7 @@\n \n import org.elasticsearch.action.ActionRequestBuilder;\n import com.google.common.base.Predicate;\n+import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;\n import org.elasticsearch.action.bulk.BulkRequestBuilder;\n import org.elasticsearch.action.count.CountResponse;\n import org.elasticsearch.action.get.GetResponse;\n@@ -225,6 +226,11 @@ public void testNoMasterActions_writeMasterBlock() throws Exception {\n         client().prepareIndex(\"test2\", \"type1\", \"1\").setSource(\"field\", \"value1\").get();\n         refresh();\n \n+        ensureSearchable(\"test1\", \"test2\");\n+\n+        ClusterStateResponse clusterState = client().admin().cluster().prepareState().get();\n+        logger.info(\"Cluster state:\\n\" + clusterState.getState().prettyPrint());\n+\n         internalCluster().stopRandomDataNode();\n         assertThat(awaitBusy(new Predicate<Object>() {\n             public boolean apply(Object o) {",
    "output": "Make sure all shards are allocated before killing a random data node"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java\n--- a/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java\n+++ b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java\n@@ -67,6 +67,7 @@\n public class DiscoveryWithNetworkFailuresTests extends ElasticsearchIntegrationTest {\n \n     private static final Settings nodeSettings = ImmutableSettings.settingsBuilder()\n+            .put(\"gateway.type\", \"local\")\n             .put(\"discovery.type\", \"zen\") // <-- To override the local setting if set externally\n             .put(\"discovery.zen.fd.ping_timeout\", \"1s\") // <-- for hitting simulated network failures quickly\n             .put(\"discovery.zen.fd.ping_retries\", \"1\") // <-- for hitting simulated network failures quickly",
    "output": "Use local gateway This is important to for proper primary allocation decisions"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java\n--- a/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java\n+++ b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java\n@@ -161,7 +161,12 @@ public void testVerifyApiBlocksDuringPartition() throws Exception {\n         internalCluster().startNodesAsync(3, nodeSettings).get();\n         // Wait until a 3 nodes are part of the cluster\n         ensureStableCluster(3);\n-        createIndex(\"test\");\n+\n+        // Makes sure that the get request can be executed on each node locally:\n+        assertAcked(prepareCreate(\"test\").setSettings(ImmutableSettings.builder()\n+                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)\n+                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)\n+        ));\n \n         // Everything is stable now, it is now time to simulate evil...\n         // but first make sure we have no initializing shards and all is green",
    "output": "Make sure get request is always local"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java b/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java\n--- a/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java\n+++ b/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java\n@@ -60,7 +60,7 @@ public class ZenFaultDetectionTests extends ElasticsearchTestCase {\n     @Before\n     public void setUp() throws Exception {\n         super.setUp();\n-        threadPool = new ThreadPool();\n+        threadPool = new ThreadPool(getClass().getName());\n         serviceA = build(ImmutableSettings.builder().put(\"name\", \"TS_A\").build(), version0);\n         nodeA = new DiscoveryNode(\"TS_A\", \"TS_A\", serviceA.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), version0);\n         serviceB = build(ImmutableSettings.builder().put(\"name\", \"TS_B\").build(), version1);",
    "output": "Fix compilation issue caused by the lack of a thread pool name"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java b/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java\n--- a/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java\n+++ b/src/main/java/org/elasticsearch/discovery/DiscoverySettings.java\n@@ -29,6 +29,8 @@\n import org.elasticsearch.node.settings.NodeSettingsService;\n import org.elasticsearch.rest.RestStatus;\n \n+import java.util.EnumSet;\n+\n /**\n  * Exposes common discovery settings that may be supported by all the different discovery implementations\n  */\n@@ -42,8 +44,8 @@ public class DiscoverySettings extends AbstractComponent {\n     public final static int NO_MASTER_BLOCK_ID = 2;\n \n     private final static ClusterBlock ALL = new ClusterBlock(NO_MASTER_BLOCK_ID, \"no master\", true, true, RestStatus.SERVICE_UNAVAILABLE, ClusterBlockLevel.ALL);\n-    private final static ClusterBlock WRITE = new ClusterBlock(NO_MASTER_BLOCK_ID, \"no master\", true, false, RestStatus.SERVICE_UNAVAILABLE, ClusterBlockLevel.WRITE, ClusterBlockLevel.METADATA);\n-    private final static ClusterBlock METADATA = new ClusterBlock(NO_MASTER_BLOCK_ID, \"no master\", true, false, RestStatus.SERVICE_UNAVAILABLE, ClusterBlockLevel.METADATA);\n+    private final static ClusterBlock WRITE = new ClusterBlock(NO_MASTER_BLOCK_ID, \"no master\", true, false, RestStatus.SERVICE_UNAVAILABLE, EnumSet.of(ClusterBlockLevel.WRITE, ClusterBlockLevel.METADATA));\n+    private final static ClusterBlock METADATA = new ClusterBlock(NO_MASTER_BLOCK_ID, \"no master\", true, false, RestStatus.SERVICE_UNAVAILABLE, EnumSet.of(ClusterBlockLevel.METADATA));\n \n     private volatile ClusterBlock noMasterBlock;\n     private volatile TimeValue publishTimeout = DEFAULT_PUBLISH_TIMEOUT;",
    "output": "Upgrade to use ClusterBlocks new constructor signature Introduced with: 11a3201a092ed6c5d31516ae4b30dbb618ba348c"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java b/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java\n--- a/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java\n+++ b/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java\n@@ -113,7 +113,10 @@ public void onRemoval(RemovalNotification<Key, Accountable> notification) {\n         IndexFieldCache indexCache = key.indexCache;\n         long sizeInBytes = key.sizeInBytes;\n         final Accountable value = notification.getValue();\n-        assert value == null || sizeInBytes > 0 && sizeInBytes == value.ramBytesUsed() : \"Expected size [\" + sizeInBytes + \"] to be positive or value [\" + value + \"] to be non-null\";\n+        assert sizeInBytes >= 0 || value != null : \"Expected size [\" + sizeInBytes + \"] to be positive or value [\" + value + \"] to be non-null\";\n+        if (sizeInBytes == -1 && value != null) {\n+            sizeInBytes = value.ramBytesUsed();\n+        }\n         for (IndexFieldDataCache.Listener listener : key.listeners) {\n             try {\n                 listener.onUnload(indexCache.fieldNames, indexCache.fieldDataType, notification.wasEvicted(), sizeInBytes);\n@@ -220,7 +223,6 @@ public Accountable call() throws Exception {\n                             logger.error(\"Failed to call listener on global ordinals loading\", e);\n                         }\n                     }\n-                    key.sizeInBytes = ifd.ramBytesUsed();\n                     return ifd;\n                 }\n             });",
    "output": "Fix issue clearing fielddata breaker introduced in 6950c38a0436ec937797f01fba8d7d95e6d6225f"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/action/IndicesRequestTests.java b/src/test/java/org/elasticsearch/action/IndicesRequestTests.java\n--- a/src/test/java/org/elasticsearch/action/IndicesRequestTests.java\n+++ b/src/test/java/org/elasticsearch/action/IndicesRequestTests.java\n@@ -861,7 +861,7 @@ private String[] randomUniqueIndicesOrAliases() {\n     private static void assertAllRequestsHaveBeenConsumed() {\n         Iterable<TransportService> transportServices = internalCluster().getInstances(TransportService.class);\n         for (TransportService transportService : transportServices) {\n-            assertThat(((InterceptingTransportService)transportService).requests.isEmpty(), equalTo(true));\n+            assertThat(((InterceptingTransportService)transportService).requests.entrySet(), emptyIterable());\n         }\n     }\n ",
    "output": "Use more verbose assertion in IndicesRequestTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n--- a/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n@@ -393,7 +393,7 @@ private static Settings getRandomNodeSettings(long seed) {\n \n     public static String clusterName(String prefix, String childVMId, long clusterSeed) {\n         StringBuilder builder = new StringBuilder(prefix);\n-        builder.append('-').append(NetworkUtils.getLocalAddress().getHostName());\n+        builder.append('-').append(NetworkUtils.getLocalHostName(\"__default_host__\"));\n         builder.append(\"-CHILD_VM=[\").append(childVMId).append(']');\n         builder.append(\"-CLUSTER_SEED=[\").append(clusterSeed).append(']');\n         // if multiple maven task run on a single host we better have an identifier that doesn't rely on input params",
    "output": "Use a default host name if localAddress is not available"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/Segment.java b/src/main/java/org/elasticsearch/index/engine/Segment.java\n--- a/src/main/java/org/elasticsearch/index/engine/Segment.java\n+++ b/src/main/java/org/elasticsearch/index/engine/Segment.java\n@@ -157,4 +157,21 @@ public void writeTo(StreamOutput out) throws IOException {\n         out.writeOptionalString(mergeId);\n         out.writeLong(memoryInBytes);\n     }\n+\n+    @Override\n+    public String toString() {\n+        return \"Segment{\" +\n+                \"name='\" + name + '\\'' +\n+                \", generation=\" + generation +\n+                \", committed=\" + committed +\n+                \", search=\" + search +\n+                \", sizeInBytes=\" + sizeInBytes +\n+                \", docCount=\" + docCount +\n+                \", delDocCount=\" + delDocCount +\n+                \", version='\" + version + '\\'' +\n+                \", compound=\" + compound +\n+                \", mergeId='\" + mergeId + '\\'' +\n+                \", memoryInBytes=\" + memoryInBytes +\n+                '}';\n+    }\n }\n\\ No newline at end of file",
    "output": "Add toString() method to Segment.java for debugging purposes"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java b/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java\n--- a/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java\n+++ b/src/main/java/org/elasticsearch/index/store/StoreFileMetaData.java\n@@ -53,19 +53,19 @@ public StoreFileMetaData(String name, long length) {\n     }\n \n     public StoreFileMetaData(String name, long length, String checksum) {\n-        this(name, length, checksum, null, new BytesRef());\n+        this(name, length, checksum, null, null);\n     }\n \n     public StoreFileMetaData(String name, long length, String checksum, Version writtenBy) {\n-        this(name, length, checksum, writtenBy, new BytesRef());\n+        this(name, length, checksum, writtenBy, null);\n     }\n \n     public StoreFileMetaData(String name, long length, String checksum, Version writtenBy, BytesRef hash) {\n         this.name = name;\n         this.length = length;\n         this.checksum = checksum;\n         this.writtenBy = writtenBy;\n-        this.hash = hash;\n+        this.hash = hash == null ? new BytesRef() : hash;\n     }\n \n \n@@ -126,6 +126,8 @@ public void readFrom(StreamInput in) throws IOException {\n         }\n         if (in.getVersion().onOrAfter(org.elasticsearch.Version.V_1_4_0)) {\n             hash = in.readBytesRef();\n+        } else {\n+            hash = new BytesRef();\n         }\n     }\n ",
    "output": "Use empty BytesRef if we read from <= 1.4.0"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/index/IndexRequest.java b/src/main/java/org/elasticsearch/action/index/IndexRequest.java\n--- a/src/main/java/org/elasticsearch/action/index/IndexRequest.java\n+++ b/src/main/java/org/elasticsearch/action/index/IndexRequest.java\n@@ -483,6 +483,15 @@ public IndexRequest opType(OpType opType) {\n         return this;\n     }\n \n+    /**\n+     * Sets a string representation of the {@link #opType(org.elasticsearch.action.index.IndexRequest.OpType)}. Can\n+     * be either \"index\" or \"create\".\n+     */\n+    public IndexRequest opType(String opType) throws ElasticsearchIllegalArgumentException {\n+        return opType(OpType.fromString(opType));\n+    }\n+\n+\n     /**\n      * Set to <tt>true</tt> to force this index to use {@link OpType#CREATE}.\n      */",
    "output": "Add back string op type to IndexRequest This was removed by accident I think, and it breaks backward comp. on the Java API in minor 1.3 version"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/xcontent/MapperTestUtils.java b/src/test/java/org/elasticsearch/index/mapper/xcontent/MapperTestUtils.java\n--- a/src/test/java/org/elasticsearch/index/mapper/xcontent/MapperTestUtils.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/xcontent/MapperTestUtils.java\n@@ -39,7 +39,7 @@\n import org.elasticsearch.index.similarity.SimilarityLookupService;\n import org.elasticsearch.indices.analysis.IndicesAnalysisModule;\n import org.elasticsearch.indices.analysis.IndicesAnalysisService;\n-import org.elasticsearch.indices.fielddata.breaker.NoneCircuitBreakerService;\n+import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n \n public class MapperTestUtils {\n ",
    "output": "Upgrade to elasticsearch 1.4.0 Related to #77. (cherry picked from commit 7e65cfb)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n@@ -1307,7 +1307,7 @@ public void failEngine(String reason, Throwable failure) {\n                     return;\n                 }\n                 try {\n-                    logger.warn(\"failed engine [{}]\", reason, failure);\n+                    logger.warn(\"failed engine [{}]\", failure, reason);\n                     // we must set a failure exception, generate one if not supplied\n                     failedEngine = failure;\n                     for (FailedEngineListener listener : failedEngineListeners) {",
    "output": "Fix failed engine exception logging"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java b/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java\n--- a/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java\n+++ b/src/main/java/org/elasticsearch/script/groovy/GroovySandboxExpressionChecker.java\n@@ -88,6 +88,7 @@ public GroovySandboxExpressionChecker(Settings settings) {\n \n     // Default whitelisted receiver classes for the Groovy sandbox\n     private final static String[] defaultReceiverWhitelist = new String [] {\n+            groovy.util.GroovyCollections.class.getName(),\n             java.lang.Math.class.getName(),\n             java.lang.Integer.class.getName(), \"[I\", \"[[I\", \"[[[I\",\n             java.lang.Float.class.getName(), \"[F\", \"[[F\", \"[[[F\",\n\ndiff --git a/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java b/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java\n--- a/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java\n+++ b/src/test/java/org/elasticsearch/script/GroovySandboxScriptTests.java\n@@ -47,6 +47,8 @@ public void testSandboxedGroovyScript() {\n         testSuccess(\"def v = doc['foo'].value; def m = [:]; m.put(\\\\\\\"value\\\\\\\", v)\");\n         // Times\n         testSuccess(\"def t = Instant.now().getMillis()\");\n+        // GroovyCollections\n+        testSuccess(\"def n = [1,2,3]; GroovyCollections.max(n)\");\n \n         // Fail cases\n         testFailure(\"pr = Runtime.getRuntime().exec(\\\\\\\"touch /tmp/gotcha\\\\\\\"); pr.waitFor()\",",
    "output": "Add GroovyCollections to the sandbox whitelist Also clarify in the docs that changing the whitelist/blacklist settings replace the list, they don't add to it"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java b/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n--- a/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n+++ b/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n@@ -148,7 +148,7 @@ public VerboseProgress(PrintStream out) {\n          * @param writer the output stream.\n          */\n         public VerboseProgress(PrintWriter writer) {\n-            this.writer = this.writer;\n+            this.writer = writer;\n         }\n \n         /**",
    "output": "Fix VerboseProgress(PrintWriter) does not set the writer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/ShieldVersion.java b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n--- a/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n+++ b/src/main/java/org/elasticsearch/shield/ShieldVersion.java\n@@ -27,7 +27,7 @@ public class ShieldVersion implements Serializable {\n     // the (internal) format of the id is there so we can easily do after/before checks on the id\n \n     public static final int V_1_0_0_ID = /*00*/1000099;\n-    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, false, Version.V_1_4_0);\n+    public static final ShieldVersion V_1_0_0 = new ShieldVersion(V_1_0_0_ID, true, Version.V_1_4_0);\n \n     public static final ShieldVersion CURRENT = V_1_0_0;\n ",
    "output": "Fix ShieldVersion to be a snapshot"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java b/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n--- a/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n+++ b/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java\n@@ -359,7 +359,7 @@ private static void assign(Edge[] holes, Coordinate[][] points, int numHoles, Ed\n             current.intersect = current.coordinate;\n             final int intersections = intersections(current.coordinate.x, edges);\n             final int pos = Arrays.binarySearch(edges, 0, intersections, current, INTERSECTION_ORDER);\n-            if (pos < 0) {\n+            if (pos >= 0) {\n                 throw new ElasticsearchParseException(\"Invaild shape: Hole is not within polygon\");\n             }\n             final int index = -(pos+2);",
    "output": "Fix for failing BasePolygonBuilder"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/bwcompat/UnicastBackwardsCompatibilityTest.java b/src/test/java/org/elasticsearch/bwcompat/UnicastBackwardsCompatibilityTest.java\n--- a/src/test/java/org/elasticsearch/bwcompat/UnicastBackwardsCompatibilityTest.java\n+++ b/src/test/java/org/elasticsearch/bwcompat/UnicastBackwardsCompatibilityTest.java\n@@ -34,7 +34,7 @@ protected Settings nodeSettings(int nodeOrdinal) {\n         return ImmutableSettings.builder()\n                 .put(\"transport.tcp.port\", 9380 + nodeOrdinal)\n                 .put(\"discovery.zen.ping.multicast.enabled\", false)\n-                .put(\"discovery.zen.ping.unicast.hosts\", \"localhost:9390,localhost:9391\")\n+                .put(\"discovery.zen.ping.unicast.hosts\", \"localhost:9380,localhost:9381,localhost:9390,localhost:9391\")\n                 .put(super.nodeSettings(nodeOrdinal))\n                 .build();\n     }\n@@ -44,13 +44,13 @@ protected Settings externalNodeSettings(int nodeOrdinal) {\n         return ImmutableSettings.settingsBuilder()\n                 .put(\"transport.tcp.port\", 9390 + nodeOrdinal)\n                 .put(\"discovery.zen.ping.multicast.enabled\", false)\n-                .put(\"discovery.zen.ping.unicast.hosts\", \"localhost:9380,localhost:9381\")\n+                .put(\"discovery.zen.ping.unicast.hosts\", \"localhost:9380,localhost:9381,localhost:9390,localhost:9391\")\n                 .put(super.nodeSettings(nodeOrdinal))\n                 .build();\n     }\n \n     @Test\n-    public void testUnicastDiscovery() throws Exception {\n+    public void testUnicastDiscovery() {\n         ClusterHealthResponse healthResponse = client().admin().cluster().prepareHealth().get();\n         assertThat(healthResponse.getNumberOfDataNodes(), equalTo(cluster().numDataNodes()));\n     }",
    "output": "Fix unicast bw comp test configuration The second internal node, when present, wasn't able to join the existing cluster due ti misconfigured unicast hosts, thus it would form its own cluster"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/action/termvector/GetTermVectorTests.java b/src/test/java/org/elasticsearch/action/termvector/GetTermVectorTests.java\n--- a/src/test/java/org/elasticsearch/action/termvector/GetTermVectorTests.java\n+++ b/src/test/java/org/elasticsearch/action/termvector/GetTermVectorTests.java\n@@ -214,33 +214,40 @@ public void testRandomSingleTermVectors() throws ElasticsearchException, IOExcep\n         switch (config) {\n             case 0: {\n                 // do nothing\n+                break;\n             }\n             case 1: {\n                 storeTermVectors = true;\n+                break;\n             }\n             case 2: {\n                 storeTermVectors = true;\n                 storePositions = true;\n+                break;\n             }\n             case 3: {\n                 storeTermVectors = true;\n                 storeOffsets = true;\n+                break;\n             }\n             case 4: {\n                 storeTermVectors = true;\n                 storePositions = true;\n                 storeOffsets = true;\n+                break;\n             }\n             case 5: {\n                 storeTermVectors = true;\n                 storePositions = true;\n                 storePayloads = true;\n+                break;\n             }\n             case 6: {\n                 storeTermVectors = true;\n                 storePositions = true;\n                 storeOffsets = true;\n                 storePayloads = true;\n+                break;\n             }\n         }\n         ft.setStoreTermVectors(storeTermVectors);",
    "output": "Fix GetTermVectorTests, added missing break statements in randomization switch"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java b/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java\n--- a/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java\n+++ b/src/test/java/org/elasticsearch/transport/ActionNamesBackwardsCompatibilityTest.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.action.bench.BenchmarkAction;\n import org.elasticsearch.action.bench.BenchmarkService;\n import org.elasticsearch.action.bench.BenchmarkStatusAction;\n+import org.elasticsearch.action.exists.ExistsAction;\n import org.elasticsearch.action.indexedscripts.delete.DeleteIndexedScriptAction;\n import org.elasticsearch.action.indexedscripts.get.GetIndexedScriptAction;\n import org.elasticsearch.action.indexedscripts.put.PutIndexedScriptAction;\n@@ -123,6 +124,9 @@ private static boolean isActionNotFoundExpected(Version version, String action)\n         actionsVersions.put(BenchmarkStatusAction.NAME, Version.V_1_4_0);\n         actionsVersions.put(AbortBenchmarkAction.NAME, Version.V_1_4_0);\n \n+        actionsVersions.put(ExistsAction.NAME, Version.V_1_4_0);\n+        actionsVersions.put(ExistsAction.NAME + \"[s]\", Version.V_1_4_0);\n+\n         actionsVersions.put(IndicesStore.ACTION_SHARD_EXISTS, Version.V_1_3_0);\n \n         actionsVersions.put(GetIndexedScriptAction.NAME, Version.V_1_3_0);",
    "output": "Fix action names bw comp tests, action not found is expected for newly added exists actions"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/azure/AbstractAzureComputeServiceTest.java b/src/test/java/org/elasticsearch/discovery/azure/AbstractAzureComputeServiceTest.java\n--- a/src/test/java/org/elasticsearch/discovery/azure/AbstractAzureComputeServiceTest.java\n+++ b/src/test/java/org/elasticsearch/discovery/azure/AbstractAzureComputeServiceTest.java\n@@ -20,12 +20,13 @@\n package org.elasticsearch.discovery.azure;\n \n import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;\n-import org.elasticsearch.cloud.azure.AbstractAzureTest;\n import org.elasticsearch.cloud.azure.AzureComputeService;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.plugins.PluginsService;\n+import org.elasticsearch.test.ElasticsearchIntegrationTest;\n \n-public abstract class AbstractAzureComputeServiceTest extends AbstractAzureTest {\n+public abstract class AbstractAzureComputeServiceTest extends ElasticsearchIntegrationTest {\n \n     private Class<? extends AzureComputeService> mock;\n \n@@ -34,6 +35,14 @@ public AbstractAzureComputeServiceTest(Class<? extends AzureComputeService> mock\n         this.mock = mock;\n     }\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        ImmutableSettings.Builder settings = ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true);\n+        return settings.build();\n+    }\n+\n     protected void checkNumberOfNodes(int expected) {\n         NodesInfoResponse nodeInfos = client().admin().cluster().prepareNodesInfo().execute().actionGet();\n         assertNotNull(nodeInfos);",
    "output": "Fix non integration tests With change #24, non integration can not run anymore. (cherry picked from commit 76eecc8)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java b/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java\n@@ -131,6 +131,7 @@ public static void writeTo(Type type, StreamOutput out) throws IOException {\n                     break;\n                 case THROTTLE:\n                     out.writeVInt(2);\n+                    break;\n                 default:\n                     throw new ElasticsearchIllegalArgumentException(\"Invalid Type [\" + type + \"]\");\n             }",
    "output": "Fix missing break statement causing reroute serialization failure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java b/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java\n--- a/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java\n+++ b/src/main/java/org/elasticsearch/cloud/azure/AzureStorageServiceImpl.java\n@@ -120,6 +120,9 @@ public void removeContainer(String container) throws URISyntaxException, Storage\n         options.setRetryPolicyFactory(new RetryNoRetry());\n         blob_container.deleteIfExists(options, null);\n         */\n+        if (logger.isTraceEnabled()) {\n+            logger.trace(\"removing container [{}]\", container);\n+        }\n         blob_container.deleteIfExists();\n     }\n ",
    "output": "Add a missing trace to `removeContainer`"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -192,6 +192,8 @@ public class Version implements Serializable {\n     public static final Version V_1_3_0 = new Version(V_1_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n     public static final int V_1_3_1_ID = /*00*/1030199;\n     public static final Version V_1_3_1 = new Version(V_1_3_1_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n+    public static final int V_1_3_2_ID = /*00*/1030299;\n+    public static final Version V_1_3_2 = new Version(V_1_3_2_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n     public static final int V_1_4_0_ID = /*00*/1040099;\n     public static final Version V_1_4_0 = new Version(V_1_4_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n@@ -213,6 +215,8 @@ public static Version fromId(int id) {\n                 return V_2_0_0;\n             case V_1_4_0_ID:\n                 return V_1_4_0;\n+            case V_1_3_2_ID:\n+                return V_1_3_2;\n             case V_1_3_1_ID:\n                 return V_1_3_1;\n             case V_1_3_0_ID:",
    "output": "Add [1.3.2] version constant"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n--- a/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n@@ -44,6 +44,8 @@\n import java.io.IOException;\n import java.util.Locale;\n \n+import static org.elasticsearch.common.lucene.search.NoopCollector.NOOP_COLLECTOR;\n+\n /**\n  *\n  */",
    "output": "Add missing import"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java b/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java\n--- a/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java\n@@ -122,6 +122,11 @@ public void setUp() throws Exception {\n             }\n         }\n \n+        for (String term : terms) {\n+            referenceAll.put(term, new FreqHolder());\n+            referenceFilter.put(term, new FreqHolder());\n+            referenceNotDeleted.put(term, new FreqHolder());\n+        }\n \n         // now go over each doc, build the relevant references and filter\n         reader = DirectoryReader.open(iw, true);\n@@ -145,10 +150,6 @@ private void addFreqs(Document doc, Map<String, FreqHolder> reference) {\n         for (IndexableField field : doc.getFields(\"field\")) {\n             String term = field.stringValue();\n             FreqHolder freqHolder = reference.get(term);\n-            if (freqHolder == null) {\n-                freqHolder = new FreqHolder();\n-                reference.put(term, freqHolder);\n-            }\n             if (!addedDocFreq.contains(term)) {\n                 freqHolder.docFreq++;\n                 addedDocFreq.add(term);",
    "output": "Fix NPE in FreqTermsEnumTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n@@ -234,11 +234,6 @@ public void setNextDocId(int doc) {\n             lookup.setNextDocId(doc);\n         }\n \n-        @Override\n-        public void setNextScore(float score) {\n-            ScriptableObject.putProperty(scope, \"_score\", score);\n-        }\n-\n         @Override\n         public void setNextVar(String name, Object value) {\n             ScriptableObject.putProperty(scope, name, value);",
    "output": "Upgrade to elasticsearch 1.4.0 . (cherry picked from commit e03a16b)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java b/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n@@ -182,11 +182,6 @@ public void setNextSource(Map<String, Object> source) {\n             lookup.source().setNextSource(source);\n         }\n \n-        @Override\n-        public void setNextScore(float score) {\n-            pyVars.__setitem__(\"_score\", Py.java2py(score));\n-        }\n-\n         @Override\n         public void setNextVar(String name, Object value) {\n             pyVars.__setitem__(name, Py.java2py(value));",
    "output": "Upgrade to elasticsearch 1.4.0 Related to #14. (cherry picked from commit 964de0d)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java b/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java\n--- a/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java\n+++ b/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;\n import org.elasticsearch.plugins.PluginsService;\n+import org.elasticsearch.script.ScriptService;\n import org.elasticsearch.search.sort.SortOrder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.hamcrest.CoreMatchers;\n@@ -228,7 +229,8 @@ public void testPythonEmptyParameters() throws Exception {\n         index(\"test\", \"type1\", \"1\", jsonBuilder().startObject().field(\"myfield\", \"foo\").endObject());\n         refresh();\n \n-        client().prepareUpdate(\"test\", \"type1\", \"1\").setScriptLang(\"python\").setScript(\"ctx[\\\"_source\\\"][\\\"myfield\\\"]=\\\"bar\\\"\")\n+        client().prepareUpdate(\"test\", \"type1\", \"1\").setScriptLang(\"python\")\n+                .setScript(\"ctx[\\\"_source\\\"][\\\"myfield\\\"]=\\\"bar\\\"\", ScriptService.ScriptType.INLINE)\n             .execute().actionGet();\n         refresh();\n ",
    "output": "Upgrade to Lucene 4.9.0 / elasticsearch 1.3.0 . Related to #13. (cherry picked from commit 8f077d6)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/core/AbstractFieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/core/AbstractFieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/core/AbstractFieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/core/AbstractFieldMapper.java\n@@ -761,7 +761,7 @@ protected void doXContentBody(XContentBuilder builder, boolean includeDefaults,\n         if (similarity() != null) {\n             builder.field(\"similarity\", similarity().name());\n         } else if (includeDefaults) {\n-            builder.field(\"similariry\", SimilarityLookupService.DEFAULT_SIMILARITY);\n+            builder.field(\"similarity\", SimilarityLookupService.DEFAULT_SIMILARITY);\n         }\n \n         if (customFieldDataSettings != null) {",
    "output": "Fix typo in AbstractFieldMapper similariry -> similarity"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n--- a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n+++ b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n@@ -588,6 +588,10 @@ public UpdateRequest source(BytesReference source) throws Exception {\n                     currentFieldName = parser.currentName();\n                 } else if (\"script\".equals(currentFieldName)) {\n                     script = parser.textOrNull();\n+                    scriptType = ScriptService.ScriptType.INLINE;\n+                } else if (\"script_id\".equals(currentFieldName)) {\n+                    script = parser.textOrNull();\n+                    scriptType = ScriptService.ScriptType.INDEXED;\n                 } else if (\"params\".equals(currentFieldName)) {\n                     scriptParams = parser.map();\n                 } else if (\"lang\".equals(currentFieldName)) {",
    "output": "Fix Fix update parser to accept script_id"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/IndexedScriptTests.java b/src/test/java/org/elasticsearch/script/IndexedScriptTests.java\n--- a/src/test/java/org/elasticsearch/script/IndexedScriptTests.java\n+++ b/src/test/java/org/elasticsearch/script/IndexedScriptTests.java\n@@ -58,7 +58,7 @@ public void testFieldIndexedScript()  throws ExecutionException, InterruptedExce\n \n         indexRandom(true,builders);\n         SearchResponse searchResponse;\n-        String query = \"{ \\\"query\\\" : { \\\"match_all\\\": {}} , \\\"script_fields\\\" : { \\\"test1\\\" : { \\\"id\\\" : \\\"script1\\\", \\\"lang\\\":\\\"groovy\\\" }, \\\"test2\\\" : { \\\"id\\\" : \\\"script2\\\", \\\"lang\\\":\\\"groovy\\\", \\\"params\\\":{\\\"factor\\\":3}  }}, size:1}\";\n+        String query = \"{ \\\"query\\\" : { \\\"match_all\\\": {}} , \\\"script_fields\\\" : { \\\"test1\\\" : { \\\"script_id\\\" : \\\"script1\\\", \\\"lang\\\":\\\"groovy\\\" }, \\\"test2\\\" : { \\\"script_id\\\" : \\\"script2\\\", \\\"lang\\\":\\\"groovy\\\", \\\"params\\\":{\\\"factor\\\":3}  }}, size:1}\";\n         searchResponse = client().prepareSearch().setSource(query).setIndices(\"test\").setTypes(\"scriptTest\").get();\n         assertHitCount(searchResponse,5);\n         assertTrue(searchResponse.getHits().hits().length == 1);",
    "output": "Fix indexed script test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/shield/n2n/IPFilteringN2NAuthentricator.java b/src/main/java/org/elasticsearch/shield/n2n/IPFilteringN2NAuthentricator.java\n--- a/src/main/java/org/elasticsearch/shield/n2n/IPFilteringN2NAuthentricator.java\n+++ b/src/main/java/org/elasticsearch/shield/n2n/IPFilteringN2NAuthentricator.java\n@@ -11,14 +11,14 @@\n import org.elasticsearch.common.component.AbstractComponent;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.logging.ESLogger;\n+import org.elasticsearch.common.netty.handler.ipfilter.IpFilterRule;\n+import org.elasticsearch.common.netty.handler.ipfilter.IpSubnetFilterRule;\n+import org.elasticsearch.common.netty.handler.ipfilter.PatternRule;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.env.Environment;\n import org.elasticsearch.watcher.FileChangesListener;\n import org.elasticsearch.watcher.FileWatcher;\n import org.elasticsearch.watcher.ResourceWatcherService;\n-import org.jboss.netty.handler.ipfilter.IpFilterRule;\n-import org.jboss.netty.handler.ipfilter.IpSubnetFilterRule;\n-import org.jboss.netty.handler.ipfilter.PatternRule;\n \n import java.io.File;\n import java.io.IOException;",
    "output": "Remove netty dependency. Use shaded classes as imports"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/DistributorDirectoryTest.java b/src/test/java/org/elasticsearch/index/store/DistributorDirectoryTest.java\n--- a/src/test/java/org/elasticsearch/index/store/DistributorDirectoryTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/DistributorDirectoryTest.java\n@@ -24,6 +24,7 @@\n import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;\n import org.apache.lucene.store.BaseDirectoryTestCase;\n import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.LuceneTestCase;\n import org.apache.lucene.util.TimeUnits;\n import org.elasticsearch.test.ElasticsearchThreadFilter;\n import org.elasticsearch.test.junit.listeners.LoggingListener;\n@@ -35,6 +36,7 @@\n @ThreadLeakScope(ThreadLeakScope.Scope.NONE)\n @TimeoutSuite(millis = 20 * TimeUnits.MINUTE) // timeout the suite after 20min and fail the test.\n @Listeners(LoggingListener.class)\n+@LuceneTestCase.SuppressSysoutChecks(bugUrl = \"we log a lot on purpose\")\n public class DistributorDirectoryTest extends BaseDirectoryTestCase {\n \n     @Override",
    "output": "Add SuppressSysoutChecks to DistributorDirectoryTest"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n--- a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n+++ b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n@@ -651,7 +651,7 @@ public void writeTo(StreamOutput out) throws IOException {\n         out.writeString(id);\n         out.writeOptionalString(routing);\n         out.writeOptionalString(script);\n-        if (script != null && out.getVersion().onOrAfter(Version.V_1_3_0)) {\n+        if (Strings.hasLength(script) && out.getVersion().onOrAfter(Version.V_1_3_0)) {\n             ScriptService.ScriptType.writeTo(scriptType, out);\n         }\n         out.writeOptionalString(scriptLang);",
    "output": "Fix normalize serialization of ScriptType in UpdateRequest"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -188,6 +188,8 @@ public class Version implements Serializable {\n     public static final Version V_1_2_3 = new Version(V_1_2_3_ID, false, org.apache.lucene.util.Version.LUCENE_4_8);\n     public static final int V_1_3_0_ID = /*00*/1030099;\n     public static final Version V_1_3_0 = new Version(V_1_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n+    public static final int V_1_4_0_ID = /*00*/1040099;\n+    public static final Version V_1_4_0 = new Version(V_1_4_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n     public static final Version V_2_0_0 = new Version(V_2_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_4_9);\n \n@@ -205,6 +207,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_2_0_0_ID:\n                 return V_2_0_0;\n+            case V_1_4_0_ID:\n+                return V_1_4_0;\n             case V_1_3_0_ID:\n                 return V_1_3_0;\n             case V_1_2_3_ID:",
    "output": "Add [1.4.0] version"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n--- a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n+++ b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n@@ -651,7 +651,7 @@ public void writeTo(StreamOutput out) throws IOException {\n         out.writeString(id);\n         out.writeOptionalString(routing);\n         out.writeOptionalString(script);\n-        if (script != null) {\n+        if (script != null && out.getVersion().onOrAfter(Version.V_1_3_0)) {\n             ScriptService.ScriptType.writeTo(scriptType, out);\n         }\n         out.writeOptionalString(scriptLang);",
    "output": "Add missing version based serialization"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n--- a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n+++ b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.action.update;\n \n import com.google.common.collect.Maps;\n+import org.elasticsearch.Version;\n import org.elasticsearch.action.ActionRequestValidationException;\n import org.elasticsearch.action.WriteConsistencyLevel;\n import org.elasticsearch.action.index.IndexRequest;\n@@ -610,8 +611,12 @@ public void readFrom(StreamInput in) throws IOException {\n         id = in.readString();\n         routing = in.readOptionalString();\n         script = in.readOptionalString();\n-        if( Strings.hasLength(script)) {\n-            scriptType = ScriptService.ScriptType.readFrom(in);\n+        if(Strings.hasLength(script)) {\n+            if (in.getVersion().onOrAfter(Version.V_1_3_0)) {\n+                scriptType = ScriptService.ScriptType.readFrom(in);\n+            } else {\n+                scriptType = null;\n+            }\n         }\n         scriptLang = in.readOptionalString();\n         scriptParams = in.readMap();",
    "output": "Add version check before reading script type in UpdateRequest"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n--- a/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n+++ b/src/test/java/org/elasticsearch/index/store/CorruptedFileTest.java\n@@ -136,7 +136,9 @@ public void testCorruptFileAndRecover() throws ExecutionException, InterruptedEx\n         Settings build = ImmutableSettings.builder().put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, \"2\").build();\n         client().admin().indices().prepareUpdateSettings(\"test\").setSettings(build).get();\n         ClusterHealthResponse health = client().admin().cluster()\n-                .health(Requests.clusterHealthRequest(\"test\").waitForGreenStatus().waitForRelocatingShards(0)).actionGet();\n+                .health(Requests.clusterHealthRequest(\"test\").waitForGreenStatus()\n+                        .timeout(\"5m\") // sometimes due to cluster rebalacing and random settings default timeout is just not enough.\n+                        .waitForRelocatingShards(0)).actionGet();\n         if (health.isTimedOut()) {\n             logger.info(\"cluster state:\\n{}\\n{}\", client().admin().cluster().prepareState().get().getState().prettyPrint(), client().admin().cluster().preparePendingClusterTasks().get().prettyPrint());\n             assertThat(\"timed out waiting for green state\", health.isTimedOut(), equalTo(false));",
    "output": "Use higher timeout to wait for balanced cluster CorruptFileTest sometimes hits conditions where lots of rebalancing happens. In such a case the default timeout is just not enough - this timeout just makes sure that the cluster has enough time to balance itself"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/count/simple/SimpleCountTests.java b/src/test/java/org/elasticsearch/count/simple/SimpleCountTests.java\n--- a/src/test/java/org/elasticsearch/count/simple/SimpleCountTests.java\n+++ b/src/test/java/org/elasticsearch/count/simple/SimpleCountTests.java\n@@ -47,8 +47,14 @@ public void testCountRandomPreference() throws InterruptedException, ExecutionEx\n \n         int iters = scaledRandomIntBetween(10, 100);\n         for (int i = 0; i < iters; i++) {\n+\n+            String randomPreference = randomUnicodeOfLengthBetween(0, 4);\n+            // randomPreference should not start with '_' (reserved for known preference types (e.g. _shards, _primary)\n+            while (randomPreference.startsWith(\"_\")) {\n+                randomPreference = randomUnicodeOfLengthBetween(0, 4);\n+            }\n             // id is not indexed, but lets see that we automatically convert to\n-            CountResponse countResponse = client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).setPreference(randomUnicodeOfLengthBetween(0, 4)).get();\n+            CountResponse countResponse = client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).setPreference(randomPreference).get();\n             assertHitCount(countResponse, 6l);\n         }\n     }",
    "output": "Fix random preference string test to accomodate for the new more strict preference type"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/IndexedScriptTests.java b/src/test/java/org/elasticsearch/script/IndexedScriptTests.java\n--- a/src/test/java/org/elasticsearch/script/IndexedScriptTests.java\n+++ b/src/test/java/org/elasticsearch/script/IndexedScriptTests.java\n@@ -58,7 +58,7 @@ public void testFieldIndexedScript()  throws ExecutionException, InterruptedExce\n \n         indexRandom(true,builders);\n         SearchResponse searchResponse;\n-        String query = \"{ \\\"query\\\" : { \\\"match_all\\\": {}} , \\\"script_fields\\\" : { \\\"test1\\\" : { \\\"id\\\" : \\\"script1\\\" }, \\\"test2\\\" : { \\\"id\\\" : \\\"script2\\\", \\\"params\\\":{\\\"factor\\\":3}  }}, size:1}\";\n+        String query = \"{ \\\"query\\\" : { \\\"match_all\\\": {}} , \\\"script_fields\\\" : { \\\"test1\\\" : { \\\"id\\\" : \\\"script1\\\", \\\"lang\\\":\\\"groovy\\\" }, \\\"test2\\\" : { \\\"id\\\" : \\\"script2\\\", \\\"lang\\\":\\\"groovy\\\", \\\"params\\\":{\\\"factor\\\":3}  }}, size:1}\";\n         searchResponse = client().prepareSearch().setSource(query).setIndices(\"test\").setTypes(\"scriptTest\").get();\n         assertHitCount(searchResponse,5);\n         assertTrue(searchResponse.getHits().hits().length == 1);",
    "output": "Fix test issues with branches still using mvel as default scripting language"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java b/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java\n--- a/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java\n+++ b/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java\n@@ -97,8 +97,16 @@ public void testLocalPluginInstallWithBinAndConfig() throws Exception {\n         Tuple<Settings, Environment> initialSettings = InternalSettingsPreparer.prepareSettings(\n                 ImmutableSettings.settingsBuilder().build(), false);\n         Environment env = initialSettings.v2();\n-        File pluginBinDir = new File(new File(env.homeFile(), \"bin\"), pluginName);\n-        File pluginConfigDir = new File(env.configFile(), pluginName);\n+        File binDir = new File(env.homeFile(), \"bin\");\n+        if (!binDir.exists() && !FileSystemUtils.mkdirs(binDir)) {\n+            throw new IOException(\"Could not create bin directory [\" + binDir.getAbsolutePath() + \"]\");\n+        }\n+        File pluginBinDir = new File(binDir, pluginName);\n+        File configDir = env.configFile();\n+        if (!configDir.exists() && !FileSystemUtils.mkdirs(configDir)) {\n+            throw new IOException(\"Could not create config directory [\" + configDir.getAbsolutePath() + \"]\");\n+        }\n+        File pluginConfigDir = new File(configDir, pluginName);\n         try {\n \n             PluginManager pluginManager = pluginManager(getPluginUrlForResource(\"plugin_with_bin_and_config.zip\"), initialSettings);",
    "output": "Add a fix to the PluginManagerTests to create config & bin dirs if they don't exist"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginManager.java b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -211,7 +211,9 @@ public void downloadAndExtract(String name) throws IOException {\n             File toLocation = pluginHandle.binDir(environment);\n             debug(\"Found bin, moving to \" + toLocation.getAbsolutePath());\n             FileSystemUtils.deleteRecursively(toLocation);\n-            binFile.renameTo(toLocation);\n+            if (!binFile.renameTo(toLocation)) {\n+                throw new IOException(\"Could not move [\"+ binFile.getAbsolutePath() + \"] to [\" + toLocation.getAbsolutePath() + \"]\");\n+            }\n             debug(\"Installed \" + name + \" into \" + toLocation.getAbsolutePath());\n         }\n \n@@ -220,7 +222,9 @@ public void downloadAndExtract(String name) throws IOException {\n             File toLocation = pluginHandle.configDir(environment);\n             debug(\"Found config, moving to \" + toLocation.getAbsolutePath());\n             FileSystemUtils.deleteRecursively(toLocation);\n-            configFile.renameTo(toLocation);\n+            if (!configFile.renameTo(toLocation)) {\n+                throw new IOException(\"Could not move [\"+ configFile.getAbsolutePath() + \"] to [\" + configFile.getAbsolutePath() + \"]\");\n+            }\n             debug(\"Installed \" + name + \" into \" + toLocation.getAbsolutePath());\n         }\n ",
    "output": "Add a check on moving bin & config plugin dirs Plugins can contain bin & config sub-dirs that are copied to es's bin & config directories. If moving these directories fails we now throw an error"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java b/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java\n--- a/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java\n+++ b/src/main/java/org/elasticsearch/indices/analysis/HunspellService.java\n@@ -140,7 +140,7 @@ private void scanAndLoadDictionaries() {\n      */\n     private Dictionary loadDictionary(String locale, Settings nodeSettings, Environment env) throws Exception {\n         if (logger.isDebugEnabled()) {\n-            logger.debug(\"Loading huspell dictionary [{}]...\", locale);\n+            logger.debug(\"Loading hunspell dictionary [{}]...\", locale);\n         }\n         File dicDir = new File(hunspellDir, locale);\n         if (!dicDir.exists() || !dicDir.isDirectory()) {",
    "output": "Fix typo in Hunspell logging"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -184,6 +184,8 @@ public class Version implements Serializable {\n     public static final Version V_1_2_1 = new Version(V_1_2_1_ID, false, org.apache.lucene.util.Version.LUCENE_4_8);\n     public static final int V_1_2_2_ID = /*00*/1020299;\n     public static final Version V_1_2_2 = new Version(V_1_2_2_ID, false, org.apache.lucene.util.Version.LUCENE_4_8);\n+    public static final int V_1_2_3_ID = /*00*/1020399;\n+    public static final Version V_1_2_3 = new Version(V_1_2_3_ID, false, org.apache.lucene.util.Version.LUCENE_4_8);\n     public static final int V_1_3_0_ID = /*00*/1030099;\n     public static final Version V_1_3_0 = new Version(V_1_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_4_9);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n@@ -205,6 +207,8 @@ public static Version fromId(int id) {\n                 return V_2_0_0;\n             case V_1_3_0_ID:\n                 return V_1_3_0;\n+            case V_1_2_3_ID:\n+                return V_1_2_3;\n             case V_1_2_2_ID:\n                 return V_1_2_2;\n             case V_1_2_1_ID:",
    "output": "Add v1.2.3 to Version.java"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/benchmark/mapping/ManyMappingsBenchmark.java b/src/test/java/org/elasticsearch/benchmark/mapping/ManyMappingsBenchmark.java\n--- a/src/test/java/org/elasticsearch/benchmark/mapping/ManyMappingsBenchmark.java\n+++ b/src/test/java/org/elasticsearch/benchmark/mapping/ManyMappingsBenchmark.java\n@@ -82,22 +82,26 @@ public class ManyMappingsBenchmark {\n     private static final String TYPE_NAME = \"type\";\n     private static final int FIELD_COUNT = 100000;\n     private static final int DOC_COUNT = 10000000;\n+    private static final boolean TWO_NODES = false;\n \n     public static void main(String[] args) throws Exception {\n         System.setProperty(\"es.logger.prefix\", \"\");\n         Natives.tryMlockall();\n         Settings settings = settingsBuilder()\n-                .put(\"index.refresh_interval\", \"-1\")\n                 .put(\"gateway.type\", \"local\")\n                 .put(SETTING_NUMBER_OF_SHARDS, 5)\n                 .put(SETTING_NUMBER_OF_REPLICAS, 0)\n-                .put(TransportModule.TRANSPORT_TYPE_KEY, \"local\")\n                 .build();\n \n         String clusterName = ManyMappingsBenchmark.class.getSimpleName();\n         Node node = nodeBuilder().clusterName(clusterName)\n                 .settings(settingsBuilder().put(settings))\n                 .node();\n+        if (TWO_NODES) {\n+            Node node2 = nodeBuilder().clusterName(clusterName)\n+                    .settings(settingsBuilder().put(settings))\n+                    .node();\n+        }\n \n         Client client = node.client();\n ",
    "output": "Add more options to many mappings test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java\n@@ -66,11 +66,11 @@ public Names(String name, String indexName, String indexNameClean, String fullNa\n         }\n \n         public Names(String name, String indexName, String indexNameClean, String fullName, @Nullable String sourcePath) {\n-            this.name = name.intern();\n-            this.indexName = indexName.intern();\n-            this.indexNameClean = indexNameClean.intern();\n-            this.fullName = fullName.intern();\n-            this.sourcePath = sourcePath == null ? this.fullName : sourcePath.intern();\n+            this.name = name;\n+            this.indexName = indexName;\n+            this.indexNameClean = indexNameClean;\n+            this.fullName = fullName;\n+            this.sourcePath = sourcePath == null ? this.fullName : sourcePath;\n         }\n \n         /**",
    "output": "Remove intern calls on FieldMapper#Names remove internal callas on FieldMappers#Names, we properly reuse FieldMapper, so there is no need to try and call intern in order to reuse the names. This can be heavy with many fields and continuous mapping parsing"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java b/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java\n--- a/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/ClusterServiceTests.java\n@@ -405,7 +405,6 @@ public void onFailure(String source, Throwable t) {\n     }\n \n     @Test\n-    @Repeat(iterations = 1000)\n     public void testPendingUpdateTask() throws Exception {\n         Settings settings = settingsBuilder()\n                 .put(\"discovery.type\", \"local\")",
    "output": "Remove repeat lefover"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginManager.java b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -248,19 +248,28 @@ public void removePlugin(String name) throws IOException {\n         File pluginToDelete = pluginHandle.extractedDir(environment);\n         if (pluginToDelete.exists()) {\n             debug(\"Removing: \" + pluginToDelete.getPath());\n-            FileSystemUtils.deleteRecursively(pluginToDelete, true);\n+            if (!FileSystemUtils.deleteRecursively(pluginToDelete, true)) {\n+                throw new IOException(\"Unable to remove \" + pluginHandle.name + \". Check file permissions on \" +\n+                        pluginToDelete.toString());\n+            }\n             removed = true;\n         }\n         pluginToDelete = pluginHandle.distroFile(environment);\n         if (pluginToDelete.exists()) {\n             debug(\"Removing: \" + pluginToDelete.getPath());\n-            pluginToDelete.delete();\n+            if (!pluginToDelete.delete()) {\n+                throw new IOException(\"Unable to remove \" + pluginHandle.name + \". Check file permissions on \" +\n+                        pluginToDelete.toString());\n+            }\n             removed = true;\n         }\n         File binLocation = pluginHandle.binDir(environment);\n         if (binLocation.exists()) {\n             debug(\"Removing: \" + binLocation.getPath());\n-            FileSystemUtils.deleteRecursively(binLocation);\n+            if (!FileSystemUtils.deleteRecursively(binLocation)) {\n+                throw new IOException(\"Unable to remove \" + pluginHandle.name + \". Check file permissions on \" +\n+                        binLocation.toString());\n+            }\n             removed = true;\n         }\n         if (removed) {",
    "output": "Remove plugin does not fail when plugin dir is read only If you try to remove a plugin in read only dir, you get a successful result: ``` $ bin/plugin --remove marvel -> Removing marvel Removed marvel ``` But actually the plugin has not been removed. When installing, if fails properly: ``` $ bin/plugin -i elasticsearch/marvel/latest -> Installing elasticsearch/marvel/latest... Failed to install elasticsearch/marvel/latest, reason: plugin directory /usr/local/elasticsearch/plugins is read only ``` This change throw an exception when we don't succeed removing the plugin"
  },
  {
    "input": "diff --git a/src/main/java/org/apache/lucene/analysis/SimpleAnalyzerWrapper.java b/src/main/java/org/apache/lucene/analysis/SimpleAnalyzerWrapper.java\n--- a/src/main/java/org/apache/lucene/analysis/SimpleAnalyzerWrapper.java\n+++ b/src/main/java/org/apache/lucene/analysis/SimpleAnalyzerWrapper.java\n@@ -32,6 +32,10 @@\n  */\n public abstract class SimpleAnalyzerWrapper extends AnalyzerWrapper {\n \n+    static {\n+        assert org.elasticsearch.Version.CURRENT.luceneVersion == org.apache.lucene.util.Version.LUCENE_4_9: \"Remove this code once we upgrade to Lucene 4.10 (LUCENE-5803)\";\n+    }\n+\n     public SimpleAnalyzerWrapper() {\n         super(new DelegatingReuseStrategy());\n         ((DelegatingReuseStrategy) getReuseStrategy()).wrapper = this;",
    "output": "Make sure we use the new analyzer wrapper on 4.10"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/CompositeTestCluster.java b/src/test/java/org/elasticsearch/test/CompositeTestCluster.java\n--- a/src/test/java/org/elasticsearch/test/CompositeTestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/CompositeTestCluster.java\n@@ -108,15 +108,17 @@ public synchronized boolean upgradeOneNode() throws InterruptedException, IOExce\n     public synchronized boolean upgradeOneNode(Settings nodeSettings) throws InterruptedException, IOException {\n         Collection<ExternalNode> runningNodes = runningNodes();\n         if (!runningNodes.isEmpty()) {\n+            final Client existingClient = cluster.client();\n             ExternalNode externalNode = RandomPicks.randomFrom(random, runningNodes);\n             externalNode.stop();\n             String s = cluster.startNode(nodeSettings);\n-            ExternalNode.waitForNode(cluster.client(), s);\n+            ExternalNode.waitForNode(existingClient, s);\n             return true;\n         }\n         return false;\n     }\n \n+\n     /**\n      * Returns the a simple pattern that matches all \"new\" nodes in the cluster.\n      */",
    "output": "Use existing client that is already in the cluster to wait for joining node"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginManager.java b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -482,7 +482,7 @@ List<URL> urls() {\n                 // Sonatype repository\n                 addUrl(urls, \"https://oss.sonatype.org/service/local/repositories/releases/content/\" + user.replace('.', '/') + \"/\" + repo + \"/\" + version + \"/\" + repo + \"-\" + version + \".zip\");\n                 // Github repository\n-                addUrl(urls, \"https://github.com/\" + user + \"/\" + repo + \"/archive/v\" + version + \".zip\");\n+                addUrl(urls, \"https://github.com/\" + user + \"/\" + repo + \"/archive/\" + version + \".zip\");\n             }\n             // Github repository for master branch (assume site)\n             addUrl(urls, \"https://github.com/\" + user + \"/\" + repo + \"/archive/master.zip\");",
    "output": "Fix github download link when using specific version"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java b/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java\n--- a/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java\n+++ b/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java\n@@ -23,17 +23,16 @@\n import org.elasticsearch.action.ActionRequestValidationException;\n import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;\n import org.elasticsearch.action.count.CountResponse;\n-import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.metadata.MappingMetaData;\n import org.elasticsearch.common.collect.ImmutableOpenMap;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n-import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;\n import org.junit.Test;\n \n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n-import static org.hamcrest.Matchers.*;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.notNullValue;\n \n /**\n  *\n@@ -42,6 +41,7 @@ public class SimpleDeleteMappingTests extends ElasticsearchIntegrationTest {\n \n     @Test\n     public void simpleDeleteMapping() throws Exception {\n+        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", \"value\", \"type=string\").execute().actionGet());\n         for (int i = 0; i < 10; i++) {\n             client().prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(jsonBuilder().startObject()\n                     .field(\"value\", \"test\" + i)",
    "output": "Fix SimpleDeleteMappingTests. The failure was hard to reproduce but it looked to me like dynamic mapping updates were overriding the delete mappings request"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n@@ -1705,6 +1705,7 @@ public void testPercolationWithDynamicTemplates() throws Exception {\n                 .endObject()\n                 .endArray()\n                 .endObject().endObject()));\n+        ensureGreen(\"idx\");\n \n         client().prepareIndex(\"idx\", PercolatorService.TYPE_NAME, \"1\")\n                 .setSource(jsonBuilder().startObject().field(\"query\", QueryBuilders.queryString(\"color:red\")).endObject())\n@@ -1756,8 +1757,7 @@ public void testUpdateMappingDynamicallyWhilePercolating() throws Exception {\n         assertMatchCount(response, 0l);\n         assertThat(response.getMatches(), arrayWithSize(0));\n \n-        ensureYellow(\"test\"); // wait for at least primaries allocations so concretely allocated on it\n-        waitForConcreteMappingsOnAll(\"test\", \"type1\", \"field1\", \"field2\");\n+        waitForMappingOnMaster(\"test\", \"type1\");\n \n         GetMappingsResponse mappingsResponse = client().admin().indices().prepareGetMappings(\"test\").get();\n         assertThat(mappingsResponse.getMappings().get(\"test\"), notNullValue());",
    "output": "Fix PercolatorTests to wait for mappings on master"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/fields/SearchFieldsTests.java b/src/test/java/org/elasticsearch/search/fields/SearchFieldsTests.java\n--- a/src/test/java/org/elasticsearch/search/fields/SearchFieldsTests.java\n+++ b/src/test/java/org/elasticsearch/search/fields/SearchFieldsTests.java\n@@ -185,7 +185,7 @@ public void testScriptDocAndFields() throws Exception {\n \n     @Test\n     public void testUidBasedScriptFields() throws Exception {\n-        createIndex(\"test\");\n+        prepareCreate(\"test\").addMapping(\"type1\", \"num1\", \"type=long\").execute().actionGet();\n         ensureYellow();\n \n         int numDocs = randomIntBetween(1, 30);",
    "output": "Fix failure in SearchFieldsTests.testUidBasedScriptFields. Sorting fails on unmapped fields so the new propagation delay of the mappings exposed this issue. I added explicit mappings as part of index creation to fix it"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/Store.java b/src/main/java/org/elasticsearch/index/store/Store.java\n--- a/src/main/java/org/elasticsearch/index/store/Store.java\n+++ b/src/main/java/org/elasticsearch/index/store/Store.java\n@@ -224,8 +224,9 @@ private static Map<String, String> readChecksums(Directory[] dirs, Map<String, S\n     public void writeChecksums() throws IOException {\n         ensureOpen();\n         ImmutableMap<String, StoreFileMetaData> files = list();\n-        String checksumName = CHECKSUMS_PREFIX + System.currentTimeMillis();\n+        String checksumName;\n         synchronized (mutex) {\n+            checksumName = CHECKSUMS_PREFIX + System.currentTimeMillis();\n             Map<String, String> checksums = new HashMap<>();\n             for (StoreFileMetaData metaData : files.values()) {\n                 if (metaData.checksum() != null) {",
    "output": "Fix possible race condition in checksum name generator When three threads are trying to write checksums at the same time, it's possible for all three threads to obtain the same checksum file name A. Then the first thread enters the synchronized section, creates the file with name A and exits. The second thread enters the synchronized section, checks that A exists, creates file A+1 and exits the critical section. Then it proceeds to clean up and deletes all checksum files including A. If it happens before the third thread enters the synchronized section, it's possible for the third thread to check for A and since it no longer exists create the checksum file A the second time, which triggers \"file _checksums-XXXXXXXXXXXXX was already written to\" exception in MockDirectoryWrapper and fails recovery"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n--- a/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/InternalTestCluster.java\n@@ -92,7 +92,6 @@\n import java.util.concurrent.atomic.AtomicInteger;\n \n import static com.carrotsearch.randomizedtesting.RandomizedTest.frequently;\n-import static com.carrotsearch.randomizedtesting.RandomizedTest.randomIntBetween;\n import static com.carrotsearch.randomizedtesting.RandomizedTest.systemPropertyAsBoolean;\n import static org.apache.lucene.util.LuceneTestCase.rarely;\n import static org.apache.lucene.util.LuceneTestCase.usually;\n@@ -343,7 +342,7 @@ private static Settings getRandomNodeSettings(long seed) {\n         }\n \n         if (random.nextBoolean()) {\n-            builder.put(MappingUpdatedAction.INDICES_MAPPING_ADDITIONAL_MAPPING_CHANGE_TIME, randomIntBetween(0, 500) /*milliseconds*/);\n+            builder.put(MappingUpdatedAction.INDICES_MAPPING_ADDITIONAL_MAPPING_CHANGE_TIME, RandomInts.randomIntBetween(random, 0, 500) /*milliseconds*/);\n         }\n \n         return builder.build();",
    "output": "Improve reproducibility of mappings propagation delays related issues"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryTests.java b/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryTests.java\n--- a/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryTests.java\n+++ b/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.indices.recovery;\n \n import com.carrotsearch.randomizedtesting.LifecycleScope;\n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.admin.cluster.snapshots.create.CreateSnapshotResponse;\n import org.elasticsearch.action.admin.cluster.snapshots.restore.RestoreSnapshotResponse;\n import org.elasticsearch.action.admin.indices.recovery.RecoveryResponse;\n@@ -161,6 +162,7 @@ public void gatewayRecoveryTestActiveOnly() throws Exception {\n     }\n \n     @Test\n+    @LuceneTestCase.AwaitsFix(bugUrl = \"test ensureGreen times out. Boaz looking into it\")\n     public void replicaRecoveryTest() throws Exception {\n         logger.info(\"--> start node A\");\n         String nodeA = internalCluster().startNode(settingsBuilder().put(\"gateway.type\", \"local\"));",
    "output": "Add awaitFix to rerouteRecoveryTest"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -696,6 +696,7 @@ public void handleResponse(TransportResponse.Empty vResponse) {\n \n                     @Override\n                     public void handleException(TransportException exp) {\n+                        logger.trace(\"[{}] Transport failure during replica request [{}] \", exp, node, request);\n                         if (!ignoreReplicaException(exp.unwrapCause())) {\n                             logger.warn(\"Failed to perform \" + transportAction + \" on remote replica \" + node + shardIt.shardId(), exp);\n                             shardStateAction.shardFailed(shard, indexMetaData.getUUID(),\n@@ -757,6 +758,7 @@ public boolean isForceExecution() {\n     }\n \n     private void failReplicaIfNeeded(String index, int shardId, Throwable t) {\n+        logger.trace(\"failure on replica [{}][{}]\", t, index, shardId);\n         if (!ignoreReplicaException(t)) {\n             IndexService indexService = indicesService.indexService(index);\n             if (indexService == null) {",
    "output": "Improve logging for replica operation failures"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java b/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java\n--- a/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java\n+++ b/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java\n@@ -50,6 +50,7 @@\n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.elasticsearch.test.ElasticsearchIntegrationTest.Scope;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;\n import static org.hamcrest.Matchers.*;\n \n /**\n@@ -91,8 +92,8 @@ public void verifyThreadNames() throws Exception {\n         indexRandom(true, builders);\n         int numSearches = randomIntBetween(2, 100);\n         for (int i = 0; i < numSearches; i++) {\n-            assertAllSuccessful(client().prepareSearch(\"idx\").setQuery(QueryBuilders.termQuery(\"str_value\", \"s\" + i)).get());\n-            assertAllSuccessful(client().prepareSearch(\"idx\").setQuery(QueryBuilders.termQuery(\"l_value\", i)).get());\n+            assertNoFailures(client().prepareSearch(\"idx\").setQuery(QueryBuilders.termQuery(\"str_value\", \"s\" + i)).get());\n+            assertNoFailures(client().prepareSearch(\"idx\").setQuery(QueryBuilders.termQuery(\"l_value\", i)).get());\n         }\n         Set<String> threadNames = Sets.newHashSet();\n         for (long l : threadBean.getAllThreadIds()) {",
    "output": "Use no failures, shard might not have been initialize yet"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/ScriptModule.java b/src/main/java/org/elasticsearch/script/ScriptModule.java\n--- a/src/main/java/org/elasticsearch/script/ScriptModule.java\n+++ b/src/main/java/org/elasticsearch/script/ScriptModule.java\n@@ -80,21 +80,24 @@ protected void configure() {\n         multibinder.addBinding().to(NativeScriptEngineService.class);\n \n         try {\n+            settings.getClassLoader().loadClass(\"groovy.lang.GroovyClassLoader\");\n             multibinder.addBinding().to(GroovyScriptEngineService.class);\n         } catch (Throwable t) {\n-            Loggers.getLogger(GroovyScriptEngineService.class).debug(\"failed to load groovy\", t);\n+            Loggers.getLogger(ScriptService.class, settings).debug(\"failed to load groovy\", t);\n         }\n \n         try {\n+            settings.getClassLoader().loadClass(\"org.mvel2.MVEL\");\n             multibinder.addBinding().to(MvelScriptEngineService.class);\n         } catch (Throwable t) {\n-            Loggers.getLogger(MvelScriptEngineService.class).debug(\"failed to load mvel\", t);\n+            Loggers.getLogger(ScriptService.class, settings).debug(\"failed to load mvel\", t);\n         }\n         \n         try {\n+            settings.getClassLoader().loadClass(\"com.github.mustachejava.Mustache\");\n             multibinder.addBinding().to(MustacheScriptEngineService.class);\n         } catch (Throwable t) {\n-            Loggers.getLogger(MustacheScriptEngineService.class).debug(\"failed to load mustache\", t);\n+            Loggers.getLogger(ScriptService.class, settings).debug(\"failed to load mustache\", t);\n         }\n \n         for (Class<? extends ScriptEngineService> scriptEngine : scriptEngines) {",
    "output": "Fix optional default script loading Groovy is optional as a dependency in the classpath, make sure we properly detect when its not at the right time to disable it"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/TransportAction.java b/src/main/java/org/elasticsearch/action/support/TransportAction.java\n--- a/src/main/java/org/elasticsearch/action/support/TransportAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/TransportAction.java\n@@ -97,7 +97,7 @@ public void run() {\n                     }\n                 });\n             } catch (EsRejectedExecutionException ex) {\n-                logger.debug(\"Can not run threaded action, exectuion rejected [{}] running on current thread\", listener);\n+                logger.debug(\"Can not run threaded action, execution rejected [{}] running on current thread\", listener);\n                 /* we don't care if that takes long since we are shutting down. But if we not respond somebody could wait\n                  * for the response on the listener side which could be a remote machine so make sure we push it out there.*/\n                 try {",
    "output": "Fix typo in TransportAction log line"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/get/GetActionTests.java b/src/test/java/org/elasticsearch/get/GetActionTests.java\n--- a/src/test/java/org/elasticsearch/get/GetActionTests.java\n+++ b/src/test/java/org/elasticsearch/get/GetActionTests.java\n@@ -41,7 +41,6 @@\n \n import static org.elasticsearch.client.Requests.clusterHealthRequest;\n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;\n import static org.hamcrest.Matchers.*;\n \n@@ -855,7 +854,6 @@ public void testGetFields_complexField() throws Exception {\n \n         FlushResponse flushResponse = client().admin().indices().prepareFlush(\"my-index\").get();\n         assertNoFailures(flushResponse);\n-        assertAllSuccessful(flushResponse);\n \n         getResponse = client().prepareGet(\"my-index\", \"my-type1\", \"1\").setFields(field).get();\n         assertThat(getResponse.isExists(), equalTo(true));",
    "output": "Remove incorrect assertion (it is expected that the flush doesn't execute on all shard copies, because we don't wait for green status)"
  },
  {
    "input": "diff --git a/src/test/java/org/apache/lucene/util/AbstractRandomizedTest.java b/src/test/java/org/apache/lucene/util/AbstractRandomizedTest.java\n--- a/src/test/java/org/apache/lucene/util/AbstractRandomizedTest.java\n+++ b/src/test/java/org/apache/lucene/util/AbstractRandomizedTest.java\n@@ -58,7 +58,8 @@\n         JUnit4MethodProvider.class\n })\n @Listeners({\n-        ReproduceInfoPrinter.class\n+        ReproduceInfoPrinter.class,\n+        FailureMarker.class\n })\n @RunWith(value = com.carrotsearch.randomizedtesting.RandomizedRunner.class)\n @SuppressCodecs(value = \"Lucene3x\")",
    "output": "Add FailureMarker to test listeners so -Dtests.failfast works"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -260,7 +260,14 @@ private static void initializeGlobalCluster() {\n                 GLOBAL_CLUSTER = new ExternalTestCluster(transportAddresses);\n             } else {\n                 long masterSeed = SeedUtils.parseSeed(RandomizedContext.current().getRunnerSeedAsString());\n-                GLOBAL_CLUSTER = new TestCluster(masterSeed, clusterName(\"shared\", ElasticsearchTestCase.CHILD_VM_ID, masterSeed));\n+                int numClientNodes;\n+                if (COMPATIBILITY_VERSION.before(Version.V_1_2_0)) {\n+                    numClientNodes = 0;\n+                } else {\n+                    numClientNodes = TestCluster.DEFAULT_NUM_CLIENT_NODES;\n+                }\n+                GLOBAL_CLUSTER = new TestCluster(masterSeed, TestCluster.DEFAULT_MIN_NUM_DATA_NODES, TestCluster.DEFAULT_MAX_NUM_DATA_NODES,\n+                        clusterName(\"shared\", ElasticsearchTestCase.CHILD_VM_ID, masterSeed), numClientNodes, TestCluster.DEFAULT_ENABLE_RANDOM_BENCH_NODES);\n             }\n         }\n     }",
    "output": "Add backwards compatibility check to control whether to enable client nodes or not within TestCluster Our REST backwards compatibility tests need to be able to disable client nodes within the TestCluster when running older tests that assume client nodes are not around"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/versioning/SimpleVersioningTests.java b/src/test/java/org/elasticsearch/versioning/SimpleVersioningTests.java\n--- a/src/test/java/org/elasticsearch/versioning/SimpleVersioningTests.java\n+++ b/src/test/java/org/elasticsearch/versioning/SimpleVersioningTests.java\n@@ -491,9 +491,9 @@ public void testRandomIDsAndVersions() throws Exception {\n \n         int numIDs;\n         if (isNightly()) {\n-            numIDs = scaledRandomIntBetween(3000, 10000);\n+            numIDs = scaledRandomIntBetween(300, 1000);\n         } else {\n-            numIDs = scaledRandomIntBetween(500, 1000);\n+            numIDs = scaledRandomIntBetween(50, 100);\n         }\n \n         while (idsSet.size() < numIDs) {\n@@ -506,7 +506,7 @@ public void testRandomIDsAndVersions() throws Exception {\n \n         // Attach random versions to them:\n         long version = 0;\n-        final IDAndVersion[] idVersions = new IDAndVersion[TestUtil.nextInt(random, numIDs/2, numIDs*(isNightly() ? 4 : 2))];\n+        final IDAndVersion[] idVersions = new IDAndVersion[TestUtil.nextInt(random, numIDs/2, numIDs*(isNightly() ? 8 : 2))];\n         final Map<String,IDAndVersion> truth = new HashMap<>();\n \n         if (VERBOSE) {",
    "output": "Make test less evil"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java b/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java\n@@ -239,7 +239,7 @@ public RecoveryResponse newInstance() {\n                         .append(\", took [\").append(timeValueMillis(recoveryResponse.phase3Time)).append(\"]\");\n                 logger.trace(sb.toString());\n             } else if (logger.isDebugEnabled()) {\n-                logger.debug(\"recovery completed from [{}], took [{}]\", request.shardId(), request.sourceNode(), stopWatch.totalTime());\n+                logger.debug(\"{} recovery completed from [{}], took [{}]\", request.shardId(), request.sourceNode(), stopWatch.totalTime());\n             }\n             removeAndCleanOnGoingRecovery(recoveryStatus);\n             listener.onRecoveryDone();",
    "output": "Fix recovery debug logging param mismatch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -178,6 +178,8 @@ public class Version implements Serializable {\n     public static final Version V_1_1_2 = new Version(V_1_1_2_ID, false, org.apache.lucene.util.Version.LUCENE_47);\n     public static final int V_1_2_0_ID = /*00*/1020099;\n     public static final Version V_1_2_0 = new Version(V_1_2_0_ID, false, org.apache.lucene.util.Version.LUCENE_48);\n+    public static final int V_1_2_1_ID = /*00*/1020199;\n+    public static final Version V_1_2_1 = new Version(V_1_2_1_ID, false, org.apache.lucene.util.Version.LUCENE_48);\n     public static final int V_1_3_0_ID = /*00*/1030099;\n     public static final Version V_1_3_0 = new Version(V_1_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_48);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n@@ -199,6 +201,8 @@ public static Version fromId(int id) {\n                 return V_2_0_0;\n             case V_1_3_0_ID:\n                 return V_1_3_0;\n+            case V_1_2_1_ID:\n+                return V_1_2_1;\n             case V_1_2_0_ID:\n                 return V_1_2_0;\n             case V_1_1_2_ID:",
    "output": "Add [1.2.1] Release"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/stats/RestNodesStatsAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/stats/RestNodesStatsAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/stats/RestNodesStatsAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/stats/RestNodesStatsAction.java\n@@ -53,10 +53,8 @@ public RestNodesStatsAction(Settings settings, Client client, RestController con\n         controller.registerHandler(GET, \"/_nodes/{nodeId}/stats/{metric}\", this);\n \n         controller.registerHandler(GET, \"/_nodes/stats/{metric}/{indexMetric}\", this);\n-        controller.registerHandler(GET, \"/_nodes/stats/{metric}/{indexMetric}/{fields}\", this);\n \n         controller.registerHandler(GET, \"/_nodes/{nodeId}/stats/{metric}/{indexMetric}\", this);\n-        controller.registerHandler(GET, \"/_nodes/{nodeId}/stats/{metric}/{indexMetric}/{fields}\", this);\n     }\n \n     @Override",
    "output": "Remove support for field names in node_stats url Field names ended up making the urls too long, fields are still supported as query string parameters though (same as indices stats)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java b/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/attachment/AttachmentMapper.java\n@@ -351,10 +351,6 @@ public void parse(ParseContext context) throws IOException {\n                         contentType = parser.text();\n                     } else if (\"_name\".equals(currentFieldName)) {\n                         name = parser.text();\n-                    } else if (\"language\".equals(currentFieldName)) {\n-                        // TODO deprecated form. Will be removed in 2.3\n-                    \tlanguage = parser.text();\n-                        logger.debug(\"`language` is now deprecated. Use `_language`. See https://github.com/elasticsearch/elasticsearch-mapper-attachments/issues/68\");\n                     } else if (\"_language\".equals(currentFieldName)) {\n                         language = parser.text();\n                     }",
    "output": "Remove deprecated `language` forced field With #68 we replaced `language`field with `_language`. We can now remove the old deprecated name. . (cherry picked from commit e39f144)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java b/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java\n--- a/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java\n+++ b/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java\n@@ -177,7 +177,10 @@ public static void close() {\n     public void reset() throws IOException, RestException {\n         //skip test if it matches one of the blacklist globs\n         for (PathMatcher blacklistedPathMatcher : blacklistPathMatchers) {\n-            assumeFalse(\"[\" + testCandidate.getTestPath() + \"] skipped, reason: blacklisted\", blacklistedPathMatcher.matches(Paths.get(testCandidate.getTestPath())));\n+            //we need to replace a few characters otherwise the test section name can't be parsed as a path on windows\n+            String testSection = testCandidate.getTestSection().getName().replace(\"*\", \"\").replace(\"\\\\\", \"/\").replaceAll(\"\\\\s+/\", \"/\").trim();\n+            String testPath = testCandidate.getSuitePath() + \"/\" + testSection;\n+            assumeFalse(\"[\" + testCandidate.getTestPath() + \"] skipped, reason: blacklisted\", blacklistedPathMatcher.matches(Paths.get(testPath)));\n         }\n \n         restTestExecutionContext.resetClient(immutableCluster().httpAddresses());",
    "output": "Make sure that the -Dtests.rest.blacklist parameter works on windows too Some reserved characters need to be replaced in the test section names, which gets parsed as a path although it isn't a filename"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java b/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n--- a/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n+++ b/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n@@ -73,7 +73,6 @@ public ConcurrentMergeSchedulerProvider(ShardId shardId, @IndexSettings Settings\n     @Override\n     public MergeScheduler buildMergeScheduler() {\n         CustomConcurrentMergeScheduler concurrentMergeScheduler = new CustomConcurrentMergeScheduler(logger, shardId, this);\n-        // nocommit but this doesn't handle SMS ... should we even expose/allow SMS?  or, if user requests SMS can we just use CMS(1,1),\n         // which would then stall if there are 2 merges in flight, and unstall once we are back to 1 or 0 merges\n         // NOTE: we pass maxMergeCount+1 here so that CMS will allow one too many merges to kick off which then allows\n         // InternalEngine.IndexThrottle to detect too-many-merges and throttle:",
    "output": "Remove stale nocommit"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indexing/IndexActionTests.java b/src/test/java/org/elasticsearch/indexing/IndexActionTests.java\n--- a/src/test/java/org/elasticsearch/indexing/IndexActionTests.java\n+++ b/src/test/java/org/elasticsearch/indexing/IndexActionTests.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.action.index.IndexResponse;\n import org.elasticsearch.index.VersionType;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.junit.Test;\n \n import java.util.ArrayList;\n@@ -47,6 +48,7 @@ public class IndexActionTests extends ElasticsearchIntegrationTest {\n      * while the index is being created.\n      */\n     @Test\n+    @TestLogging(\"action.search:TRACE\")\n     public void testAutoGenerateIdNoDuplicates() throws Exception {\n         int numberOfIterations = randomIntBetween(10, 50);\n         for (int i = 0; i < numberOfIterations; i++) {\n@@ -57,6 +59,7 @@ public void testAutoGenerateIdNoDuplicates() throws Exception {\n                 builders.add(client().prepareIndex(\"test\", \"type\").setSource(\"field\", \"value\"));\n             }\n             indexRandom(true, builders);\n+            logger.info(\"verifying indexed content\");\n             int numOfChecks = randomIntBetween(5, 10);\n             for (int j = 0; j < numOfChecks; j++) {\n                 assertHitCount(client().prepareSearch(\"test\").get(), numOfDocs);",
    "output": "Add search trace logging to IndexActionTests.testAutoGenerateIdNoDuplicates"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cloud/aws/AbstractAwsTest.java b/src/test/java/org/elasticsearch/cloud/aws/AbstractAwsTest.java\n--- a/src/test/java/org/elasticsearch/cloud/aws/AbstractAwsTest.java\n+++ b/src/test/java/org/elasticsearch/cloud/aws/AbstractAwsTest.java\n@@ -20,6 +20,9 @@\n package org.elasticsearch.cloud.aws;\n \n import com.carrotsearch.randomizedtesting.annotations.TestGroup;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n \n import java.lang.annotation.Documented;\n@@ -62,4 +65,11 @@ public abstract class AbstractAwsTest extends ElasticsearchIntegrationTest {\n      */\n     public static final String SYSPROP_AWS = \"tests.aws\";\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n }",
    "output": "Upgrade to elasticsearch 1.3.0 . (cherry picked from commit d65a970)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/ICUIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/ICUIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/ICUIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/ICUIntegrationTests.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n@@ -38,6 +39,14 @@\n @ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class ICUIntegrationTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @Override\n     public Settings indexSettings() {\n         Settings settings = ImmutableSettings.builder()",
    "output": "Upgrade to elasticsearch 1.3.0 . (cherry picked from commit 4d17e47)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimplePhoneticIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimplePhoneticIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimplePhoneticIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimplePhoneticIntegrationTests.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n@@ -38,6 +39,14 @@\n @ElasticsearchIntegrationTest.ClusterScope(numDataNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimplePhoneticIntegrationTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @Override\n     public Settings indexSettings() {\n         Settings settings = ImmutableSettings.builder()",
    "output": "Upgrade to elasticsearch 1.3.0 . (cherry picked from commit 60b7c55)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n@@ -20,6 +20,9 @@\n package org.elasticsearch.index.analysis;\n \n import org.elasticsearch.action.admin.indices.analyze.AnalyzeResponse;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n@@ -30,6 +33,14 @@\n @ElasticsearchIntegrationTest.ClusterScope(numDataNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimpleSmartChineseIntegrationTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @Test\n     public void testSmartcnAnalyzer() throws ExecutionException, InterruptedException {\n         AnalyzeResponse response = client().admin().indices()",
    "output": "Upgrade to elasticsearch 1.3.0 . (cherry picked from commit a1b37f6)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n@@ -27,7 +27,7 @@\n \n import static org.hamcrest.CoreMatchers.*;\n \n-@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n+@ElasticsearchIntegrationTest.ClusterScope(numDataNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimpleSmartChineseIntegrationTests extends ElasticsearchIntegrationTest {\n \n     @Test",
    "output": "Upgrade to Lucene 4.8 / Elasticsearch 1.2.0 Related to #18"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n@@ -20,7 +20,10 @@\n package org.elasticsearch.index.analysis;\n \n import org.elasticsearch.action.admin.indices.analyze.AnalyzeResponse;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n@@ -34,6 +37,14 @@\n @ElasticsearchIntegrationTest.ClusterScope(numDataNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimplePolishIntegrationTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @Test\n     public void testPolishAnalyzer() throws ExecutionException, InterruptedException {\n         AnalyzeResponse response = client().admin().indices()",
    "output": "Upgrade to elasticsearch 1.3.0 . (cherry picked from commit 5effcce)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n@@ -31,7 +31,7 @@\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.CoreMatchers.notNullValue;\n \n-@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n+@ElasticsearchIntegrationTest.ClusterScope(numDataNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimplePolishIntegrationTests extends ElasticsearchIntegrationTest {\n \n     @Test",
    "output": "Upgrade to elasticsearch 1.2.0 elasticsearch 1.2.0 has been released. We need to update from SNAPSHOT to released version. . (cherry picked from commit ae3f3c23e3fde3b2327c1b5d759ff27675ecb40c)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java b/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java\n--- a/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java\n+++ b/src/test/java/org/elasticsearch/script/python/PythonScriptSearchTests.java\n@@ -21,7 +21,10 @@\n \n import org.elasticsearch.action.search.SearchResponse;\n import org.elasticsearch.action.search.SearchType;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.search.sort.SortOrder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.hamcrest.CoreMatchers;\n@@ -43,8 +46,17 @@\n /**\n  *\n  */\n+@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class PythonScriptSearchTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @After\n     public void close() {\n         // We need to clear some system properties",
    "output": "Fix tests Tests fail because we now disable automatic plugin loading from the classpat when running tests (cherry picked from commit c5554ad)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n--- a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n+++ b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n@@ -21,7 +21,10 @@\n \n import org.elasticsearch.action.search.SearchResponse;\n import org.elasticsearch.action.search.SearchType;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.search.sort.SortOrder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n@@ -40,8 +43,17 @@\n /**\n  *\n  */\n+@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class JavaScriptScriptSearchTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @Test\n     public void testJavaScriptFilter() throws Exception {\n         createIndex(\"test\");",
    "output": "Upgrade to elasticsearch 1.3.0"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java\n@@ -81,6 +81,11 @@ public String[] extensions() {\n         return new String[]{\"js\"};\n     }\n \n+    @Override\n+    public boolean sandboxed() {\n+        return false;\n+    }\n+\n     @Override\n     public Object compile(String script) {\n         Context ctx = Context.enter();\n\ndiff --git a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTest.java b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTest.java\n--- a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTest.java\n+++ b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTest.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.script.javascript;\n \n import org.elasticsearch.common.settings.ImmutableSettings;\n-import org.elasticsearch.common.util.concurrent.jsr166y.ThreadLocalRandom;\n import org.elasticsearch.script.ExecutableScript;\n import org.elasticsearch.test.ElasticsearchTestCase;\n import org.junit.Test;\n@@ -29,6 +28,7 @@\n import java.util.Map;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.ThreadLocalRandom;\n import java.util.concurrent.atomic.AtomicBoolean;\n \n import static org.hamcrest.Matchers.equalTo;",
    "output": "Upgrade to elasticsearch 1.2.0"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java b/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n@@ -62,6 +62,11 @@ public String[] extensions() {\n         return new String[]{\"py\"};\n     }\n \n+    @Override\n+    public boolean sandboxed() {\n+        return false;\n+    }\n+\n     @Override\n     public Object compile(String script) {\n         return interp.compile(script);\n\ndiff --git a/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTest.java b/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTest.java\n--- a/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTest.java\n+++ b/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTest.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.script.python;\n \n import org.elasticsearch.common.settings.ImmutableSettings;\n-import org.elasticsearch.common.util.concurrent.jsr166y.ThreadLocalRandom;\n import org.elasticsearch.script.ExecutableScript;\n import org.elasticsearch.test.ElasticsearchTestCase;\n import org.junit.After;\n@@ -30,6 +29,7 @@\n import java.util.Map;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.ThreadLocalRandom;\n import java.util.concurrent.atomic.AtomicBoolean;\n \n import static org.hamcrest.Matchers.equalTo;",
    "output": "Upgrade to elasticsearch 1.2.0 . (cherry picked from commit 8a87054)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/KuromojiIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/KuromojiIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/KuromojiIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/KuromojiIntegrationTests.java\n@@ -19,6 +19,9 @@\n package org.elasticsearch.index.analysis;\n \n import org.elasticsearch.action.admin.indices.analyze.AnalyzeResponse;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.plugins.PluginsService;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n@@ -30,6 +33,14 @@\n @ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class KuromojiIntegrationTests extends ElasticsearchIntegrationTest {\n \n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return ImmutableSettings.builder()\n+                .put(super.nodeSettings(nodeOrdinal))\n+                .put(\"plugins.\" + PluginsService.LOAD_PLUGIN_FROM_CLASSPATH, true)\n+                .build();\n+    }\n+\n     @Test\n     public void testKuromojiAnalyzer() throws ExecutionException, InterruptedException {\n         AnalyzeResponse response = client().admin().indices()",
    "output": "Fix integration tests Due to change in test infra, we disable by default automatic loading for classpath plugins (see https://github.com/elasticsearch/elasticsearch/commit/75efa47d5ad89da8d51bbdf82e0e4c3c67108139), we need to explicitly enable it again"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/jna/Natives.java b/src/main/java/org/elasticsearch/common/jna/Natives.java\n--- a/src/main/java/org/elasticsearch/common/jna/Natives.java\n+++ b/src/main/java/org/elasticsearch/common/jna/Natives.java\n@@ -52,7 +52,7 @@ public static void tryMlockall() {\n             if (errno == CLibrary.ENOMEM && System.getProperty(\"os.name\").toLowerCase(Locale.ROOT).contains(\"linux\")) {\n                 logger.warn(\"Unable to lock JVM memory (ENOMEM).\"\n                         + \" This can result in part of the JVM being swapped out.\"\n-                        + \" Increase RLIMIT_MEMLOCK or run elasticsearch as root.\");\n+                        + \" Increase RLIMIT_MEMLOCK (ulimit).\");\n             } else if (!System.getProperty(\"os.name\").toLowerCase(Locale.ROOT).contains(\"mac\")) {\n                 // OS X allows mlockall to be called, but always returns an error\n                 logger.warn(\"Unknown mlockall error \" + errno);",
    "output": "Improve error when mlockall fails ()"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java b/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java\n--- a/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java\n+++ b/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java\n@@ -40,13 +40,14 @@ public String[] names() {\n     public HighlightField highlight(HighlighterContext highlighterContext) {\n         SearchContextHighlight.Field field = highlighterContext.field;\n         CacheEntry cacheEntry = (CacheEntry) highlighterContext.hitContext.cache().get(\"test-custom\");\n+        final int docId = highlighterContext.hitContext.readerContext().docBase + highlighterContext.hitContext.docId();\n         if (cacheEntry == null) {\n             cacheEntry = new CacheEntry();\n             highlighterContext.hitContext.cache().put(\"test-custom\", cacheEntry);\n-            cacheEntry.docId = highlighterContext.hitContext.docId();\n+            cacheEntry.docId = docId;\n             cacheEntry.position = 1;\n         } else {\n-            if (cacheEntry.docId == highlighterContext.hitContext.docId()) {\n+            if (cacheEntry.docId == docId) {\n                 cacheEntry.position++;\n             } else {\n                 cacheEntry.docId = highlighterContext.hitContext.docId();",
    "output": "Fix test to use index-level doc IDs instead of segment-level doc IDs"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/validate/SimpleValidateQueryTests.java b/src/test/java/org/elasticsearch/validate/SimpleValidateQueryTests.java\n--- a/src/test/java/org/elasticsearch/validate/SimpleValidateQueryTests.java\n+++ b/src/test/java/org/elasticsearch/validate/SimpleValidateQueryTests.java\n@@ -80,7 +80,7 @@ public void simpleValidateQuery() throws Exception {\n     private static String filter(String uncachedFilter) {\n         String filter = uncachedFilter;\n         if (cluster().hasFilterCache()) {\n-            filter = \"cached(\" + filter + \")\";\n+            filter = \"cache(\" + filter + \")\";\n         }\n         return filter;\n     }",
    "output": "Fix test bug in SimpleValidateQueryTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/ReverseNestedTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/ReverseNestedTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/ReverseNestedTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/ReverseNestedTests.java\n@@ -25,7 +25,6 @@\n import org.elasticsearch.search.aggregations.bucket.nested.ReverseNested;\n import org.elasticsearch.search.aggregations.bucket.terms.Terms;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n-import org.junit.Before;\n import org.junit.Test;\n \n import java.util.ArrayList;\n@@ -43,11 +42,10 @@\n /**\n  *\n  */\n-@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE, numDataNodes = 1)\n+@ElasticsearchIntegrationTest.SuiteScopeTest\n public class ReverseNestedTests extends ElasticsearchIntegrationTest {\n \n-    @Before\n-    public void init() throws Exception {\n+    public void setupSuiteScopeCluster() throws Exception {\n         assertAcked(prepareCreate(\"idx\")\n                 .addMapping(\n                         \"type1\",",
    "output": "Use SuiteScopeTest annotation instead of ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE, numDataNodes = 1)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java b/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n--- a/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n@@ -1979,6 +1979,26 @@ public void testQueryBeforeChildType() throws Exception {\n \n     }\n \n+    @Test\n+    // https://github.com/elasticsearch/elasticsearch/issues/6256\n+    public void testParentFieldInMultiMatchField() throws Exception {\n+        assertAcked(prepareCreate(\"test\")\n+                .addMapping(\"type1\")\n+                .addMapping(\"type2\", \"_parent\", \"type=type1\")\n+        );\n+        ensureGreen();\n+\n+        client().prepareIndex(\"test\", \"type2\", \"1\").setParent(\"1\").setSource(\"field\", \"value\").get();\n+        refresh();\n+\n+        SearchResponse response = client().prepareSearch(\"test\")\n+                .setQuery(multiMatchQuery(\"1\", \"_parent\"))\n+                .get();\n+\n+        assertThat(response.getHits().totalHits(), equalTo(1l));\n+        assertThat(response.getHits().getAt(0).id(), equalTo(\"1\"));\n+    }\n+\n     private static HasChildFilterBuilder hasChildFilter(String type, QueryBuilder queryBuilder) {\n         HasChildFilterBuilder hasChildFilterBuilder = FilterBuilders.hasChildFilter(type, queryBuilder);\n         hasChildFilterBuilder.setShortCircuitCutoff(randomInt(10));",
    "output": "Add test for"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/docset/DocIdSets.java b/src/main/java/org/elasticsearch/common/lucene/docset/DocIdSets.java\n--- a/src/main/java/org/elasticsearch/common/lucene/docset/DocIdSets.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/docset/DocIdSets.java\n@@ -24,7 +24,6 @@\n import org.apache.lucene.search.DocIdSetIterator;\n import org.apache.lucene.util.Bits;\n import org.apache.lucene.util.FixedBitSet;\n-import org.apache.lucene.util.OpenBitSetIterator;\n import org.elasticsearch.common.Nullable;\n \n import java.io.IOException;\n@@ -56,15 +55,6 @@ public static boolean isFastIterator(DocIdSet set) {\n         return set instanceof FixedBitSet;\n     }\n \n-    /**\n-     * Is {@link org.apache.lucene.search.DocIdSetIterator} implemented in a \"fast\" manner.\n-     * For example, it does not ends up iterating one doc at a time check for its \"value\".\n-     */\n-    public static boolean isFastIterator(DocIdSetIterator iterator) {\n-        // this is the iterator in the FixedBitSet.\n-        return iterator instanceof OpenBitSetIterator;\n-    }\n-\n     /**\n      * Converts to a cacheable {@link DocIdSet}\n      * <p/>",
    "output": "Remove `DocIdSets.isFastIterator(DocIdSetIterator iterator)`. This method was unused and its implementation wasn't correct since FixedBitSet has its own iterator since Lucene 4.7"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -178,6 +178,8 @@ public class Version implements Serializable {\n     public static final Version V_1_1_2 = new Version(V_1_1_2_ID, false, org.apache.lucene.util.Version.LUCENE_47);\n     public static final int V_1_2_0_ID = /*00*/1020099;\n     public static final Version V_1_2_0 = new Version(V_1_2_0_ID, false, org.apache.lucene.util.Version.LUCENE_48);\n+    public static final int V_1_3_0_ID = /*00*/1030099;\n+    public static final Version V_1_3_0 = new Version(V_1_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_48);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n     public static final Version V_2_0_0 = new Version(V_2_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_48);\n \n@@ -195,6 +197,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_2_0_0_ID:\n                 return V_2_0_0;\n+            case V_1_3_0_ID:\n+                return V_1_3_0;\n             case V_1_2_0_ID:\n                 return V_1_2_0;\n             case V_1_1_2_ID:",
    "output": "Add Version [1.3.0]"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/gateway/local/LocalGatewayIndexStateTests.java b/src/test/java/org/elasticsearch/gateway/local/LocalGatewayIndexStateTests.java\n--- a/src/test/java/org/elasticsearch/gateway/local/LocalGatewayIndexStateTests.java\n+++ b/src/test/java/org/elasticsearch/gateway/local/LocalGatewayIndexStateTests.java\n@@ -529,7 +529,14 @@ public Settings onNodeStopped(String nodeName) throws Exception {\n         logger.info(\"--> index a different doc\");\n         client().prepareIndex(\"test\", \"type1\", \"2\").setSource(\"field1\", \"value2\").setRefresh(true).execute().actionGet();\n \n-        assertThat(client().prepareGet(\"test\", \"type1\", \"1\").execute().actionGet().isExists(), equalTo(false));\n+        logger.info(\"--> verify that doc 2 does exist\");\n         assertThat(client().prepareGet(\"test\", \"type1\", \"2\").execute().actionGet().isExists(), equalTo(true));\n+\n+        // Need an ensure yellow here, since the index gets created (again) when we index doc2, so the shard that doc\n+        // with id 1 is assigned to might not be in a started state. We don't need to do this when verifying if doc 2\n+        // exists, because we index into the shard that doc gets assigned to.\n+        ensureYellow(\"test\");\n+        logger.info(\"--> verify that doc 1 doesn't exist\");\n+        assertThat(client().prepareGet(\"test\", \"type1\", \"1\").execute().actionGet().isExists(), equalTo(false));\n     }\n }",
    "output": "Add await for yellow status, because the shard the get request for 'test' index, 'type1' type and id 1 is getting executed on may not be in a started state and also added more logging"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java b/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java\n@@ -263,6 +263,6 @@ public Term newTerm(String value) {\n     }\n \n     protected boolean forceAnalyzeQueryString() {\n-        return this.queryBuilder.forceAnalyzeQueryString();\n+        return this.queryBuilder == null ? super.forceAnalyzeQueryString() : this.queryBuilder.forceAnalyzeQueryString();\n     }\n }\n\\ No newline at end of file\n\ndiff --git a/src/test/java/org/elasticsearch/search/query/MultiMatchQueryTests.java b/src/test/java/org/elasticsearch/search/query/MultiMatchQueryTests.java\n--- a/src/test/java/org/elasticsearch/search/query/MultiMatchQueryTests.java\n+++ b/src/test/java/org/elasticsearch/search/query/MultiMatchQueryTests.java\n@@ -210,6 +210,15 @@ public void testPhraseType() {\n         assertHitCount(searchResponse, 2l);\n     }\n \n+    @Test\n+    public void testSingleField() {\n+        SearchResponse searchResponse = client().prepareSearch(\"test\")\n+                .setQuery(randomizeType(multiMatchQuery(\"15\", \"skill\"))).get();\n+        assertNoFailures(searchResponse);\n+        assertFirstHit(searchResponse, hasId(\"theone\"));\n+        // TODO we need equivalence tests with match query here\n+    }\n+\n     @Test\n     public void testCutoffFreq() throws ExecutionException, InterruptedException {\n         final long numDocs = client().prepareCount(\"test\")",
    "output": "Use default forceAnalyzeQueryString if no query builder is present In the single field case no query builder is selected which causes NPE when the query has only a numeric field"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.bootstrap;\n \n+import com.google.common.base.Charsets;\n import org.elasticsearch.ExceptionsHelper;\n import org.elasticsearch.Version;\n import org.elasticsearch.common.collect.Tuple;\n@@ -153,7 +154,7 @@ public static void main(String[] args) {\n                     FileSystemUtils.mkdirs(fPidFile.getParentFile());\n                 }\n                 FileOutputStream outputStream = new FileOutputStream(fPidFile);\n-                outputStream.write(Long.toString(JvmInfo.jvmInfo().pid()).getBytes());\n+                outputStream.write(Long.toString(JvmInfo.jvmInfo().pid()).getBytes(Charsets.UTF_8));\n                 outputStream.close();\n \n                 fPidFile.deleteOnExit();",
    "output": "Use UTF-8 as string encoding"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java b/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java\n@@ -97,6 +97,7 @@ private RecoveryResponse recover(final StartRecoveryRequest request) {\n         // the index operations will not be routed to it properly\n         RoutingNode node = clusterService.state().readOnlyRoutingNodes().node(request.targetNode().id());\n         if (node == null) {\n+            logger.debug(\"delaying recovery of {} as source node {} is unknown\", request.shardId(), request.targetNode());\n             throw new DelayRecoveryException(\"source node does not have the node [\" + request.targetNode() + \"] in its state yet..\");\n         }\n         ShardRouting targetShardRouting = null;\n@@ -107,9 +108,12 @@ private RecoveryResponse recover(final StartRecoveryRequest request) {\n             }\n         }\n         if (targetShardRouting == null) {\n+            logger.debug(\"delaying recovery of {} as it is not listed as assigned to target node {}\", request.shardId(), request.targetNode());\n             throw new DelayRecoveryException(\"source node does not have the shard listed in its state as allocated on the node\");\n         }\n         if (!targetShardRouting.initializing()) {\n+            logger.debug(\"delaying recovery of {} as it is not listed as initializing on the target node {}. known shards state is [{}]\",\n+                    request.shardId(), request.targetNode(), targetShardRouting.state());\n             throw new DelayRecoveryException(\"source node has the state of the target shard to be [\" + targetShardRouting.state() + \"], expecting to be [initializing]\");\n         }\n ",
    "output": "Add some debug logs to the recovery process"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/indices/template/put/TransportPutIndexTemplateAction.java b/src/main/java/org/elasticsearch/action/admin/indices/template/put/TransportPutIndexTemplateAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/indices/template/put/TransportPutIndexTemplateAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/indices/template/put/TransportPutIndexTemplateAction.java\n@@ -96,7 +96,7 @@ public void onResponse(MetaDataIndexTemplateService.PutResponse response) {\n \n                     @Override\n                     public void onFailure(Throwable t) {\n-                        logger.debug(\"failed to delete template [{}]\", t, request.name());\n+                        logger.debug(\"failed to put template [{}]\", t, request.name());\n                         listener.onFailure(t);\n                     }\n                 });",
    "output": "Fix debug logging message for put template action"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/bench/BenchmarkService.java b/src/main/java/org/elasticsearch/action/bench/BenchmarkService.java\n--- a/src/main/java/org/elasticsearch/action/bench/BenchmarkService.java\n+++ b/src/main/java/org/elasticsearch/action/bench/BenchmarkService.java\n@@ -286,7 +286,8 @@ public void messageReceived(NodeStatusRequest request, TransportChannel channel)\n \n         @Override\n         public String executor() {\n-            return ThreadPool.Names.BENCH;\n+            // Perform management tasks on GENERIC so as not to block pending acquisition of a thread from BENCH.\n+            return ThreadPool.Names.GENERIC;\n         }\n     }\n \n@@ -308,7 +309,8 @@ public void messageReceived(NodeAbortRequest request, TransportChannel channel)\n \n         @Override\n         public String executor() {\n-            return ThreadPool.Names.BENCH;\n+            // Perform management tasks on GENERIC so as not to block pending acquisition of a thread from BENCH.\n+            return ThreadPool.Names.GENERIC;\n         }\n     }\n ",
    "output": "Fix bug for BENCH thread pool size == 1 On small hardware, the BENCH thread pool can be set to size 1. This is problematic as it means that while a benchmark is active, there are no threads available to service administrative tasks such as listing and aborting. This change fixes that by executing list and abort operations on the GENERIC thread pool"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/bytes/PagedBytesReferenceTest.java b/src/test/java/org/elasticsearch/common/bytes/PagedBytesReferenceTest.java\n--- a/src/test/java/org/elasticsearch/common/bytes/PagedBytesReferenceTest.java\n+++ b/src/test/java/org/elasticsearch/common/bytes/PagedBytesReferenceTest.java\n@@ -26,7 +26,6 @@\n import org.elasticsearch.common.util.BigArrays;\n import org.elasticsearch.common.util.ByteArray;\n import org.elasticsearch.test.ElasticsearchTestCase;\n-import org.elasticsearch.test.cache.recycler.MockBigArrays;\n import org.jboss.netty.buffer.ChannelBuffer;\n import org.junit.After;\n import org.junit.Before;\n@@ -61,7 +60,7 @@ public void testGet() {\n         int sliceLength = Math.max(1, length - sliceOffset - 1);\n         BytesReference slice = pbr.slice(sliceOffset, sliceLength);\n         assertEquals(pbr.get(sliceOffset), slice.get(0));\n-        assertEquals(pbr.get(sliceOffset + sliceLength), slice.get(sliceLength));\n+        assertEquals(pbr.get(sliceOffset + sliceLength - 1), slice.get(sliceLength - 1));\n     }\n \n     public void testLength() {",
    "output": "Fix test bug in PagedBytesReferenceTest"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/ClearScrollResponse.java b/src/main/java/org/elasticsearch/action/search/ClearScrollResponse.java\n--- a/src/main/java/org/elasticsearch/action/search/ClearScrollResponse.java\n+++ b/src/main/java/org/elasticsearch/action/search/ClearScrollResponse.java\n@@ -69,8 +69,6 @@ public RestStatus status() {\n \n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n-        builder.startObject();\n-        builder.endObject();\n         return builder;\n     }\n ",
    "output": "Remove useless and illegal json object in the response. Relates to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java b/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java\n@@ -79,7 +79,6 @@ public void beforeBenchmarkIntegrationTests() throws Exception {\n     }\n \n     @Test\n-    @AwaitsFix(bugUrl = \"https://github.com/elasticsearch/elasticsearch/issues/6094\")\n     public void testSubmitBenchmark() throws Exception {\n \n         final BenchmarkRequest request =\n\ndiff --git a/src/test/java/org/elasticsearch/action/bench/BenchmarkTestUtil.java b/src/test/java/org/elasticsearch/action/bench/BenchmarkTestUtil.java\n--- a/src/test/java/org/elasticsearch/action/bench/BenchmarkTestUtil.java\n+++ b/src/test/java/org/elasticsearch/action/bench/BenchmarkTestUtil.java\n@@ -42,8 +42,8 @@ public class BenchmarkTestUtil {\n     public static final int MAX_MULTIPLIER = 500;\n     public static final int MIN_SMALL_INTERVAL = 1;\n     public static final int MAX_SMALL_INTERVAL = 3;\n-    public static final int MIN_LARGE_INTERVAL = 11;\n-    public static final int MAX_LARGE_INTERVAL = 19;\n+    public static final int MIN_LARGE_INTERVAL = 5;\n+    public static final int MAX_LARGE_INTERVAL = 7;\n \n     public static final String BENCHMARK_NAME = \"test_benchmark\";\n     public static final String COMPETITOR_PREFIX = \"competitor_\";",
    "output": "Fix for benchmark test timeout Lower number of random requests generated for each test so as not to timeout on heavy tests. Addresses"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java b/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/action/bench/BenchmarkIntegrationTest.java\n@@ -30,8 +30,6 @@\n import org.junit.Before;\n import org.junit.Test;\n \n-import java.math.BigDecimal;\n-import java.math.RoundingMode;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n@@ -232,17 +230,14 @@ private void validateCompetitionResult(CompetitionResult result, BenchmarkSettin\n \n     private void validatePercentiles(Map<Double, Double> percentiles) {\n         int i = 0;\n-        Double last = null;\n+        double last = Double.NEGATIVE_INFINITY;\n         for (Map.Entry<Double, Double> entry : percentiles.entrySet()) {\n             assertThat(entry.getKey(), equalTo(BenchmarkSettings.DEFAULT_PERCENTILES[i++]));\n-            if (last != null) {\n-                assertThat(entry.getValue(), greaterThanOrEqualTo(last));\n-            }\n             // This is a hedge against rounding errors. Sometimes two adjacent percentile values will\n             // be nearly equivalent except for some insignificant decimal places. In such cases we\n             // want the two values to compare as equal.\n-            final BigDecimal bd = new BigDecimal(entry.getValue()).setScale(2, RoundingMode.HALF_DOWN);\n-            last = bd.doubleValue();\n+            assertThat(entry.getValue(), greaterThanOrEqualTo(last - 1e-6));\n+            last = entry.getValue();\n         }\n     }\n ",
    "output": "Improve BenchmarkIntegrationTest's check that percentiles are increasing. Percentiles are supposed to be monotonically increasing but floating-point rounding issues can come into play and make the test fail if checks are too strict"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/section/DoSection.java b/src/test/java/org/elasticsearch/test/rest/section/DoSection.java\n--- a/src/test/java/org/elasticsearch/test/rest/section/DoSection.java\n+++ b/src/test/java/org/elasticsearch/test/rest/section/DoSection.java\n@@ -131,6 +131,6 @@ private String formatStatusCodeMessage(RestResponse restResponse, String expecte\n         catches.put(\"missing\", tuple(\"404\", equalTo(404)));\n         catches.put(\"conflict\", tuple(\"409\", equalTo(409)));\n         catches.put(\"forbidden\", tuple(\"403\", equalTo(403)));\n-        catches.put(\"request\", tuple(\"4xx|5xx\", greaterThanOrEqualTo(400)));\n+        catches.put(\"request\", tuple(\"4xx|5xx\", allOf(greaterThanOrEqualTo(400), not(equalTo(404)), not(equalTo(409)), not(equalTo(403)))));\n     }\n }",
    "output": "Make catch request more accurate in REST tests runner Excluded 404, 403 and 409 status codes from the catch request as they have their own specific catch codes"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n@@ -1597,6 +1597,8 @@ public boolean apply(Object o) {\n             }\n         });\n \n+        ensureGreen(\"test1\", \"test2\");\n+\n         assertAcked(client().admin().indices().prepareDeleteMapping(\"test1\").setType(PercolatorService.TYPE_NAME));\n         response = client().preparePercolate()\n                 .setIndices(\"test1\", \"test2\").setDocumentType(\"type\").setOnlyCount(true)",
    "output": "Make sure all shards are allocated before the delete type is being executed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java b/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java\n--- a/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java\n+++ b/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java\n@@ -36,7 +36,7 @@ public class FieldSortBuilder extends SortBuilder {\n \n     private Object missing;\n \n-    private Boolean ignoreUnampped;\n+    private Boolean ignoreUnmapped;\n \n     private String sortMode;\n \n@@ -80,7 +80,7 @@ public FieldSortBuilder missing(Object missing) {\n      * to <tt>false</tt> (not ignoring).\n      */\n     public FieldSortBuilder ignoreUnmapped(boolean ignoreUnmapped) {\n-        this.ignoreUnampped = ignoreUnmapped;\n+        this.ignoreUnmapped = ignoreUnmapped;\n         return this;\n     }\n \n@@ -123,8 +123,8 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n         if (missing != null) {\n             builder.field(\"missing\", missing);\n         }\n-        if (ignoreUnampped != null) {\n-            builder.field(\"ignore_unmapped\", ignoreUnampped);\n+        if (ignoreUnmapped != null) {\n+            builder.field(\"ignore_unmapped\", ignoreUnmapped);\n         }\n         if (sortMode != null) {\n             builder.field(\"mode\", sortMode);",
    "output": "Fix typos in FieldSortBuilder"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java b/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n--- a/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n+++ b/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n@@ -276,15 +276,19 @@ public void testSimpleMoreLikeInclude() throws Exception {\n \n         logger.info(\"Running More Like This with include true\");\n         SearchResponse mltResponse = client().moreLikeThis(\n-                moreLikeThisRequest(\"test\").type(\"type1\").id(\"1\").minTermFreq(1).minDocFreq(1).include(true)).actionGet();\n+                moreLikeThisRequest(\"test\").type(\"type1\").id(\"1\").minTermFreq(1).minDocFreq(1).include(true).percentTermsToMatch(0))\n+                .actionGet();\n         assertOrderedSearchHits(mltResponse, \"1\", \"2\");\n \n         mltResponse = client().moreLikeThis(\n-                moreLikeThisRequest(\"test\").type(\"type1\").id(\"2\").minTermFreq(1).minDocFreq(1).include(true)).actionGet();\n+                moreLikeThisRequest(\"test\").type(\"type1\").id(\"2\").minTermFreq(1).minDocFreq(1).include(true).percentTermsToMatch(0))\n+                .actionGet();\n         assertOrderedSearchHits(mltResponse, \"2\", \"1\");\n \n         logger.info(\"Running More Like This with include false\");\n-        mltResponse = client().moreLikeThis(moreLikeThisRequest(\"test\").type(\"type1\").id(\"1\").minTermFreq(1).minDocFreq(1)).actionGet();\n+        mltResponse = client().moreLikeThis(\n+                moreLikeThisRequest(\"test\").type(\"type1\").id(\"1\").minTermFreq(1).minDocFreq(1).percentTermsToMatch(0))\n+                .actionGet();\n         assertSearchHits(mltResponse, \"2\");\n     }\n ",
    "output": "Remove the restriction on the number of bool clauses that must match. The test failed because 'percent_terms_to_match' defaults to 0.3, which results in requiring that some terms only found in the queried document must match, when all the documents are on the same shard"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java b/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java\n--- a/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java\n+++ b/src/test/java/org/elasticsearch/test/rest/ElasticsearchRestTests.java\n@@ -22,7 +22,6 @@\n import com.carrotsearch.randomizedtesting.annotations.Name;\n import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;\n import com.google.common.collect.Lists;\n-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;\n import org.elasticsearch.Version;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n@@ -52,7 +51,6 @@\n //tests distribution disabled for now since it causes reporting problems,\n // due to the non unique suite name\n //@ReplicateOnEachVm\n-@AwaitsFix(bugUrl=\"https://github.com/elasticsearch/elasticsearch/issues/6033\")\n public class ElasticsearchRestTests extends ElasticsearchIntegrationTest {\n \n     /**",
    "output": "Fix _cat/thread_pool REST tests with local transport, in case the transport port is not available and gets returned as '-' Re-enabled REST tests suite"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/cache/filter/IndicesFilterCache.java b/src/main/java/org/elasticsearch/indices/cache/filter/IndicesFilterCache.java\n--- a/src/main/java/org/elasticsearch/indices/cache/filter/IndicesFilterCache.java\n+++ b/src/main/java/org/elasticsearch/indices/cache/filter/IndicesFilterCache.java\n@@ -95,7 +95,7 @@ public IndicesFilterCache(Settings settings, ThreadPool threadPool, CacheRecycle\n         super(settings);\n         this.threadPool = threadPool;\n         this.cacheRecycler = cacheRecycler;\n-        this.size = componentSettings.get(\"size\", \"20%\");\n+        this.size = componentSettings.get(\"size\", \"10%\");\n         this.expire = componentSettings.getAsTime(\"expire\", null);\n         this.cleanInterval = componentSettings.getAsTime(\"clean_interval\", TimeValue.timeValueSeconds(60));\n         computeSizeInBytes();\n\ndiff --git a/src/main/java/org/elasticsearch/indices/fielddata/breaker/InternalCircuitBreakerService.java b/src/main/java/org/elasticsearch/indices/fielddata/breaker/InternalCircuitBreakerService.java\n--- a/src/main/java/org/elasticsearch/indices/fielddata/breaker/InternalCircuitBreakerService.java\n+++ b/src/main/java/org/elasticsearch/indices/fielddata/breaker/InternalCircuitBreakerService.java\n@@ -38,7 +38,7 @@ public class InternalCircuitBreakerService extends AbstractLifecycleComponent<In\n     public static final String CIRCUIT_BREAKER_OVERHEAD_SETTING = \"indices.fielddata.breaker.overhead\";\n \n     public static final double DEFAULT_OVERHEAD_CONSTANT = 1.03;\n-    private static final String DEFAULT_BREAKER_LIMIT = \"80%\";\n+    private static final String DEFAULT_BREAKER_LIMIT = \"60%\";\n \n     private volatile MemoryCircuitBreaker breaker;\n     private volatile long maxBytes;",
    "output": "Change default filter cache to 10% and circuit breaker to 60% The defaults we have today in our data intensive memory structures don't properly add up to properly protected from potential OOM. The circuit breaker, today at 80%, aims at protecting from extensive field data loading. The default threshold today is too permissive and can still cause OOMs. The filter cache today is at 20%, and its too high when adding it to other limits we have, reduce it to 10%, which is still a big enough portion of the heap, yet provides improved safety measure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/jna/CLibrary.java b/src/main/java/org/elasticsearch/common/jna/CLibrary.java\n--- a/src/main/java/org/elasticsearch/common/jna/CLibrary.java\n+++ b/src/main/java/org/elasticsearch/common/jna/CLibrary.java\n@@ -40,9 +40,9 @@ public class CLibrary {\n         try {\n             Native.register(\"c\");\n         } catch (NoClassDefFoundError e) {\n-            logger.warn(\"jna not found. native methods (mlockall) will be disabled.\");\n+            logger.warn(\"JNA not found. native methods (mlockall) will be disabled.\");\n         } catch (UnsatisfiedLinkError e) {\n-            logger.debug(\"unable to link C library. native methods (mlockall) will be disabled.\");\n+            logger.warn(\"unable to link C library. native methods (mlockall) will be disabled.\");\n         }\n     }\n ",
    "output": "Upgrade JNA to latest version Updating to this version allows to configure a special JNA directory, in case the /tmp directory is mounted with the noexec option, as JNA extracts some data and tries to execute parts of it. Also updated documentation to clarify mlockall and memory settings as well as pointing to the new jna.tmpdir system property"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/GlobalOrdinalsSignificantTermsAggregator.java b/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/GlobalOrdinalsSignificantTermsAggregator.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/GlobalOrdinalsSignificantTermsAggregator.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/GlobalOrdinalsSignificantTermsAggregator.java\n@@ -153,8 +153,10 @@ public void collect(int doc, long owningBucketOrdinal) throws IOException {\n                 long bucketOrd = bucketOrds.add(globalOrd);\n                 if (bucketOrd < 0) {\n                     bucketOrd = -1 - bucketOrd;\n+                    collectExistingBucket(doc, bucketOrd);\n+                } else {\n+                    collectBucket(doc, bucketOrd);\n                 }\n-                collectBucket(doc, bucketOrd);\n             }\n         }\n ",
    "output": "Use collectExistingBucket in GlobalOrdinalsSignificantTermsAggregator.WithHash. Relates to #5955"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/GlobalOrdinalsStringTermsAggregator.java b/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/GlobalOrdinalsStringTermsAggregator.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/GlobalOrdinalsStringTermsAggregator.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/GlobalOrdinalsStringTermsAggregator.java\n@@ -28,6 +28,7 @@\n import org.elasticsearch.common.util.LongArray;\n import org.elasticsearch.common.util.LongHash;\n import org.elasticsearch.index.fielddata.BytesValues;\n+import org.elasticsearch.index.fielddata.ordinals.InternalGlobalOrdinalsBuilder.GlobalOrdinalMapping;\n import org.elasticsearch.index.fielddata.ordinals.Ordinals;\n import org.elasticsearch.search.aggregations.Aggregator;\n import org.elasticsearch.search.aggregations.AggregatorFactories;\n@@ -39,8 +40,6 @@\n import java.io.IOException;\n import java.util.Arrays;\n \n-import static org.elasticsearch.index.fielddata.ordinals.InternalGlobalOrdinalsBuilder.GlobalOrdinalMapping;\n-\n /**\n  * An aggregator of string values that relies on global ordinals in order to build buckets.\n  */\n@@ -159,8 +158,10 @@ public void collect(int doc, long owningBucketOrdinal) throws IOException {\n                 long bucketOrd = bucketOrds.add(globalOrd);\n                 if (bucketOrd < 0) {\n                     bucketOrd = -1 - bucketOrd;\n+                    collectExistingBucket(doc, bucketOrd);\n+                } else {\n+                    collectBucket(doc, bucketOrd);\n                 }\n-                collectBucket(doc, bucketOrd);\n             }\n         }\n ",
    "output": "Use collectExistingBucket in GlobalOrdinalsStringTermsAggregator.WithHash. Relates to #5955"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/gce/AbstractGceComputeServiceTest.java b/src/test/java/org/elasticsearch/discovery/gce/AbstractGceComputeServiceTest.java\n--- a/src/test/java/org/elasticsearch/discovery/gce/AbstractGceComputeServiceTest.java\n+++ b/src/test/java/org/elasticsearch/discovery/gce/AbstractGceComputeServiceTest.java\n@@ -32,7 +32,7 @@\n \n @ElasticsearchIntegrationTest.ClusterScope(\n         scope = ElasticsearchIntegrationTest.Scope.SUITE,\n-        numNodes = 2,\n+        numDataNodes = 2,\n         transportClientRatio = 0.0)\n public abstract class AbstractGceComputeServiceTest extends ElasticsearchIntegrationTest {\n     /**\n\ndiff --git a/src/test/java/org/elasticsearch/gce/itest/GceSimpleITest.java b/src/test/java/org/elasticsearch/gce/itest/GceSimpleITest.java\n--- a/src/test/java/org/elasticsearch/gce/itest/GceSimpleITest.java\n+++ b/src/test/java/org/elasticsearch/gce/itest/GceSimpleITest.java\n@@ -37,7 +37,7 @@\n @AbstractGceTest.GceTest\n @ElasticsearchIntegrationTest.ClusterScope(\n         scope = ElasticsearchIntegrationTest.Scope.TEST,\n-        numNodes = 1,\n+        numDataNodes = 1,\n         transportClientRatio = 0.0)\n public class GceSimpleITest extends AbstractGceTest {\n ",
    "output": "Upgrade to Lucene 4.8.0/ elasticsearch 2.0.0 Latest changes break tests . (cherry picked from commit 04c77e8)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryITest.java b/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryITest.java\n--- a/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryITest.java\n+++ b/src/test/java/org/elasticsearch/discovery/ec2/Ec2DiscoveryITest.java\n@@ -35,7 +35,7 @@\n  * This test requires AWS to run.\n  */\n @AwsTest\n-@ClusterScope(scope = Scope.TEST, numNodes = 0)\n+@ClusterScope(scope = Scope.TEST, numDataNodes = 0)\n public class Ec2DiscoveryITest extends AbstractAwsTest {\n \n     @Test\n\ndiff --git a/src/test/java/org/elasticsearch/repositories/s3/S3SnapshotRestoreTest.java b/src/test/java/org/elasticsearch/repositories/s3/S3SnapshotRestoreTest.java\n--- a/src/test/java/org/elasticsearch/repositories/s3/S3SnapshotRestoreTest.java\n+++ b/src/test/java/org/elasticsearch/repositories/s3/S3SnapshotRestoreTest.java\n@@ -52,7 +52,7 @@\n /**\n  */\n @AwsTest\n-@ClusterScope(scope = Scope.SUITE, numNodes = 2)\n+@ClusterScope(scope = Scope.SUITE, numDataNodes = 2)\n public class S3SnapshotRestoreTest extends AbstractAwsTest {\n \n     @Override",
    "output": "Upgrade to elasticsearch 2.0.0 / Lucene 4.8 Breaking changes in tests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/LoggerInfoStream.java b/src/main/java/org/elasticsearch/common/lucene/LoggerInfoStream.java\n--- a/src/main/java/org/elasticsearch/common/lucene/LoggerInfoStream.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/LoggerInfoStream.java\n@@ -36,7 +36,7 @@ public LoggerInfoStream(Settings settings, ShardId shardId) {\n     }\n \n     public void message(String component, String message) {\n-        logger.trace(\"{}: {}\",  component, message);\n+        logger.trace(\"{} {}: {}\", Thread.currentThread().getName(), component, message);\n     }\n   \n     public boolean isEnabled(String component) {",
    "output": "Add thread name to logger message from IndexWriter's infoStream"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/KuromojiPartOfSpeechFilterFactory.java b/src/main/java/org/elasticsearch/index/analysis/KuromojiPartOfSpeechFilterFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/KuromojiPartOfSpeechFilterFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/KuromojiPartOfSpeechFilterFactory.java\n@@ -48,7 +48,7 @@ public KuromojiPartOfSpeechFilterFactory(Index index, @IndexSettings Settings in\n \n     @Override\n     public TokenStream create(TokenStream tokenStream) {\n-        return new JapanesePartOfSpeechStopFilter(Version.LUCENE_44, tokenStream, stopTags);\n+        return new JapanesePartOfSpeechStopFilter(Version.LUCENE_48, tokenStream, stopTags);\n     }\n \n }\n\ndiff --git a/src/main/java/org/elasticsearch/indices/analysis/KuromojiIndicesAnalysis.java b/src/main/java/org/elasticsearch/indices/analysis/KuromojiIndicesAnalysis.java\n--- a/src/main/java/org/elasticsearch/indices/analysis/KuromojiIndicesAnalysis.java\n+++ b/src/main/java/org/elasticsearch/indices/analysis/KuromojiIndicesAnalysis.java\n@@ -94,7 +94,7 @@ public String name() {\n \n                     @Override\n                     public TokenStream create(TokenStream tokenStream) {\n-                        return new JapanesePartOfSpeechStopFilter(Version.LUCENE_44,\n+                        return new JapanesePartOfSpeechStopFilter(Version.LUCENE_48,\n                                 tokenStream, JapaneseAnalyzer\n                                 .getDefaultStopTags());\n                     }",
    "output": "Upgrade to Lucene 4.8 . (cherry picked from commit bf7cc95)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n@@ -31,7 +31,7 @@\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.CoreMatchers.notNullValue;\n \n-@ElasticsearchIntegrationTest.ClusterScope(numNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n+@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimplePolishIntegrationTests extends ElasticsearchIntegrationTest {\n \n     @Test",
    "output": "Upgrade to Lucene 4.8 . (cherry picked from commit 64a1d9c)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimpleSmartChineseIntegrationTests.java\n@@ -27,7 +27,7 @@\n \n import static org.hamcrest.CoreMatchers.*;\n \n-@ElasticsearchIntegrationTest.ClusterScope(numNodes = 1, scope = ElasticsearchIntegrationTest.Scope.SUITE)\n+@ElasticsearchIntegrationTest.ClusterScope(scope = ElasticsearchIntegrationTest.Scope.SUITE)\n public class SimpleSmartChineseIntegrationTests extends ElasticsearchIntegrationTest {\n \n     @Test",
    "output": "Upgrade to Lucene 4.8 (cherry picked from commit e2a98c9)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/fielddata/ordinals/MultiOrdinalsTests.java b/src/test/java/org/elasticsearch/index/fielddata/ordinals/MultiOrdinalsTests.java\n--- a/src/test/java/org/elasticsearch/index/fielddata/ordinals/MultiOrdinalsTests.java\n+++ b/src/test/java/org/elasticsearch/index/fielddata/ordinals/MultiOrdinalsTests.java\n@@ -125,7 +125,7 @@ public int compare(OrdAndId o1, OrdAndId o2) {\n                     assertIter(docs, docId, array);\n                 }\n                 for (int i = docId + 1; i < ordAndId.id; i++) {\n-                    assertThat(docs.getOrd(i), equalTo(0L));\n+                    assertThat(docs.getOrd(i), equalTo(Ordinals.MISSING_ORDINAL));\n                 }\n                 docId = ordAndId.id;\n                 docOrds.clear();",
    "output": "Fix test bug in MultiOrdinalsTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n@@ -1134,7 +1134,7 @@ public void singleValueField_WithExtendedBounds() throws Exception {\n         if (frequently()) {\n             boundsMinKey = baseKey.minusDays(addedBucketsLeft * interval);\n         } else {\n-            boundsMinKey = baseKey.plus(addedBucketsLeft * interval);\n+            boundsMinKey = baseKey.plusDays(addedBucketsLeft * interval);\n             addedBucketsLeft = 0;\n         }\n         DateTime boundsMin = boundsMinKey.plusDays(randomIntBetween(0, interval - 1));",
    "output": "Fix typo in DateHistogramTests that fails the test since it expects dates to be rounded by day"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/plain/FSTBytesAtomicFieldData.java b/src/main/java/org/elasticsearch/index/fielddata/plain/FSTBytesAtomicFieldData.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/plain/FSTBytesAtomicFieldData.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/plain/FSTBytesAtomicFieldData.java\n@@ -96,10 +96,7 @@ public BytesValues.WithOrdinals getBytesValues(boolean needsHashes) {\n                     }\n                     assert fstEnum.next() == null;\n                 } catch (IOException e) {\n-                    // Don't use new \"AssertionError(\"Cannot happen\", e)\" directly as this is a Java 1.7-only API\n-                    final AssertionError error = new AssertionError(\"Cannot happen\");\n-                    error.initCause(e);\n-                    throw error;\n+                    throw new AssertionError(\"Cannot happen\", e);\n                 }\n                 this.hashes = hashes;\n             }",
    "output": "Remove java6ism in FSTBytesAtomicFieldData"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/translog/TranslogService.java b/src/main/java/org/elasticsearch/index/translog/TranslogService.java\n--- a/src/main/java/org/elasticsearch/index/translog/TranslogService.java\n+++ b/src/main/java/org/elasticsearch/index/translog/TranslogService.java\n@@ -67,7 +67,7 @@ public TranslogService(ShardId shardId, @IndexSettings Settings indexSettings, I\n         this.indexShard = indexShard;\n         this.translog = translog;\n \n-        this.flushThresholdOperations = componentSettings.getAsInt(\"flush_threshold_ops\", componentSettings.getAsInt(\"flush_threshold\", 5000));\n+        this.flushThresholdOperations = componentSettings.getAsInt(\"flush_threshold_ops\", componentSettings.getAsInt(\"flush_threshold\", Integer.MAX_VALUE));\n         this.flushThresholdSize = componentSettings.getAsBytesSize(\"flush_threshold_size\", new ByteSizeValue(200, ByteSizeUnit.MB));\n         this.flushThresholdPeriod = componentSettings.getAsTime(\"flush_threshold_period\", TimeValue.timeValueMinutes(30));\n         this.interval = componentSettings.getAsTime(\"interval\", timeValueMillis(5000));",
    "output": "Use unlimited flush_threshold_ops for translog Currently we use 5k operations as a flush threshold. Indexing 5k documents per second is rather common which would cause the index to be committed on the lucene level each time the flush logic runs which is 5 seconds by default. We should rather use a size based threshold similar to the lucene index writer that doesn't cause such agressive commits which can slow down indexing significantly especially since they cause the underlying devices to fsync their data"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/suggest/phrase/NoisyChannelSpellCheckerTests.java b/src/test/java/org/elasticsearch/search/suggest/phrase/NoisyChannelSpellCheckerTests.java\n--- a/src/test/java/org/elasticsearch/search/suggest/phrase/NoisyChannelSpellCheckerTests.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/phrase/NoisyChannelSpellCheckerTests.java\n@@ -269,9 +269,7 @@ protected TokenStreamComponents createComponents(String fieldName, Reader reader\n         assertThat(corrections[0].join(new BytesRef(\" \")).utf8ToString(), equalTo(\"xorr the god jewel\"));\n         assertThat(corrections[1].join(new BytesRef(\" \")).utf8ToString(), equalTo(\"zorr the god jewel\"));\n         assertThat(corrections[2].join(new BytesRef(\" \")).utf8ToString(), equalTo(\"gorr the god jewel\"));\n-        assertThat(corrections[3].join(new BytesRef(\" \")).utf8ToString(), equalTo(\"varr the god jewel\"));\n-        \n-        \n+\n \n         corrections = suggester.getCorrections(wrapper, new BytesRef(\"Zorr the Got-Jewel\"), generator, 0.5f, 1, ir, \"body\", wordScorer, 1.5f, 2).corrections;\n         assertThat(corrections.length, equalTo(1));",
    "output": "Remove ambigious 4th suggestion - order differs slightly on Java 8"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java b/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n--- a/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n+++ b/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n@@ -87,9 +87,14 @@ public void testSimpleStats() throws Exception {\n         // THERE WILL BE AT LEAST 2 NODES HERE SO WE CAN WAIT FOR GREEN\n         ensureGreen();\n         refresh();\n-        int iters = scaledRandomIntBetween(20, 50);\n+        int iters = scaledRandomIntBetween(100, 150);\n         for (int i = 0; i < iters; i++) {\n-            SearchResponse searchResponse = cluster().clientNodeClient().prepareSearch().setQuery(QueryBuilders.termQuery(\"field\", \"value\")).setStats(\"group1\", \"group2\").execute().actionGet();\n+            SearchResponse searchResponse = cluster().clientNodeClient().prepareSearch()\n+                    .setQuery(QueryBuilders.termQuery(\"field\", \"value\")).setStats(\"group1\", \"group2\")\n+                    .addHighlightedField(\"field\")\n+                    .addScriptField(\"scrip1\", \"_source.field\")\n+                    .setSize(100)\n+                    .execute().actionGet();\n             assertHitCount(searchResponse, docsTest1 + docsTest2);\n             assertAllSuccessful(searchResponse);\n         }",
    "output": "Make fetch time in millis test more resilient beef up the fetch work, and increase teh number of iterations (since we count in nanos, but reports in rounded millis)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/network/NetworkUtils.java b/src/main/java/org/elasticsearch/common/network/NetworkUtils.java\n--- a/src/main/java/org/elasticsearch/common/network/NetworkUtils.java\n+++ b/src/main/java/org/elasticsearch/common/network/NetworkUtils.java\n@@ -49,11 +49,12 @@ public static enum StackType {\n     private final static InetAddress localAddress;\n \n     static {\n-        InetAddress localAddressX = null;\n+        InetAddress localAddressX;\n         try {\n             localAddressX = InetAddress.getLocalHost();\n-        } catch (UnknownHostException e) {\n-            logger.trace(\"Failed to find local host\", e);\n+        } catch (Throwable e) {\n+            logger.warn(\"failed to resolve local host, fallback to loopback\", e);\n+            localAddressX = InetAddress.getLoopbackAddress();\n         }\n         localAddress = localAddressX;\n     }",
    "output": "Use loopback when localhost is not resolved we use the \"local host\" address in sevearl places in our networking layer, if local host is not resolved for some reason, still continue and operate but using the loopback interface"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java b/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java\n--- a/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java\n+++ b/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java\n@@ -226,8 +226,8 @@ public List<DiscoveryNode> buildDynamicNodes() {\n                         // If user has set `es_port` metadata, we don't need to ping all ports\n                         // we only limit to 1 addresses, makes no sense to ping 100 ports\n                         for (int i = 0; i < addresses.length; i++) {\n-                            logger.trace(\"adding {}, type {}, image {}, address {}, transport_address {}, status {}\", name, type\n-                                    , ip_private, addresses[i], status);\n+                            logger.trace(\"adding {}, type {}, address {}, transport_address {}, status {}\", name, type,\n+                                    ip_private, addresses[i], status);\n                             cachedDiscoNodes.add(new DiscoveryNode(\"#cloud-\" + name + \"-\" + i, addresses[i], Version.CURRENT));\n                         }\n                     }",
    "output": "Fix log Related to #19"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/io/FileSystemUtils.java b/src/main/java/org/elasticsearch/common/io/FileSystemUtils.java\n--- a/src/main/java/org/elasticsearch/common/io/FileSystemUtils.java\n+++ b/src/main/java/org/elasticsearch/common/io/FileSystemUtils.java\n@@ -80,11 +80,7 @@ public static int maxOpenFiles(File testDir) {\n         } catch (IOException ioe) {\n             int i = 0;\n             for (RandomAccessFile raf : files) {\n-                try {\n-                    raf.close();\n-                } catch (IOException e) {\n-                    // ignore\n-                }\n+                IOUtils.closeWhileHandlingException(raf);\n                 new File(testDir, \"tmp\" + i++).delete();\n             }\n             if (dirCreated) {\n@@ -229,33 +225,6 @@ public static void syncFile(File fileToSync, boolean isDir) throws IOException {\n         throw exc;\n     }\n \n-    public static void copyFile(File sourceFile, File destinationFile) throws IOException {\n-        FileInputStream sourceIs = null;\n-        FileChannel source = null;\n-        FileOutputStream destinationOs = null;\n-        FileChannel destination = null;\n-        try {\n-            sourceIs = new FileInputStream(sourceFile);\n-            source = sourceIs.getChannel();\n-            destinationOs = new FileOutputStream(destinationFile);\n-            destination = destinationOs.getChannel();\n-            destination.transferFrom(source, 0, source.size());\n-        } finally {\n-            if (source != null) {\n-                source.close();\n-            }\n-            if (sourceIs != null) {\n-                sourceIs.close();\n-            }\n-            if (destination != null) {\n-                destination.close();\n-            }\n-            if (destinationOs != null) {\n-                destinationOs.close();\n-            }\n-        }\n-    }\n-\n     /**\n      * Check that a directory exists, is a directory and is readable\n      * by the current user",
    "output": "Remove unused FileSystemUtils#copyFile"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/suggest/stats/SuggestStatsTests.java b/src/test/java/org/elasticsearch/index/suggest/stats/SuggestStatsTests.java\n--- a/src/test/java/org/elasticsearch/index/suggest/stats/SuggestStatsTests.java\n+++ b/src/test/java/org/elasticsearch/index/suggest/stats/SuggestStatsTests.java\n@@ -99,7 +99,8 @@ public void testSimpleStats() throws Exception {\n \n         // check suggest time\n         assertThat(indicesStats.getTotal().getSuggest().getTimeInMillis(), greaterThan(0l));\n-        assertThat(indicesStats.getTotal().getSuggest().getTimeInMillis(), lessThanOrEqualTo(endTime - startTime));\n+        // the upperbound is num shards * total time since we do searches in parallel\n+        assertThat(indicesStats.getTotal().getSuggest().getTimeInMillis(), lessThanOrEqualTo(totalShards * (endTime - startTime)));\n \n         NodesStatsResponse nodeStats = client().admin().cluster().prepareNodesStats().execute().actionGet();\n         NodeStats[] nodes = nodeStats.getNodes();",
    "output": "Use a real upperbound for the check on the time spend during suggestions"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java b/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n--- a/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n+++ b/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.nested;\n \n import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n import org.elasticsearch.action.admin.indices.status.IndicesStatusResponse;\n import org.elasticsearch.action.delete.DeleteResponse;\n@@ -863,6 +864,7 @@ public void testSimpleNestedSorting_withNestedFilterMissing() throws Exception {\n         client().prepareClearScroll().addScrollId(\"_all\").get();\n     }\n \n+    @LuceneTestCase.AwaitsFix(bugUrl = \"boaz is looking into failures here\")\n     @Test\n     public void testSortNestedWithNestedFilter() throws Exception {\n                 assertAcked(prepareCreate(\"test\")",
    "output": "Add awaitFix for SimpleNestedTests.testSortNestedWithNestedFilter While investigating failures"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/spec/RestApiParser.java b/src/test/java/org/elasticsearch/test/rest/spec/RestApiParser.java\n--- a/src/test/java/org/elasticsearch/test/rest/spec/RestApiParser.java\n+++ b/src/test/java/org/elasticsearch/test/rest/spec/RestApiParser.java\n@@ -126,7 +126,7 @@ public RestApi parse(XContentParser parser) throws IOException {\n             }\n \n             parser.nextToken();\n-            assert parser.currentToken() == XContentParser.Token.END_OBJECT;\n+            assert parser.currentToken() == XContentParser.Token.END_OBJECT : \"Expected [END_OBJECT] but was [\"  + parser.currentToken() +\"]\";\n             parser.nextToken();\n \n             return restApi;\n\ndiff --git a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n--- a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n+++ b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n@@ -56,7 +56,7 @@ public static RestSpec parseFrom(String optionalPathPrefix, String... paths) thr\n                     XContentParser parser = JsonXContent.jsonXContent.createParser(new FileInputStream(jsonFile));\n                     RestApi restApi = new RestApiParser().parse(parser);\n                     restSpec.addApi(restApi);\n-                } catch (IOException ex) {\n+                } catch (Throwable ex) {\n                     throw new IOException(\"Can't parse rest spec file: [\" + jsonFile + \"]\", ex);\n                 }\n             }",
    "output": "Add better error reporting to RestApiParser if assertions are tripped"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/document/BulkTests.java b/src/test/java/org/elasticsearch/document/BulkTests.java\n--- a/src/test/java/org/elasticsearch/document/BulkTests.java\n+++ b/src/test/java/org/elasticsearch/document/BulkTests.java\n@@ -216,7 +216,11 @@ public void testBulkUpdate_largerVolume() throws Exception {\n         createIndex(\"test\");\n         ensureGreen();\n \n-        int numDocs = 2000;\n+        int numDocs = scaledRandomIntBetween(100, 2000);\n+        if (numDocs % 2 == 1) {\n+            numDocs++; // this test needs an even num of docs\n+        }\n+        logger.info(\"Bulk-Indexing {} docs\", numDocs);\n         BulkRequestBuilder builder = client().prepareBulk();\n         for (int i = 0; i < numDocs; i++) {\n             builder.add(\n@@ -356,11 +360,11 @@ public void testBulkIndexingWhileInitializing() throws Exception {\n                         .put(indexSettings())\n                         .put(\"index.number_of_replicas\", replica)));\n \n-        int numDocs = 5000;\n-        int bulk = 50;\n+        int numDocs = scaledRandomIntBetween(100, 5000);\n+        int bulk = scaledRandomIntBetween(1, 99);\n         for (int i = 0; i < numDocs; ) {\n-            BulkRequestBuilder builder = client().prepareBulk();\n-            for (int j = 0; j < bulk; j++, i++) {\n+            final BulkRequestBuilder builder = client().prepareBulk();\n+            for (int j = 0; j < bulk && i < numDocs; j++, i++) {\n                 builder.add(client().prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(\"val\", i));\n             }\n             logger.info(\"bulk indexing {}-{}\", i - bulk, i - 1);",
    "output": "Add more randomization to bulk tests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java b/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java\n--- a/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java\n+++ b/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java\n@@ -246,11 +246,13 @@ public void onFailure(Throwable t) {\n         void onFirstPhaseResult(int shardIndex, ShardRouting shard, FirstResult result, ShardIterator shardIt) {\n             result.shardTarget(new SearchShardTarget(shard.currentNodeId(), shard.index(), shard.id()));\n             processFirstPhaseResult(shardIndex, shard, result);\n-\n+            // we need to increment successful ops first before we compare the exit condition otherwise if we\n+            // are fast we could concurrently update totalOps but then preempt one of the threads which can\n+            // cause the successor to read a wrong value from successfulOps if second phase is very fast ie. count etc.\n+            successulOps.incrementAndGet();\n             // increment all the \"future\" shards to update the total ops since we some may work and some may not...\n             // and when that happens, we break on total ops, so we must maintain them\n-            int xTotalOps = totalOps.addAndGet(shardIt.remaining() + 1);\n-            successulOps.incrementAndGet();\n+            final int xTotalOps = totalOps.addAndGet(shardIt.remaining() + 1);\n             if (xTotalOps == expectedTotalOps) {\n                 try {\n                     innerMoveToSecondPhase();",
    "output": "Make sure successful operations are correct if second phase is fast In TransportSearchTypeAction we need to increment successful ops first before we increment and compare the exit condition otherwise if we are fast we could concurrently update totalOps but then preempt one of the threads which can cause the successor to read a wrong value from successfulOps if second phase is very fast ie. searchType == count etc. This can cause wrong success stats in the search response"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -749,10 +749,6 @@ public void indexRandom(boolean forceRefresh, IndexRequestBuilder... builders) t\n      * layout.\n      */\n     public void indexRandom(boolean forceRefresh, List<IndexRequestBuilder> builders) throws InterruptedException, ExecutionException {\n-        if (builders.size() == 0) {\n-            return;\n-        }\n-\n         Random random = getRandom();\n         Set<String> indicesSet = new HashSet<>();\n         for (IndexRequestBuilder builder : builders) {",
    "output": "Make sure refresh is called by `indexRandom`, even if the list of documents to index is empty"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n@@ -146,11 +146,7 @@ public static SearchRequest parseSearchRequest(RestRequest request) {\n             }\n         }\n \n-        // add extra source based on the request parameters\n-        if (!isTemplateRequest) {\n-            searchRequest.extraSource(parseSearchSource(request));\n-        }\n-\n+        searchRequest.extraSource(parseSearchSource(request));\n         searchRequest.searchType(request.param(\"search_type\"));\n \n         String scroll = request.param(\"scroll\");",
    "output": "Make template endpoint compatible with search endpoint Before this the from/size parameters did not work. Also updated the rest api spec definition file with all the query_string parameters"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java b/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java\n--- a/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java\n@@ -76,7 +76,10 @@ public void setUp() throws Exception {\n \n         Directory dir = newDirectory();\n         IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n-        conf.setMergeScheduler(NoMergeScheduler.INSTANCE); // we don't want to do any merges, so we won't expunge deletes\n+        if (frequently()) {\n+            // we don't want to do any merges, so we won't expunge deletes\n+            conf.setMergePolicy(randomBoolean() ? NoMergePolicy.COMPOUND_FILES : NoMergePolicy.NO_COMPOUND_FILES);\n+        }\n         iw = new IndexWriter(dir, conf);\n         terms = new String[scaledRandomIntBetween(10, 300)];\n         for (int i = 0; i < terms.length; i++) {",
    "output": "Use NoMergePolicy rather than NoMergeScheduler in FreqTermsEnumTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataCache.java b/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataCache.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataCache.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataCache.java\n@@ -151,7 +151,7 @@ public void onClose(Object coreCacheKey) {\n \n         static class Key {\n             final Object readerKey;\n-            final List<Listener> listeners = new ArrayList<>(); // optional stats listener\n+            final List<Listener> listeners = new ArrayList<>();\n             long sizeInBytes = -1; // optional size in bytes (we keep it here in case the values are soft references)\n \n             Key(Object readerKey) {\n\ndiff --git a/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java b/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java\n--- a/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java\n+++ b/src/main/java/org/elasticsearch/indices/fielddata/cache/IndicesFieldDataCache.java\n@@ -197,7 +197,7 @@ public static class Key {\n         public final IndexFieldCache indexCache;\n         public final Object readerKey;\n \n-        public final List<IndexFieldDataCache.Listener> listeners = new ArrayList<>(); // optional stats listener\n+        public final List<IndexFieldDataCache.Listener> listeners = new ArrayList<>();\n         long sizeInBytes = -1; // optional size in bytes (we keep it here in case the values are soft references)\n \n ",
    "output": "Remove incorrect comment"
  },
  {
    "input": "diff --git a/src/test/java/org/apache/lucene/queries/BlendedTermQueryTest.java b/src/test/java/org/apache/lucene/queries/BlendedTermQueryTest.java\n--- a/src/test/java/org/apache/lucene/queries/BlendedTermQueryTest.java\n+++ b/src/test/java/org/apache/lucene/queries/BlendedTermQueryTest.java\n@@ -67,7 +67,8 @@ public void testBooleanQuery() throws IOException {\n         for (int j = 0; j < iters; j++) {\n             Document d = new Document();\n             d.add(new TextField(\"id\", Integer.toString(firstNames.length + j), Field.Store.YES));\n-            d.add(new TextField(\"firstname\", rarely() ? \"some_other_name\" : \"simon\", Field.Store.NO));\n+            d.add(new TextField(\"firstname\", rarely() ? \"some_other_name\" :\n+                    \"simon the sorcerer\", Field.Store.NO)); // make sure length-norm is the tie-breaker\n             d.add(new TextField(\"surname\", \"bogus\", Field.Store.NO));\n             w.addDocument(d);\n         }",
    "output": "Use length-norm as the tie-breaker in BlendedTermQueryTest"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java b/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n--- a/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n+++ b/src/test/java/org/elasticsearch/test/junit/listeners/ReproduceInfoPrinter.java\n@@ -116,7 +116,7 @@ public ReproduceErrorMessageBuilder appendOpt(String sysPropName, String value)\n \n         public ReproduceErrorMessageBuilder appendESProperties() {\n             appendProperties(\"es.logger.level\", \"es.node.mode\", \"es.node.local\", TESTS_CLUSTER, TestCluster.TESTS_ENABLE_MOCK_MODULES,\n-                    \"tests.assertion.disabled\", \"tests.security.manager\", \"tests.nighly\", \"tests.jvms\", \"tests.client.ratio\", \"tests.heap.size\");\n+                    \"tests.assertion.disabled\", \"tests.security.manager\", \"tests.nightly\", \"tests.jvms\", \"tests.client.ratio\", \"tests.heap.size\");\n             if (System.getProperty(\"tests.jvm.argline\") != null && !System.getProperty(\"tests.jvm.argline\").isEmpty()) {\n                 appendOpt(\"tests.jvm.argline\", \"\\\"\" + System.getProperty(\"tests.jvm.argline\") + \"\\\"\");\n             }",
    "output": "Fix typo in ReproduceInfoPrinter (s/nighly/nightly)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/junit/RestTestSuiteRunner.java b/src/test/java/org/elasticsearch/test/rest/junit/RestTestSuiteRunner.java\n--- a/src/test/java/org/elasticsearch/test/rest/junit/RestTestSuiteRunner.java\n+++ b/src/test/java/org/elasticsearch/test/rest/junit/RestTestSuiteRunner.java\n@@ -79,7 +79,6 @@\n  * - tests.iters: runs multiple iterations\n  * - tests.seed: seed to base the random behaviours on\n  * - tests.appendseed[true|false]: enables adding the seed to each test section's description (default false)\n- * - tests.cluster_seed: seed used to create the test cluster (if enabled)\n  *\n  */\n public class RestTestSuiteRunner extends ParentRunner<RestTestCandidate> {",
    "output": "Remove last occurences of cluster_seed, no longer used Relates to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/codec/postingformat/ElasticsearchPostingsFormatTest.java b/src/test/java/org/elasticsearch/index/codec/postingformat/ElasticsearchPostingsFormatTest.java\n--- a/src/test/java/org/elasticsearch/index/codec/postingformat/ElasticsearchPostingsFormatTest.java\n+++ b/src/test/java/org/elasticsearch/index/codec/postingformat/ElasticsearchPostingsFormatTest.java\n@@ -19,12 +19,25 @@\n \n package org.elasticsearch.index.codec.postingformat;\n \n+import com.carrotsearch.randomizedtesting.annotations.Listeners;\n+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakFilters;\n+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;\n+import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;\n import org.apache.lucene.codecs.Codec;\n import org.apache.lucene.index.BasePostingsFormatTestCase;\n+import org.apache.lucene.util.TimeUnits;\n import org.apache.lucene.util._TestUtil;\n import org.elasticsearch.index.codec.postingsformat.Elasticsearch090PostingsFormat;\n+import org.elasticsearch.test.ElasticsearchThreadFilter;\n+import org.elasticsearch.test.junit.listeners.ReproduceInfoPrinter;\n \n /** Runs elasticsearch postings format against lucene's standard postings format tests */\n+@Listeners({\n+        ReproduceInfoPrinter.class\n+})\n+@ThreadLeakFilters(defaultFilters = true, filters = {ElasticsearchThreadFilter.class})\n+@ThreadLeakScope(ThreadLeakScope.Scope.NONE)\n+@TimeoutSuite(millis = TimeUnits.HOUR)\n public class ElasticsearchPostingsFormatTest extends BasePostingsFormatTestCase {\n \n     @Override",
    "output": "Add ThreadLeaks protection to ElasticsearchPostingsFormatTest since we keep running clusters around in the JVM"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/tribe/TribeTests.java b/src/test/java/org/elasticsearch/tribe/TribeTests.java\n--- a/src/test/java/org/elasticsearch/tribe/TribeTests.java\n+++ b/src/test/java/org/elasticsearch/tribe/TribeTests.java\n@@ -39,6 +39,7 @@\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;\n import static org.hamcrest.Matchers.equalTo;\n \n@@ -171,10 +172,10 @@ public void testIndexWriteBlocks() throws Exception {\n     @Test\n     public void testOnConflictDrop() throws Exception {\n         logger.info(\"create 2 indices, test1 on t1, and test2 on t2\");\n-        cluster().client().admin().indices().prepareCreate(\"conflict\").get();\n-        cluster2.client().admin().indices().prepareCreate(\"conflict\").get();\n-        cluster().client().admin().indices().prepareCreate(\"test1\").get();\n-        cluster2.client().admin().indices().prepareCreate(\"test2\").get();\n+        assertAcked(cluster().client().admin().indices().prepareCreate(\"conflict\"));\n+        assertAcked(cluster2.client().admin().indices().prepareCreate(\"conflict\"));\n+        assertAcked(cluster().client().admin().indices().prepareCreate(\"test1\"));\n+        assertAcked(cluster2.client().admin().indices().prepareCreate(\"test2\"));\n \n         setupTribeNode(ImmutableSettings.builder()\n                 .put(\"tribe.on_conflict\", \"drop\")",
    "output": "Use assertAcked when creating indices"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/document/BulkTests.java b/src/test/java/org/elasticsearch/document/BulkTests.java\n--- a/src/test/java/org/elasticsearch/document/BulkTests.java\n+++ b/src/test/java/org/elasticsearch/document/BulkTests.java\n@@ -40,6 +40,7 @@\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n+import java.util.Arrays;\n import java.util.Map;\n import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.CyclicBarrier;\n@@ -613,13 +614,13 @@ public void testThatInvalidIndexNamesShouldNotBreakCompleteBulkRequest() {\n         int bulkEntryCount = randomIntBetween(10, 50);\n         BulkRequestBuilder builder = client().prepareBulk();\n         boolean[] expectedFailures = new boolean[bulkEntryCount];\n+        boolean expectFailure = false;\n         for (int i = 0; i < bulkEntryCount; i++) {\n-            expectedFailures[i] = randomBoolean();\n+            expectFailure |= expectedFailures[i] = randomBoolean();\n             builder.add(client().prepareIndex().setIndex(expectedFailures[i] ? \"INVALID.NAME\" : \"test\").setType(\"type1\").setId(\"1\").setSource(\"field\", 1));\n         }\n         BulkResponse bulkResponse = builder.get();\n-\n-        assertThat(bulkResponse.hasFailures(), is(true));\n+        assertThat(bulkResponse.hasFailures(), is(expectFailure));\n         assertThat(bulkResponse.getItems().length, is(bulkEntryCount));\n         for (int i = 0; i < bulkEntryCount; i++) {\n             assertThat(bulkResponse.getItems()[i].isFailed(), is(expectedFailures[i]));",
    "output": "Fix BulkTests#testThatInvalidIndexNamesShouldNotBreakCompleteBulkRequest - randomBoolean() doesn't always return true"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerTests.java b/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerTests.java\n--- a/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerTests.java\n+++ b/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerTests.java\n@@ -164,9 +164,8 @@ public void createIndexWarmer() {\n     @Test\n     public void deleteNonExistentIndexWarmerTest() {\n         createIndex(\"test\");\n-\n         try {\n-            client().admin().indices().prepareDeleteWarmer().setIndices(\"test\").setNames(\"foo\").execute().actionGet(1000);\n+            client().admin().indices().prepareDeleteWarmer().setIndices(\"test\").setNames(\"foo\").execute().actionGet();\n             fail(\"warmer foo should not exist\");\n         } catch (IndexWarmerMissingException ex) {\n             assertThat(ex.names()[0], equalTo(\"foo\"));",
    "output": "Remove timeout from deleteWarmer call with many shards that might just take a while"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/object/DynamicTemplate.java b/src/main/java/org/elasticsearch/index/mapper/object/DynamicTemplate.java\n--- a/src/main/java/org/elasticsearch/index/mapper/object/DynamicTemplate.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/object/DynamicTemplate.java\n@@ -154,7 +154,7 @@ public boolean hasType() {\n     }\n \n     public String mappingType(String dynamicType) {\n-        return mapping.containsKey(\"type\") ? mapping.get(\"type\").toString() : dynamicType;\n+        return mapping.containsKey(\"type\") ? mapping.get(\"type\").toString().replace(\"{dynamic_type}\", dynamicType).replace(\"{dynamicType}\", dynamicType) : dynamicType;\n     }\n \n     private boolean patternMatch(String pattern, String str) {",
    "output": "Fix dynamic_type in dynamic_template"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/support/Features.java b/src/test/java/org/elasticsearch/test/rest/support/Features.java\n--- a/src/test/java/org/elasticsearch/test/rest/support/Features.java\n+++ b/src/test/java/org/elasticsearch/test/rest/support/Features.java\n@@ -33,7 +33,7 @@\n  */\n public final class Features {\n \n-    private static final List<String> SUPPORTED = Lists.newArrayList(\"regex\", \"gtelte\");\n+    private static final List<String> SUPPORTED = Lists.newArrayList(\"gtelte\");\n \n     private Features() {\n ",
    "output": "Remove skip regex sections as all the runners implemented the feature"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -199,7 +199,7 @@ public final void before() throws IOException {\n             }\n             currentCluster.beforeTest(getRandom(), getPerTestTransportClientRatio());\n             cluster().wipe();\n-            randomIndexTemplate();\n+            cluster().randomIndexTemplate();\n             logger.info(\"[{}#{}]: before test\", getTestClass().getSimpleName(), getTestName());\n         } catch (OutOfMemoryError e) {\n             if (e.getMessage().contains(\"unable to create new native thread\")) {\n@@ -278,14 +278,6 @@ public static Client client() {\n         return client;\n     }\n \n-    /**\n-     * Creates a randomized index template. This template is used to pass in randomized settings on a\n-     * per index basis.\n-     */\n-    private static void randomIndexTemplate() {\n-        cluster().randomIndexTemplate();\n-    }\n-\n     public static Iterable<Client> clients() {\n         return cluster();\n     }",
    "output": "Remove leftover ElasticsearchIntegrationTest#randomIndexTemplate used cluster().randomIndexTemplate instead"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java b/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/gce/GceDiscovery.java\n@@ -28,6 +28,7 @@\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.network.NetworkService;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.discovery.DiscoverySettings;\n import org.elasticsearch.discovery.zen.ZenDiscovery;\n import org.elasticsearch.discovery.zen.ping.ZenPing;\n import org.elasticsearch.discovery.zen.ping.ZenPingService;\n@@ -45,8 +46,9 @@ public class GceDiscovery extends ZenDiscovery {\n     public GceDiscovery(Settings settings, ClusterName clusterName, ThreadPool threadPool, TransportService transportService,\n                         ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n                         DiscoveryNodeService discoveryNodeService, GceComputeService gceComputeService,\n-                        NetworkService networkService) {\n-        super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService, discoveryNodeService, pingService, Version.CURRENT);\n+                        NetworkService networkService, DiscoverySettings discoverySettings) {\n+        super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n+                discoveryNodeService, pingService, Version.CURRENT, discoverySettings);\n         if (settings.getAsBoolean(\"cloud.enabled\", true)) {\n             ImmutableList<? extends ZenPing> zenPings = pingService.zenPings();\n             UnicastZenPing unicastZenPing = null;",
    "output": "Upgrade to elasticsearch master"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java b/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/azure/AzureDiscovery.java\n@@ -28,6 +28,7 @@\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.network.NetworkService;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.discovery.DiscoverySettings;\n import org.elasticsearch.discovery.zen.ZenDiscovery;\n import org.elasticsearch.discovery.zen.ping.ZenPing;\n import org.elasticsearch.discovery.zen.ping.ZenPingService;\n@@ -46,8 +47,10 @@ public class AzureDiscovery extends ZenDiscovery {\n     @Inject\n     public AzureDiscovery(Settings settings, ClusterName clusterName, ThreadPool threadPool, TransportService transportService,\n                           ClusterService clusterService, NodeSettingsService nodeSettingsService, ZenPingService pingService,\n-                          DiscoveryNodeService discoveryNodeService, AzureComputeService azureService, NetworkService networkService) {\n-        super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService, discoveryNodeService, pingService, Version.CURRENT);\n+                          DiscoveryNodeService discoveryNodeService, AzureComputeService azureService, NetworkService networkService,\n+                          DiscoverySettings discoverySettings) {\n+        super(settings, clusterName, threadPool, transportService, clusterService, nodeSettingsService,\n+                discoveryNodeService, pingService, Version.CURRENT, discoverySettings);\n         if (settings.getAsBoolean(\"cloud.enabled\", true)) {\n             ImmutableList<? extends ZenPing> zenPings = pingService.zenPings();\n             UnicastZenPing unicastZenPing = null;",
    "output": "Upgrade to elasticsearch 1.1.0"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/IndicesOptionsTests.java b/src/test/java/org/elasticsearch/indices/IndicesOptionsTests.java\n--- a/src/test/java/org/elasticsearch/indices/IndicesOptionsTests.java\n+++ b/src/test/java/org/elasticsearch/indices/IndicesOptionsTests.java\n@@ -201,7 +201,9 @@ public void testSpecifiedIndexUnavailable_snapshotRestore() throws Exception {\n \n         options = IndicesOptions.strict();\n         assertAcked(prepareCreate(\"test2\"));\n-        ensureYellow();\n+        //TODO: temporary work-around for #5531\n+        ensureGreen();\n+        waitForRelocation();\n         verify(snapshot(\"snap3\", \"test1\", \"test2\").setIndicesOptions(options), false);\n         verify(restore(\"snap3\", \"test1\", \"test2\").setIndicesOptions(options), false);\n     }\n@@ -361,7 +363,9 @@ public void testWildcardBehaviour_snapshotRestore() throws Exception {\n         verify(restore(\"snap2\", \"foo*\", \"bar*\").setIndicesOptions(options), false);\n \n         assertAcked(prepareCreate(\"barbaz\"));\n-        ensureYellow();\n+        //TODO: temporary work-around for #5531\n+        ensureGreen();\n+        waitForRelocation();\n         options = IndicesOptions.fromOptions(false, false, true, false);\n         verify(snapshot(\"snap3\", \"foo*\", \"bar*\").setIndicesOptions(options), false);\n         verify(restore(\"snap3\", \"foo*\", \"bar*\").setIndicesOptions(options), false);",
    "output": "Make sure that there are no relocating shards before taking snapshot Temporary workaround for"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/util/UnsafeUtils.java b/src/main/java/org/elasticsearch/common/util/UnsafeUtils.java\n--- a/src/main/java/org/elasticsearch/common/util/UnsafeUtils.java\n+++ b/src/main/java/org/elasticsearch/common/util/UnsafeUtils.java\n@@ -80,9 +80,12 @@ public static boolean equals(BytesRef b1, BytesRef b2) {\n     }\n \n     /**\n-     * Compare <code>b1[o1:o1+len)</code>against <code>b1[o2:o2+len)</code>.\n+     * Compare <code>b1[offset1:offset1+length)</code>against <code>b1[offset2:offset2+length)</code>.\n      */\n-    public static boolean equals(byte[] b1, int o1, byte[] b2, int o2, int len) {\n+    public static boolean equals(byte[] b1, int offset1, byte[] b2, int offset2, int length) {\n+        int o1 = offset1;\n+        int o2 = offset2;\n+        int len = length;\n         while (len >= 8) {\n             if (readLong(b1, o1) != readLong(b2, o2)) {\n                 return false;",
    "output": "Fix PMD warning: don't reassign method parameters"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java b/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n--- a/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n+++ b/src/main/java/org/elasticsearch/common/io/stream/BytesStreamOutput.java\n@@ -19,8 +19,9 @@\n \n package org.elasticsearch.common.io.stream;\n \n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.common.bytes.BytesArray;\n import org.elasticsearch.common.bytes.BytesReference;\n-import org.elasticsearch.common.bytes.PagedBytesReference;\n import org.elasticsearch.common.io.BytesStream;\n import org.elasticsearch.common.util.BigArrays;\n import org.elasticsearch.common.util.ByteArray;",
    "output": "Fix compilation error from last commit"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchTestCase.java b/src/test/java/org/elasticsearch/test/ElasticsearchTestCase.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchTestCase.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchTestCase.java\n@@ -166,7 +166,7 @@ public boolean apply(Object input) {\n                 if (!w.successfullyClosed()) {\n                     if (w.closeException() == null) {\n                         w.close();\n-                        if (w.closeException() == null) {\n+                        if (w.closeException() != null) {\n                             throw w.closeException();\n                         }\n                     } else {",
    "output": "Fix potential NPE, throw failure only if exists"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java b/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java\n--- a/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java\n+++ b/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java\n@@ -30,7 +30,7 @@\n import java.io.*;\n \n /**\n- * A JSON based content implementation using Jackson.\n+ * A Smile based content implementation using Jackson.\n  */\n public class SmileXContent implements XContent {\n \n@@ -100,6 +100,6 @@ public XContentParser createParser(BytesReference bytes) throws IOException {\n \n     @Override\n     public XContentParser createParser(Reader reader) throws IOException {\n-        return new JsonXContentParser(smileFactory.createParser(reader));\n+        return new SmileXContentParser(smileFactory.createParser(reader));\n     }\n }",
    "output": "Fix incorrect return impl in SmileXContent.createParser"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n--- a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n+++ b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n@@ -653,7 +653,7 @@ public void testFiltersWithCustomCacheKey() throws Exception {\n \n     @Test\n     public void testMatchQueryNumeric() throws Exception {\n-        createIndex(\"test\");\n+        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", \"long\", \"type=long\", \"double\", \"type=double\"));\n         ensureGreen();\n \n         indexRandom(true, client().prepareIndex(\"test\", \"type1\", \"1\").setSource(\"long\", 1l, \"double\", 1.0d),",
    "output": "Add mapping to ensure all nodes / shards parse a numeric field"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/VersionTests.java b/src/test/java/org/elasticsearch/VersionTests.java\n--- a/src/test/java/org/elasticsearch/VersionTests.java\n+++ b/src/test/java/org/elasticsearch/VersionTests.java\n@@ -60,5 +60,15 @@ public void testVersionConstantPresent() {\n             assertThat(version.luceneVersion, sameInstance(Version.fromId(version.id).luceneVersion));\n         }\n     }\n+    @Test\n+    public void testCURRENTIsLatest() {\n+        final int iters = scaledRandomIntBetween(100, 1000);\n+        for (int i = 0; i < iters; i++) {\n+            Version version = randomVersion();\n+            if (version != Version.CURRENT) {\n+                assertThat(\"Version: \" + version + \" should be before: \" + Version.CURRENT + \" but wasn't\", version.before(Version.CURRENT), is(true));\n+            }\n+        }\n+    }\n \n }\n\\ No newline at end of file",
    "output": "Add a test that ensures Version#CURRENT is actually the latest version"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java b/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n--- a/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n+++ b/src/test/java/org/elasticsearch/nested/SimpleNestedTests.java\n@@ -375,7 +375,12 @@ private void testFacets(int numberOfShards) throws Exception {\n                 .addMapping(\"type1\", jsonBuilder().startObject().startObject(\"type1\").startObject(\"properties\")\n                         .startObject(\"nested1\")\n                         .field(\"type\", \"nested\").startObject(\"properties\")\n-                        .startObject(\"nested2\").field(\"type\", \"nested\").endObject()\n+                        .startObject(\"nested2\").field(\"type\", \"nested\")\n+                            .startObject(\"properties\")\n+                                .startObject(\"field2_1\").field(\"type\", \"string\").endObject()\n+                                .startObject(\"field2_2\").field(\"type\", \"long\").endObject()\n+                            .endObject()\n+                        .endObject()\n                         .endObject().endObject()\n                         .endObject().endObject().endObject()));\n ",
    "output": "Make sure that the facet fields exist"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java b/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n--- a/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n+++ b/src/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n@@ -69,7 +69,7 @@ public void testSimpleMoreLikeThis() throws Exception {\n     @Test\n     public void testSimpleMoreLikeOnLongField() throws Exception {\n         logger.info(\"Creating index test\");\n-        createIndex(\"test\");\n+        assertAcked(prepareCreate(\"test\").addMapping(\"type1\", \"some_long\", \"type=long\"));\n         logger.info(\"Running Cluster Health\");\n         assertThat(ensureGreen(), equalTo(ClusterHealthStatus.GREEN));\n ",
    "output": "Add mapping to MoreLikeThisActionTests to make sure doc mapper exists on all shards / nodes"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/fielddata/breaker/CircuitBreakerServiceTests.java b/src/test/java/org/elasticsearch/indices/fielddata/breaker/CircuitBreakerServiceTests.java\n--- a/src/test/java/org/elasticsearch/indices/fielddata/breaker/CircuitBreakerServiceTests.java\n+++ b/src/test/java/org/elasticsearch/indices/fielddata/breaker/CircuitBreakerServiceTests.java\n@@ -46,7 +46,8 @@ public class CircuitBreakerServiceTests extends ElasticsearchIntegrationTest {\n \n     private String randomRidiculouslySmallLimit() {\n         // 3 different ways to say 100 bytes\n-        return randomFrom(Arrays.asList(\"100b\", \"100\", (10000. / JvmInfo.jvmInfo().getMem().getHeapMax().bytes()) + \"%\"));\n+        return randomFrom(Arrays.asList(\"100b\", \"100\"));\n+         //, (10000. / JvmInfo.jvmInfo().getMem().getHeapMax().bytes()) + \"%\")); // this is prone to rounding errors and will fail if JVM memory changes!\n     }\n \n     @Test",
    "output": "Fix CircuitBreakerServiceTests from failing due to rounding errors"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/merge/policy/ElasticsearchMergePolicy.java b/src/main/java/org/elasticsearch/index/merge/policy/ElasticsearchMergePolicy.java\n--- a/src/main/java/org/elasticsearch/index/merge/policy/ElasticsearchMergePolicy.java\n+++ b/src/main/java/org/elasticsearch/index/merge/policy/ElasticsearchMergePolicy.java\n@@ -51,6 +51,7 @@\n  * For now, this {@link MergePolicy} takes care of moving versions that used to\n  * be stored as payloads to numeric doc values.\n  */\n+@SuppressWarnings(\"PMD.ProperCloneImplementation\")\n public final class ElasticsearchMergePolicy extends MergePolicy {\n \n     private final MergePolicy delegate;",
    "output": "Remove PMD clone warning Removed PMD clone warning on class ElasticsearchMergePolicy"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java b/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n--- a/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n+++ b/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java\n@@ -332,13 +332,14 @@ private boolean downloadFile() throws FileNotFoundException, IOException {\n                 }\n                 finished = !isInterrupted();\n             } finally {\n-                IOUtils.close(os, is);\n-\n-                // we have started to (over)write dest, but failed.\n-                // Try to delete the garbage we'd otherwise leave\n-                // behind.\n                 if (!finished) {\n+                    // we have started to (over)write dest, but failed.\n+                    // Try to delete the garbage we'd otherwise leave\n+                    // behind.\n+                    IOUtils.closeWhileHandlingException(os, is);\n                     dest.delete();\n+                } else {\n+                    IOUtils.close(os, is);\n                 }\n             }\n             progress.endDownload();",
    "output": "Improve exception handling in HttpDownloadHelper"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java b/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n--- a/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n@@ -124,7 +124,7 @@ public void multiLevelChild() throws Exception {\n     // see #2744\n     public void test2744() throws ElasticsearchException, IOException {\n         assertAcked(prepareCreate(\"test\")\n-                .addMapping(\"parent\")\n+                .addMapping(\"foo\")\n                 .addMapping(\"test\", \"_parent\", \"type=foo\"));\n         ensureGreen();\n ",
    "output": "Make sure that the parent exists (`foo` is the parent type and not `parent`)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n@@ -410,9 +410,12 @@ public void testSizeAndSort() throws Exception {\n     \n     @Test // see #2817\n     public void testStopwordsOnlyPhraseSuggest() throws ElasticsearchException, IOException {\n-        createIndex(\"test\");\n+        assertAcked(prepareCreate(\"test\").addMapping(\"typ1\", \"body\", \"type=string,analyzer=stopwd\").setSettings(\n+                settingsBuilder()\n+                        .put(\"index.analysis.analyzer.stopwd.tokenizer\", \"whitespace\")\n+                        .putArray(\"index.analysis.analyzer.stopwd.filter\", \"stop\")\n+        ));\n         ensureGreen();\n-\n         index(\"test\", \"typ1\", \"1\", \"body\", \"this is a test\");\n         refresh();\n ",
    "output": "Add mapping to use an actual stopword analyzer This test was added when the default analyzer was filtering stopwords. But since 1.0 the default analyzer doesn't filter stopwords"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/discovery/DiscoveryTests.java b/src/test/java/org/elasticsearch/discovery/DiscoveryTests.java\n--- a/src/test/java/org/elasticsearch/discovery/DiscoveryTests.java\n+++ b/src/test/java/org/elasticsearch/discovery/DiscoveryTests.java\n@@ -34,8 +34,8 @@ public class DiscoveryTests extends ElasticsearchIntegrationTest {\n \n     @Override\n     protected Settings nodeSettings(int nodeOrdinal) {\n-        return ImmutableSettings.settingsBuilder().put(\"discovery.zen.multicast.enabled\", false)\n-                .put(\"discovery.zen.unicast.hosts\", \"localhost\").put(super.nodeSettings(nodeOrdinal)).build();\n+        return ImmutableSettings.settingsBuilder().put(\"discovery.zen.ping.multicast.enabled\", false)\n+                .put(\"discovery.zen.ping.unicast.hosts\", \"localhost\").put(super.nodeSettings(nodeOrdinal)).build();\n     }\n     \n     @Test",
    "output": "Fix incorrect discovery options"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetExecutor.java b/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetExecutor.java\n--- a/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetExecutor.java\n+++ b/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetExecutor.java\n@@ -209,6 +209,8 @@ public void setNextReader(AtomicReaderContext context) throws IOException {\n                 total += current.total - current.counts.get(0);\n                 if (current.values.ordinals().getNumOrds() > 0) {\n                     aggregators.add(current);\n+                } else {\n+                    Releasables.release(current);\n                 }\n             }\n             values = indexFieldData.load(context).getBytesValues(false);",
    "output": "Fix missing release"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n--- a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n+++ b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n@@ -728,12 +728,10 @@ public void testMultiMatchQuery() throws Exception {\n         refresh();\n \n         builder = multiMatchQuery(\"value1\", \"field1\", \"field2\", \"field4\");\n-        try {\n-            client().prepareSearch().setQuery(builder).get();\n-            fail(\"Exception expected\");\n-        } catch (SearchPhaseExecutionException e) {\n-            assertThat(e.shardFailures()[0].status(), equalTo(RestStatus.BAD_REQUEST));\n-        }\n+\n+        assertFailures(client().prepareSearch().setQuery(builder),\n+                RestStatus.BAD_REQUEST,\n+                containsString(\"NumberFormatException[For input string: \\\"value1\\\"]\"));\n \n         builder.lenient(true);\n         searchResponse = client().prepareSearch().setQuery(builder).get();",
    "output": "Fix SimpleQueryTests#testMultiMatchQuery check for shard failures It can happen that not all shards are ready, thus we won't have a total failure, but we do need to check that we have at least a failure. Checked also the message of the failure"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java b/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n--- a/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n+++ b/src/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n@@ -28,8 +28,6 @@\n import org.elasticsearch.cluster.routing.GroupShardsIterator;\n import org.elasticsearch.cluster.routing.ShardIterator;\n import org.elasticsearch.cluster.routing.ShardRouting;\n-import org.elasticsearch.common.settings.ImmutableSettings;\n-import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.index.query.QueryBuilders;\n import org.elasticsearch.index.search.stats.SearchStats.Stats;\n@@ -45,12 +43,10 @@\n /**\n  */\n public class SearchStatsTests extends ElasticsearchIntegrationTest {\n-    \n+\n     @Override\n-    public Settings indexSettings() {\n-        return ImmutableSettings.builder()\n-                .put(\"index.number_of_replicas\", 0)\n-                .build();\n+    protected int numberOfReplicas() {\n+        return 0;\n     }\n \n     @Test\n@@ -72,6 +68,10 @@ public void testSimpleStats() throws Exception {\n             }\n         }\n         cluster().ensureAtMostNumNodes(numAssignedShards(\"test1\", \"test2\"));\n+        assertThat(cluster().size(), greaterThanOrEqualTo(2));\n+        assertThat(numAssignedShards(\"test1\", \"test2\"), greaterThanOrEqualTo(2));\n+        // THERE WILL BE AT LEAST 2 NODES HERE SO WE CAN WAIT FOR GREEN\n+        ensureGreen();\n         for (int i = 0; i < 200; i++) {\n             client().prepareSearch().setQuery(QueryBuilders.termQuery(\"field\", \"value\")).setStats(\"group1\", \"group2\").execute().actionGet();\n         }",
    "output": "Fix SearchStatsTests to have all shards allocated If randomization brings up a single shard per index in this test we might run our searches on only one index which causes the assertions to fail afterwards that's why we need to wait until everything is alloated"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n@@ -1262,7 +1262,7 @@ private void innerClose() {\n                 }\n             }\n         } catch (Throwable e) {\n-            logger.debug(\"failed to rollback writer on close\", e);\n+            logger.warn(\"failed to rollback writer on close\", e);\n         } finally {\n             indexWriter = null;\n         }",
    "output": "Change debug log to warn for when IW#rollback fails with an exception other than AlreadyClosedException"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n--- a/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n+++ b/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptSearchTests.java\n@@ -106,7 +106,6 @@ public void testScriptFieldUsingSource() throws Exception {\n \n         SearchResponse response = client().prepareSearch()\n                 .setQuery(matchAllQuery())\n-                .addField(\"_source.obj1\") // we also automatically detect _source in fields\n                 .addScriptField(\"s_obj1\", \"js\", \"_source.obj1\", null)\n                 .addScriptField(\"s_obj1_test\", \"js\", \"_source.obj1.test\", null)\n                 .addScriptField(\"s_obj2\", \"js\", \"_source.obj2\", null)",
    "output": "Remove `_source.obj1` Related to #14"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java b/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java\n@@ -119,7 +119,13 @@ public void setNextReader(AtomicReaderContext reader) {\n \n                 @Override\n                 public InternalAggregation buildAggregation(long owningBucketOrdinal) {\n-                    return aggregators.get(owningBucketOrdinal).buildAggregation(0);\n+                    // The bucket ordinal may be out of range in case of eg. a terms/filter/terms where\n+                    // the filter matches no document in the highest buckets of the first terms agg\n+                    if (owningBucketOrdinal >= aggregators.size() || aggregators.get(owningBucketOrdinal) == null) {\n+                        return first.buildEmptyAggregation();\n+                    } else {\n+                        return aggregators.get(owningBucketOrdinal).buildAggregation(0);\n+                    }\n                 }\n \n                 @Override",
    "output": "Fix NPE/AIOOBE when building a bucket which has not been collected"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/metrics/PercentilesTests.java b/src/test/java/org/elasticsearch/search/aggregations/metrics/PercentilesTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/metrics/PercentilesTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/metrics/PercentilesTests.java\n@@ -23,10 +23,10 @@\n import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.search.aggregations.bucket.histogram.Histogram;\n import org.elasticsearch.search.aggregations.bucket.histogram.Histogram.Order;\n-import org.elasticsearch.search.aggregations.metrics.percentiles.PercentilesBuilder;\n import org.elasticsearch.search.aggregations.metrics.percentiles.Percentiles;\n import org.elasticsearch.search.aggregations.metrics.percentiles.Percentiles.Estimator.TDigest;\n import org.elasticsearch.search.aggregations.metrics.percentiles.Percentiles.Percentile;\n+import org.elasticsearch.search.aggregations.metrics.percentiles.PercentilesBuilder;\n import org.junit.Test;\n \n import java.util.Arrays;\n@@ -66,7 +66,7 @@ private static double[] randomPercentiles() {\n     private static PercentilesBuilder randomEstimator(PercentilesBuilder builder) {\n         if (randomBoolean()) {\n             TDigest estimator = TDigest.tDigest();\n-            estimator.compression(randomDouble() * 100);\n+            estimator.compression(randomIntBetween(20, 120) + randomDouble());\n             builder.estimator(estimator);\n         }\n         return builder;",
    "output": "Fix test bug: a too low compression level can make accuracy terrible"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginUtils.java b/src/main/java/org/elasticsearch/plugins/PluginUtils.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginUtils.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginUtils.java\n@@ -115,7 +115,7 @@ static List<URL> lookupPluginProperties(List<File> pluginClassPath) throws Excep\n                 try {\n                     JarEntry jarEntry = jar.getJarEntry(\"es-plugin.properties\");\n                     if (jarEntry != null) {\n-                        found.add(new URL(\"jar:\" + file.toURI().toString() + \"!/es.plugin.properties\"));\n+                        found.add(new URL(\"jar:\" + file.toURI().toString() + \"!/es-plugin.properties\"));\n                     }\n                 } finally {\n                     IOUtils.closeWhileHandlingException(jar);",
    "output": "Fix typo causing incorrect plugin properties lookup in jars relates"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java b/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java\n--- a/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java\n+++ b/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java\n@@ -125,6 +125,7 @@ public void testIsolatedPluginProperties() throws Exception {\n             String[] hashes = Strings.delimitedListToStringArray(prop, \" \");\n             // 2 plugins plus trailing space\n             assertThat(hashes.length, greaterThanOrEqualTo(count + 2));\n+            Arrays.sort(hashes);\n             assertThat(Arrays.binarySearch(hashes, p.getProperty(\"es.test.isolated.plugin.instantiated\")), greaterThanOrEqualTo(0));\n         } finally {\n             System.setProperties(props);",
    "output": "Fix incorrect array search in test (by sorting it first) relates to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java b/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java\n--- a/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java\n+++ b/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java\n@@ -54,16 +54,10 @@ public MockPageCacheRecycler(Settings settings, ThreadPool threadPool) {\n \n     private <T> V<T> wrap(final V<T> v) {\n         ACQUIRED_PAGES.put(v, new Throwable());\n-        final Thread t = Thread.currentThread();\n         return new V<T>() {\n \n             @Override\n             public boolean release() throws ElasticsearchException {\n-                if (t != Thread.currentThread()) {\n-                    // Releasing from a different thread doesn't break anything but this is bad practice as pages should be acquired\n-                    // as late as possible and released as soon as possible in a try/finally fashion\n-                    throw new RuntimeException(\"Page was allocated in \" + t + \" but released in \" + Thread.currentThread());\n-                }\n                 final Throwable t = ACQUIRED_PAGES.remove(v);\n                 if (t == null) {\n                     throw new IllegalStateException(\"Releasing a page that has not been acquired\");",
    "output": "Remove same-thread checks when recycling ()"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java b/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java\n--- a/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java\n+++ b/src/test/java/org/elasticsearch/plugins/IsolatedPluginTests.java\n@@ -43,7 +43,7 @@\n \n // NB: the tests uses System Properties to pass the information from different plugins (loaded in separate CLs) to the test.\n // hence the use of try/finally blocks to clean these up after the test has been executed as otherwise the test framework will trigger a failure\n-@ClusterScope(scope = Scope.TEST, numNodes = 1)\n+@ClusterScope(scope = Scope.TEST, numNodes = 0)\n public class IsolatedPluginTests extends ElasticsearchIntegrationTest {\n \n     private static final Settings SETTINGS;\n@@ -113,7 +113,7 @@ public void testPluginNumberOfIsolatedInstances() throws Exception {\n     @Test\n     public void testIsolatedPluginProperties() throws Exception {\n         try {\n-            cluster().client();\n+            client();\n             Properties p = System.getProperties();\n             assertThat(p.getProperty(\"es.test.isolated.plugin.count\"), equalTo(\"2\"));\n             String prop = p.getProperty(\"es.test.isolated.plugin.instantiated.hashes\");",
    "output": "Fix failing IsolatedPluginTests (change numNodes to 0) (cherry picked from commit f26a369a78ade032df44fcf331f378644f74b9ea)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/SegmentReaderUtils.java b/src/main/java/org/elasticsearch/common/lucene/SegmentReaderUtils.java\n--- a/src/main/java/org/elasticsearch/common/lucene/SegmentReaderUtils.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/SegmentReaderUtils.java\n@@ -21,6 +21,7 @@\n import org.apache.lucene.index.AtomicReader;\n import org.apache.lucene.index.FilterAtomicReader;\n import org.apache.lucene.index.SegmentReader;\n+import org.apache.lucene.util.Version;\n import org.elasticsearch.ElasticsearchIllegalStateException;\n import org.elasticsearch.common.Nullable;\n \n@@ -31,6 +32,8 @@ public class SegmentReaderUtils {\n     private static final Field FILTER_ATOMIC_READER_IN;\n \n     static {\n+        assert Version.LUCENE_47.onOrAfter(Lucene.VERSION) : \"Lucene 4.8 has FilterAtomicReader.unwrap\";\n+\n         Field in = null;\n         try { // and another one bites the dust...\n             in = FilterAtomicReader.class.getDeclaredField(\"in\");",
    "output": "Add assertion to not forget to replace reflection with the new FilterAtomicReader.unwrap"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n@@ -251,11 +251,14 @@ public final void after() throws IOException {\n                         .transientSettings().getAsMap().size(), equalTo(0));\n \n             }\n-            ensureEstimatedStats();\n-            wipeIndices(\"_all\"); // wipe after to make sure we fail in the test that\n-            // didn't ack the delete\n-            wipeTemplates();\n-            wipeRepositories();\n+            try {\n+                ensureEstimatedStats();\n+            } finally {\n+                wipeIndices(\"_all\"); // wipe after to make sure we fail in the test that\n+                // didn't ack the delete\n+                wipeTemplates();\n+                wipeRepositories();\n+            }\n             ensureAllSearchersClosed();\n             ensureAllFilesClosed();\n             logger.info(\"[{}#{}]: cleaned up after test\", getTestClass().getSimpleName(), getTestName());\n@@ -350,7 +353,8 @@ public static void ensureEstimatedStats() {\n             NodesStatsResponse nodeStats = client().admin().cluster().prepareNodesStats()\n                     .clear().setBreaker(true).execute().actionGet();\n             for (NodeStats stats : nodeStats.getNodes()) {\n-                assertThat(\"Breaker reset to 0 \", stats.getBreaker().getEstimated(), equalTo(0L));\n+                assertThat(\"Breaker reset to 0 - cleared on [\" + all.getSuccessfulShards() + \"] shards total [\" + all.getTotalShards() + \"]\",\n+                        stats.getBreaker().getEstimated(), equalTo(0L));\n             }\n         }\n     }",
    "output": "Improve error reporting on breaker stats assertion"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/fielddata/breaker/RandomExceptionCircuitBreakerTests.java b/src/test/java/org/elasticsearch/indices/fielddata/breaker/RandomExceptionCircuitBreakerTests.java\n--- a/src/test/java/org/elasticsearch/indices/fielddata/breaker/RandomExceptionCircuitBreakerTests.java\n+++ b/src/test/java/org/elasticsearch/indices/fielddata/breaker/RandomExceptionCircuitBreakerTests.java\n@@ -56,7 +56,6 @@\n public class RandomExceptionCircuitBreakerTests extends ElasticsearchIntegrationTest {\n \n     @Test\n-    @TestLogging(\"org.elasticsearch.indices.fielddata.breaker:TRACE,org.elasticsearch.index.fielddata:TRACE,org.elasticsearch.common.breaker:TRACE\")\n     public void testBreakerWithRandomExceptions() throws IOException, InterruptedException, ExecutionException {\n         for (NodeStats node : client().admin().cluster().prepareNodesStats()\n                 .clear().setBreaker(true).execute().actionGet().getNodes()) {",
    "output": "Remove trace logging from testBreakerWithRandomExceptions()"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -144,6 +144,8 @@ public class Version implements Serializable {\n     public static final Version V_0_90_10 = new Version(V_0_90_10_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n     public static final int V_0_90_11_ID = /*00*/901199;\n     public static final Version V_0_90_11 = new Version(V_0_90_11_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n+    public static final int V_0_90_12_ID = /*00*/901299;\n+    public static final Version V_0_90_12 = new Version(V_0_90_12_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n \n     public static final int V_1_0_0_Beta1_ID = /*00*/1000001;\n     public static final Version V_1_0_0_Beta1 = new Version(V_1_0_0_Beta1_ID, false, org.apache.lucene.util.Version.LUCENE_45);\n@@ -186,6 +188,8 @@ public static Version fromId(int id) {\n                 return V_1_0_0_Beta2;\n             case V_1_0_0_Beta1_ID:\n                 return V_1_0_0_Beta1;\n+            case V_0_90_12_ID:\n+                return V_0_90_12;\n             case V_0_90_11_ID:\n                 return V_0_90_11;\n             case V_0_90_10_ID:",
    "output": "Add coming 0.90.12 version to the constants"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginManager.java b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -491,7 +491,6 @@ List<URL> urls() {\n \n         private static void addUrl(List<URL> urls, String url) {\n             try {\n-                URL _url = new URL(url);\n                 urls.add(new URL(url));\n             } catch (MalformedURLException e) {\n                 // We simply ignore malformed URL",
    "output": "Remove useless URL instanciation"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java b/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java\n--- a/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java\n+++ b/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java\n@@ -72,7 +72,7 @@ public static XContentBuilder smileBuilder(OutputStream os) throws IOException {\n      * Returns a content builder using YAML format ({@link org.elasticsearch.common.xcontent.XContentType#YAML}.\n      */\n     public static XContentBuilder yamlBuilder() throws IOException {\n-        return contentBuilder(XContentType.SMILE);\n+        return contentBuilder(XContentType.YAML);\n     }\n \n     /**",
    "output": "Fix yamlBuilder() to return YAML builder instead of SMILE"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimplePolishIntegrationTests.java\n@@ -20,11 +20,14 @@\n package org.elasticsearch.index.analysis;\n \n import org.elasticsearch.action.admin.indices.analyze.AnalyzeResponse;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.junit.Test;\n \n+import java.io.IOException;\n import java.util.concurrent.ExecutionException;\n \n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.CoreMatchers.notNullValue;\n \n@@ -50,4 +53,25 @@ public void testPolishStemmerTokenFilter() throws ExecutionException, Interrupte\n         assertThat(response, notNullValue());\n         assertThat(response.getTokens().size(), is(1));\n     }\n+\n+    @Test\n+    public void testPolishAnalyzerInMapping() throws ExecutionException, InterruptedException, IOException {\n+        final XContentBuilder mapping = jsonBuilder().startObject()\n+            .startObject(\"type\")\n+                .startObject(\"properties\")\n+                    .startObject(\"foo\")\n+                        .field(\"type\", \"string\")\n+                        .field(\"analyzer\", \"polish\")\n+                    .endObject()\n+                .endObject()\n+            .endObject()\n+            .endObject();\n+\n+        client().admin().indices().prepareCreate(\"test\").addMapping(\"type\", mapping).get();\n+\n+        index(\"test\", \"type\", \"1\", \"foo\", \"wirtualna polska\");\n+\n+        ensureYellow();\n+    }\n+\n }",
    "output": "Add test stempel analyzer in mapping"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -155,6 +155,8 @@ public class Version implements Serializable {\n     public static final Version V_1_0_0_RC2 = new Version(V_1_0_0_RC2_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n     public static final int V_1_0_0_ID = /*00*/1000099;\n     public static final Version V_1_0_0 = new Version(V_1_0_0_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n+    public static final int V_1_1_0_ID = /*00*/1010099;\n+    public static final Version V_1_1_0 = new Version(V_1_1_0_ID, true, org.apache.lucene.util.Version.LUCENE_46);\n     public static final int V_2_0_0_ID = /*00*/2000099;\n     public static final Version V_2_0_0 = new Version(V_2_0_0_ID, true, org.apache.lucene.util.Version.LUCENE_46);\n \n@@ -172,6 +174,8 @@ public static Version fromId(int id) {\n         switch (id) {\n             case V_2_0_0_ID:\n                 return V_2_0_0;\n+            case V_1_1_0_ID:\n+                return V_1_1_0;\n             case V_1_0_0_ID:\n                 return V_1_0_0;\n             case V_1_0_0_RC2_ID:",
    "output": "Add Version.1_1_0 (missing in master but already in 1.x)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -142,6 +142,8 @@ public class Version implements Serializable {\n     public static final Version V_0_90_9 = new Version(V_0_90_9_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n     public static final int V_0_90_10_ID = /*00*/901099;\n     public static final Version V_0_90_10 = new Version(V_0_90_10_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n+    public static final int V_0_90_11_ID = /*00*/901199;\n+    public static final Version V_0_90_11 = new Version(V_0_90_11_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n \n     public static final int V_1_0_0_Beta1_ID = /*00*/1000001;\n     public static final Version V_1_0_0_Beta1 = new Version(V_1_0_0_Beta1_ID, false, org.apache.lucene.util.Version.LUCENE_45);\n@@ -180,6 +182,8 @@ public static Version fromId(int id) {\n                 return V_1_0_0_Beta2;\n             case V_1_0_0_Beta1_ID:\n                 return V_1_0_0_Beta1;\n+            case V_0_90_11_ID:\n+                return V_0_90_11;\n             case V_0_90_10_ID:\n                 return V_0_90_10;\n             case V_0_90_9_ID:",
    "output": "Add [0.90.11] version as a constant"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java b/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java\n--- a/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java\n+++ b/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java\n@@ -86,8 +86,16 @@ public PercolateStats stats() {\n \n     private static long computeSizeInMemory(HashedBytesRef id, Query query) {\n         long size = (3 * RamUsageEstimator.NUM_BYTES_INT) + RamUsageEstimator.NUM_BYTES_OBJECT_REF + RamUsageEstimator.NUM_BYTES_OBJECT_HEADER + id.bytes.bytes.length;\n-        size += RamUsageEstimator.sizeOf(query);\n+        size += RamEstimator.sizeOf(query);\n         return size;\n     }\n \n+    private static final class RamEstimator {\n+        // we move this into it's own class to exclude it from the forbidden API checks\n+        // it's fine to use here!\n+        static long sizeOf(Query query) {\n+            return RamUsageEstimator.sizeOf(query);\n+        }\n+    }\n+\n }",
    "output": "Add RamUsageEstimator#sizeOf(Object) to forbidden APIs This method can be a performance trap since it traverse the entire object tree that is referenced by the provided object. See LUCENE-5373"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java b/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n@@ -44,7 +44,6 @@ public void testDynamicTemplateCopyTo() throws Exception {\n                 client().admin().indices().prepareCreate(\"test-idx\")\n                         .addMapping(\"doc\", createDynamicTemplateMapping())\n         );\n-        ensureGreen(\"test-idx\");\n \n         int recordCount = between(1, 200);\n ",
    "output": "Remove waiting for green in CopyToMapperIntegrationTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java b/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n@@ -44,6 +44,7 @@ public void testDynamicTemplateCopyTo() throws Exception {\n                 client().admin().indices().prepareCreate(\"test-idx\")\n                         .addMapping(\"doc\", createDynamicTemplateMapping())\n         );\n+        ensureGreen(\"test-idx\");\n \n         int recordCount = between(1, 200);\n ",
    "output": "Improve test stability"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java b/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java\n--- a/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java\n+++ b/src/main/java/org/elasticsearch/discovery/gce/GceUnicastHostsProvider.java\n@@ -123,6 +123,11 @@ public List<DiscoveryNode> buildDynamicNodes() {\n         try {\n             Collection<Instance> instances = gceComputeService.instances();\n \n+            if (instances == null) {\n+                logger.trace(\"no instance found for project [{}], zone [{}].\", this.project, this.zone);\n+                return cachedDiscoNodes;\n+            }\n+\n             for (Instance instance : instances) {\n                 String name = instance.getName();\n                 String type = instance.getMachineType();",
    "output": "Upgrade to GCE API 1.17.0-rc Seen in #9, Google changed its APIs. We need to update as it previous version causes a `404` error"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java b/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n--- a/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n+++ b/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java\n@@ -51,12 +51,15 @@ public class GceComputeServiceImpl extends AbstractLifecycleComponent<GceCompute\n     @Override\n     public Collection<Instance> instances() {\n         try {\n+            logger.debug(\"get instances for project [{}], zone [{}]\", project, zone);\n+\n             Compute.Instances.List list = client().instances().list(project, zone);\n             InstanceList instanceList = list.execute();\n \n             return instanceList.getItems();\n         } catch (IOException e) {\n-            logger.warn(\"can not get list of nodes. Disabling GCE discovery.\");\n+            logger.warn(\"disabling GCE discovery. Can not get list of nodes: {}\", e.getMessage());\n+            logger.debug(\"Full exception:\", e);\n             return new ArrayList<Instance>();\n         }\n     }",
    "output": "Add more traces when failing"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridTests.java\n@@ -101,6 +101,7 @@ public void init() throws Exception {\n             }\n         }\n         indexRandom(true, cities);\n+        ensureSearchable();\n     }\n \n \n@@ -166,9 +167,6 @@ public void filtered() throws Exception {\n \n     @Test\n     public void unmapped() throws Exception {\n-        client().admin().cluster().prepareHealth(\"idx_unmapped\").setWaitForYellowStatus().execute().actionGet();\n-\n-\n         for (int precision = 1; precision <= highestPrecisionGeohash; precision++) {\n             SearchResponse response = client().prepareSearch(\"idx_unmapped\")\n                     .addAggregation(geohashGrid(\"geohashgrid\")",
    "output": "Use #ensureSearchable() in GeoHashGridTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java b/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java\n@@ -66,8 +66,8 @@ public static void registerStream() {\n     public static class Bucket implements Histogram.Bucket {\n \n         long key;\n-        private long docCount;\n-        private InternalAggregations aggregations;\n+        long docCount;\n+        InternalAggregations aggregations;\n \n         public Bucket(long key, long docCount, InternalAggregations aggregations) {\n             this.key = key;\n\ndiff --git a/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java b/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java\n@@ -62,7 +62,7 @@ public static class Bucket implements Range.Bucket {\n         private double from = Double.NEGATIVE_INFINITY;\n         private double to = Double.POSITIVE_INFINITY;\n         private long docCount;\n-        private InternalAggregations aggregations;\n+        InternalAggregations aggregations;\n         private String key;\n         private boolean explicitKey;\n ",
    "output": "Fix compilation error on jdk7"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java b/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/index/engine/internal/InternalEngineIntegrationTest.java\n@@ -39,7 +39,6 @@\n import org.hamcrest.Matchers;\n import org.junit.Test;\n \n-import java.lang.reflect.Field;\n import java.util.Collection;\n \n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n@@ -164,6 +163,7 @@ private void assertTotalCompoundSegments(int i, int t, String index) {\n \n     @Test\n     public void test4093() {\n+        cluster().ensureAtMostNumNodes(1);\n         assertAcked(prepareCreate(\"test\").setSettings(ImmutableSettings.settingsBuilder()\n                 .put(\"index.store.type\", \"memory\")\n                 .put(\"cache.memory.large_cache_size\", new ByteSizeValue(1, ByteSizeUnit.MB)) // no need to cache a lot\n@@ -179,7 +179,7 @@ public void test4093() {\n             ByteSizeValue directMemoryMax = info.getJvm().getMem().getDirectMemoryMax();\n             logger.debug(\"  --> JVM max direct memory for node [{}] is set to [{}]\", info.getNode().getName(), directMemoryMax);\n         }\n-        final int numDocs = between(30, 100); // 30 docs are enough to fail without the fix for #4093\n+        final int numDocs = between(30, 50); // 30 docs are enough to fail without the fix for #4093\n         logger.debug(\"  --> Indexing [{}] documents\", numDocs);\n         for (int i = 0; i < numDocs; i++) {\n             if ((i + 1) % 10 == 0) {",
    "output": "Make test more reliable"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/geo/GeoEncodingTests.java b/src/test/java/org/elasticsearch/index/mapper/geo/GeoEncodingTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/geo/GeoEncodingTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/geo/GeoEncodingTests.java\n@@ -36,7 +36,7 @@ public void test() {\n         for (int i = 0; i < 10000; ++i) {\n             final double lat = randomDouble() * 180 - 90;\n             final double lon = randomDouble() * 360 - 180;\n-            final Distance precision = new Distance(randomDouble() * 10, randomFrom(Arrays.asList(DistanceUnit.MILLIMETERS, DistanceUnit.METERS, DistanceUnit.KILOMETERS)));\n+            final Distance precision = new Distance(1+(randomDouble() * 9), randomFrom(Arrays.asList(DistanceUnit.MILLIMETERS, DistanceUnit.METERS, DistanceUnit.KILOMETERS)));\n             final GeoPointFieldMapper.Encoding encoding = GeoPointFieldMapper.Encoding.of(precision);\n             assertThat(encoding.precision().convert(DistanceUnit.METERS).value, lessThanOrEqualTo(precision.convert(DistanceUnit.METERS).value));\n             final GeoPoint geoPoint = encoding.decode(encoding.encodeCoordinate(lat), encoding.encodeCoordinate(lon), new GeoPoint());",
    "output": "Change GeoEncodingTests to ensure accuracy always >1mm due to rounding errors with very small numbers"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java b/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java\n--- a/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java\n+++ b/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java\n@@ -34,6 +34,7 @@ public enum SimpleQueryStringFlag {\n     NOT(XSimpleQueryParser.NOT_OPERATOR),\n     OR(XSimpleQueryParser.OR_OPERATOR),\n     PREFIX(XSimpleQueryParser.PREFIX_OPERATOR),\n+    PHRASE(XSimpleQueryParser.PHRASE_OPERATOR),\n     PRECEDENCE(XSimpleQueryParser.PRECEDENCE_OPERATORS),\n     ESCAPE(XSimpleQueryParser.ESCAPE_OPERATOR),\n     WHITESPACE(XSimpleQueryParser.WHITESPACE_OPERATOR);",
    "output": "Add missing PHRASE flag for simple_query_string"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java b/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/copyto/CopyToMapperIntegrationTests.java\n@@ -45,7 +45,7 @@ public void testDynamicTemplateCopyTo() throws Exception {\n                         .addMapping(\"doc\", createDynamicTemplateMapping())\n         );\n \n-        int recordCount = randomInt(200);\n+        int recordCount = between(1, 200);\n \n         for (int i = 0; i < recordCount * 2; i++) {\n             client().prepareIndex(\"test-idx\", \"doc\", Integer.toString(i))",
    "output": "Fix test to use at least one document"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/support/RestTable.java b/src/main/java/org/elasticsearch/rest/action/support/RestTable.java\n--- a/src/main/java/org/elasticsearch/rest/action/support/RestTable.java\n+++ b/src/main/java/org/elasticsearch/rest/action/support/RestTable.java\n@@ -233,6 +233,10 @@ private static String renderValue(RestRequest request, Object value) {\n                 return Long.toString(v.mb());\n             } else if (\"g\".equals(resolution)) {\n                 return Long.toString(v.gb());\n+            } else if (\"t\".equals(resolution)) {\n+                return Long.toString(v.tb());\n+            } else if (\"p\".equals(resolution)) {\n+                return Long.toString(v.pb());\n             } else {\n                 return v.toString();\n             }\n@@ -248,6 +252,10 @@ private static String renderValue(RestRequest request, Object value) {\n                 return Long.toString(v.mega());\n             } else if (\"g\".equals(resolution)) {\n                 return Long.toString(v.giga());\n+            } else if (\"t\".equals(resolution)) {\n+                return Long.toString(v.tera());\n+            } else if (\"p\".equals(resolution)) {\n+                return Long.toString(v.peta());\n             } else {\n                 return v.toString();\n             }",
    "output": "Add tera and peta to RestTable.renderValue()"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java b/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java\n--- a/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java\n+++ b/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java\n@@ -43,10 +43,6 @@ public class IndexWarmersMetaData implements IndexMetaData.Custom {\n \n     public static final Factory FACTORY = new Factory();\n \n-    static {\n-        IndexMetaData.registerFactory(TYPE, FACTORY);\n-    }\n-\n     public static class Entry {\n         private final String name;\n         private final String[] types;",
    "output": "Remove duplicated registration of warmers as custom metadata type Already done in a static block within IndexMetaData"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java b/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java\n@@ -804,7 +804,10 @@ private boolean tryRelocateShard(Operation operation, ModelNode minNode, ModelNo\n                             if ((srcDecision = maxNode.removeShard(shard)) != null) {\n                                 minNode.addShard(shard, srcDecision);\n                                 final float delta = weight.weight(operation, this, minNode, idx) - weight.weight(operation, this, maxNode, idx);\n-                                if (delta < minCost) {\n+                                if (delta < minCost ||\n+                                        (candidate != null && delta == minCost && candidate.id() > shard.id())) {\n+                                    /* this last line is a tie-breaker to make the shard allocation alg deterministic\n+                                     * otherwise we rely on the iteration order of the index.getAllShards() which is a set.*/\n                                     minCost = delta;\n                                     candidate = shard;\n                                     decision = new Decision.Multi().add(allocationDecision).add(rebalanceDecision);",
    "output": "Make shard balancing deterministic if weights are identical It happens to be the case that the iteration order of a HashMaps keyset might be different across runs. This can cause undeterministic results in shard balancing if weights are identical and multiple shards of the same index are eligable for relocation. This commit adds a tie-breaker based on the shard ID to prioritise the lowest shard ID. This also makes `AddIncrementallyTests#testAddNodesAndIndices` reproducible"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/river/routing/RiversRouter.java b/src/main/java/org/elasticsearch/river/routing/RiversRouter.java\n--- a/src/main/java/org/elasticsearch/river/routing/RiversRouter.java\n+++ b/src/main/java/org/elasticsearch/river/routing/RiversRouter.java\n@@ -241,6 +241,7 @@ public RiverClusterState execute(RiverClusterState currentState) {\n                 it.remove();\n                 routing.node(smallest);\n                 nodesToRivers.get(smallest).add(routing);\n+                logger.debug(\"going to allocate river [{}] on node {}\", routing.riverName().getName(), smallest);\n             }\n         }\n ",
    "output": "Add log line to better debug where rivers will get allocated"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/VersionTests.java b/src/test/java/org/elasticsearch/VersionTests.java\n--- a/src/test/java/org/elasticsearch/VersionTests.java\n+++ b/src/test/java/org/elasticsearch/VersionTests.java\n@@ -24,8 +24,10 @@\n \n import static org.elasticsearch.Version.V_0_20_0;\n import static org.elasticsearch.Version.V_0_90_0;\n+import static org.hamcrest.CoreMatchers.equalTo;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.sameInstance;\n \n public class VersionTests extends ElasticsearchTestCase {\n \n@@ -48,4 +50,16 @@ public void testVersions() throws Exception {\n         assertThat(V_0_90_0.onOrAfter(V_0_20_0), is(true));\n     }\n \n+    @Test\n+    public void testVersionConstantPresent() {\n+        assertThat(Version.CURRENT, sameInstance(Version.fromId(Version.CURRENT.id)));\n+        assertThat(Version.CURRENT.luceneVersion.ordinal(), equalTo(org.apache.lucene.util.Version.LUCENE_CURRENT.ordinal() - 1));\n+        final int iters = atLeast(20);\n+        for (int i = 0; i < iters; i++) {\n+            Version version = randomVersion();\n+            assertThat(version, sameInstance(Version.fromId(version.id)));\n+            assertThat(version.luceneVersion, sameInstance(Version.fromId(version.id).luceneVersion));\n+        }\n+    }\n+\n }\n\\ No newline at end of file",
    "output": "Add tests that ensures all version are in the Version#fromId(int) switch statement"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/percolate/RestPercolateAction.java b/src/main/java/org/elasticsearch/rest/action/percolate/RestPercolateAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/percolate/RestPercolateAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/percolate/RestPercolateAction.java\n@@ -71,8 +71,6 @@ void parseDocPercolate(PercolateRequest percolateRequest, RestRequest restReques\n         percolateRequest.preference(restRequest.param(\"preference\"));\n         percolateRequest.source(restRequest.content(), restRequest.contentUnsafe());\n \n-        percolateRequest.routing(restRequest.param(\"routing\"));\n-        percolateRequest.preference(restRequest.param(\"preference\"));\n         percolateRequest.indicesOptions(IndicesOptions.fromRequest(restRequest, percolateRequest.indicesOptions()));\n         executePercolate(percolateRequest, restRequest, restChannel);\n     }\n@@ -97,9 +95,6 @@ void parseExistingDocPercolate(PercolateRequest percolateRequest, RestRequest re\n         percolateRequest.preference(restRequest.param(\"percolate_preference\"));\n         percolateRequest.source(restRequest.content(), restRequest.contentUnsafe());\n \n-        percolateRequest.routing(restRequest.param(\"percolate_routing\"));\n-        percolateRequest.preference(restRequest.param(\"percolate_preference\"));\n-\n         percolateRequest.indicesOptions(IndicesOptions.fromRequest(restRequest, percolateRequest.indicesOptions()));\n         executePercolate(percolateRequest, restRequest, restChannel);\n     }",
    "output": "Remove redundant statements"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -235,10 +235,10 @@ public void run() {\n             }\n             String errorMessage = buildErrorMessage(stage, e);\n             if (foreground) {\n-                logger.error(errorMessage);\n-            } else {\n                 System.err.println(errorMessage);\n                 System.err.flush();\n+            } else {\n+                logger.error(errorMessage);\n             }\n             Loggers.disableConsoleLogging();\n             if (logger.isDebugEnabled()) {",
    "output": "Fix logging on immediate exit on start If elasticsearch was started in the foreground an immediate exit on startup led to logging in the logfile, where as when starting in the background, an immediate exit logged to stdout"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n--- a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n+++ b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n@@ -38,6 +38,22 @@ private RestSpec() {\n     }\n \n     void addApi(RestApi restApi) {\n+        if (\"index\".equals(restApi.getName())) {\n+            RestApi create = new RestApi(\"create\");\n+            create.addPath(\"/{index}/{type}\");\n+            create.addPath(\"/{index}/{type}/{id}/_create\");\n+            create.setBodyRequired();\n+            for (String method : restApi.getMethods()) {\n+                create.addMethod(method);\n+            }\n+            for (String param : restApi.getParams()) {\n+                create.addParam(param);\n+            }\n+            for (String pathPart : restApi.getPathParts()) {\n+                create.addPathPart(pathPart);\n+            }\n+            restApiMap.put(create.getName(), create);\n+        }\n         restApiMap.put(restApi.getName(), restApi);\n     }\n ",
    "output": "Add create api (hardcoded) to REST tests suite as it has no spec but it's just a variation of the index api"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/action/admin/HotThreadsTest.java b/src/test/java/org/elasticsearch/action/admin/HotThreadsTest.java\n--- a/src/test/java/org/elasticsearch/action/admin/HotThreadsTest.java\n+++ b/src/test/java/org/elasticsearch/action/admin/HotThreadsTest.java\n@@ -108,9 +108,6 @@ public void onFailure(Throwable e) {\n                     client().prepareIndex(\"test\", \"type1\", \"2\").setSource(\"field1\", \"value2\"),\n                     client().prepareIndex(\"test\", \"type1\", \"3\").setSource(\"field1\", \"value3\"));\n             ensureSearchable();\n-            if (randomBoolean()) {\n-                optimize();\n-            }\n             while(latch.getCount() > 0) {\n                 assertHitCount(\n                         client().prepareSearch()",
    "output": "Remove unnecessary optimize call that destabelizes test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/parser/RestTestSuiteParseContext.java b/src/test/java/org/elasticsearch/test/rest/parser/RestTestSuiteParseContext.java\n--- a/src/test/java/org/elasticsearch/test/rest/parser/RestTestSuiteParseContext.java\n+++ b/src/test/java/org/elasticsearch/test/rest/parser/RestTestSuiteParseContext.java\n@@ -136,7 +136,7 @@ public void advanceToFieldName() throws IOException, RestTestParseException {\n             token = parser.nextToken();\n         }\n         if (token != XContentParser.Token.FIELD_NAME) {\n-            throw new RestTestParseException(\"malformed test section: field suiteName expected but found \" + token);\n+            throw new RestTestParseException(\"malformed test section: field name expected but found \" + token);\n         }\n     }\n ",
    "output": "Fix error message in REST tests runner"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/repositories/put/RestPutRepositoryAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/repositories/put/RestPutRepositoryAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/repositories/put/RestPutRepositoryAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/repositories/put/RestPutRepositoryAction.java\n@@ -50,7 +50,6 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n         putRepositoryRequest.source(request.content().toUtf8());\n         putRepositoryRequest.masterNodeTimeout(request.paramAsTime(\"master_timeout\", putRepositoryRequest.masterNodeTimeout()));\n         putRepositoryRequest.timeout(request.paramAsTime(\"timeout\", putRepositoryRequest.timeout()));\n-        putRepositoryRequest.masterNodeTimeout(request.paramAsTime(\"master_timeout\", putRepositoryRequest.masterNodeTimeout()));\n         client.admin().cluster().putRepository(putRepositoryRequest, new AcknowledgedRestResponseActionListener<PutRepositoryResponse>(request, channel, logger));\n     }\n }",
    "output": "Remove double masterNodeTimeout set in RestPutRepositoryAction"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java b/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n--- a/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n+++ b/src/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n@@ -18,6 +18,7 @@\n  */\n package org.elasticsearch.indices.template;\n \n+import com.carrotsearch.randomizedtesting.LifecycleScope;\n import com.google.common.base.Charsets;\n import com.google.common.io.Files;\n import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;\n@@ -27,9 +28,7 @@\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.elasticsearch.test.ElasticsearchIntegrationTest.ClusterScope;\n import org.elasticsearch.test.ElasticsearchIntegrationTest.Scope;\n-import org.junit.Rule;\n import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n \n import java.io.File;\n import java.util.HashSet;\n@@ -43,16 +42,14 @@\n @ClusterScope(scope=Scope.TEST, numNodes=1)\n public class IndexTemplateFileLoadingTests extends ElasticsearchIntegrationTest {\n \n-    @Rule\n-    public TemporaryFolder temporaryFolder = new TemporaryFolder();\n \n     @Override\n     protected Settings nodeSettings(int nodeOrdinal) {\n         ImmutableSettings.Builder settingsBuilder = ImmutableSettings.settingsBuilder();\n         settingsBuilder.put(super.nodeSettings(nodeOrdinal));\n \n         try {\n-            File directory = temporaryFolder.newFolder();\n+            File directory = newTempDir(LifecycleScope.SUITE);\n             settingsBuilder.put(\"path.conf\", directory.getPath());\n \n             File templatesDir = new File(directory + File.separator + \"templates\");",
    "output": "Add SecurityManger / policy when running tests. This commit adds a security manager to the test JVMs that prevents mainly writing files outside of the JVMs current test directory"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n--- a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n+++ b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n@@ -40,12 +40,7 @@ private RestSpec() {\n     }\n \n     void addApi(RestApi restApi) {\n-        if (\"info\".equals(restApi.getName())) {\n-            //TODO info and ping should really be two different api in the rest spec\n-            //info (GET|HEAD /) needs to be manually split into 1) info: GET /  2) ping: HEAD /\n-            restApiMap.put(\"info\", new RestApi(restApi, \"info\", \"GET\"));\n-            restApiMap.put(\"ping\", new RestApi(restApi, \"ping\", \"HEAD\"));\n-        } else if (\"get\".equals(restApi.getName())) {\n+        if (\"get\".equals(restApi.getName())) {\n             //TODO get_source endpoint shouldn't be present in the rest spec for the get api\n             //as get_source is already a separate api\n             List<String> paths = Lists.newArrayList();",
    "output": "Remove TODO and custom code now that ping and info are two different apis in the REST spec"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n@@ -1145,6 +1145,7 @@ public void testPercolateScoreAndSorting() throws Exception {\n             }\n             controlMap.get(value).add(i);\n         }\n+        List<Integer> usedValues = new ArrayList<Integer>(controlMap.keySet());\n         refresh();\n \n         // Only retrieve the score\n@@ -1166,7 +1167,6 @@ public void testPercolateScoreAndSorting() throws Exception {\n         }\n \n         // Sort the queries by the score\n-        runs = randomInt(27);\n         for (int i = 0; i < runs; i++) {\n             int size = randomIntBetween(1, 10);\n             PercolateResponse response = client().preparePercolate().setIndices(\"my-index\").setDocumentType(\"my-type\")\n@@ -1188,9 +1188,8 @@ public void testPercolateScoreAndSorting() throws Exception {\n         }\n \n \n-        runs = randomInt(27);\n         for (int i = 0; i < runs; i++) {\n-            int value = randomInt(10);\n+            int value = usedValues.get(randomInt(usedValues.size() - 1));\n             NavigableSet<Integer> levels = controlMap.get(value);\n             int size = randomIntBetween(1, levels.size());\n             PercolateResponse response = client().preparePercolate().setIndices(\"my-index\").setDocumentType(\"my-type\")",
    "output": "Fix test bug, was using value that wasn't generated"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java b/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java\n--- a/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java\n+++ b/src/test/java/org/elasticsearch/common/breaker/MemoryCircuitBreakerTests.java\n@@ -54,7 +54,7 @@ public void run() {\n                             if (tripped.get()) {\n                                 assertThat(\"tripped too many times\", true, equalTo(false));\n                             } else {\n-                                assert tripped.compareAndSet(false, true);\n+                                assertThat(tripped.compareAndSet(false, true), equalTo(true));\n                             }\n                         } catch (Throwable e2) {\n                             lastException.set(e2);\n@@ -86,7 +86,6 @@ public void testConstantFactor() throws Exception {\n             breaker.addEstimateBytesAndMaybeBreak(3);\n             fail(\"should never reach this\");\n         } catch (CircuitBreakingException cbe) {\n-            assert true;\n         }\n \n         // shouldn't throw an exception\n@@ -102,7 +101,6 @@ public void testConstantFactor() throws Exception {\n             breaker.addEstimateBytesAndMaybeBreak(0);\n             fail(\"should never reach this\");\n         } catch (CircuitBreakingException cbe) {\n-            assert true;\n         }\n     }\n }",
    "output": "Use assertThat instead of plain asserts in MemoryCircuitBreakerTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreTests.java b/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreTests.java\n--- a/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreTests.java\n+++ b/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreTests.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.action.admin.cluster.snapshots.create.CreateSnapshotResponse;\n import org.elasticsearch.action.admin.cluster.snapshots.restore.RestoreSnapshotResponse;\n import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.Priority;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.snapshots.mockstore.MockRepositoryModule;\n@@ -152,6 +153,7 @@ public void restoreIndexWithMissingShards() throws Exception {\n \n         logger.info(\"--> shutdown one of the nodes\");\n         cluster().stopRandomNode();\n+        assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout(\"1m\").setWaitForNodes(\"<2\").execute().actionGet().isTimedOut(), equalTo(false));\n \n         assertAcked(prepareCreate(\"test-idx-2\", 1, settingsBuilder().put(\"number_of_shards\", 6)\n                 .put(\"number_of_replicas\", 0)",
    "output": "Fix possible race condition in the restoreIndexWithMissingShards test Due to a race condition the index creation operation might still try to create an index on the closing node"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/path/PathTrieTests.java b/src/test/java/org/elasticsearch/common/path/PathTrieTests.java\n--- a/src/test/java/org/elasticsearch/common/path/PathTrieTests.java\n+++ b/src/test/java/org/elasticsearch/common/path/PathTrieTests.java\n@@ -111,6 +111,22 @@ public void testPreferNonWildcardExecution() {\n         assertThat(trie.retrieve(\"/b/a\", params), equalTo(\"test4\"));\n     }\n \n+    @Test\n+    public void testSamePathConcreteResolution() {\n+        PathTrie<String> trie = new PathTrie<String>();\n+        trie.insert(\"{x}/{y}/{z}\", \"test1\");\n+        trie.insert(\"{x}/_y/{k}\", \"test2\");\n+\n+        Map<String, String> params = newHashMap();\n+        assertThat(trie.retrieve(\"/a/b/c\", params), equalTo(\"test1\"));\n+        assertThat(params.get(\"x\"), equalTo(\"a\"));\n+        assertThat(params.get(\"y\"), equalTo(\"b\"));\n+        assertThat(params.get(\"z\"), equalTo(\"c\"));\n+        assertThat(trie.retrieve(\"/a/_y/c\", params), equalTo(\"test2\"));\n+        assertThat(params.get(\"x\"), equalTo(\"a\"));\n+        assertThat(params.get(\"k\"), equalTo(\"c\"));\n+    }\n+\n     @Test\n     public void testNamedWildcardAndLookupWithWildcard() {\n         PathTrie<String> trie = new PathTrie<String>();",
    "output": "Add similar concrete path trie tests resolution"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n--- a/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n+++ b/src/test/java/org/elasticsearch/test/rest/spec/RestSpec.java\n@@ -71,9 +71,13 @@ public static RestSpec parseFrom(String optionalPathPrefix, String... paths) thr\n         RestSpec restSpec = new RestSpec();\n         for (String path : paths) {\n             for (File jsonFile : FileUtils.findJsonSpec(optionalPathPrefix, path)) {\n-                XContentParser parser = JsonXContent.jsonXContent.createParser(new FileInputStream(jsonFile));\n-                RestApi restApi = new RestApiParser().parse(parser);\n-                restSpec.addApi(restApi);\n+                try {\n+                    XContentParser parser = JsonXContent.jsonXContent.createParser(new FileInputStream(jsonFile));\n+                    RestApi restApi = new RestApiParser().parse(parser);\n+                    restSpec.addApi(restApi);\n+                } catch (IOException ex) {\n+                    throw new IOException(\"Can't parse rest spec file: [\" + jsonFile + \"]\", ex);\n+                }\n             }\n         }\n         return restSpec;",
    "output": "Add better error reporting if a json spec can not be parsed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodesStatsRequestBuilder.java b/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodesStatsRequestBuilder.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodesStatsRequestBuilder.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodesStatsRequestBuilder.java\n@@ -58,6 +58,11 @@ public NodesStatsRequestBuilder setIndices(boolean indices) {\n         return this;\n     }\n \n+    public NodesStatsRequestBuilder setBreaker(boolean breaker) {\n+        request.breaker(breaker);\n+        return this;\n+    }\n+\n     /**\n      * Should the node indices stats be returned.\n      */",
    "output": "Add missing #setBreaker setter to NodesStatsRequestBuilder"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java b/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n--- a/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n+++ b/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n@@ -176,7 +176,7 @@ public InternalIndexShard(ShardId shardId, @IndexSettings Settings indexSettings\n         this.codecService = codecService;\n         state = IndexShardState.CREATED;\n \n-        this.refreshInterval = indexSettings.getAsTime(\"engine.robin.refresh_interval\", indexSettings.getAsTime(INDEX_REFRESH_INTERVAL, engine.defaultRefreshInterval()));\n+        this.refreshInterval = indexSettings.getAsTime(INDEX_REFRESH_INTERVAL, engine.defaultRefreshInterval());\n         this.mergeInterval = indexSettings.getAsTime(\"index.merge.async_interval\", TimeValue.timeValueSeconds(1));\n \n         indexSettingsService.addListener(applyRefreshSettings);\n@@ -888,7 +888,7 @@ public void onRefreshSettings(Settings settings) {\n                 if (state == IndexShardState.CLOSED) {\n                     return;\n                 }\n-                TimeValue refreshInterval = settings.getAsTime(\"engine.robin.refresh_interval\", settings.getAsTime(INDEX_REFRESH_INTERVAL, InternalIndexShard.this.refreshInterval));\n+                TimeValue refreshInterval = settings.getAsTime(INDEX_REFRESH_INTERVAL, InternalIndexShard.this.refreshInterval);\n                 if (!refreshInterval.equals(InternalIndexShard.this.refreshInterval)) {\n                     logger.info(\"updating refresh_interval from [{}] to [{}]\", InternalIndexShard.this.refreshInterval, refreshInterval);\n                     if (refreshScheduledFuture != null) {",
    "output": "Remove ancient `engine.robin.refresh_interval`"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java b/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/KuromojiTokenizerFactory.java\n@@ -23,7 +23,7 @@\n import org.apache.lucene.analysis.ja.JapaneseTokenizer;\n import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;\n import org.apache.lucene.analysis.ja.dict.UserDictionary;\n-import org.elasticsearch.ElasticSearchException;\n+import org.elasticsearch.ElasticsearchException;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.inject.assistedinject.Assisted;\n import org.elasticsearch.common.settings.Settings;\n@@ -66,7 +66,7 @@ public static UserDictionary getUserDictionary(Environment env, Settings setting\n                 }\n             }\n         } catch (IOException e) {\n-            throw new ElasticSearchException(\"failed to load kuromoji user dictionary\", e);\n+            throw new ElasticsearchException(\"failed to load kuromoji user dictionary\", e);\n         }\n     }\n ",
    "output": "Upgrade to elasticsearch 1.0.0.RC1"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -140,6 +140,8 @@ public class Version implements Serializable {\n     public static final Version V_0_90_8 = new Version(V_0_90_8_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n     public static final int V_0_90_9_ID = /*00*/900999;\n     public static final Version V_0_90_9 = new Version(V_0_90_9_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n+    public static final int V_0_90_10_ID = /*00*/901099;\n+    public static final Version V_0_90_10 = new Version(V_0_90_10_ID, false, org.apache.lucene.util.Version.LUCENE_46);\n \n     public static final int V_1_0_0_Beta1_ID = /*00*/1000001;\n     public static final Version V_1_0_0_Beta1 = new Version(V_1_0_0_Beta1_ID, false, org.apache.lucene.util.Version.LUCENE_45);\n@@ -166,6 +168,8 @@ public static Version fromId(int id) {\n                 return V_1_0_0_Beta2;\n             case V_1_0_0_Beta1_ID:\n                 return V_1_0_0_Beta1;\n+            case V_0_90_10_ID:\n+                return V_0_90_10;\n             case V_0_90_9_ID:\n                 return V_0_90_9;\n             case V_0_90_8_ID:",
    "output": "Add 0.90.10 to master"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/Strings.java b/src/main/java/org/elasticsearch/common/Strings.java\n--- a/src/main/java/org/elasticsearch/common/Strings.java\n+++ b/src/main/java/org/elasticsearch/common/Strings.java\n@@ -1548,4 +1548,21 @@ public static String randomBase64UUID(Random random) {\n             throw new ElasticsearchIllegalStateException(\"should not be thrown\");\n         }\n     }\n+\n+    /**\n+     * Return substring(beginIndex, endIndex) that is impervious to string length.\n+     */\n+    public static String substring(String s, int beginIndex, int endIndex) {\n+        if (s == null) {\n+            return s;\n+        }\n+\n+        int realEndIndex = s.length() > 0 ? s.length() - 1 : 0;\n+\n+        if (endIndex > realEndIndex) {\n+            return s.substring(beginIndex);\n+        } else {\n+            return s.substring(beginIndex, endIndex);\n+        }\n+    }\n }",
    "output": "Add Strings.substring() that handles short strings"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestGetSettingsAction.java b/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestGetSettingsAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestGetSettingsAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestGetSettingsAction.java\n@@ -46,6 +46,7 @@ public RestGetSettingsAction(Settings settings, Client client, RestController co\n         super(settings, client);\n         controller.registerHandler(GET, \"/_settings\", this);\n         controller.registerHandler(GET, \"/{index}/_settings\", this);\n+        controller.registerHandler(GET, \"/{index}/{prefix}/_settings\", this);\n     }\n \n     @Override",
    "output": "Add extra rest endpoint for get settings api. Added rest test to also test the get settings' prefix option"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java b/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java\n--- a/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java\n+++ b/src/test/java/org/elasticsearch/plugin/PluginManagerTests.java\n@@ -213,6 +213,7 @@ public void testInstallSitePlugin() throws IOException {\n \n \n     private void singlePluginInstallAndRemove(String pluginShortName, String pluginCoordinates) throws IOException {\n+        logger.info(\"--> trying to download and install [{}]\", pluginShortName);\n         PluginManager pluginManager = pluginManager(pluginCoordinates);\n         try {\n             pluginManager.downloadAndExtract(pluginShortName);\n@@ -225,8 +226,12 @@ private void singlePluginInstallAndRemove(String pluginShortName, String pluginC\n             plugins = pluginManager.getListInstalledPlugins();\n             assertThat(plugins, notNullValue());\n             assertThat(plugins.length, is(0));\n+        } catch (IOException e) {\n+            logger.warn(\"--> IOException raised while downloading plugin [{}].\", e, pluginShortName);\n+            throw e;\n         } catch (ElasticsearchTimeoutException e) {\n             logger.warn(\"--> timeout exception raised while downloading plugin [{}]. Skipping test.\", pluginShortName);\n+            throw e;\n         }\n     }\n ",
    "output": "Add more traces in case of failure when testing with actual plugins (cherry picked from commit 0b2ff1e)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java b/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java\n--- a/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java\n+++ b/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java\n@@ -158,7 +158,7 @@ public void run() {\n //            monitorDeadlock();\n                 monitorLongGc();\n             } catch (Throwable t) {\n-                t.printStackTrace();\n+                logger.debug(\"failed to monitor\", t);\n             }\n         }\n ",
    "output": "Use proper logging"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchTests.java b/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchTests.java\n@@ -38,6 +38,7 @@\n import org.elasticsearch.search.highlight.HighlightBuilder.Field;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n import org.hamcrest.Matcher;\n+import org.hamcrest.Matchers;\n import org.junit.Test;\n \n import java.io.IOException;\n@@ -2554,7 +2555,7 @@ private void phraseBoostTestCase(String highlighterType) {\n \n     private <P extends QueryBuilder & BoostableQueryBuilder> void\n             phraseBoostTestCaseForClauses(String highlighterType, float boost, QueryBuilder terms, P phrase) {\n-        Matcher<String> highlightedMatcher = either(containsString(\"<em>highlight words together</em>\")).or(\n+        Matcher<String> highlightedMatcher = Matchers.<String>either(containsString(\"<em>highlight words together</em>\")).or(\n                 containsString(\"<em>highlight</em> <em>words</em> <em>together</em>\"));\n         SearchRequestBuilder search = client().prepareSearch(\"test\").setHighlighterRequireFieldMatch(true)\n                 .setHighlighterOrder(\"score\").setHighlighterType(highlighterType)",
    "output": "Fix compilation under javac 1.6"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java b/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java\n--- a/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java\n+++ b/src/main/java/org/elasticsearch/snapshots/SnapshotInfo.java\n@@ -209,8 +209,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n         if (endTime != 0) {\n             builder.field(Fields.END_TIME, DATE_TIME_FORMATTER.printer().print(endTime));\n             builder.field(Fields.END_TIME_IN_MILLIS, endTime);\n-            builder.field(Fields.DURATION, endTime - startTime);\n-            builder.field(Fields.DURATION_IN_MILLIS, TimeValue.timeValueMillis(endTime - startTime));\n+            builder.timeValueField(Fields.DURATION_IN_MILLIS, Fields.DURATION, endTime - startTime);\n         }\n         builder.startArray(Fields.FAILURES);\n         for (SnapshotShardFailure shardFailure : shardFailures) {",
    "output": "Fix mixed up duration and duration_in_millis fields in snapshot information output"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java b/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java\n--- a/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java\n+++ b/src/test/java/org/elasticsearch/test/rest/section/MatchAssertion.java\n@@ -45,12 +45,12 @@ protected void doAssert(Object actualValue, Object expectedValue) {\n         logger.trace(\"assert that [{}] matches [{}]\", actualValue, expectedValue);\n         if (!actualValue.getClass().equals(expectedValue.getClass())) {\n             if (actualValue instanceof Number && expectedValue instanceof Number) {\n-                //Double 1.0 is equals to Integer 1\n+                //Double 1.0 is equal to Integer 1\n                 assertThat(errorMessage(), ((Number) actualValue).doubleValue(), equalTo(((Number) expectedValue).doubleValue()));\n+                return;\n             }\n-        } else {\n-            assertThat(errorMessage(), actualValue, equalTo(expectedValue));\n         }\n+        assertThat(errorMessage(), actualValue, equalTo(expectedValue));\n     }\n \n     private String errorMessage() {",
    "output": "Fix match assertion that didn't run any assert with object of different types that don't extend Number"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java b/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java\n@@ -107,7 +107,7 @@ Table getTableWithHeader(final RestRequest request) {\n         table.startHeaders()\n                 .addCell(\"index\", \"default:true;desc:index name\")\n                 .addCell(\"shard\", \"default:true;desc:shard name\")\n-                .addCell(\"p/r\", \"default:true;desc:primary or replica\")\n+                .addCell(\"prirep\", \"alias:pr,primaryOrReplica;default:true;desc:primary or replica\")\n                 .addCell(\"state\", \"default:true;desc:shard state\")\n                 .addCell(\"docs\", \"text-align:right;desc:number of docs in shard\")\n                 .addCell(\"store\", \"text-align:right;desc:store size of shard (how much disk it uses)\")",
    "output": "Upgrade primaryOrReplica column"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java b/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java\n@@ -134,7 +134,7 @@ Table getTableWithHeader(final RestRequest request) {\n         table.addCell(\"primaries.store.size\", \"text-align:right;desc:store size of primaries\");\n         table.addCell(\"total.store.size\", \"text-align:right;desc:store size of primaries & replicas\");\n \n-        table.addCell(\"primaries.completion.size\", \"default:false;text-align:right;desc:size of completion\");\n+        table.addCell(\"primaries.completion.size\", \"alias:pcs,primariesCompletionSize;default:false;text-align:right;desc:size of completion\");\n \n         table.addCell(\"primaries.fielddata.memory_size\", \"default:false;text-align:right;desc:used fielddata cache\");\n         table.addCell(\"primaries.fielddata.evictions\", \"default:false;text-align:right;desc:fielddata evictions\");",
    "output": "Add alias sample"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/SegmentsStats.java b/src/main/java/org/elasticsearch/index/engine/SegmentsStats.java\n--- a/src/main/java/org/elasticsearch/index/engine/SegmentsStats.java\n+++ b/src/main/java/org/elasticsearch/index/engine/SegmentsStats.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.io.stream.Streamable;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.common.xcontent.ToXContent;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.common.xcontent.XContentBuilderString;\n@@ -68,6 +69,10 @@ public long getMemoryInBytes() {\n         return this.memoryInBytes;\n     }\n \n+    public ByteSizeValue getMemory() {\n+        return new ByteSizeValue(memoryInBytes);\n+    }\n+\n     public static SegmentsStats readSegmentsStats(StreamInput in) throws IOException {\n         SegmentsStats stats = new SegmentsStats();\n         stats.readFrom(in);",
    "output": "Add ByteSizeValue to SegmentStats"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/Table.java b/src/main/java/org/elasticsearch/common/Table.java\n--- a/src/main/java/org/elasticsearch/common/Table.java\n+++ b/src/main/java/org/elasticsearch/common/Table.java\n@@ -73,7 +73,12 @@ public Table startRow() {\n \n     public Table endRow(boolean check) {\n         if (check && (currentCells.size() != headers.size())) {\n-            throw new ElasticSearchIllegalArgumentException(\"mismatch on number of cells in a row compared to header\");\n+            StringBuilder s = new StringBuilder();\n+            s.append(\"mismatch on number of cells \");\n+            s.append(currentCells.size());\n+            s.append(\" in a row compared to header \");\n+            s.append(headers.size());\n+            throw new ElasticSearchIllegalArgumentException(s.toString());\n         }\n         rows.add(currentCells);\n         currentCells = null;",
    "output": "Add more info to table row size errors"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n@@ -82,10 +82,15 @@ public void close() throws ElasticSearchException {\n \n     @Override\n     public void clear() {\n-        for (Iterator<SimpleIdReaderCache> it = idReaders.values().iterator(); it.hasNext(); ) {\n-            SimpleIdReaderCache idReaderCache = it.next();\n-            it.remove();\n-            onRemoval(idReaderCache);\n+        // Make a copy of the live id readers...\n+        Map<Object, SimpleIdReaderCache> copy = new HashMap<Object, SimpleIdReaderCache>(idReaders);\n+        for (Map.Entry<Object, SimpleIdReaderCache> entry : copy.entrySet()) {\n+            SimpleIdReaderCache removed = idReaders.remove(entry.getKey());\n+            // ... and only if the id reader still exists in live readers we decrement stats,\n+            // this will prevent double onRemoval calls\n+            if (removed != null) {\n+                onRemoval(removed);\n+            }\n         }\n     }\n ",
    "output": "Fix SimpleIdCache#clear() to not invoke onRemoval twice, which can happen in rare cases"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/engine/robin/RobinEngineIntegrationTest.java b/src/test/java/org/elasticsearch/index/engine/robin/RobinEngineIntegrationTest.java\n--- a/src/test/java/org/elasticsearch/index/engine/robin/RobinEngineIntegrationTest.java\n+++ b/src/test/java/org/elasticsearch/index/engine/robin/RobinEngineIntegrationTest.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.index.engine.robin;\n \n import com.google.common.base.Predicate;\n+import org.apache.lucene.util.LuceneTestCase.Slow;\n import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;\n import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;\n import org.elasticsearch.action.admin.indices.segments.IndexSegments;\n@@ -47,6 +48,7 @@\n public class RobinEngineIntegrationTest extends ElasticsearchIntegrationTest {\n \n     @Test\n+    @Slow\n     public void testSettingLoadBloomFilterDefaultTrue() throws Exception {\n         Field allowRamBytesUsed = RobinEngine.class.getDeclaredField(\"allowRamBytesUsed\");\n         allowRamBytesUsed.setAccessible(true);\n@@ -90,6 +92,7 @@ public boolean apply(Object o) {\n     }\n \n     @Test\n+    @Slow\n     public void testSettingLoadBloomFilterDefaultFalse() throws Exception {\n         Field allowRamBytesUsed = RobinEngine.class.getDeclaredField(\"allowRamBytesUsed\");\n         allowRamBytesUsed.setAccessible(true);",
    "output": "Add @Slow annotation to bad apples"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java b/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java\n--- a/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java\n+++ b/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java\n@@ -154,6 +154,22 @@ public static void main(String[] args) throws Exception {\n         totalTime = System.currentTimeMillis() - start;\n         System.err.println(\"--> Perf (ARC) - no optimize_bbox \" + (totalTime / NUM_RUNS) + \"ms\");\n \n+        System.err.println(\"--> Warming up (SLOPPY_ARC)\");\n+        start = System.currentTimeMillis();\n+        for (int i = 0; i < NUM_WARM; i++) {\n+            run(client, GeoDistance.SLOPPY_ARC, \"memory\");\n+        }\n+        totalTime = System.currentTimeMillis() - start;\n+        System.err.println(\"--> Warmup (SLOPPY_ARC) \" + (totalTime / NUM_WARM) + \"ms\");\n+\n+        System.err.println(\"--> Perf (SLOPPY_ARC)\");\n+        start = System.currentTimeMillis();\n+        for (int i = 0; i < NUM_RUNS; i++) {\n+            run(client, GeoDistance.SLOPPY_ARC, \"memory\");\n+        }\n+        totalTime = System.currentTimeMillis() - start;\n+        System.err.println(\"--> Perf (SLOPPY_ARC) \" + (totalTime / NUM_RUNS) + \"ms\");\n+\n         System.err.println(\"--> Warming up (PLANE)\");\n         start = System.currentTimeMillis();\n         for (int i = 0; i < NUM_WARM; i++) {",
    "output": "Add SLOPPY_ARC to GeoDistanceSearchBenchmark"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java b/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java\n--- a/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java\n+++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java\n@@ -94,7 +94,7 @@ public RangeAggregator(String name,\n                            AggregationContext aggregationContext,\n                            Aggregator parent) {\n \n-        super(name, BucketAggregationMode.MULTI_BUCKETS, factories, ranges.size() * parent.estimatedBucketCount(), aggregationContext, parent);\n+        super(name, BucketAggregationMode.MULTI_BUCKETS, factories, ranges.size() * (parent == null ? 1 : parent.estimatedBucketCount()), aggregationContext, parent);\n         assert valuesSource != null;\n         this.valuesSource = valuesSource;\n         this.keyed = keyed;",
    "output": "Fix NPE in RangeAggregator"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/TestCluster.java b/src/test/java/org/elasticsearch/test/TestCluster.java\n--- a/src/test/java/org/elasticsearch/test/TestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/TestCluster.java\n@@ -19,6 +19,7 @@\n package org.elasticsearch.test;\n \n import com.carrotsearch.randomizedtesting.SeedUtils;\n+import com.carrotsearch.randomizedtesting.generators.RandomPicks;\n import com.google.common.base.Predicate;\n import com.google.common.base.Predicates;\n import com.google.common.collect.Collections2;\n@@ -202,7 +203,7 @@ private static Settings getRandomNodeSettings(long seed, String clusterName) {\n         } else {\n             builder.put(Transport.TransportSettings.TRANSPORT_TCP_COMPRESS, random.nextInt(10) == 0);\n         }\n-        builder.put(\"type\", CacheRecycler.Type.values()[random.nextInt(CacheRecycler.Type.values().length)]);\n+        builder.put(\"type\", RandomPicks.randomFrom(random, CacheRecycler.Type.values()));\n         return builder.build();\n     }\n ",
    "output": "Use RandomPicks to select a random array element"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/cat/AbstractCatAction.java b/src/main/java/org/elasticsearch/rest/action/cat/AbstractCatAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/cat/AbstractCatAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/cat/AbstractCatAction.java\n@@ -49,7 +49,7 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n             for (Table.Cell cell : table.getHeaders()) {\n                 // need to do left-align always, so create new cells\n                 pad(new Table.Cell(cell.value), width[0], request, out);\n-                out.append(\" \");\n+                out.append(\" | \");\n                 pad(new Table.Cell(cell.attr.containsKey(\"desc\") ? cell.attr.get(\"desc\") : \"not available\"), width[1], request, out);\n                 out.append(\"\\n\");\n             }",
    "output": "Add column separator for help output"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormatProvider.java b/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormatProvider.java\n--- a/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormatProvider.java\n+++ b/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormatProvider.java\n@@ -42,7 +42,7 @@ public BloomFilterPostingsFormatProvider(@IndexSettings Settings indexSettings,\n         this.delegate = Helper.lookup(indexSettings, postingsFormatSettings.get(\"delegate\"), postingFormatFactories);\n         this.postingsFormat = new BloomFilterPostingsFormat(\n                 delegate.get(),\n-                BloomFilter.Factory.buildFromString(indexSettings.get(\"fpp\"))\n+                BloomFilter.Factory.buildFromString(postingsFormatSettings.get(\"fpp\"))\n         );\n     }\n ",
    "output": "Fix bloom filter posting format to get the fpp from the correct settings"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java b/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n@@ -3,8 +3,8 @@\n import com.ibm.icu.text.Collator;\n import com.ibm.icu.text.RuleBasedCollator;\n import com.ibm.icu.util.ULocale;\n-import org.apache.lucene.analysis.core.KeywordTokenizer;\n import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.core.KeywordTokenizer;\n import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.elasticsearch.common.inject.Injector;\n import org.elasticsearch.common.inject.ModulesBuilder;\n@@ -290,6 +290,10 @@ private void assertCollation(TokenStream stream1, TokenStream stream2, int compa\n                 .addAttribute(CharTermAttribute.class);\n         CharTermAttribute term2 = stream2\n                 .addAttribute(CharTermAttribute.class);\n+\n+        stream1.reset();\n+        stream2.reset();\n+\n         assertThat(stream1.incrementToken(), equalTo(true));\n         assertThat(stream2.incrementToken(), equalTo(true));\n         assertThat(Integer.signum(term1.toString().compareTo(term2.toString())), equalTo(Integer.signum(comparison)));",
    "output": "Upgrade to Elasticsearch 0.90.8 / Lucene 4.6.0"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormat.java b/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormat.java\n--- a/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormat.java\n+++ b/src/main/java/org/elasticsearch/index/codec/postingsformat/BloomFilterPostingsFormat.java\n@@ -27,8 +27,6 @@\n import org.apache.lucene.util.Bits;\n import org.apache.lucene.util.BytesRef;\n import org.apache.lucene.util.IOUtils;\n-import org.apache.lucene.util.RamUsageEstimator;\n-import org.apache.lucene.util.automaton.CompiledAutomaton;\n import org.elasticsearch.common.util.BloomFilter;\n \n import java.io.IOException;\n@@ -184,10 +182,12 @@ public long getUniqueTermCount() throws IOException {\n \n         @Override\n         public long ramBytesUsed() {\n-            return RamUsageEstimator.sizeOf(this);\n+            long size = delegateFieldsProducer.ramBytesUsed();\n+            for (BloomFilter bloomFilter : bloomsByFieldName.values()) {\n+                size += bloomFilter.getSizeInBytes();\n+            }\n+            return size;\n         }\n-\n-\n     }\n     \n     public static final class BloomFilteredTerms extends FilterAtomicReader.FilterTerms {",
    "output": "Fix computation of ram bytes used in bloom filter posting format"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java b/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java\n@@ -52,9 +52,9 @@ public SameShardAllocationDecider(Settings settings) {\n \n     @Override\n     public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {\n-        for (MutableShardRouting nodeShard : node) {\n-            // we do not allow for two shards of the same shard id to exists on the same node\n-            if (nodeShard.shardId().equals(shardRouting.shardId())) {\n+        Iterable<MutableShardRouting> assignedShards = allocation.routingNodes().assignedShards(shardRouting);\n+        for (MutableShardRouting assignedShard : assignedShards) {\n+            if (node.nodeId().equals(assignedShard.currentNodeId())) {\n                 return Decision.NO;\n             }\n         }\n@@ -68,8 +68,8 @@ public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, Routing\n                     if (!checkNode.node().address().sameHost(node.node().address())) {\n                         continue;\n                     }\n-                    for (MutableShardRouting nodeShard : checkNode) {\n-                        if (nodeShard.shardId().equals(shardRouting.shardId())) {\n+                    for (MutableShardRouting assignedShard : assignedShards) {\n+                        if (checkNode.nodeId().equals(assignedShard.currentNodeId())) {\n                             return Decision.NO;\n                         }\n                     }",
    "output": "Use the computed data structure to optimize the same shard allocation decider"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java b/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java\n--- a/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java\n+++ b/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java\n@@ -81,7 +81,7 @@ private static File resolveFile(String optionalPathPrefix, String path, String o\n         URL resource = findResource(path, optionalFileSuffix);\n         if (resource == null) {\n             //try within classpath with optional prefix: /rest-spec/test (or /rest-test/api) is optional\n-            String newPath = optionalPathPrefix + File.separator + path;\n+            String newPath = optionalPathPrefix + \"/\" + path;\n             resource = findResource(newPath, optionalFileSuffix);\n             if (resource == null) {\n                 //if it wasn't on classpath we look outside ouf the classpath",
    "output": "Fix FileUtilsTests, used wrong path separator (worked only on *nix)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java b/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n@@ -302,7 +302,6 @@ public int nextDoc() throws IOException {\n                     }\n \n                     HashedBytesArray uid = idTypeCache.idByDoc(currentDocId);\n-                    currentScore = uidToScore.get(uid);\n                     if (uidToScore.containsKey(uid)) {\n                         // Can use lget b/c uidToScore is only used by one thread at the time (via CacheRecycler)\n                         currentScore = uidToScore.lget();",
    "output": "Remove unnecessary get call"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java b/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java\n@@ -121,7 +121,6 @@ protected ClusterStatsNodeResponse nodeOperation(ClusterStatsNodeRequest nodeReq\n                 continue;\n             }\n             for (IndexShard indexShard : indexService) {\n-                logger.warn(\"\" + indexShard.shardId() + \" \" + indexShard.state());\n                 if (indexShard.routingEntry().active()) {\n                     // only report on fully started shards\n                     shardsStats.add(new ShardStats(indexShard, SHARD_STATS_FLAGS));",
    "output": "Remove a left over debug log"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n@@ -1314,9 +1314,8 @@ public void testPercolatorWithHighlighting() throws Exception {\n                                         .field(\"term_vector\", \"with_positions_offsets\").endObject()\n                                     .endObject()\n                                     .endObject().endObject()\n-                    )\n-                    .execute().actionGet();\n-        } if (randomBoolean()) {\n+                    ).get();\n+        } else if (randomBoolean()) {\n             // plain hl with stored fields\n             client.admin().indices().preparePutMapping(\"test\").setType(\"type\")\n                     .setSource(\n@@ -1325,8 +1324,7 @@ public void testPercolatorWithHighlighting() throws Exception {\n                                     .startObject(\"field1\").field(\"type\", \"string\").field(\"store\", true).endObject()\n                                     .endObject()\n                                     .endObject().endObject()\n-                    )\n-                    .execute().actionGet();\n+                    ).get();\n         } else if (randomBoolean()) {\n             // positions hl\n             client.admin().indices().preparePutMapping(\"test\").setType(\"type\")\n@@ -1338,8 +1336,7 @@ public void testPercolatorWithHighlighting() throws Exception {\n                                     .endObject()\n                                     .endObject()\n                                     .endObject().endObject()\n-                    )\n-                    .execute().actionGet();\n+                    ).get();\n         }\n \n         logger.info(\"--> register a queries\");",
    "output": "Fix test bug"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java b/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java\n--- a/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java\n+++ b/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java\n@@ -93,6 +93,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n         builder.field(Fields.CURRENT, current);\n         builder.field(Fields.MEMORY_SIZE_IN_BYTES, memorySizeInBytes);\n         builder.field(Fields.MEMORY_SIZE, getMemorySize());\n+        builder.field(Fields.QUERIES, getNumQueries());\n         builder.endObject();\n         return builder;\n     }\n@@ -117,6 +118,7 @@ static final class Fields {\n         static final XContentBuilderString CURRENT = new XContentBuilderString(\"current\");\n         static final XContentBuilderString MEMORY_SIZE_IN_BYTES = new XContentBuilderString(\"memory_size_in_bytes\");\n         static final XContentBuilderString MEMORY_SIZE = new XContentBuilderString(\"memory_size\");\n+        static final XContentBuilderString QUERIES = new XContentBuilderString(\"queries\");\n     }\n \n     public static PercolateStats readPercolateStats(StreamInput in) throws IOException {",
    "output": "Add `queries` to XContent output of PercolateStats The queries stats tracked but not exposed to the Rest API"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java b/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java\n--- a/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java\n@@ -202,15 +202,15 @@ public Explanation explain(AtomicReaderContext context, int doc) throws IOExcept\n                 factor = filterExplanations.get(0).getValue();\n                 break;\n             case Max:\n-                double maxFactor = Double.NEGATIVE_INFINITY;\n+                factor = Double.NEGATIVE_INFINITY;\n                 for (int i = 0; i < filterExplanations.size(); i++) {\n-                    factor = Math.max(filterExplanations.get(i).getValue(), maxFactor);\n+                    factor = Math.max(filterExplanations.get(i).getValue(), factor);\n                 }\n                 break;\n             case Min:\n-                double minFactor = Double.POSITIVE_INFINITY;\n+                factor = Double.POSITIVE_INFINITY;\n                 for (int i = 0; i < filterExplanations.size(); i++) {\n-                    factor = Math.min(filterExplanations.get(i).getValue(), minFactor);\n+                    factor = Math.min(filterExplanations.get(i).getValue(), factor);\n                 }\n                 break;\n             case Multiply:",
    "output": "Fix bug in explain for function_score queries. The explain output for function_score queries with score_mode=max or score_mode=min was incorrect, returning instead the value of the last function. This change fixes this"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java b/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java\n--- a/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java\n+++ b/src/test/java/org/elasticsearch/benchmark/search/geo/GeoDistanceSearchBenchmark.java\n@@ -41,7 +41,7 @@ public class GeoDistanceSearchBenchmark {\n \n     public static void main(String[] args) throws Exception {\n \n-        Node node = NodeBuilder.nodeBuilder().node();\n+        Node node = NodeBuilder.nodeBuilder().clusterName(GeoDistanceSearchBenchmark.class.getSimpleName()).node();\n         Client client = node.client();\n \n         ClusterHealthResponse clusterHealthResponse = client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();",
    "output": "Use a dedicated cluster name for GeoDistanceSearchBenchmark (like we do for other benchmarks)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java b/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java\n--- a/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java\n+++ b/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java\n@@ -71,7 +71,9 @@ public AtomicReaderContext readerContext() {\n \n         public IndexSearcher searcher() {\n             if (atomicIndexSearcher == null) {\n-                atomicIndexSearcher = new IndexSearcher(readerContext);\n+                // Use the reader directly otherwise the IndexSearcher assertion will trip because it expects a top level\n+                // reader context.\n+                atomicIndexSearcher = new IndexSearcher(readerContext.reader());\n             }\n             return atomicIndexSearcher;\n         }",
    "output": "Fix test failure"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/metrics/AbstractNumericTests.java b/src/test/java/org/elasticsearch/search/aggregations/metrics/AbstractNumericTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/metrics/AbstractNumericTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/metrics/AbstractNumericTests.java\n@@ -72,7 +72,6 @@ public void init() throws Exception {\n                     .endObject()));\n         }\n         indexRandom(true, builders);\n-        ensureGreen(); // wait until we are ready to serve requests\n     }\n \n     public abstract void testEmptyAggregation() throws Exception;\n\ndiff --git a/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java b/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n@@ -61,7 +61,6 @@ public void init() throws Exception {\n         }\n         client().admin().indices().prepareFlush().execute().actionGet();\n         client().admin().indices().prepareRefresh().execute().actionGet();\n-        ensureGreen();\n     }\n \n     @Test",
    "output": "Remove ensureGreen for debugging"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java b/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java\n--- a/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java\n+++ b/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java\n@@ -217,7 +217,8 @@ public void testMatchedWithShould() throws Exception {\n         refresh();\n \n         // Execute search at least two times to load it in cache\n-        for (int i = 0; i < atLeast(2); i++) {\n+        int iter = atLeast(2);\n+        for (int i = 0; i < iter; i++) {\n             SearchResponse searchResponse = client().prepareSearch()\n                     .setQuery(\n                             boolQuery()",
    "output": "Use random number of iteration for tests Thanks @simonw for the review. Related to #4361 and #4371"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java b/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java\n--- a/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java\n+++ b/src/test/java/org/elasticsearch/search/matchedqueries/MatchedQueriesTests.java\n@@ -216,8 +216,8 @@ public void testMatchedWithShould() throws Exception {\n         client().prepareIndex(\"test\", \"type1\", \"2\").setSource(\"content\", \"consectetur adipisicing elit\").get();\n         refresh();\n \n-        // Execute search 5 times to load it in cache\n-        for (int i = 0; i < 5; i++) {\n+        // Execute search at least two times to load it in cache\n+        for (int i = 0; i < atLeast(2); i++) {\n             SearchResponse searchResponse = client().prepareSearch()\n                     .setQuery(\n                             boolQuery()",
    "output": "Use random number of iteration for tests Thanks @simonw for the review. Related to #4361 and #4371"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java b/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java\n--- a/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java\n+++ b/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java\n@@ -97,10 +97,13 @@ public final class AssertingSearcher implements Searcher {\n         private final ShardId shardId;\n         private RuntimeException firstReleaseStack;\n         private final Object lock = new Object();\n+        private final int initialRefCount;\n \n         public AssertingSearcher(Searcher searcher, ShardId shardId) {\n             this.searcher = searcher;\n             this.shardId = shardId;\n+            initialRefCount = searcher.reader().getRefCount();\n+            assert initialRefCount > 0 : \"IndexReader#getRefCount() was [\" + initialRefCount + \"] expected a value > [0] - reader is already closed\";\n             INFLIGHT_ENGINE_SEARCHERS.put(this, new RuntimeException(\"Unreleased Searcher, source [\" + searcher.source() + \"]\"));\n         }\n \n@@ -124,6 +127,10 @@ public boolean release() throws ElasticSearchException {\n                     firstReleaseStack = new RuntimeException(\"Searcher Released first here, source [\" + searcher.source() + \"]\");\n                 }\n             }\n+            final int refCount = searcher.reader().getRefCount();\n+            // this assert seems to be paranoid but given LUCENE-5362 we better add some assertions here to make sure we catch any potential\n+            // problems.\n+            assert refCount > 0 : \"IndexReader#getRefCount() was [\" + refCount + \"] expected a value > [0] - reader is already closed. Initial refCount was: [\" + initialRefCount + \"]\";\n             try {\n                 return searcher.release();\n             } catch (RuntimeException ex) {",
    "output": "Add refCount assertion due to LUCENE-5362"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -356,7 +356,7 @@ public void updateMapping(final String index, final String indexUUID, final Stri\n             insertOrder = ++refreshOrUpdateInsertOrder;\n             refreshOrUpdateQueue.add(new UpdateTask(index, indexUUID, type, mappingSource, order, nodeId, listener));\n         }\n-        clusterService.submitStateUpdateTask(\"update-mapping [\" + index + \"][\" + type + \"]\", Priority.HIGH, new ClusterStateUpdateTask() {\n+        clusterService.submitStateUpdateTask(\"update-mapping [\" + index + \"][\" + type + \"] / node [\" + nodeId + \"], order [\" + order + \"]\", Priority.HIGH, new ClusterStateUpdateTask() {\n             @Override\n             public void onFailure(String source, Throwable t) {\n                 listener.onFailure(t);",
    "output": "Add node and order to the source of update mapping"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/monitor/os/OsStats.java b/src/main/java/org/elasticsearch/monitor/os/OsStats.java\n--- a/src/main/java/org/elasticsearch/monitor/os/OsStats.java\n+++ b/src/main/java/org/elasticsearch/monitor/os/OsStats.java\n@@ -116,6 +116,7 @@ static final class Fields {\n         static final XContentBuilderString CPU = new XContentBuilderString(\"cpu\");\n         static final XContentBuilderString SYS = new XContentBuilderString(\"sys\");\n         static final XContentBuilderString USER = new XContentBuilderString(\"user\");\n+        static final XContentBuilderString USAGE = new XContentBuilderString(\"usage\");\n         static final XContentBuilderString IDLE = new XContentBuilderString(\"idle\");\n         static final XContentBuilderString STOLEN = new XContentBuilderString(\"stolen\");\n \n@@ -165,6 +166,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n             builder.field(Fields.SYS, cpu.sys());\n             builder.field(Fields.USER, cpu.user());\n             builder.field(Fields.IDLE, cpu.idle());\n+            builder.field(Fields.USAGE, cpu.user() + cpu.sys());\n             builder.field(Fields.STOLEN, cpu.stolen());\n             builder.endObject();\n         }",
    "output": "Add an `usage` key to the CPU section of OsStats.toXContent. This is just the sum of existing `sys` and `user`"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingTests.java b/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingTests.java\n--- a/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingTests.java\n+++ b/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingTests.java\n@@ -78,7 +78,7 @@ public boolean apply(Object input) {\n         assertThat(response.getCount(), equalTo((long) recCount));\n \n         logger.info(\"checking all the fields are in the mappings\");\n-        String source = client().admin().indices().prepareGetMappings(\"test\").setTypes(\"type\").get().getMappings().get(\"test\").get(\"type\").source().string();\n+        String source = client().admin().cluster().prepareState().get().getState().getMetaData().getIndices().get(\"test\").getMappings().get(\"type\").source().string();\n         for (int rec = 0; rec < recCount; rec++) {\n             assertThat(source, containsString(\"\\\"field\" + rec + \"\\\"\"));\n         }",
    "output": "Upgrade the test to use the same API as 0.90 so backports will be simpler for now"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/percolator/PercolatorService.java b/src/main/java/org/elasticsearch/percolator/PercolatorService.java\n--- a/src/main/java/org/elasticsearch/percolator/PercolatorService.java\n+++ b/src/main/java/org/elasticsearch/percolator/PercolatorService.java\n@@ -263,6 +263,8 @@ private ParsedDocument parseRequest(IndexService documentIndexService, Percolate\n                         MapperService mapperService = documentIndexService.mapperService();\n                         DocumentMapper docMapper = mapperService.documentMapperWithAutoCreate(request.documentType());\n                         doc = docMapper.parse(source(parser).type(request.documentType()).flyweight(true));\n+                        // the document parsing exists the \"doc\" object, so we need to set the new current field.\n+                        currentFieldName = parser.currentName();\n                     }\n                 } else if (token == XContentParser.Token.START_OBJECT) {\n                     SearchParseElement element = hlElements.get(currentFieldName);",
    "output": "Fix parsing bug in percolator, where everything after the `doc` object was skipped"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java b/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n@@ -36,6 +36,7 @@\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n+import org.elasticsearch.test.junit.annotations.TestLogging;\n import org.junit.Test;\n \n import java.util.concurrent.CountDownLatch;\n@@ -185,6 +186,7 @@ public void testRestartNodePercolator2() throws Exception {\n \n     @Test\n     @Slow\n+    @TestLogging(\"index.percolator:TRACE,percolator:TRACE\")\n     public void testLoadingPercolateQueriesDuringCloseAndOpen() throws Exception {\n         Settings settings = settingsBuilder()\n                 .put(super.indexSettings())",
    "output": "Add test logging"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/mapper/core/TokenCountFieldMapperTests.java b/src/test/java/org/elasticsearch/index/mapper/core/TokenCountFieldMapperTests.java\n--- a/src/test/java/org/elasticsearch/index/mapper/core/TokenCountFieldMapperTests.java\n+++ b/src/test/java/org/elasticsearch/index/mapper/core/TokenCountFieldMapperTests.java\n@@ -46,7 +46,7 @@ public void testMerge() throws IOException {\n                     .startObject(\"properties\")\n                         .startObject(\"tc\")\n                             .field(\"type\", \"token_count\")\n-                            .field(\"tokenizer\", \"keyword\")\n+                            .field(\"analyzer\", \"keyword\")\n                         .endObject()\n                     .endObject()\n                 .endObject().endObject().string();\n@@ -57,7 +57,7 @@ public void testMerge() throws IOException {\n                     .startObject(\"properties\")\n                         .startObject(\"tc\")\n                             .field(\"type\", \"token_count\")\n-                            .field(\"tokenizer\", \"standard\")\n+                            .field(\"analyzer\", \"standard\")\n                         .endObject()\n                     .endObject()\n                 .endObject().endObject().string();",
    "output": "Fix broken test"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/PercolatorTests.java\n@@ -558,7 +558,7 @@ public void testPercolateStatistics() throws Exception {\n                 .setIndices(\"test\").setDocumentType(\"type\")\n                 .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                 .execute().actionGet();\n-        assertThat(response.getMatches(), arrayWithSize(1));\n+        assertMatchCount(response, 1l);\n         assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n \n         IndicesStatsResponse indicesResponse = client().admin().indices().prepareStats(\"test\").execute().actionGet();\n@@ -579,6 +579,7 @@ public void testPercolateStatistics() throws Exception {\n                 .setIndices(\"test\").setDocumentType(\"type\")\n                 .setSource(jsonBuilder().startObject().startObject(\"doc\").field(\"field\", \"val\").endObject().endObject())\n                 .execute().actionGet();\n+        assertMatchCount(response, 1l);\n         assertThat(response.getMatches(), arrayWithSize(1));\n         assertThat(convertFromTextArray(response.getMatches(), \"test\"), arrayContaining(\"1\"));\n ",
    "output": "Use EA#assertMatchCount() over just checking the match count"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n@@ -807,7 +807,7 @@ public void script_MultiValued_WithAggregatorInherited() throws Exception {\n \n     @Test\n     public void unmapped() throws Exception {\n-        client().admin().cluster().prepareHealth(\"idx_unmapped\").setWaitForYellowStatus().execute().actionGet();\n+        client().admin().cluster().prepareHealth(\"idx_unmapped\").setWaitForGreenStatus().execute().actionGet();\n \n         SearchResponse response = client().prepareSearch(\"idx_unmapped\")\n                 .addAggregation(dateHistogram(\"histo\").field(\"date\").interval(DateHistogram.Interval.MONTH))",
    "output": "Add more wait for green status on aggs tests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/FilterTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/FilterTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/FilterTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/FilterTests.java\n@@ -82,6 +82,7 @@ public void init() throws Exception {\n                     .endObject()));\n         }\n         indexRandom(true, builders.toArray(new IndexRequestBuilder[builders.size()]));\n+        ensureGreen();\n     }\n \n     @Test\n\ndiff --git a/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java b/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n@@ -61,6 +61,7 @@ public void init() throws Exception {\n         }\n         client().admin().indices().prepareFlush().execute().actionGet();\n         client().admin().indices().prepareRefresh().execute().actionGet();\n+        ensureGreen();\n     }\n \n     @Test",
    "output": "Add more ensureGreen to aggs tests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java b/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n@@ -76,7 +76,7 @@ public void onResponse(ClusterStateResponse response) {\n \n                     // Default to pretty printing, but allow ?pretty=false to disable\n                     if (!request.hasParam(\"pretty\")) {\n-                        builder.prettyPrint();\n+                        builder.prettyPrint().lfAtEnd();\n                     }\n \n                     builder.startObject();",
    "output": "Add line feed for prettified main REST action"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java b/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n@@ -329,7 +329,6 @@ public long cost() {\n \n         private final class AvgParentScorer extends ParentScorer {\n \n-            HashedBytesArray currentUid;\n             final ObjectIntOpenHashMap<HashedBytesArray> uidToCount;\n \n             AvgParentScorer(Weight weight, IdReaderTypeCache idTypeCache, ObjectFloatOpenHashMap<HashedBytesArray> uidToScore, ObjectIntOpenHashMap<HashedBytesArray> uidToCount, DocIdSetIterator parentsIterator) {\n@@ -345,11 +344,11 @@ public int nextDoc() throws IOException {\n                         return currentDocId;\n                     }\n \n-                    currentUid = idTypeCache.idByDoc(currentDocId);\n-                    currentScore = uidToScore.get(currentUid);\n+                    HashedBytesArray uid = idTypeCache.idByDoc(currentDocId);\n+                    currentScore = uidToScore.get(uid);\n                     if (currentScore != 0) {\n                         remaining--;\n-                        currentScore /= uidToCount.get(currentUid);\n+                        currentScore /= uidToCount.get(uid);\n                         return currentDocId;\n                     }\n                 }\n@@ -366,7 +365,7 @@ public int advance(int target) throws IOException {\n                 currentScore = uidToScore.get(uid);\n                 if (currentScore != 0) {\n                     remaining--;\n-                    currentScore /= uidToCount.get(currentUid);\n+                    currentScore /= uidToCount.get(uid);\n                     return currentDocId;\n                 } else {\n                     return nextDoc();",
    "output": "Fix positive infinity bug that can occur in specific scenarios when score mode average is used"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/NestedTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/NestedTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/NestedTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/NestedTests.java\n@@ -26,9 +26,9 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.search.aggregations.bucket.histogram.Histogram;\n+import org.elasticsearch.search.aggregations.bucket.nested.Nested;\n import org.elasticsearch.search.aggregations.bucket.terms.LongTerms;\n import org.elasticsearch.search.aggregations.bucket.terms.Terms.Bucket;\n-import org.elasticsearch.search.aggregations.bucket.nested.Nested;\n import org.elasticsearch.search.aggregations.metrics.max.Max;\n import org.elasticsearch.search.aggregations.metrics.stats.Stats;\n import org.elasticsearch.test.ElasticsearchIntegrationTest;\n@@ -73,9 +73,17 @@ public void init() throws Exception {\n \n         numParents = randomIntBetween(3, 10);\n         numChildren = new int[numParents];\n+        int totalChildren = 0;\n         for (int i = 0; i < numParents; ++i) {\n-            numChildren[i] = randomInt(5);\n+            if (i == numParents - 1 && totalChildren == 0) {\n+                // we need at least one child overall\n+                numChildren[i] = randomIntBetween(1, 5);\n+            } else {\n+                numChildren[i] = randomInt(5);\n+            }\n+            totalChildren += numChildren[i];\n         }\n+        assert totalChildren > 0;\n \n         for (int i = 0; i < numParents; i++) {\n             XContentBuilder source = jsonBuilder()",
    "output": "Fix test bug: we need at least one parent to have 1 child or more"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/aggregations/bucket/MissingTests.java b/src/test/java/org/elasticsearch/search/aggregations/bucket/MissingTests.java\n--- a/src/test/java/org/elasticsearch/search/aggregations/bucket/MissingTests.java\n+++ b/src/test/java/org/elasticsearch/search/aggregations/bucket/MissingTests.java\n@@ -91,6 +91,8 @@ public void init() throws Exception {\n \n     @Test\n     public void unmapped() throws Exception {\n+        client().admin().cluster().prepareHealth(\"unmapped_idx\").setWaitForYellowStatus().execute().actionGet();\n+\n         SearchResponse response = client().prepareSearch(\"unmapped_idx\")\n                 .addAggregation(missing(\"missing_tag\").field(\"tag\"))\n                 .execute().actionGet();\n@@ -105,6 +107,8 @@ public void unmapped() throws Exception {\n \n     @Test\n     public void partiallyUnmapped() throws Exception {\n+        client().admin().cluster().prepareHealth(\"unmapped_idx\").setWaitForYellowStatus().execute().actionGet();\n+\n         SearchResponse response = client().prepareSearch(\"idx\", \"unmapped_idx\")\n                 .addAggregation(missing(\"missing_tag\").field(\"tag\"))\n                 .execute().actionGet();",
    "output": "Add a waitForGreen condition for the unmapped tests on missing agg"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java\n--- a/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java\n+++ b/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java\n@@ -901,7 +901,7 @@ private ImmutableMap<ShardId, SnapshotMetaData.ShardSnapshotStatus> shards(Snaps\n                 ShardRouting primary = indexRoutingTable.shard(i).primaryShard();\n                 if (primary == null || !primary.assignedToNode()) {\n                     //TODO: Should we bailout completely or just mark this shard as failed?\n-                    builder.put(shardId, new SnapshotMetaData.ShardSnapshotStatus(primary.currentNodeId(), State.FAILED, \"primary shard is not allocated\"));\n+                    builder.put(shardId, new SnapshotMetaData.ShardSnapshotStatus(null, State.FAILED, \"primary shard is not allocated\"));\n                 } else if (!primary.started()) {\n                     builder.put(shardId, new SnapshotMetaData.ShardSnapshotStatus(primary.currentNodeId(), State.FAILED, \"primary shard hasn't been started yet\"));\n                 } else {",
    "output": "Fix possible NPE in snapshot service if a shard doesn't have primary"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/store/MockRamDirectoryService.java b/src/test/java/org/elasticsearch/test/store/MockRamDirectoryService.java\n--- a/src/test/java/org/elasticsearch/test/store/MockRamDirectoryService.java\n+++ b/src/test/java/org/elasticsearch/test/store/MockRamDirectoryService.java\n@@ -29,13 +29,13 @@\n \n import java.io.IOException;\n \n-public class MockRamDirecorySerivce extends AbstractIndexShardComponent implements DirectoryService {\n+public class MockRamDirectoryService extends AbstractIndexShardComponent implements DirectoryService {\n \n     private final MockDirectoryHelper helper;\n     private final DirectoryService delegateService;\n \n     @Inject\n-    public MockRamDirecorySerivce(ShardId shardId, Settings indexSettings, ByteBufferCache byteBufferCache) {\n+    public MockRamDirectoryService(ShardId shardId, Settings indexSettings, ByteBufferCache byteBufferCache) {\n         super(shardId, indexSettings);\n         helper = new MockDirectoryHelper(shardId, indexSettings, logger);\n         delegateService = helper.randomRamDirecoryService(byteBufferCache);\n\ndiff --git a/src/test/java/org/elasticsearch/test/store/MockRamIndexStore.java b/src/test/java/org/elasticsearch/test/store/MockRamIndexStore.java\n--- a/src/test/java/org/elasticsearch/test/store/MockRamIndexStore.java\n+++ b/src/test/java/org/elasticsearch/test/store/MockRamIndexStore.java\n@@ -45,7 +45,7 @@ public boolean persistent() {\n \n     @Override\n     public Class<? extends DirectoryService> shardDirectory() {\n-        return MockRamDirecorySerivce.class;\n+        return MockRamDirectoryService.class;\n     }\n \n     @Override",
    "output": "Fix typo in MockRamDirectoryService name"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/common/lucene/search/XBooleanFilterTests.java b/src/test/java/org/elasticsearch/common/lucene/search/XBooleanFilterTests.java\n--- a/src/test/java/org/elasticsearch/common/lucene/search/XBooleanFilterTests.java\n+++ b/src/test/java/org/elasticsearch/common/lucene/search/XBooleanFilterTests.java\n@@ -482,7 +482,7 @@ public void testRandom() throws IOException {\n                     rightResult.or(rightIter);\n                 }\n \n-                assertThat(leftResult.cardinality(), equalTo(leftResult.cardinality()));\n+                assertThat(leftResult.cardinality(), equalTo(rightResult.cardinality()));\n                 for (int i = 0; i < reader.maxDoc(); i++) {\n                     assertThat(errorMsg(clauses, topLevel) + \" -- failed at index \" + i, leftResult.get(i), equalTo(rightResult.get(i)));\n                 }",
    "output": "Fix small test bug"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java\n--- a/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java\n+++ b/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java\n@@ -449,7 +449,7 @@ public void onFailure(Throwable t) {\n                         mdBuilder.putCustom(SnapshotMetaData.TYPE, snapshots);\n                         return ClusterState.builder(currentState).metaData(mdBuilder).build();\n                     }\n-                    return null;\n+                    return currentState;\n                 }\n \n                 @Override",
    "output": "Fix possible NPE in snapshot/restore during node shutdown"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContent.java b/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContent.java\n--- a/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContent.java\n+++ b/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContent.java\n@@ -102,6 +102,6 @@ public XContentParser createParser(BytesReference bytes) throws IOException {\n \n     @Override\n     public XContentParser createParser(Reader reader) throws IOException {\n-        return new JsonXContentParser(jsonFactory.createJsonParser(reader));\n+        return new JsonXContentParser(jsonFactory.createParser(reader));\n     }\n }\n\ndiff --git a/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java b/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java\n--- a/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java\n+++ b/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContent.java\n@@ -100,6 +100,6 @@ public XContentParser createParser(BytesReference bytes) throws IOException {\n \n     @Override\n     public XContentParser createParser(Reader reader) throws IOException {\n-        return new JsonXContentParser(smileFactory.createJsonParser(reader));\n+        return new JsonXContentParser(smileFactory.createParser(reader));\n     }\n }",
    "output": "Remove deprecated method usage with jackson"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/blobstore/url/AbstractURLBlobContainer.java b/src/main/java/org/elasticsearch/common/blobstore/url/AbstractURLBlobContainer.java\n--- a/src/main/java/org/elasticsearch/common/blobstore/url/AbstractURLBlobContainer.java\n+++ b/src/main/java/org/elasticsearch/common/blobstore/url/AbstractURLBlobContainer.java\n@@ -96,20 +96,20 @@ public void run() {\n                 InputStream is = null;\n                 try {\n                     is = new URL(path, blobName).openStream();\n-                } catch (IOException e) {\n-                    IOUtils.closeWhileHandlingException(is);\n-                    listener.onFailure(e);\n-                    return;\n-                }\n-                try {\n                     int bytesRead;\n                     while ((bytesRead = is.read(buffer)) != -1) {\n                         listener.onPartial(buffer, 0, bytesRead);\n                     }\n-                    listener.onCompleted();\n-                } catch (IOException e) {\n+                } catch (Throwable t) {\n                     IOUtils.closeWhileHandlingException(is);\n-                    listener.onFailure(e);\n+                    listener.onFailure(t);\n+                    return;\n+                }\n+                try {\n+                    IOUtils.closeWhileHandlingException(is);\n+                    listener.onCompleted();\n+                } catch (Throwable t) {\n+                    listener.onFailure(t);\n                 }\n             }\n         });",
    "output": "Fix file handle leak in URLBlobContainer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/blobstore/fs/AbstractFsBlobContainer.java b/src/main/java/org/elasticsearch/common/blobstore/fs/AbstractFsBlobContainer.java\n--- a/src/main/java/org/elasticsearch/common/blobstore/fs/AbstractFsBlobContainer.java\n+++ b/src/main/java/org/elasticsearch/common/blobstore/fs/AbstractFsBlobContainer.java\n@@ -84,21 +84,17 @@ public void run() {\n                 FileInputStream is = null;\n                 try {\n                     is = new FileInputStream(new File(path, blobName));\n-                } catch (FileNotFoundException e) {\n-                    IOUtils.closeWhileHandlingException(is);\n-                    listener.onFailure(e);\n-                    return;\n-                }\n-                try {\n                     int bytesRead;\n                     while ((bytesRead = is.read(buffer)) != -1) {\n                         listener.onPartial(buffer, 0, bytesRead);\n                     }\n-                    listener.onCompleted();\n-                } catch (Exception e) {\n+                } catch (Throwable e) {\n                     IOUtils.closeWhileHandlingException(is);\n                     listener.onFailure(e);\n+                    return;\n                 }\n+                IOUtils.closeWhileHandlingException(is);\n+                listener.onCompleted();\n             }\n         });\n     }",
    "output": "Fix file handle leak in readBlob method of AbstractFsBlobContainer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java b/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n--- a/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n+++ b/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n@@ -190,6 +190,11 @@ public VType get(KType key) {\n             return map.get(key);\n         }\n \n+        @Override\n+        public VType getOrDefault(KType kType, VType vType) {\n+            return map.getOrDefault(kType, vType);\n+        }\n+\n         @Override\n         public int putAll(ObjectObjectAssociativeContainer<? extends KType, ? extends VType> container) {\n             return map.putAll(container);\n\ndiff --git a/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdReaderTypeCache.java b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdReaderTypeCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdReaderTypeCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdReaderTypeCache.java\n@@ -59,13 +59,7 @@ public HashedBytesArray parentIdByDoc(int docId) {\n     }\n \n     public int docById(HashedBytesArray uid) {\n-        if (idToDoc.containsKey(uid)) {\n-            // We can't use #lget() here since the idToDoc map shared across threads, so we really need a second lookup...\n-            // BTW: This method is only used via TopChildrenQuery\n-            return idToDoc.get(uid);\n-        } else {\n-            return -1;\n-        }\n+        return idToDoc.getOrDefault(uid, -1);\n     }\n \n     public HashedBytesArray idByDoc(int docId) {",
    "output": "Upgrade to hppc version 0.5.3"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n--- a/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n+++ b/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n@@ -625,7 +625,8 @@ private void applyInitializingShard(final RoutingTable routingTable, final Disco\n                 // for master to confirm a shard started message (either master failover, or a cluster event before\n                 // we managed to tell the master we started), mark us as started\n                 if (logger.isTraceEnabled()) {\n-                    logger.trace(\"[{}][{}] master [{}] marked shard as initializing, but shard has state [{}], mark shard as started\", indexShard.state());\n+                    logger.trace(\"{} master marked shard as initializing, but shard has state [{}], resending shard started\",\n+                            indexShard.shardId(), indexShard.state());\n                 }\n                 shardStateAction.shardStarted(shardRouting, indexMetaData.getUUID(),\n                         \"master \" + nodes.masterNode() + \" marked shard as initializing, but shard state is [\" + indexShard.state() + \"], mark shard as started\");",
    "output": "Fix a broken trace logging line"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/IndexStoreModule.java b/src/main/java/org/elasticsearch/index/store/IndexStoreModule.java\n--- a/src/main/java/org/elasticsearch/index/store/IndexStoreModule.java\n+++ b/src/main/java/org/elasticsearch/index/store/IndexStoreModule.java\n@@ -48,7 +48,7 @@ public IndexStoreModule(Settings settings) {\n     public Iterable<? extends Module> spawnModules() {\n         Class<? extends Module> indexStoreModule = NioFsIndexStoreModule.class;\n         // Same logic as FSDirectory#open ...\n-        if ((Constants.WINDOWS || Constants.SUN_OS)\n+        if ((Constants.WINDOWS || Constants.SUN_OS || Constants.LINUX)\n                 && Constants.JRE_IS_64BIT && MMapDirectory.UNMAP_SUPPORTED) {\n             indexStoreModule = MmapFsIndexStoreModule.class;\n         } else if (Constants.WINDOWS) {",
    "output": "Change default store impl to mmapfs on 64bit Linux"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/marvel/monitor/exporter/ESExporter.java b/src/main/java/org/elasticsearch/marvel/monitor/exporter/ESExporter.java\n--- a/src/main/java/org/elasticsearch/marvel/monitor/exporter/ESExporter.java\n+++ b/src/main/java/org/elasticsearch/marvel/monitor/exporter/ESExporter.java\n@@ -71,7 +71,7 @@ public ESExporter(Settings settings, Discovery discovery) {\n \n \n         hosts = settings.getAsArray(\"hosts\", new String[]{\"localhost:9200\"});\n-        indexPrefix = settings.get(\"index.prefix\", \"es_monitor\");\n+        indexPrefix = settings.get(\"index.prefix\", \"marvel\");\n         String indexTimeFormat = settings.get(\"index.timeformat\", \"YYYY.MM.dd\");\n         indexTimeFormatter = DateTimeFormat.forPattern(indexTimeFormat);\n ",
    "output": "Change default index prefix to marvel-"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/azure/AzureComputeServiceImpl.java b/src/main/java/org/elasticsearch/cloud/azure/AzureComputeServiceImpl.java\n--- a/src/main/java/org/elasticsearch/cloud/azure/AzureComputeServiceImpl.java\n+++ b/src/main/java/org/elasticsearch/cloud/azure/AzureComputeServiceImpl.java\n@@ -121,8 +121,7 @@ public Set<Instance> instances() {\n             return new HashSet<Instance>();\n         } else {\n             try {\n-                String SERVICE_NAME = componentSettings.get(Fields.SERVICE_NAME, settings.get(\"cloud.\" + Fields.SERVICE_NAME));\n-                InputStream stream = getXML(\"/services/hostedservices/\" + SERVICE_NAME + \"?embed-detail=true\");\n+                InputStream stream = getXML(\"/services/hostedservices/\" + service_name + \"?embed-detail=true\");\n                 Set<Instance> instances = buildInstancesFromXml(stream, port_name);\n                 if (logger.isTraceEnabled()) logger.trace(\"get instances from azure: {}\", instances);\n ",
    "output": "Fix after review: no need to ask for SERVICE_NAME twice"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzers.java b/src/main/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzers.java\n--- a/src/main/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzers.java\n+++ b/src/main/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzers.java\n@@ -84,7 +84,7 @@ protected Analyzer create(Version version) {\n         }\n     },\n \n-    DEFAULT {\n+    DEFAULT(CachingStrategy.ELASTICSEARCH){\n         @Override\n         protected Analyzer create(Version version) {\n             // by calling get analyzer we are ensuring reuse of the same STANDARD analyzer for DEFAULT!",
    "output": "Use same caching strategy for STANDARD and DEFAULT analyzer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java b/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java\n--- a/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java\n+++ b/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java\n@@ -64,6 +64,7 @@ public ClusterDynamicSettingsModule() {\n         clusterDynamicSettings.addDynamicSetting(RecoverySettings.INDICES_RECOVERY_TRANSLOG_SIZE, Validator.BYTES_SIZE);\n         clusterDynamicSettings.addDynamicSetting(RecoverySettings.INDICES_RECOVERY_COMPRESS);\n         clusterDynamicSettings.addDynamicSetting(RecoverySettings.INDICES_RECOVERY_CONCURRENT_STREAMS, Validator.POSITIVE_INTEGER);\n+        clusterDynamicSettings.addDynamicSetting(RecoverySettings.INDICES_RECOVERY_CONCURRENT_SMALL_FILE_STREAMS, Validator.POSITIVE_INTEGER);\n         clusterDynamicSettings.addDynamicSetting(RecoverySettings.INDICES_RECOVERY_MAX_BYTES_PER_SEC, Validator.BYTES_SIZE);\n         clusterDynamicSettings.addDynamicSetting(RecoverySettings.INDICES_RECOVERY_MAX_SIZE_PER_SEC, Validator.BYTES_SIZE);\n         clusterDynamicSettings.addDynamicSetting(ThreadPool.THREADPOOL_GROUP + \"*\");",
    "output": "Fix `indices.recovery.concurrent_small_file_streams` not being dynamically settable"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java b/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n--- a/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n+++ b/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n@@ -97,6 +97,21 @@ public Iterator<ObjectObjectCursor<KType, VType>> iterator() {\n         return map.iterator();\n     }\n \n+    /**\n+     * Returns a specialized view of the keys of this associated container.\n+     * The view additionally implements {@link ObjectLookupContainer}.\n+     */\n+    public ObjectLookupContainer<KType> keys() {\n+        return map.keys();\n+    }\n+\n+    /**\n+     * @return Returns a container with all values stored in this map.\n+     */\n+    public ObjectContainer<VType> values() {\n+        return map.values();\n+    }\n+\n     @Override\n     public String toString() {\n         return map.toString();",
    "output": "Add keys/values to ImmutableOpenMap"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java b/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n--- a/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n+++ b/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java\n@@ -145,12 +145,7 @@ public Builder() {\n         }\n \n         public Builder(ImmutableOpenMap<KType, VType> map) {\n-            if (map == EMPTY) {\n-                // create a new instance if this is the shared EMPTY one\n-                this.map = new ObjectObjectOpenHashMap<KType, VType>();\n-            } else {\n-                this.map = map.map.clone();\n-            }\n+            this.map = map.map.clone();\n         }\n \n         /**",
    "output": "Remove unneeded check"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/TransportPutMappingAction.java b/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/TransportPutMappingAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/TransportPutMappingAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/indices/mapping/put/TransportPutMappingAction.java\n@@ -80,10 +80,6 @@ protected ClusterBlockException checkBlock(PutMappingRequest request, ClusterSta\n \n     @Override\n     protected void masterOperation(final PutMappingRequest request, final ClusterState state, final ActionListener<PutMappingResponse> listener) throws ElasticSearchException {\n-        ClusterState clusterState = clusterService.state();\n-\n-        // update to concrete indices\n-        request.indices(clusterState.metaData().concreteIndices(request.indices()));\n \n         metaDataMappingService.putMapping(new MetaDataMappingService.PutRequest(request.indices(), request.type(), request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()), new MetaDataMappingService.Listener() {\n             @Override",
    "output": "Remove needless concreteIndices call, already called in doExecute and set to the request object"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -310,7 +310,7 @@ public void onAllNodesAcked(@Nullable Throwable t) {\n \n             @Override\n             public void onAckTimeout() {\n-                listener.onResponse(new ClusterStateUpdateResponse(true));\n+                listener.onResponse(new ClusterStateUpdateResponse(false));\n             }\n \n             @Override",
    "output": "Fix delete mapping to return acknowledged false when ack times out"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java b/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java\n--- a/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java\n@@ -297,10 +297,7 @@ protected double distance(int docId) {\n             GeoPoint other = getValue(docId, origin);\n             double distance = Math.abs(distFunction.calculate(origin.lat(), origin.lon(), other.lat(), other.lon(),\n                     DistanceUnit.METERS)) - offset;\n-            if (distance < 0.0d) {\n-                distance = 0.0d;\n-            }\n-            return distance;\n+            return Math.max(0.0d, distance);\n         }\n \n         @Override\n@@ -345,10 +342,7 @@ private final double getValue(int doc, double missing) {\n         @Override\n         protected double distance(int docId) {\n             double distance = Math.abs(getValue(docId, origin) - origin) - offset;\n-            if (distance < 0.0) {\n-                distance = 0.0;\n-            }\n-            return distance;\n+            return Math.max(0.0d, distance);\n         }\n \n         @Override",
    "output": "Use Math.max rather than an if statement"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java b/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java\n@@ -122,6 +122,7 @@ private Table buildTable(ClusterStateResponse state, NodesInfoResponse nodesInfo\n         table.addCell(\"ip\");\n         table.addCell(\"port\");\n \n+        table.addCell(\"es\");\n         table.addCell(\"jdk\");\n         table.addCell(\"diskAvail\", \"text-align:right;\");\n         table.addCell(\"heapUsed\", \"text-align:right;\");\n@@ -163,6 +164,7 @@ private Table buildTable(ClusterStateResponse state, NodesInfoResponse nodesInfo\n             table.addCell(info.getProcess().id());\n             table.addCell(((InetSocketTransportAddress) node.address()).address().getAddress().getHostAddress());\n             table.addCell(((InetSocketTransportAddress) node.address()).address().getPort());\n+            table.addCell(info.getVersion().number());\n             table.addCell(info.getJvm().version());\n             table.addCell(availableDisk < 0 ? null : ByteSizeValue.parseBytesSizeValue(new Long(availableDisk).toString()));\n             table.addCell(new ByteSizeValue(heapUsed));",
    "output": "Add ES version to _cat/nodes"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/monitor/fs/FsStats.java b/src/main/java/org/elasticsearch/monitor/fs/FsStats.java\n--- a/src/main/java/org/elasticsearch/monitor/fs/FsStats.java\n+++ b/src/main/java/org/elasticsearch/monitor/fs/FsStats.java\n@@ -86,6 +86,18 @@ public void writeTo(StreamOutput out) throws IOException {\n             out.writeDouble(diskServiceTime);\n         }\n \n+        public String getPath() {\n+            return path;\n+        }\n+\n+        public String getMount() {\n+            return mount;\n+        }\n+\n+        public String getDev() {\n+            return dev;\n+        }\n+\n         public ByteSizeValue getTotal() {\n             return new ByteSizeValue(total);\n         }",
    "output": "Add getters for fs.path, fs.mount and fs.dev in node stats api"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n--- a/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n+++ b/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n@@ -50,7 +50,6 @@\n import java.util.List;\n import java.util.Queue;\n import java.util.concurrent.*;\n-import java.util.concurrent.atomic.AtomicInteger;\n \n import static org.elasticsearch.cluster.ClusterState.newClusterStateBuilder;\n import static org.elasticsearch.common.util.concurrent.EsExecutors.daemonThreadFactory;\n@@ -315,6 +314,10 @@ public void run() {\n                 if (updateTask instanceof ProcessedClusterStateUpdateTask) {\n                     ((ProcessedClusterStateUpdateTask) updateTask).clusterStateProcessed(source, previousClusterState, newClusterState);\n                 }\n+                if (updateTask instanceof AckedClusterStateUpdateTask) {\n+                    //no need to wait for ack if nothing changed, the update can be counted as acknowledged\n+                    ((AckedClusterStateUpdateTask)updateTask).onAllNodesAcked(null);\n+                }\n                 return;\n             }\n ",
    "output": "Add ack call when the cluster state has not changed The missing call could cause a cluster state update to hang in case there is no change no apply"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java b/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java\n--- a/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java\n+++ b/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolTests.java\n@@ -24,7 +24,7 @@\n \n /**\n  */\n-@ClusterScope(scope=Scope.SUITE, numNodes=2)\n+@ClusterScope(scope=Scope.TEST, numNodes=2)\n public class SimpleThreadPoolTests extends AbstractIntegrationTest {\n \n     @Override",
    "output": "Fix test cluster scope to be able to run it multiple times if needed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/cat/RestRecoveryAction.java b/src/main/java/org/elasticsearch/rest/action/cat/RestRecoveryAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/cat/RestRecoveryAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/cat/RestRecoveryAction.java\n@@ -34,10 +34,7 @@\n import org.elasticsearch.rest.action.support.RestTable;\n \n import java.io.IOException;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.Set;\n+import java.util.*;\n \n import static org.elasticsearch.rest.RestRequest.Method.GET;\n \n@@ -137,7 +134,7 @@ public static Table buildRecoveryTable(Map<String, Long> primarySizes, Set<Shard\n             if (primarySize == null) {\n                 t.addCell(\"NaN\");\n             } else {\n-                t.addCell(String.format(\"%1.1f%%\", 100.0 * (float)replicaSize / primarySize));\n+                t.addCell(String.format(Locale.ROOT, \"%1.1f%%\", 100.0 * (float)replicaSize / primarySize));\n             }\n             t.endRow();\n         }",
    "output": "Fix String.format to use Locale.ROOT in RestRecoveryAction"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/PercolatorFacetsTests.java b/src/test/java/org/elasticsearch/percolator/PercolatorFacetsTests.java\n--- a/src/test/java/org/elasticsearch/percolator/PercolatorFacetsTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/PercolatorFacetsTests.java\n@@ -45,7 +45,7 @@ public void testFacets() throws Exception {\n         ensureGreen();\n \n         int numQueries = atLeast(250);\n-        int numUniqueQueries = randomInt(numQueries / 2);\n+        int numUniqueQueries = between(1, numQueries / 2);\n         String[] values = new String[numUniqueQueries];\n         for (int i = 0; i < values.length; i++) {\n             values[i] = \"value\" + i;",
    "output": "Use at least one query to prevent division by zero in PercolatorFacetsTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/script/mvel/MvelScriptEngineService.java b/src/main/java/org/elasticsearch/script/mvel/MvelScriptEngineService.java\n--- a/src/main/java/org/elasticsearch/script/mvel/MvelScriptEngineService.java\n+++ b/src/main/java/org/elasticsearch/script/mvel/MvelScriptEngineService.java\n@@ -54,7 +54,6 @@ public MvelScriptEngineService(Settings settings) {\n \n         parserConfiguration = new ParserConfiguration();\n         parserConfiguration.addPackageImport(\"java.util\");\n-        parserConfiguration.addPackageImport(\"gnu.trove\");\n         parserConfiguration.addPackageImport(\"org.joda\");\n         parserConfiguration.addImport(\"time\", MVEL.getStaticMethod(System.class, \"currentTimeMillis\", new Class[0]));\n         // unboxed version of Math, better performance since conversion from boxed to unboxed my mvel is not needed",
    "output": "Remove trove import from mvel script all subclasses of trove maps have been removed in 088e05b368"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java b/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n@@ -276,6 +276,7 @@ public int docID() {\n             @Override\n             public int nextDoc() throws IOException {\n                 if (remaining == 0) {\n+                    currentDocId = NO_MORE_DOCS;\n                     return NO_MORE_DOCS;\n                 }\n \n@@ -297,6 +298,7 @@ public int nextDoc() throws IOException {\n             @Override\n             public int advance(int target) throws IOException {\n                 if (remaining == 0) {\n+                    currentDocId = NO_MORE_DOCS;\n                     return NO_MORE_DOCS;\n                 }\n ",
    "output": "Fix for has_child can cause an infinite loop (100% CPU) when used in bool query"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n--- a/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n+++ b/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n@@ -990,11 +990,11 @@ public void testTermsLookupFilter() throws Exception {\n                     .endObject().endObject().endObject()));\n         assertAcked(prepareCreate(\"lookup2\").addMapping(\"type\", \n                 jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\")\n-                    .startObject(\"terms\").field(\"type\", \"string\").endObject()\n-                    .endObject().endObject().endObject()));\n+                    .startObject(\"arr\").startObject(\"properties\").startObject(\"term\").field(\"type\", \"string\")\n+                    .endObject().endObject().endObject().endObject().endObject().endObject()));\n         assertAcked(prepareCreate(\"test\").addMapping(\"type\", \n                 jsonBuilder().startObject().startObject(\"type\").startObject(\"properties\")\n-                    .startObject(\"terms\").field(\"type\", \"string\").endObject()\n+                    .startObject(\"term\").field(\"type\", \"string\").endObject()\n                     .endObject().endObject().endObject()));\n         ensureGreen();\n         client().prepareIndex(\"lookup\", \"type\", \"1\").setSource(\"terms\", new String[]{\"1\", \"3\"}).execute().actionGet();",
    "output": "Fix small typo in terms lookup tests mapping"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/tasks/RestPendingClusterTasksAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/tasks/RestPendingClusterTasksAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/tasks/RestPendingClusterTasksAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/tasks/RestPendingClusterTasksAction.java\n@@ -52,6 +52,7 @@ public void onResponse(PendingClusterTasksResponse response) {\n                     XContentBuilder builder = RestXContentBuilder.restContentBuilder(request);\n                     builder.startObject();\n                     response.toXContent(builder, request);\n+                    builder.endObject();\n                     channel.sendResponse(new XContentRestResponse(request, RestStatus.OK, builder));\n                 } catch (Throwable e) {\n                     onFailure(e);\n\ndiff --git a/src/main/java/org/elasticsearch/river/RiversService.java b/src/main/java/org/elasticsearch/river/RiversService.java\n--- a/src/main/java/org/elasticsearch/river/RiversService.java\n+++ b/src/main/java/org/elasticsearch/river/RiversService.java\n@@ -172,6 +172,7 @@ public synchronized void createRiver(RiverName riverName, Map<String, Object> se\n                 builder.field(\"name\", clusterService.localNode().name());\n                 builder.field(\"transport_address\", clusterService.localNode().address().toString());\n                 builder.endObject();\n+                builder.endObject();\n \n                 client.prepareIndex(riverIndexName, riverName.name(), \"_status\")\n                         .setConsistencyLevel(WriteConsistencyLevel.ONE)",
    "output": "Add missing builder.endObject calls"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/gateway/local/QuorumLocalGatewayTests.java b/src/test/java/org/elasticsearch/gateway/local/QuorumLocalGatewayTests.java\n--- a/src/test/java/org/elasticsearch/gateway/local/QuorumLocalGatewayTests.java\n+++ b/src/test/java/org/elasticsearch/gateway/local/QuorumLocalGatewayTests.java\n@@ -92,7 +92,7 @@ public boolean doRestart(String nodeName) {\n         assertThat(awaitBusy(new Predicate<Object>() {\n             @Override\n             public boolean apply(Object input) {\n-                ClusterStateResponse clusterStateResponse = client().admin().cluster().prepareState().setMasterNodeTimeout(\"500ms\").get();\n+                ClusterStateResponse clusterStateResponse = cluster().smartClient().admin().cluster().prepareState().setMasterNodeTimeout(\"500ms\").get();\n                 return !clusterStateResponse.getState().routingTable().index(\"test\").allPrimaryShardsActive();\n             }\n         }, 30, TimeUnit.SECONDS), equalTo(true));",
    "output": "Use smart client in busy waiting loop This test fails since we use random transport clients. Let's see if it stabelizes with a smart client in the loop and debug further if it helps"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n--- a/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n@@ -46,7 +46,6 @@ public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer) {\n     }\n \n     public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer, int positionOffsetGap) {\n-        // our named analyzer always wrap a non per field analyzer, so no need to have per field analyzer\n         super(analyzer.getReuseStrategy());\n         this.name = name;\n         this.scope = scope;",
    "output": "Remove irrelevant comment now that we pass the reuse strategy"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/shard/IndexShardState.java b/src/main/java/org/elasticsearch/index/shard/IndexShardState.java\n--- a/src/main/java/org/elasticsearch/index/shard/IndexShardState.java\n+++ b/src/main/java/org/elasticsearch/index/shard/IndexShardState.java\n@@ -32,6 +32,14 @@ public enum IndexShardState {\n     RELOCATED((byte) 4),\n     CLOSED((byte) 5);\n \n+    private static final IndexShardState[] ORDS = new IndexShardState[IndexShardState.values().length];\n+\n+    static {\n+        for (IndexShardState state : IndexShardState.values()) {\n+            ORDS[state.id()] = state;\n+        }\n+    }\n+\n     private final byte id;\n \n     IndexShardState(byte id) {\n@@ -43,17 +51,9 @@ public byte id() {\n     }\n \n     public static IndexShardState fromId(byte id) throws ElasticSearchIllegalArgumentException {\n-        if (id == 0) {\n-            return CREATED;\n-        } else if (id == 1) {\n-            return RECOVERING;\n-        } else if (id == 2) {\n-            return STARTED;\n-        } else if (id == 3) {\n-            return RELOCATED;\n-        } else if (id == 4) {\n-            return CLOSED;\n+        if (id < ORDS[0].id && id > ORDS[ORDS.length - 1].id) {\n+            throw new ElasticSearchIllegalArgumentException(\"No mapping for id [\" + id + \"]\");\n         }\n-        throw new ElasticSearchIllegalArgumentException(\"No mapping for id [\" + id + \"]\");\n+        return ORDS[id];\n     }\n }",
    "output": "Fix serialization error. POST_RECOVERY is now also serialized"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesRequest.java b/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesRequest.java\n--- a/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesRequest.java\n+++ b/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesRequest.java\n@@ -90,7 +90,7 @@ public void writeTo(StreamOutput out) throws IOException {\n         if (out.getVersion().onOrAfter(Version.V_0_90_4)) {\n             out.writeStringArray(names);\n         } else {\n-            out.writeString(names[0]);\n+            out.writeString(names.length == 0 ? \"*\" : names[0]);\n         }\n     }\n }",
    "output": "Fix GetIndexTemlatesRequest if serialized with includeAll and a old ES version"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/search/Queries.java b/src/main/java/org/elasticsearch/common/lucene/search/Queries.java\n--- a/src/main/java/org/elasticsearch/common/lucene/search/Queries.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/search/Queries.java\n@@ -37,8 +37,6 @@ public class Queries {\n      * In this case the instance is immutable so that's ok.*/\n     public final static Query NO_MATCH_QUERY = MatchNoDocsQuery.INSTANCE;\n \n-    private static final Filter MATCH_ALL_DOCS_FILTER = new MatchAllDocsFilter();\n-\n     /**\n      * A match all docs filter. Note, requires no caching!.\n      */\n@@ -49,7 +47,7 @@ public static Query newMatchAllQuery() {\n         // We don't use MatchAllDocsQuery, its slower than the one below ... (much slower)\n         // NEVER cache this XConstantScore Query it's not immutable and based on #3521\n         // some code might set a boost on this query.\n-        return new XConstantScoreQuery(MATCH_ALL_DOCS_FILTER);\n+        return new XConstantScoreQuery(MATCH_ALL_FILTER);\n     }\n \n     /**",
    "output": "Use the already used constant for match no filter"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/StopTokenFilterTests.java b/src/test/java/org/elasticsearch/index/analysis/StopTokenFilterTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/StopTokenFilterTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/StopTokenFilterTests.java\n@@ -70,7 +70,7 @@ public void testCorrectPositionIncrementSetting() throws IOException {\n     }\n \n     @Test\n-    public void testDeprectedPositionIncrementSettingWithVerions() throws IOException {\n+    public void testDeprecatedPositionIncrementSettingWithVerions() throws IOException {\n         Settings settings = ImmutableSettings.settingsBuilder().put(\"index.analysis.filter.my_stop.type\", \"stop\")\n                 .put(\"index.analysis.filter.my_stop.enable_position_increments\", false).put(\"index.analysis.filter.my_stop.version\", \"4.3\")\n                 .build();",
    "output": "Fix typo - s/Deprected/Deprecated"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/util/concurrent/EsAbortPolicy.java b/src/main/java/org/elasticsearch/common/util/concurrent/EsAbortPolicy.java\n--- a/src/main/java/org/elasticsearch/common/util/concurrent/EsAbortPolicy.java\n+++ b/src/main/java/org/elasticsearch/common/util/concurrent/EsAbortPolicy.java\n@@ -49,7 +49,16 @@ public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {\n             }\n         }\n         rejected.inc();\n-        throw new EsRejectedExecutionException(\"rejected execution of [\" + r.getClass().getName() + \"]\");\n+        StringBuilder sb = new StringBuilder(\"rejected execution \");\n+        if (executor.isShutdown()) {\n+            sb.append(\"(shutting down) \");\n+        } else {\n+            if (executor.getQueue() instanceof SizeBlockingQueue) {\n+                sb.append(\"(queue capacity \").append(((SizeBlockingQueue) executor.getQueue()).capacity()).append(\") \");\n+            }\n+        }\n+        sb.append(\"on \").append(r.toString());\n+        throw new EsRejectedExecutionException(sb.toString());\n     }\n \n     @Override\n\ndiff --git a/src/main/java/org/elasticsearch/common/util/concurrent/SizeBlockingQueue.java b/src/main/java/org/elasticsearch/common/util/concurrent/SizeBlockingQueue.java\n--- a/src/main/java/org/elasticsearch/common/util/concurrent/SizeBlockingQueue.java\n+++ b/src/main/java/org/elasticsearch/common/util/concurrent/SizeBlockingQueue.java\n@@ -51,6 +51,10 @@ public int size() {\n         return size.get();\n     }\n \n+    public int capacity() {\n+        return this.capacity;\n+    }\n+\n     @Override\n     public Iterator<E> iterator() {\n         final Iterator<E> it = queue.iterator();",
    "output": "Improve thread pool rejection message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/enterprise/monitor/exporter/ESExporter.java b/src/main/java/org/elasticsearch/enterprise/monitor/exporter/ESExporter.java\n--- a/src/main/java/org/elasticsearch/enterprise/monitor/exporter/ESExporter.java\n+++ b/src/main/java/org/elasticsearch/enterprise/monitor/exporter/ESExporter.java\n@@ -20,6 +20,7 @@\n import org.elasticsearch.common.logging.ESLoggerFactory;\n import org.elasticsearch.common.network.NetworkUtils;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.transport.InetSocketTransportAddress;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.xcontent.ToXContent;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n@@ -272,6 +273,14 @@ private void addNodeInfo(XContentBuilder builder) throws IOException {\n         builder.field(\"name\", node.name());\n         builder.field(\"transport_address\", node.address());\n \n+        if (node.address().uniqueAddressTypeId() == 1) { // InetSocket\n+            InetSocketTransportAddress address = (InetSocketTransportAddress) node.address();\n+            InetAddress inetAddress = address.address().getAddress();\n+            if (inetAddress != null) {\n+                builder.field(\"ip\", inetAddress.getHostAddress());\n+            }\n+        }\n+\n         if (hostname != null) {\n             builder.field(\"hostname\", hostname);\n         }",
    "output": "Add IP to node description"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsTests.java b/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsTests.java\n--- a/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsTests.java\n+++ b/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsTests.java\n@@ -116,9 +116,10 @@ public void testRandomExceptions() throws IOException, InterruptedException, Exe\n             } catch (ElasticSearchException ex) {\n             }\n         }\n+        logger.info(\"Start Refresh\");\n         RefreshResponse refreshResponse = client().admin().indices().prepareRefresh(\"test\").execute().get(); // don't assert on failures here\n         final boolean refreshFailed = refreshResponse.getShardFailures().length != 0 || refreshResponse.getFailedShards() != 0;\n-        logger.info(\"Refresh failed [{}]\", refreshFailed);\n+        logger.info(\"Refresh failed [{}] numShardsFailed: [{}], shardFailuresLength: [{}], successfulShards: [{}], totalShards: [{}] \", refreshFailed, refreshResponse.getFailedShards(), refreshResponse.getShardFailures().length, refreshResponse.getSuccessfulShards(), refreshResponse.getTotalShards());\n \n         final int numSearches = atLeast(10);\n         // we don't check anything here really just making sure we don't leave any open files or a broken index behind.",
    "output": "Add more debug info to testcase"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java b/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java\n--- a/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java\n+++ b/src/test/java/org/elasticsearch/indices/mapping/SimpleDeleteMappingTests.java\n@@ -51,6 +51,11 @@ public void simpleDeleteMapping() throws Exception {\n         }\n \n         ClusterState clusterState = client().admin().cluster().prepareState().execute().actionGet().getState();\n+        if (!clusterState.metaData().index(\"test\").mappings().containsKey(\"type1\")) {\n+            logger.info(\"mapping of type [{}] is not in the clusterstate version: [{}] localNode: [{}] nodes: [{}]\", \"type1\", \n+                    clusterState.version(), clusterState.nodes().localNode(), clusterState.nodes().dataNodes().values());\n+            logger.info(\"Current mappings in clusterstate: [{}]\", clusterState.metaData().index(\"test\").mappings().keySet());\n+        }\n         assertThat(clusterState.metaData().index(\"test\").mappings().containsKey(\"type1\"), equalTo(true));\n         GetMappingsResponse mappingsResponse = client().admin().indices().prepareGetMappings(\"test\").setTypes(\"type1\").execute().actionGet();\n         assertThat(mappingsResponse.getMappings().get(\"test\").get(\"type1\"), notNullValue());",
    "output": "Add more debug info to SimpleDeleteMappingTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java b/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java\n--- a/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java\n+++ b/src/test/java/org/elasticsearch/test/engine/MockRobinEngine.java\n@@ -64,7 +64,7 @@ public MockRobinEngine(ShardId shardId, @IndexSettings Settings indexSettings, T\n         super(shardId, indexSettings, threadPool, indexSettingsService, indexingService, warmer, store,\n                 deletionPolicy, translog, mergePolicyProvider, mergeScheduler, analysisService, similarityService, codecService);\n         final long seed = indexSettings.getAsLong(AbstractIntegrationTest.INDEX_SEED_SETTING, 0l);\n-        if (logger.isTraceEnabled()){\n+        if (logger.isTraceEnabled()) {\n             logger.trace(\"Using [{}] for shard [{}] seed: [{}]\", this.getClass().getName(), shardId, seed);\n         }\n         random = new Random(seed);\n@@ -112,11 +112,13 @@ public String source() {\n         @Override\n         public boolean release() throws ElasticSearchException {\n             RuntimeException remove = INFLIGHT_ENGINE_SEARCHERS.remove(this);\n-            synchronized (lock) { \n+            synchronized (lock) {\n                 // make sure we only get this once and store the stack of the first caller!\n                 if (remove == null) {\n                     assert firstReleaseStack != null;\n-                    throw new AssertionError(\"Released Searcher more than once, source [\" + searcher.source() + \"]\", firstReleaseStack);\n+                    AssertionError error = new AssertionError(\"Released Searcher more than once, source [\" + searcher.source() + \"]\");\n+                    error.initCause(firstReleaseStack);\n+                    throw error;\n                 } else {\n                     assert firstReleaseStack == null;\n                     firstReleaseStack = new RuntimeException(\"Searcher Released first here, source [\" + searcher.source() + \"]\");",
    "output": "Fix to compile under 1.6"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n--- a/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n@@ -21,6 +21,8 @@\n \n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.analysis.CustomAnalyzerWrapper;\n+import org.apache.lucene.util.Version;\n+import org.elasticsearch.common.lucene.Lucene;\n \n /**\n  * Named analyzer is an analyzer wrapper around an actual analyzer ({@link #analyzer} that is associated\n@@ -45,6 +47,12 @@ public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer) {\n         this(name, scope, analyzer, Integer.MIN_VALUE);\n     }\n \n+\n+    static {\n+        // LUCENE MONITOR: this should be in Lucene 4.5.\n+        assert Lucene.VERSION == Version.LUCENE_44 : \"when upgrading to 4.5, we should use call analyzer#getReuseStrategy(), see https://issues.apache.org/jira/browse/LUCENE-5170\";\n+    }\n+\n     public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer, int positionOffsetGap) {\n         // our named analyzer always wrap a non per field analyzer, so no need to have per field analyzer\n         super(new GlobalReuseStrategy());",
    "output": "Add assert to make sure we fix NamedAnalyzer when upgrading to Lucene 4.5"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java b/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java\n--- a/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java\n+++ b/src/test/java/org/elasticsearch/search/basic/SearchWhileRelocatingTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.search.basic;\n \n+import org.apache.lucene.util.LuceneTestCase;\n import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.action.index.IndexRequestBuilder;\n import org.elasticsearch.action.search.SearchResponse;\n@@ -40,6 +41,9 @@\n \n public class SearchWhileRelocatingTests extends AbstractIntegrationTest {\n \n+    @LuceneTestCase.AwaitsFix(bugUrl = \"problem with search searching on 1 shard (no replica), \" +\n+            \"and between getting the cluster state to do the search, and executing it, \" +\n+            \"the shard has fully relocated (moved from started on one node, to fully started on another node\")\n     @Test\n     public void testSearchAndRelocateConcurrently0Replicas() throws Exception {\n         testSearchAndRelocateConcurrently(0);",
    "output": "Add awaitfix on search while relocation with 0 replicas"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java b/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n--- a/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n+++ b/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n@@ -749,13 +749,13 @@ private void writeAllowed(Engine.Operation.Origin origin) throws IllegalIndexSha\n             // for primaries, we only allow to write when actually started (so the cluster has decided we started)\n             // otherwise, we need to retry, we also want to still allow to index if we are relocated in case it fails\n             if (state != IndexShardState.STARTED && state != IndexShardState.RELOCATED) {\n-                throw new IllegalIndexShardStateException(shardId, state, \"operation only allowed when started/recovering\");\n+                throw new IllegalIndexShardStateException(shardId, state, \"operation only allowed when started/recovering, origin [\" + origin + \"]\");\n             }\n         } else {\n             // for replicas, we allow to write also while recovering, since we index also during recovery to replicas\n             // and rely on version checks to make sure its consistent\n             if (state != IndexShardState.STARTED && state != IndexShardState.RELOCATED && state != IndexShardState.RECOVERING && state != IndexShardState.POST_RECOVERY) {\n-                throw new IllegalIndexShardStateException(shardId, state, \"operation only allowed when started/recovering\");\n+                throw new IllegalIndexShardStateException(shardId, state, \"operation only allowed when started/recovering, origin [\" + origin + \"]\");\n             }\n         }\n     }",
    "output": "Add origin to failure message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/single/instance/TransportInstanceSingleOperationAction.java b/src/main/java/org/elasticsearch/action/support/single/instance/TransportInstanceSingleOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/single/instance/TransportInstanceSingleOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/single/instance/TransportInstanceSingleOperationAction.java\n@@ -192,7 +192,10 @@ public void run() {\n                                 shardOperation(request, listener);\n                             } catch (Throwable e) {\n                                 if (retryOnFailure(e)) {\n-                                    retry(fromClusterEvent, null);\n+                                    operationStarted.set(false);\n+                                    // we already marked it as started when we executed it (removed the listener) so pass false\n+                                    // to re-add to the cluster listener\n+                                    retry(false, null);\n                                 } else {\n                                     listener.onFailure(e);\n                                 }",
    "output": "Upgrade Operation might hang (rarely) when retrying on invalid shard state The retry logic when failing does not reset the operation started flag"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -419,7 +419,7 @@ public void handleException(TransportException e) {\n                 return;\n             }\n \n-            HashSet<DiscoveryNode> newNodes = new HashSet<DiscoveryNode>();\n+            HashSet<DiscoveryNode> newNodes = new HashSet<DiscoveryNode>(listedNodes);\n             for (ClusterStateResponse clusterStateResponse : clusterStateResponses) {\n                 if (!ignoreClusterName && !clusterName.equals(clusterStateResponse.getClusterName())) {\n                     logger.warn(\"node {} not part of the cluster {}, ignoring...\", clusterStateResponse.getState().nodes().localNode(), clusterName);",
    "output": "Add listener nodes to nodes list if 'sniff' is true TransportClient doesn't add the initial nodes to the nodes list if it doesn't retrieve any nodes from the listeners which can cause the transport client to throw a 'NoNodeAvailableException' if the 'sniff' response didn't return any nodes. This situation can occure if the client tries to get the listener nodes cluster state while that node is not yet connected to any other nodes"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java b/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java\n--- a/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java\n+++ b/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java\n@@ -320,7 +320,7 @@ public void readFrom(StreamInput in) throws IOException {\n     @Override\n     public void writeTo(StreamOutput out) throws IOException {\n         super.writeTo(out);\n-        out.writeStringArray(indices);\n+        out.writeStringArrayNullable(indices);\n         out.writeOptionalString(documentType);\n         out.writeByte(ignoreIndices.id());\n         out.writeVInt(requests.size());\n\ndiff --git a/src/main/java/org/elasticsearch/action/percolate/MultiPercolateResponse.java b/src/main/java/org/elasticsearch/action/percolate/MultiPercolateResponse.java\n--- a/src/main/java/org/elasticsearch/action/percolate/MultiPercolateResponse.java\n+++ b/src/main/java/org/elasticsearch/action/percolate/MultiPercolateResponse.java\n@@ -144,8 +144,10 @@ public void readFrom(StreamInput in) throws IOException {\n         @Override\n         public void writeTo(StreamOutput out) throws IOException {\n             if (response != null) {\n+                out.writeBoolean(true);\n                 response.writeTo(out);\n             } else {\n+                out.writeBoolean(false);\n                 out.writeString(errorMessage);\n             }\n         }",
    "output": "Fix serialisation bug for multi percolate request and response classes. This bug manifests when running with transport client"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetMappingsAction.java b/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetMappingsAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetMappingsAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetMappingsAction.java\n@@ -57,7 +57,7 @@ protected GetMappingsResponse newResponse() {\n \n     @Override\n     protected void doMasterOperation(final GetMappingsRequest request, final ClusterState state, final ActionListener<GetMappingsResponse> listener) throws ElasticSearchException {\n-        logger.debug(\"Serving getMapping request based on version {}\", state.version());\n+        logger.trace(\"serving getMapping request based on version {}\", state.version());\n         ImmutableMap<String, ImmutableMap<String, MappingMetaData>> result = state.metaData().findMappings(\n                 request.indices(), request.types()\n         );",
    "output": "Fix log to trace"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorTests.java b/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/ConcurrentPercolatorTests.java\n@@ -41,15 +41,13 @@\n import static org.elasticsearch.index.query.QueryBuilders.boolQuery;\n import static org.elasticsearch.index.query.QueryBuilders.termQuery;\n import static org.elasticsearch.percolator.PercolatorTests.convertFromTextArray;\n-import static org.elasticsearch.test.AbstractIntegrationTest.ClusterScope;\n import static org.elasticsearch.test.hamcrest.ElasticSearchAssertions.assertNoFailures;\n import static org.hamcrest.Matchers.*;\n \n \n /**\n  *\n  */\n-@ClusterScope(numNodes = 2)\n public class ConcurrentPercolatorTests extends AbstractIntegrationTest {\n \n     @Test",
    "output": "Remove ClusterScope annotation"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java b/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n--- a/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n@@ -52,7 +52,6 @@\n import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n import static org.elasticsearch.index.query.QueryBuilders.*;\n import static org.elasticsearch.percolator.PercolatorTests.convertFromTextArray;\n-import static org.elasticsearch.percolator.TTLPercolatorTests.ensureGreen;\n import static org.elasticsearch.test.hamcrest.ElasticSearchAssertions.assertNoFailures;\n import static org.hamcrest.Matchers.*;\n \n@@ -460,4 +459,11 @@ public void run() {\n         assertThat(error.get(), nullValue());\n     }\n \n+    public static void ensureGreen(Client client) {\n+        ClusterHealthResponse actionGet = client.admin().cluster()\n+                .health(Requests.clusterHealthRequest().waitForGreenStatus().waitForEvents(Priority.LANGUID).waitForRelocatingShards(0)).actionGet();\n+        assertThat(actionGet.isTimedOut(), equalTo(false));\n+        assertThat(actionGet.getStatus(), equalTo(ClusterHealthStatus.GREEN));\n+    }\n+\n }",
    "output": "Fix compile error"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/basic/SearchWhileCreatingIndexTests.java b/src/test/java/org/elasticsearch/search/basic/SearchWhileCreatingIndexTests.java\n--- a/src/test/java/org/elasticsearch/search/basic/SearchWhileCreatingIndexTests.java\n+++ b/src/test/java/org/elasticsearch/search/basic/SearchWhileCreatingIndexTests.java\n@@ -90,6 +90,15 @@ private void searchWhileCreatingIndex(int numberOfShards, int numberOfReplicas)\n                 assertHitCount(searchResponse, 1);\n                 // now, let it go to primary or replica, though in a randomized re-creatable manner\n                 searchResponse = client().prepareSearch(\"test\").setPreference(randomAsciiOfLength(5)).setQuery(QueryBuilders.termQuery(\"field\", \"test\")).execute().actionGet();\n+                if (searchResponse.getHits().getTotalHits() != 1) {\n+                    refresh();\n+                    SearchResponse searchResponseAfterRefresh = client().prepareSearch(\"test\").setPreference(randomAsciiOfLength(5)).setQuery(QueryBuilders.termQuery(\"field\", \"test\")).execute().actionGet();\n+                    logger.info(\"hits count mismatch on any shard search failed, post explicit refresh hits are {}\", searchResponseAfterRefresh.getHits().getTotalHits());\n+                    ensureGreen();\n+                    SearchResponse searchResponseAfterGreen = client().prepareSearch(\"test\").setPreference(randomAsciiOfLength(5)).setQuery(QueryBuilders.termQuery(\"field\", \"test\")).execute().actionGet();\n+                    logger.info(\"hits count mismatch on any shard search failed, post explicit wait for green hits are {}\", searchResponseAfterGreen.getHits().getTotalHits());\n+                    assertHitCount(searchResponse, 1);\n+                }\n                 assertHitCount(searchResponse, 1);\n                 status = client().admin().cluster().prepareHealth(\"test\").get().getStatus();\n                 cluster().ensureAtLeastNumNodes(numberOfReplicas + 1);",
    "output": "Add explicit refresh post failure to test log the hits post explicit refresh, and post explicit wait for green"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java b/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n--- a/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n+++ b/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n@@ -291,8 +291,6 @@ public void testSimpleCloseOpenAcknowledged() {\n         //we now set the timeout to 0, which means not wait for acknowledgement from other nodes\n         closeIndexResponse = client().admin().indices().prepareClose(\"test1\").setTimeout(TimeValue.timeValueMillis(0)).execute().actionGet();\n         assertThat(closeIndexResponse.isAcknowledged(), equalTo(false));\n-        //the cluster state is up-to-date for sure only on the master\n-        assertIndexIsClosed(\"test1\");\n     }\n \n     private void assertIndexIsOpened(String... indices) {",
    "output": "Remove wrong assertion from OpenCloseIndexTests If a request hasn't been acknowledged, there's no guarantee for any node to hold the up-to-date cluster state (not even the master yet, as the execution is asynchronous)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java b/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n--- a/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n+++ b/src/test/java/org/elasticsearch/indices/state/OpenCloseIndexTests.java\n@@ -28,6 +28,7 @@\n import org.elasticsearch.action.support.IgnoreIndices;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n+import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.indices.IndexMissingException;\n import org.elasticsearch.junit.annotations.TestLogging;\n import org.elasticsearch.AbstractSharedClusterTest;\n@@ -286,6 +287,12 @@ public void testSimpleCloseOpenAcknowledged() {\n         OpenIndexResponse openIndexResponse = client().admin().indices().prepareOpen(\"test1\").execute().actionGet();\n         assertThat(openIndexResponse.isAcknowledged(), equalTo(true));\n         assertIndexIsOpenedOnAllNodes(\"test1\");\n+\n+        //we now set the timeout to 0, which means not wait for acknowledgement from other nodes\n+        closeIndexResponse = client().admin().indices().prepareClose(\"test1\").setTimeout(TimeValue.timeValueMillis(0)).execute().actionGet();\n+        assertThat(closeIndexResponse.isAcknowledged(), equalTo(false));\n+        //the cluster state is up-to-date for sure only on the master\n+        assertIndexIsClosed(\"test1\");\n     }\n \n     private void assertIndexIsOpened(String... indices) {",
    "output": "Add acknowledgment timeout test to OpenCloseIndexTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java b/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java\n--- a/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java\n+++ b/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java\n@@ -90,7 +90,7 @@ public SortField parse(XContentParser parser, SearchContext context) throws Exce\n                 } else if (\"normalize\".equals(currentName)) {\n                     normalizeLat = parser.booleanValue();\n                     normalizeLon = parser.booleanValue();\n-                } else if (\"mode\".equals(currentName)) {\n+                } else if (\"sort_mode\".equals(currentName) || \"sortMode\".equals(currentName) || \"mode\".equals(currentName)) {\n                     sortMode = SortMode.fromString(parser.text());\n                 } else if (\"nested_path\".equals(currentName) || \"nestedPath\".equals(currentName)) {\n                     nestedPath = parser.text();",
    "output": "Add sort_mode and sortMode parameters to _geo_distance sort. Previously it just support the \"mode\" parameter, which is inconsistent"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java b/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n--- a/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n+++ b/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n@@ -90,7 +90,7 @@ public S3Gateway(Settings settings, ThreadPool threadPool, ClusterService cluste\n         ByteSizeValue chunkSize = componentSettings.getAsBytesSize(\"chunk_size\", new ByteSizeValue(100, ByteSizeUnit.MB));\n \n         int concurrentStreams = componentSettings.getAsInt(\"concurrent_streams\", 5);\n-        this.concurrentStreamPool = EsExecutors.newScalingExecutorService(1, concurrentStreams, 5, TimeUnit.SECONDS, EsExecutors.daemonThreadFactory(settings, \"[s3_stream]\"));\n+        this.concurrentStreamPool = EsExecutors.newScaling(1, concurrentStreams, 5, TimeUnit.SECONDS, EsExecutors.daemonThreadFactory(settings, \"[s3_stream]\"));\n \n         logger.debug(\"using bucket [{}], region [{}], chunk_size [{}], concurrent_streams [{}]\", bucket, region, chunkSize, concurrentStreams);\n ",
    "output": "Upgrade to elasticsearch 0.90.4 Breaking changes in to EsExecutors was introduced in elasticsearch 0.90.4"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java b/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java\n--- a/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java\n@@ -197,7 +197,7 @@ private ScoreFunction parseGeoVariable(String fieldName, XContentParser parser,\n         XContentParser.Token token;\n         String parameterName = null;\n         GeoPoint origin = new GeoPoint();\n-        String scaleString = \"1km\";\n+        String scaleString = null;\n         String offsetString = \"0km\";\n         double decay = 0.5;\n         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n@@ -215,8 +215,8 @@ private ScoreFunction parseGeoVariable(String fieldName, XContentParser parser,\n                 throw new ElasticSearchParseException(\"Parameter \" + parameterName + \" not supported!\");\n             }\n         }\n-        if (origin == null) {\n-            throw new ElasticSearchParseException(DecayFunctionBuilder.ORIGIN + \"must be set for geo fields.\");\n+        if (origin == null || scaleString == null) {\n+            throw new ElasticSearchParseException(DecayFunctionBuilder.ORIGIN + \" and \" + DecayFunctionBuilder.SCALE + \" must be set for geo fields.\");\n         }\n         double scale = DistanceUnit.parse(scaleString, DistanceUnit.METERS, DistanceUnit.METERS);\n         double offset = DistanceUnit.parse(offsetString, DistanceUnit.METERS, DistanceUnit.METERS);",
    "output": "Remove default scale for geo fields"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n--- a/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n@@ -186,7 +186,11 @@ public MapperService(Index index, @IndexSettings Settings indexSettings, Environ\n                     \"}\";\n         }\n \n-        logger.debug(\"using dynamic[{}], default mapping: default_mapping_location[{}], loaded_from[{}] and source[{}], default percolator mapping: location[{}], loaded_from[{}] and source[{}]\", dynamic, defaultMappingLocation, defaultMappingUrl, defaultMappingSource, percolatorMappingLocation, percolatorMappingUrl, percolatorMappingSource);\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"using dynamic[{}], default mapping: default_mapping_location[{}], loaded_from[{}], default percolator mapping: location[{}], loaded_from[{}]\", dynamic, defaultMappingLocation, defaultMappingUrl, percolatorMappingLocation, percolatorMappingUrl);\n+        } else if (logger.isTraceEnabled()) {\n+            logger.trace(\"using dynamic[{}], default mapping: default_mapping_location[{}], loaded_from[{}] and source[{}], default percolator mapping: location[{}], loaded_from[{}] and source[{}]\", dynamic, defaultMappingLocation, defaultMappingUrl, defaultMappingSource, percolatorMappingLocation, percolatorMappingUrl, percolatorMappingSource);\n+        }\n     }\n \n     public void close() {",
    "output": "Improve logging the source of the default mappings should be trace logged"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java b/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java\n--- a/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java\n+++ b/src/test/java/org/elasticsearch/cluster/NoMasterNodeTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.cluster;\n \n import com.google.common.base.Predicate;\n+import org.elasticsearch.AbstractNodesTests;\n import org.elasticsearch.action.percolate.PercolateSourceBuilder;\n import org.elasticsearch.cluster.block.ClusterBlockException;\n import org.elasticsearch.common.settings.Settings;\n@@ -28,7 +29,6 @@\n import org.elasticsearch.discovery.Discovery;\n import org.elasticsearch.node.Node;\n import org.elasticsearch.rest.RestStatus;\n-import org.elasticsearch.AbstractNodesTests;\n import org.junit.After;\n import org.junit.Test;\n \n@@ -64,6 +64,7 @@ public void testNoMasterActions() throws Exception {\n         // start a second node, create an index, and then shut it down so we have no master block\n         Node node2 = startNode(\"node2\", settings);\n         node.client().admin().indices().prepareCreate(\"test\").execute().actionGet();\n+        node.client().admin().cluster().prepareHealth(\"test\").setWaitForGreenStatus().execute().actionGet();\n         node2.close();\n         awaitBusy(new Predicate<Object>() {\n             public boolean apply(Object o) {",
    "output": "Add wait for green to prevent test failure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/Strings.java b/src/main/java/org/elasticsearch/common/Strings.java\n--- a/src/main/java/org/elasticsearch/common/Strings.java\n+++ b/src/main/java/org/elasticsearch/common/Strings.java\n@@ -1042,7 +1042,7 @@ public static Set<String> splitStringToSet(final String s, final char c) {\n     }\n \n     public static String[] splitStringToArray(final CharSequence s, final char c) {\n-        if (s.length() == 0) {\n+        if (s == null || s.length() == 0) {\n             return Strings.EMPTY_ARRAY;\n         }\n         int count = 1;",
    "output": "Fix possible NPE due to #3658 change"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/search/simple/SimpleSearchTests.java b/src/test/java/org/elasticsearch/search/simple/SimpleSearchTests.java\n--- a/src/test/java/org/elasticsearch/search/simple/SimpleSearchTests.java\n+++ b/src/test/java/org/elasticsearch/search/simple/SimpleSearchTests.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.common.xcontent.XContentFactory;\n import org.elasticsearch.index.query.QueryBuilders;\n import org.elasticsearch.AbstractSharedClusterTest;\n+import org.elasticsearch.junit.annotations.TestLogging;\n import org.junit.Test;\n \n import java.util.concurrent.ExecutionException;\n@@ -143,7 +144,7 @@ public void simpleDateRangeWithUpperInclusiveDisabledTests() throws Exception {\n         assertHitCount(searchResponse, 1l);\n     }\n \n-    @Test\n+    @Test @TestLogging(\"action.search.type:TRACE,action.admin.indices.refresh:TRACE\")\n     public void simpleDateMathTests() throws Exception {\n         prepareCreate(\"test\").setSettings(ImmutableSettings.settingsBuilder()).execute().actionGet();\n         client().prepareIndex(\"test\", \"type1\", \"1\").setSource(\"field\", \"2010-01-05T02:00\").execute().actionGet();",
    "output": "Add specific log level to check which shards were refreshed and which shards we searched on"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/state/OpenCloseIndexTests.java b/src/test/java/org/elasticsearch/test/integration/indices/state/OpenCloseIndexTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/state/OpenCloseIndexTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/state/OpenCloseIndexTests.java\n@@ -252,7 +252,7 @@ public void testSimpleCloseOpenAlias() {\n         assertIndexIsOpened(\"test1\");\n     }\n \n-    @Test @TestLogging(\"org.elasticsearch.cluster.metadata:TRACE\")\n+    @Test @TestLogging(\"cluster.metadata:TRACE\")\n     public void testCloseOpenAliasMultipleIndices() {\n         Client client = client();\n         createIndex(\"test1\", \"test2\");\n\ndiff --git a/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java b/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n@@ -50,7 +50,7 @@ public class RecoveryWhileUnderLoadTests extends AbstractSharedClusterTest {\n \n     private final ESLogger logger = Loggers.getLogger(RecoveryWhileUnderLoadTests.class);\n \n-    @Test @TestLogging(\"org.elasticsearch.action.search.type:TRACE,org.elasticsearch.action.admin.indices.refresh:TRACE\")\n+    @Test @TestLogging(\"action.search.type:TRACE,action.admin.indices.refresh:TRACE\")\n     @Slow\n     public void recoverWhileUnderLoadAllocateBackupsTest() throws Exception {\n         logger.info(\"--> creating test index ...\");",
    "output": "Remove logger prefixes when using @TestLogging annotation"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/unit/transport/AbstractSimpleTransportTests.java b/src/test/java/org/elasticsearch/test/unit/transport/AbstractSimpleTransportTests.java\n--- a/src/test/java/org/elasticsearch/test/unit/transport/AbstractSimpleTransportTests.java\n+++ b/src/test/java/org/elasticsearch/test/unit/transport/AbstractSimpleTransportTests.java\n@@ -27,6 +27,7 @@\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.junit.annotations.TestLogging;\n import org.elasticsearch.test.integration.ElasticsearchTestCase;\n import org.elasticsearch.threadpool.ThreadPool;\n import org.elasticsearch.transport.*;\n@@ -440,6 +441,7 @@ public void handleException(TransportException exp) {\n     }\n \n     @Test\n+    @TestLogging(\"_root:TRACE\")\n     public void testTimeoutSendExceptionWithDelayedResponse() throws Exception {\n         serviceA.registerHandler(\"sayHelloTimeoutDelayedResponse\", new BaseTransportRequestHandler<StringMessageRequest>() {\n             @Override",
    "output": "Change logging level of testTimeoutSendExceptionWithDelayedResponse to TRACE"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/warmer/LocalGatewayIndicesWarmerTests.java b/src/test/java/org/elasticsearch/test/integration/indices/warmer/LocalGatewayIndicesWarmerTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/warmer/LocalGatewayIndicesWarmerTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/warmer/LocalGatewayIndicesWarmerTests.java\n@@ -17,7 +17,7 @@\n  * under the License.\n  */\n \n-package org.elasticsearch.test.integration.indices.wamer;\n+package org.elasticsearch.test.integration.indices.warmer;\n \n import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.cluster.ClusterState;\n\ndiff --git a/src/test/java/org/elasticsearch/test/integration/indices/warmer/SimpleIndicesWarmerTests.java b/src/test/java/org/elasticsearch/test/integration/indices/warmer/SimpleIndicesWarmerTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/warmer/SimpleIndicesWarmerTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/warmer/SimpleIndicesWarmerTests.java\n@@ -17,7 +17,7 @@\n  * under the License.\n  */\n \n-package org.elasticsearch.test.integration.indices.wamer;\n+package org.elasticsearch.test.integration.indices.warmer;\n \n import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;\n import org.elasticsearch.action.admin.indices.warmer.get.GetWarmersResponse;",
    "output": "Fix typo: renamed test wamer package to warmer"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java b/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java\n@@ -771,9 +771,10 @@ public void testEmptyShards() throws IOException, InterruptedException {\n                 .put(\"index.analysis.filter.shingler.output_unigrams\", true)).addMapping(\"type1\", mappingBuilder));\n         ensureGreen();\n \n-        index(\"text\", \"type2\", \"1\", \"foo\", \"bar\");\n-        index(\"text\", \"type2\", \"2\", \"foo\", \"bar\");\n-        index(\"text\", \"type1\", \"1\", \"name\", \"Just testing the suggestions api\");\n+        index(\"test\", \"type2\", \"1\", \"foo\", \"bar\");\n+        index(\"test\", \"type2\", \"2\", \"foo\", \"bar\");\n+        index(\"test\", \"type1\", \"1\", \"name\", \"Just testing the suggestions api\");\n+        index(\"test\", \"type1\", \"2\", \"name\", \"An other title about equal length\");\n         refresh();\n \n         SearchResponse searchResponse = client().prepareSearch()",
    "output": "Use same index name for indexing that is used for creating the index"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -113,7 +113,7 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen\n     private volatile Thread currentJoinThread;\n \n     private final AtomicBoolean initialStateSent = new AtomicBoolean();\n-    \n+\n \n     @Nullable\n     private NodeService nodeService;\n@@ -155,7 +155,7 @@ public ZenDiscovery(Settings settings, ClusterName clusterName, ThreadPool threa\n \n         transportService.registerHandler(RejoinClusterRequestHandler.ACTION, new RejoinClusterRequestHandler());\n     }\n-    \n+\n     @Override\n     public void setNodeService(@Nullable NodeService nodeService) {\n         this.nodeService = nodeService;\n@@ -889,11 +889,11 @@ public void onRefreshSettings(Settings settings) {\n             }\n         }\n     }\n-    \n+\n     private final String getNodeUUID(Settings settings) {\n         String seed = settings.get(\"discovery.id.seed\");\n         if (seed != null) {\n-            logger.warn(\"using stable discover node UUIDs with seed: [{}]\", seed);\n+            logger.trace(\"using stable discover node UUIDs with seed: [{}]\", seed);\n             Strings.randomBase64UUID(new Random(Long.parseLong(seed)));\n         }\n         return Strings.randomBase64UUID();",
    "output": "Fix logging level"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java b/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java\n@@ -113,7 +113,7 @@ protected ShardRefreshResponse newShardResponse() {\n     protected ShardRefreshResponse shardOperation(ShardRefreshRequest request) throws ElasticSearchException {\n         IndexShard indexShard = indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());\n         indexShard.refresh(new Engine.Refresh().force(request.force()));\n-        logger.debug(\"{} Refresh request executed. Force: [{}].\", indexShard.shardId(), request.force());\n+        logger.trace(\"{} refresh request executed, force: [{}]\", indexShard.shardId(), request.force());\n         return new ShardRefreshResponse(request.index(), request.shardId());\n     }\n ",
    "output": "Change to trace level logging"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java b/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java\n--- a/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java\n+++ b/src/main/java/org/elasticsearch/action/search/type/TransportSearchTypeAction.java\n@@ -404,7 +404,7 @@ final void innerMoveToSecondPhase() throws Exception {\n                     sb.append(result.shardTarget());\n                 }\n \n-                logger.debug(\"Moving to second phase, based on results from: {}\", sb);\n+                logger.debug(\"Moving to second phase, based on results from: {} (cluster state version: {})\", sb, clusterState.version());\n             }\n             moveToSecondPhase();\n         }",
    "output": "Add cluster state version to the debug logging of shards instances used in search"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/TestCluster.java b/src/test/java/org/elasticsearch/test/integration/TestCluster.java\n--- a/src/test/java/org/elasticsearch/test/integration/TestCluster.java\n+++ b/src/test/java/org/elasticsearch/test/integration/TestCluster.java\n@@ -378,7 +378,7 @@ public Set<String> nRandomNodes(int numNodes) {\n     public Client nodeClient() {\n         ensureOpen();\n         if (clientNode == null) {\n-            String name = buildNodeName();\n+            String name = \"client_\" + buildNodeName();\n             String settingsSource = getClass().getName().replace('.', '/') + \".yml\";\n             Settings finalSettings = settingsBuilder().loadFromClasspath(settingsSource).put(defaultSettings).put(\"node.client\", true).put(\"name\", name)\n                     .build();",
    "output": "Add client_ prefix to node clients created by TestCluster (client_node_#)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/rest/helper/HttpClient.java b/src/test/java/org/elasticsearch/test/integration/rest/helper/HttpClient.java\n--- a/src/test/java/org/elasticsearch/test/integration/rest/helper/HttpClient.java\n+++ b/src/test/java/org/elasticsearch/test/integration/rest/helper/HttpClient.java\n@@ -105,10 +105,12 @@ public HttpClientResponse request(String method, String path, Map<String, String\n         } catch (IOException e) {\n             InputStream errStream = urlConnection.getErrorStream();\n             String body = null;\n-            try {\n-                body = Streams.copyToString(new InputStreamReader(errStream, Charsets.UTF_8));\n-            } catch (IOException e1) {\n-                throw new ElasticSearchException(\"problem reading error stream\", e1);\n+            if (errStream != null) {\n+                try {\n+                    body = Streams.copyToString(new InputStreamReader(errStream, Charsets.UTF_8));\n+                } catch (IOException e1) {\n+                    throw new ElasticSearchException(\"problem reading error stream\", e1);\n+                }\n             }\n             return new HttpClientResponse(body, errorCode, respHeaders, e);\n         } finally {",
    "output": "Add errorStream null check in HttpClient (used for testing purpose)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java b/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java\n@@ -134,6 +134,9 @@ public TokenStream create(TokenStream tokenStream) {\n         } else if (\"possessive_english\".equalsIgnoreCase(language) || \"possessiveEnglish\".equalsIgnoreCase(language)) {\n             return new EnglishPossessiveFilter(version, tokenStream);\n         } else if (\"light_finish\".equalsIgnoreCase(language) || \"lightFinish\".equalsIgnoreCase(language)) {\n+            // leaving this for backward compatibility\n+            return new FinnishLightStemFilter(tokenStream);\n+        } else if (\"light_finnish\".equalsIgnoreCase(language) || \"lightFinnish\".equalsIgnoreCase(language)) {\n             return new FinnishLightStemFilter(tokenStream);\n         } else if (\"light_french\".equalsIgnoreCase(language) || \"lightFrench\".equalsIgnoreCase(language)) {\n             return new FrenchLightStemFilter(tokenStream);",
    "output": "Fix a typo in the config of light finnish stemmer (old last_finish is still supported for backward compatibility)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginManager.java b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -126,7 +126,7 @@ public void downloadAndExtract(String name, boolean verbose) throws IOException\n                 if (elements.length > 2) {\n                     version = elements[2];\n                 }\n-                filterZipName = userName + \"-\" + repoName;\n+                filterZipName = repoName;\n                 // the installation file should not include the userName, just the repoName\n                 name = repoName;\n                 if (name.startsWith(\"elasticsearch-\")) {\n@@ -225,13 +225,13 @@ public void downloadAndExtract(String name, boolean verbose) throws IOException\n                 if (zipEntry.isDirectory()) {\n                     continue;\n                 }\n-                String zipName = zipEntry.getName().replace('\\\\', '/');\n+                String zipEntryName = zipEntry.getName().replace('\\\\', '/');\n                 if (filterZipName != null) {\n-                    if (zipName.startsWith(filterZipName)) {\n-                        zipName = zipName.substring(zipName.indexOf('/'));\n+                    if (zipEntryName.startsWith(filterZipName)) {\n+                        zipEntryName = zipEntryName.substring(zipEntryName.indexOf('/'));\n                     }\n                 }\n-                File target = new File(extractLocation, zipName);\n+                File target = new File(extractLocation, zipEntryName);\n                 FileSystemUtils.mkdirs(target.getParentFile());\n                 Streams.copy(zipFile.getInputStream(zipEntry), new FileOutputStream(target));\n             }",
    "output": "Fix extraction of site plugins downloaded from github, so that we skip the top-level folder and we place the files directly under the _site folder"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java b/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java\n@@ -333,9 +333,16 @@ public void run() {\n                         String preference;\n                         if (node2Id == null && node3Id == null) {\n                             preference = \"_local\";\n+                        } else if (node2Id == null || node3Id == null) {\n+                            if (node2Id != null) {\n+                                preference = \"_prefer_node:\" + node2Id;\n+                            } else {\n+                                preference = \"_prefer_node:\" + node3Id;\n+                            }\n                         } else {\n                             preference = \"_prefer_node:\" + (randomBoolean() ? node2Id : node3Id);\n                         }\n+\n                         if (multiPercolate) {\n                             MultiPercolateRequestBuilder builder = client\n                                     .prepareMultiPercolate();",
    "output": "Make sure preference isn't null"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/percolate/TransportMultiPercolateAction.java b/src/main/java/org/elasticsearch/action/percolate/TransportMultiPercolateAction.java\n--- a/src/main/java/org/elasticsearch/action/percolate/TransportMultiPercolateAction.java\n+++ b/src/main/java/org/elasticsearch/action/percolate/TransportMultiPercolateAction.java\n@@ -220,6 +220,7 @@ public void onResponse(TransportShardMultiPercolateAction.Response response) {\n                 @Override\n                 @SuppressWarnings(\"unchecked\")\n                 public void onFailure(Throwable e) {\n+                    logger.debug(\"Shard multi percolate failure\", e);\n                     try {\n                         TIntArrayList slots = shardToSlots.get(shardId);\n                         for (int i = 0; i < slots.size(); i++) {",
    "output": "Add extra logging"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java b/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n@@ -294,18 +294,25 @@ public void run() {\n         logger.info(\"--> refreshing the index\");\n         refreshAndAssert();\n         logger.info(\"--> verifying indexed content\");\n-        refreshAndAssert();\n         for (int i = 0; i < 10; i++) {\n             CountResponse actionGet = client().prepareCount().setQuery(matchAllQuery()).execute().actionGet();\n             assertNoFailures(actionGet);\n             assertThat(\"iteration: \" + i + \" failed\", actionGet.getCount(), equalTo(indexCounter.get()));\n         }\n     }\n     \n-    private RefreshResponse refreshAndAssert() {\n-        RefreshResponse actionGet = client().admin().indices().prepareRefresh().execute().actionGet();\n-        assertNoFailures(actionGet);\n-        return actionGet;\n+    private void refreshAndAssert() throws InterruptedException {\n+        assertThat(awaitBusy(new Predicate<Object>() {\n+            public boolean apply(Object o) {\n+                try {\n+                    RefreshResponse actionGet = client().admin().indices().prepareRefresh().execute().actionGet();\n+                    assertNoFailures(actionGet);\n+                    return actionGet.getTotalShards() == actionGet.getSuccessfulShards();\n+                } catch (Throwable e) {\n+                    throw new RuntimeException(e);\n+                }\n+            }\n+        }, 5, TimeUnit.MINUTES), equalTo(true));\n     }\n     \n     private void waitForDocs(final long numDocs) throws InterruptedException {",
    "output": "Make sure all shards are refreshed during recovery test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n--- a/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n+++ b/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n@@ -35,6 +35,7 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.SizeValue;\n import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsAbortPolicy;\n import org.elasticsearch.common.util.concurrent.EsExecutors;\n import org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor;\n import org.elasticsearch.common.util.concurrent.XRejectedExecutionHandler;\n@@ -123,7 +124,7 @@ public ThreadPool(Settings settings, @Nullable NodeSettingsService nodeSettingsS\n         }\n         executors.put(Names.SAME, new ExecutorHolder(MoreExecutors.sameThreadExecutor(), new Info(Names.SAME, \"same\")));\n         this.executors = ImmutableMap.copyOf(executors);\n-        this.scheduler = (ScheduledThreadPoolExecutor) Executors.newScheduledThreadPool(1, EsExecutors.daemonThreadFactory(settings, \"scheduler\"));\n+        this.scheduler = new ScheduledThreadPoolExecutor(1, EsExecutors.daemonThreadFactory(settings, \"scheduler\"), new EsAbortPolicy());\n         this.scheduler.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n         this.scheduler.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n         if (nodeSettingsService != null) {",
    "output": "Use our abort policy in the scheduler thread pool"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java b/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java\n@@ -179,8 +179,6 @@ public RoutingAllocation.Result rerouteWithNoReassign(ClusterState clusterState)\n     }\n \n     private boolean reroute(RoutingAllocation allocation) {\n-        Iterable<DiscoveryNode> dataNodes = allocation.nodes().dataNodes().values();\n-\n         boolean changed = false;\n         // first, clear from the shards any node id they used to belong to that is now dead\n         changed |= deassociateDeadNodes(allocation);",
    "output": "Remove unused variable"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/operation/plain/PlainOperationRouting.java b/src/main/java/org/elasticsearch/cluster/routing/operation/plain/PlainOperationRouting.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/operation/plain/PlainOperationRouting.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/operation/plain/PlainOperationRouting.java\n@@ -130,6 +130,10 @@ public int searchShardsCount(ClusterState clusterState, String[] indices, String\n                         // we might get duplicates, but that's ok, its an estimated count? (we just want to know if its 1 or not)\n                         set.add(indexShard.shardId());\n                     }\n+                } else {\n+                    for (IndexShardRoutingTable indexShard : indexRouting) {\n+                        set.add(indexShard.shardId());\n+                    }\n                 }\n             }\n             return set.size();",
    "output": "Fix search shards count method when targeting concrete and routing-aliased indices"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -417,7 +417,11 @@ public boolean start(final boolean fromClusterEvent) throws ElasticSearchExcepti\n                             threadPool.executor(executor).execute(new Runnable() {\n                                 @Override\n                                 public void run() {\n-                                    performOnPrimary(shard.id(), fromClusterEvent, shard, clusterState);\n+                                    try {\n+                                        performOnPrimary(shard.id(), fromClusterEvent, shard, clusterState);\n+                                    } catch (Throwable t) {\n+                                        listener.onFailure(t);\n+                                    }\n                                 }\n                             });\n                         } else {",
    "output": "Add a top level try catch for threaded operations. Exception which bubbled up could cause requests to hang"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java b/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java\n--- a/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java\n+++ b/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java\n@@ -268,7 +268,7 @@ private void updateMappingOnMaster(final IndexRequest request) {\n                 return;\n             }\n             documentMapper.refreshSource();\n-\n+            logger.debug(\"Sending mapping updated to master: index [{}] type [{}]\", request.index(), request.type());\n             mappingUpdatedAction.execute(new MappingUpdatedAction.MappingUpdatedRequest(request.index(), request.type(), documentMapper.mappingSource()), new ActionListener<MappingUpdatedAction.MappingUpdatedResponse>() {\n                 @Override\n                 public void onResponse(MappingUpdatedAction.MappingUpdatedResponse mappingUpdatedResponse) {",
    "output": "Add a debug log when sending an mapping updated request to master"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/junit/listerners/ReproduceInfoPrinter.java b/src/test/java/org/elasticsearch/junit/listerners/ReproduceInfoPrinter.java\n--- a/src/test/java/org/elasticsearch/junit/listerners/ReproduceInfoPrinter.java\n+++ b/src/test/java/org/elasticsearch/junit/listerners/ReproduceInfoPrinter.java\n@@ -3,6 +3,9 @@\n import com.carrotsearch.randomizedtesting.RandomizedContext;\n import com.carrotsearch.randomizedtesting.ReproduceErrorMessageBuilder;\n import com.carrotsearch.randomizedtesting.TraceFormatting;\n+import org.elasticsearch.common.logging.ESLogger;\n+import org.elasticsearch.common.logging.Loggers;\n+import org.elasticsearch.test.integration.ElasticsearchTestCase;\n import org.junit.internal.AssumptionViolatedException;\n import org.junit.runner.Description;\n import org.junit.runner.notification.Failure;\n@@ -14,7 +17,13 @@\n  */\n public class ReproduceInfoPrinter extends RunListener {\n \n-    \n+    protected final ESLogger logger = Loggers.getLogger(ElasticsearchTestCase.class);\n+\n+    @Override\n+    public void testStarted(Description description) throws Exception {\n+        logger.info(\"Test {} started\", description.getDisplayName());\n+    }\n+\n     @Override\n     public void testFailure(Failure failure) throws Exception {\n         // Ignore assumptions.\n@@ -39,7 +48,7 @@ public void testFailure(Failure failure) throws Exception {\n             }\n             traces.formatThrowable(b, failure.getException());\n         }\n-        System.out.println(b.toString());\n+        logger.error(b.toString());\n     }\n \n     private static class MavenMessageBuilder extends ReproduceErrorMessageBuilder {",
    "output": "Add test method information to log output Often it's hard to tell which testmethods were already executed when a particualr test fails. This commit adds a log output when a new test is started to better differentiate which log output belongs to which test. This commit also moves the reproduce line to logging output to gain timestamps for the failure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n@@ -68,7 +68,7 @@ public RestSearchAction(Settings settings, Client client, RestController control\n     public void handleRequest(final RestRequest request, final RestChannel channel) {\n         SearchRequest searchRequest;\n         try {\n-            searchRequest = parseSearchRequest(request);\n+            searchRequest = RestSearchAction.parseSearchRequest(request);\n             searchRequest.listenerThreaded(false);\n             SearchOperationThreading operationThreading = SearchOperationThreading.fromString(request.param(\"operation_threading\"), null);\n             if (operationThreading != null) {\n@@ -118,7 +118,7 @@ public void onFailure(Throwable e) {\n         });\n     }\n \n-    private SearchRequest parseSearchRequest(RestRequest request) {\n+    public static SearchRequest parseSearchRequest(RestRequest request) {\n         String[] indices = RestActions.splitIndices(request.param(\"index\"));\n         SearchRequest searchRequest = new SearchRequest(indices);\n         // get the content, and put it in the body\n@@ -150,7 +150,7 @@ private SearchRequest parseSearchRequest(RestRequest request) {\n         return searchRequest;\n     }\n \n-    private SearchSourceBuilder parseSearchSource(RestRequest request) {\n+    public static SearchSourceBuilder parseSearchSource(RestRequest request) {\n         SearchSourceBuilder searchSourceBuilder = null;\n         String queryString = request.param(\"q\");\n         if (queryString != null) {",
    "output": "Make RestSearchAction#parseSearchXXX(RestRequest) public When building a plugin with a new search endpoint, you need to parse the request as a searchRequest. Methods exist in RestSearchAction class but are private. We will modify them to be public static. This applies to: * `RestSearchAction#parseSearchRequest(RestRequest)` * `RestSearchAction#parseSearchSource(RestRequest)`"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n--- a/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.index.analysis;\n \n import org.apache.lucene.analysis.Analyzer;\n-import org.apache.lucene.analysis.AnalyzerWrapper;\n import org.apache.lucene.analysis.CustomAnalyzerWrapper;\n \n /**\n@@ -49,8 +48,6 @@ public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer) {\n     public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer, int positionOffsetGap) {\n         // our named analyzer always wrap a non per field analyzer, so no need to have per field analyzer\n         super(new GlobalReuseStrategy());\n-        // TODO would be nice to pick the reuse start based on the analyzer...\n-        assert !(analyzer instanceof AnalyzerWrapper); // this is the only one in Lucene currently that uses PerFieldStrategy, make sure we don't wrap it\n         this.name = name;\n         this.scope = scope;\n         this.analyzer = analyzer;",
    "output": "Remove the assert on AnalyzerWrapper see https://issues.apache.org/jira/browse/LUCENE-5170"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java b/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java\n@@ -162,7 +162,10 @@ public Builder(String index, @Nullable Settings indexSettings, RootObjectMapper.\n                     idFieldMapper = new IdFieldMapper(fieldType);\n                 }\n             }\n+            // UID first so it will be the first stored field to load (so will benefit from \"fields: []\" early termination\n+            this.rootMappers.put(UidFieldMapper.class, new UidFieldMapper());\n             this.rootMappers.put(IdFieldMapper.class, idFieldMapper);\n+            this.rootMappers.put(RoutingFieldMapper.class, new RoutingFieldMapper());\n             // add default mappers, order is important (for example analyzer should come before the rest to set context.analyzer)\n             this.rootMappers.put(SizeFieldMapper.class, new SizeFieldMapper());\n             this.rootMappers.put(IndexFieldMapper.class, new IndexFieldMapper());\n@@ -171,10 +174,8 @@ public Builder(String index, @Nullable Settings indexSettings, RootObjectMapper.\n             this.rootMappers.put(AnalyzerMapper.class, new AnalyzerMapper());\n             this.rootMappers.put(AllFieldMapper.class, new AllFieldMapper());\n             this.rootMappers.put(BoostFieldMapper.class, new BoostFieldMapper());\n-            this.rootMappers.put(RoutingFieldMapper.class, new RoutingFieldMapper());\n             this.rootMappers.put(TimestampFieldMapper.class, new TimestampFieldMapper());\n             this.rootMappers.put(TTLFieldMapper.class, new TTLFieldMapper());\n-            this.rootMappers.put(UidFieldMapper.class, new UidFieldMapper());\n             // don't add parent field, by default its \"null\"\n         }\n ",
    "output": "Make sure we add the _uid as the first field in a doc this will improve early termination loading times, but requires potential improvements in Lucene in terms of decompression"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/unit/index/mapper/source/DefaultSourceMappingTests.java b/src/test/java/org/elasticsearch/test/unit/index/mapper/source/DefaultSourceMappingTests.java\n--- a/src/test/java/org/elasticsearch/test/unit/index/mapper/source/DefaultSourceMappingTests.java\n+++ b/src/test/java/org/elasticsearch/test/unit/index/mapper/source/DefaultSourceMappingTests.java\n@@ -137,7 +137,7 @@ public void testDefaultMappingAndNoMapping() throws Exception {\n         assertThat(mapper.type(), equalTo(\"my_type\"));\n         assertThat(mapper.sourceMapper().enabled(), equalTo(false));\n         try {\n-            mapper = MapperTestUtils.newParser().parse(null, getRandom().nextBoolean() ? null : \"\", defaultMapping);\n+            mapper = MapperTestUtils.newParser().parse(null, null, defaultMapping);\n             assertThat(mapper.type(), equalTo(\"my_type\"));\n             assertThat(mapper.sourceMapper().enabled(), equalTo(false));\n             assert false;",
    "output": "Remove random empty string from test since it triggers a different exception"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java b/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java\n--- a/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java\n@@ -242,6 +242,10 @@ private Tuple<String, Map<String, Object>> extractMapping(String type, String so\n             throw new MapperParsingException(\"failed to parse mapping definition\", e);\n         }\n \n+        if (root.keySet().size() == 0) {\n+            throw new MapperParsingException(\"malformed mapping definition: no JSON root object found\");\n+        }\n+\n         // we always assume the first and single key is the mapping type root\n         if (root.keySet().size() != 1) {\n             throw new MapperParsingException(\"mapping must have the `type` as the root object\");",
    "output": "Improve error message when the mapping document is malformed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java b/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java\n--- a/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java\n@@ -24,6 +24,8 @@\n import org.apache.lucene.search.DocIdSetIterator;\n import org.apache.lucene.search.Filter;\n import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.Version;\n+import org.elasticsearch.common.lucene.Lucene;\n \n import java.io.IOException;\n \n@@ -32,6 +34,11 @@\n  */\n public class TermFilter extends Filter {\n \n+    static {\n+        // Remove this class and TermsFilterTests when upgrading to Lucene 4.5\n+        assert Lucene.VERSION == Version.LUCENE_44;\n+    }\n+\n     private final Term term;\n \n     public TermFilter(Term term) {",
    "output": "Add Lucene upgrade reminder"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/suggest/Suggest.java b/src/main/java/org/elasticsearch/search/suggest/Suggest.java\n--- a/src/main/java/org/elasticsearch/search/suggest/Suggest.java\n+++ b/src/main/java/org/elasticsearch/search/suggest/Suggest.java\n@@ -20,6 +20,7 @@\n \n import org.apache.lucene.util.CollectionUtil;\n import org.elasticsearch.ElasticSearchException;\n+import org.elasticsearch.Version;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.io.stream.Streamable;\n@@ -547,15 +548,19 @@ protected void setScore(float score) {\n                 @Override\n                 public void readFrom(StreamInput in) throws IOException {\n                     text = in.readText();\n-                    highlighted = in.readOptionalText();\n                     score = in.readFloat();\n+                    if (in.getVersion().onOrAfter(Version.V_0_90_4)) {\n+                        highlighted = in.readOptionalText();\n+                    }\n                 }\n \n                 @Override\n                 public void writeTo(StreamOutput out) throws IOException {\n                     out.writeText(text);\n-                    out.writeOptionalText(highlighted);\n                     out.writeFloat(score);\n+                    if (out.getVersion().onOrAfter(Version.V_0_90_4)) {\n+                        out.writeOptionalText(highlighted);\n+                    }\n                 }\n \n                 @Override",
    "output": "Add binary protocol backwards compatibility for suggest highlights This change requires different request processing on the binary protocol level since it has been we provide compatibilty across minor version. Yet, the suggest feature is still experimental but we try best effort to make upgrades as seamless as possible"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/document/BulkTests.java b/src/test/java/org/elasticsearch/test/integration/document/BulkTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/document/BulkTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/document/BulkTests.java\n@@ -337,10 +337,13 @@ public void testBulkUpdate_largerVolume() throws Exception {\n         }\n     }\n \n-    //Test for https://github.com/elasticsearch/elasticsearch/issues/3444\n+    /*\n+    Test for https://github.com/elasticsearch/elasticsearch/issues/3444\n+     */\n     @Test\n     public void testBulkUpdateDocAsUpsertWithParent() throws Exception {\n         client().admin().indices().prepareCreate(\"test\")\n+                .addMapping(\"parent\", \"{\\\"parent\\\":{}}\")\n                 .addMapping(\"child\", \"{\\\"child\\\": {\\\"_parent\\\": {\\\"type\\\": \\\"parent\\\"}}}\")\n                 .execute().actionGet();\n         client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();\n@@ -372,9 +375,13 @@ public void testBulkUpdateDocAsUpsertWithParent() throws Exception {\n         assertSearchHits(searchResponse, \"child1\");\n     }\n \n+    /*\n+    Test for https://github.com/elasticsearch/elasticsearch/issues/3444\n+     */\n     @Test\n     public void testBulkUpdateUpsertWithParent() throws Exception {\n         client().admin().indices().prepareCreate(\"test\")\n+                .addMapping(\"parent\", \"{\\\"parent\\\":{}}\")\n                 .addMapping(\"child\", \"{\\\"child\\\": {\\\"_parent\\\": {\\\"type\\\": \\\"parent\\\"}}}\")\n                 .execute().actionGet();\n         client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();",
    "output": "Add explicit creation of parent type in create index"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/cluster/NoMasterNodeTests.java b/src/test/java/org/elasticsearch/test/integration/cluster/NoMasterNodeTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/cluster/NoMasterNodeTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/cluster/NoMasterNodeTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.test.integration.cluster;\n \n+import com.google.common.base.Predicate;\n import org.elasticsearch.action.percolate.PercolateSourceBuilder;\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.block.ClusterBlockException;\n@@ -60,13 +61,17 @@ public void testNoMasterActions() throws Exception {\n \n         TimeValue timeout = TimeValue.timeValueMillis(200);\n \n-        Node node = startNode(\"node1\", settings);\n+        final Node node = startNode(\"node1\", settings);\n         // start a second node, create an index, and then shut it down so we have no master block\n         Node node2 = startNode(\"node2\", settings);\n         node.client().admin().indices().prepareCreate(\"test\").execute().actionGet();\n         node2.close();\n-\n-        Thread.sleep(200);\n+        awaitBusy(new Predicate<Object>() {\n+            public boolean apply(Object o) {\n+                ClusterState state = node.client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();\n+                return state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK);\n+            }\n+        });\n \n         ClusterState state = node.client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();\n         assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK), equalTo(true));",
    "output": "Use busy sleeps in NoMasterNodeTests The busy sleep is less prone to slow tests / machines while still fails if the actual condition isn't met"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java b/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n--- a/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n+++ b/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n@@ -185,7 +185,7 @@ public void run() {\n                             }\n                             listener.onPing(responses.values().toArray(new PingResponse[responses.size()]));\n                         } catch (RejectedExecutionException ex) {\n-                            logger.info(\"Ping execution ejected\", ex);\n+                            logger.debug(\"Ping execution ejected\", ex);\n                         }\n                     }\n                 });",
    "output": "Use debug logging rather than info for rejected ping task This exception is thrown on node shutdown and doesn't indicate an critical situation but rather is caught for consistency reasons"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java b/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java\n--- a/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java\n+++ b/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java\n@@ -70,7 +70,6 @@ public static void assertSearchHits(SearchResponse searchResponse, String... ids\n     }\n \n     public static void assertHitCount(CountResponse countResponse, long expectedHitCount) {\n-        assertThat(countResponse.getCount(), is(expectedHitCount));\n         if (countResponse.getCount() != expectedHitCount) {\n             String msg = \"Count is \" + countResponse.getCount() + \" but \" + expectedHitCount + \" was expected. \" +\n                     countResponse.getFailedShards() + \" shard failures:\";",
    "output": "Remove a left over assert made redundant by last commit"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n--- a/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n+++ b/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n@@ -178,22 +178,26 @@ private void sendIndexLifecycleEvents(final ClusterChangedEvent event) {\n             try {\n                 nodeIndexCreatedAction.nodeIndexCreated(index, event.state().nodes().localNodeId());\n             } catch (Exception e) {\n-                logger.debug(\"failed to send to master index {} created event\", index);\n+                logger.debug(\"failed to send to master index {} created event\", e, index);\n             }\n         }\n         for (String index : event.indicesDeleted()) {\n             try {\n                 nodeIndexDeletedAction.nodeIndexDeleted(index, event.state().nodes().localNodeId());\n             } catch (Exception e) {\n-                logger.debug(\"failed to send to master index {} deleted event\", index);\n+                logger.debug(\"failed to send to master index {} deleted event\", e, index);\n             }\n         }\n     }\n \n     private void notifyIndicesStateChanged(final ClusterChangedEvent event) {\n         //handles open/close index notifications\n         if (event.indicesStateChanged()) {\n-            nodeIndicesStateUpdatedAction.nodeIndexStateUpdated(new NodeIndicesStateUpdatedAction.NodeIndexStateUpdatedResponse(event.state().nodes().localNodeId(), event.state().version()));\n+            try {\n+                nodeIndicesStateUpdatedAction.nodeIndexStateUpdated(new NodeIndicesStateUpdatedAction.NodeIndexStateUpdatedResponse(event.state().nodes().localNodeId(), event.state().version()));\n+            } catch (Exception e) {\n+                logger.debug(\"failed to send to master indices state change event\", e);\n+            }\n         }\n     }\n ",
    "output": "Make sure we wrap a potential failure in sending master state change in a catch"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java\n@@ -452,6 +452,8 @@ public ClusterState execute(final ClusterState currentState) throws Exception {\n                     }\n \n                     if (mappings.isEmpty()) {\n+                        // no changes, return\n+                        listener.onResponse(new Response(true));\n                         return currentState;\n                     }\n ",
    "output": "Fix hang when submitting mappings and no changes are made Added missing listener call before return"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java b/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java\n@@ -124,6 +124,7 @@ public void onResponse(MetaDataDeleteIndexService.Response response) {\n                 @Override\n                 public void onFailure(Throwable t) {\n                     logger.debug(\"[{}] failed to delete index\", t, index);\n+                    lastFailure = t;\n                     if (count.decrementAndGet() == 0) {\n                         listener.onFailure(t);\n                     }",
    "output": "Make sure we update last failure"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java b/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java\n@@ -453,9 +453,6 @@ private void testFacets(int numberOfShards) throws Exception {\n         assertThat(termsStatsFacet.getEntries().get(0).getCount(), equalTo(3l));\n         assertThat(termsStatsFacet.getEntries().get(0).getTotal(), equalTo(8d));\n \n-        // TODO: needed?\n-        refresh();\n-\n         // test scope ones (post based)\n         searchResponse = client().prepareSearch(\"test\")\n                 .setQuery(",
    "output": "Remove useless TODO"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/bulk/RestBulkAction.java b/src/main/java/org/elasticsearch/rest/action/bulk/RestBulkAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/bulk/RestBulkAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/bulk/RestBulkAction.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.action.bulk.BulkRequest;\n import org.elasticsearch.action.bulk.BulkResponse;\n import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.delete.DeleteResponse;\n import org.elasticsearch.action.support.replication.ReplicationType;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.client.Requests;\n@@ -125,6 +126,9 @@ public void onResponse(BulkResponse response) {\n                                 }\n                                 builder.endArray();\n                             }\n+                        } else if (itemResponse.getResponse() instanceof DeleteResponse) {\n+                            DeleteResponse deleteResponse = itemResponse.getResponse();\n+                            builder.field(Fields.FOUND, !deleteResponse.isNotFound());\n                         }\n                         builder.endObject();\n                         builder.endObject();\n@@ -159,6 +163,7 @@ static final class Fields {\n         static final XContentBuilderString TOOK = new XContentBuilderString(\"took\");\n         static final XContentBuilderString _VERSION = new XContentBuilderString(\"_version\");\n         static final XContentBuilderString MATCHES = new XContentBuilderString(\"matches\");\n+        static final XContentBuilderString FOUND = new XContentBuilderString(\"found\");\n     }\n \n }",
    "output": "Add found field for bulk deletes"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/termvector/TransportSingleShardTermVectorAction.java b/src/main/java/org/elasticsearch/action/termvector/TransportSingleShardTermVectorAction.java\n--- a/src/main/java/org/elasticsearch/action/termvector/TransportSingleShardTermVectorAction.java\n+++ b/src/main/java/org/elasticsearch/action/termvector/TransportSingleShardTermVectorAction.java\n@@ -108,8 +108,9 @@ protected TermVectorResponse shardOperation(TermVectorRequest request, int shard\n         try {\n             Fields topLevelFields = MultiFields.getFields(topLevelReader);\n             Versions.DocIdAndVersion docIdAndVersion = Versions.loadDocIdAndVersion(topLevelReader, uidTerm);\n-            if(docIdAndVersion!=null) {\n-                termVectorResponse.setFields(topLevelReader.getTermVectors(docIdAndVersion.docId), request.selectedFields(),\n+\n+            if (docIdAndVersion != null) {\n+                termVectorResponse.setFields(docIdAndVersion.context.reader().getTermVectors(docIdAndVersion.docId), request.selectedFields(),\n                         request.getFlags(), topLevelFields);\n                 termVectorResponse.setDocVersion(docIdAndVersion.version);\n             } else {",
    "output": "Fix term vector api retrieved wrong doc The previous loading of term vectors from the top level reader did not use the correct docId. The docId in Versions.DocIdAndVersion is relative to the segment reader in Versions.DocIdAndVersion and not to the top level reader. Consequently the term vectors for the wrong document were returned if the document was not on the first segment of the shard"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n--- a/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n+++ b/src/main/java/org/elasticsearch/action/update/UpdateRequest.java\n@@ -110,7 +110,7 @@ public ActionRequestValidationException validate() {\n             validationException = addValidationError(\"can't provide both script and doc\", validationException);\n         }\n         if (doc == null && docAsUpsert) {\n-            validationException = addValidationError(\"can't say to upsert doc without providing doc\", validationException);\n+            validationException = addValidationError(\"doc must be specified if doc_as_upsert is enabled\", validationException);\n         }\n         return validationException;\n     }",
    "output": "Change validation error message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java b/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n--- a/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n+++ b/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java\n@@ -320,7 +320,7 @@ public BulkRequest add(BytesReference data, boolean contentUnsafe, @Nullable Str\n                 }\n \n                 if (\"delete\".equals(action)) {\n-                    add(new DeleteRequest(index, type, id).parent(parent).version(version).versionType(versionType).routing(routing), payload);\n+                    add(new DeleteRequest(index, type, id).routing(routing).parent(parent).version(version).versionType(versionType), payload);\n                 } else {\n                     nextMarker = findNextMarker(marker, from, data, length);\n                     if (nextMarker == -1) {\n\ndiff --git a/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java b/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java\n@@ -58,8 +58,8 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n         deleteRequest.listenerThreaded(false);\n         deleteRequest.operationThreaded(true);\n \n-        deleteRequest.parent(request.param(\"parent\"));\n         deleteRequest.routing(request.param(\"routing\"));\n+        deleteRequest.parent(request.param(\"parent\")); // order is important, set it after routing, so it will set the routing\n         deleteRequest.timeout(request.paramAsTime(\"timeout\", DeleteRequest.DEFAULT_TIMEOUT));\n         deleteRequest.refresh(request.paramAsBoolean(\"refresh\", deleteRequest.refresh()));\n         deleteRequest.version(RestActions.parseVersion(request));",
    "output": "Fix the issue that the `parent` option was ignored for delete requests. The `parent` option was ignored in the delete api (rest only) and for delete actions in the bulk api. This bug occurred in the case that the _parent field is enabled, and only the parent option was used. This resulted in a situation that documents are deleted even if the specified parent value is incorrect"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/TermsFilterParser.java b/src/main/java/org/elasticsearch/index/query/TermsFilterParser.java\n--- a/src/main/java/org/elasticsearch/index/query/TermsFilterParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/TermsFilterParser.java\n@@ -91,7 +91,7 @@ public Filter parse(QueryParseContext parseContext) throws IOException, QueryPar\n                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                     Object value = parser.objectBytes();\n                     if (value == null) {\n-                        throw new QueryParsingException(parseContext.index(), \"No value specified for term filter\");\n+                        throw new QueryParsingException(parseContext.index(), \"No value specified for terms filter\");\n                     }\n                     terms.add(value);\n                 }",
    "output": "Fix an error message on the terms filter"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/CustomScoreQueryParser.java b/src/main/java/org/elasticsearch/index/query/CustomScoreQueryParser.java\n--- a/src/main/java/org/elasticsearch/index/query/CustomScoreQueryParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/CustomScoreQueryParser.java\n@@ -20,12 +20,12 @@\n package org.elasticsearch.index.query;\n \n import org.apache.lucene.index.AtomicReaderContext;\n-import org.apache.lucene.search.ConstantScoreQuery;\n import org.apache.lucene.search.Explanation;\n import org.apache.lucene.search.Filter;\n import org.apache.lucene.search.Query;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.lucene.search.XConstantScoreQuery;\n import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;\n import org.elasticsearch.common.lucene.search.function.ScoreFunction;\n import org.elasticsearch.common.xcontent.XContentParser;\n@@ -101,7 +101,7 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n         if (query == null && filter == null) {\n             return null;\n         } else if (filter != null) {\n-            query = new ConstantScoreQuery(filter);\n+            query = new XConstantScoreQuery(filter);\n         }\n \n         SearchScript searchScript;",
    "output": "Use XConstantScoreQuery instead of ConstantScoreQuery. Relates to"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java b/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java\n--- a/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java\n+++ b/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java\n@@ -129,6 +129,7 @@ private ParsedDocument testParsedDocument(String uid, String id, String type, St\n         Field uidField = new Field(\"_uid\", uid, UidFieldMapper.Defaults.FIELD_TYPE);\n         Field versionField = new NumericDocValuesField(\"_version\", 0);\n         document.add(uidField);\n+        document.add(versionField);\n         return new ParsedDocument(uidField, versionField, id, type, routing, timestamp, ttl, Arrays.asList(document), analyzer, source, mappingsModified);\n     }\n ",
    "output": "Fix AbstractSimpleEngineTests versioning tests. Version is now stored on a distinct field, that AbstractSimpleEngineTests didn't correctly add before running tests. This generated a test failure when the version needed to be loaded from the index"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/AliasMissingException.java b/src/main/java/org/elasticsearch/indices/AliasMissingException.java\n--- a/src/main/java/org/elasticsearch/indices/AliasMissingException.java\n+++ b/src/main/java/org/elasticsearch/indices/AliasMissingException.java\n@@ -18,6 +18,8 @@\n \n package org.elasticsearch.indices;\n \n+import java.util.Locale;\n+\n import org.elasticsearch.ElasticSearchException;\n import org.elasticsearch.rest.RestStatus;\n \n@@ -28,7 +30,7 @@ public class AliasMissingException extends ElasticSearchException {\n     private final String[] names;\n \n     public AliasMissingException(String... names) {\n-        super(String.format(\"alias [%s] missing\", toNamesString(names)));\n+        super(String.format(Locale.ROOT, \"alias [%s] missing\", toNamesString(names)));\n         this.names = names;\n     }\n ",
    "output": "Fix String.format to use Locale.ROOT"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/util/concurrent/ThreadLocals.java b/src/main/java/org/elasticsearch/common/util/concurrent/ThreadLocals.java\n--- a/src/main/java/org/elasticsearch/common/util/concurrent/ThreadLocals.java\n+++ b/src/main/java/org/elasticsearch/common/util/concurrent/ThreadLocals.java\n@@ -98,7 +98,7 @@ private static void clearThreadLocalMap(Object map, Field internalTableField) th\n                             }\n                             if (actualValue != null) {\n                                 String actualValueClassName = actualValue.getClass().getName();\n-                                if (actualValueClassName.startsWith(\"org.elasticsearch\") || actualValueClassName.startsWith(\"org.lucene\")) {\n+                                if (actualValueClassName.startsWith(\"org.elasticsearch\") || actualValueClassName.startsWith(\"org.apache.lucene\")) {\n                                     remove = true;\n                                 }\n                             }",
    "output": "Fix package name"
  },
  {
    "input": "diff --git a/src/main/java/org/joda/time/base/BaseDateTime.java b/src/main/java/org/joda/time/base/BaseDateTime.java\n--- a/src/main/java/org/joda/time/base/BaseDateTime.java\n+++ b/src/main/java/org/joda/time/base/BaseDateTime.java\n@@ -25,10 +25,6 @@\n \n import java.io.Serializable;\n \n-/**\n- * WE COPIED THIS FILE TO REMOVE THE volatile from it!...\n- */\n-\n /**\n  * BaseDateTime is an abstract implementation of ReadableDateTime that stores\n  * data in <code>long</code> and <code>Chronology</code> fields.\n@@ -56,11 +52,12 @@ public abstract class BaseDateTime\n     /**\n      * The millis from 1970-01-01T00:00:00Z\n      */\n+    // THIS IS THE ES CHANGE not to have it volatile...\n     private long iMillis;\n     /**\n      * The chronology to use\n      */\n-    private Chronology iChronology;\n+    private volatile Chronology iChronology;\n \n     //-----------------------------------------------------------------------\n ",
    "output": "Upgrade to joda 2.2"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/cluster/allocation/ClusterRerouteTests.java b/src/test/java/org/elasticsearch/test/integration/cluster/allocation/ClusterRerouteTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/cluster/allocation/ClusterRerouteTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/cluster/allocation/ClusterRerouteTests.java\n@@ -176,8 +176,9 @@ public void rerouteWithAllocateLocalGateway() throws Exception {\n         logger.info(\"--> deleting the shard data\");\n         FileSystemUtils.deleteRecursively(shardLocation);\n \n-        logger.info(\"--> starting the first node back, will not allocate the shard since it has no data, but the index will be there\");\n+        logger.info(\"--> starting nodes back, will not allocate the shard since it has no data, but the index will be there\");\n         startNode(\"node1\", commonSettings);\n+        startNode(\"node2\", commonSettings);\n         // wait a bit for the cluster to realize that the shard is not there...\n         // TODO can we get around this? the cluster is RED, so what do we wait for?\n         Thread.sleep(300);",
    "output": "Improve test stability"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/dfs/AggregatedDfs.java b/src/main/java/org/elasticsearch/search/dfs/AggregatedDfs.java\n--- a/src/main/java/org/elasticsearch/search/dfs/AggregatedDfs.java\n+++ b/src/main/java/org/elasticsearch/search/dfs/AggregatedDfs.java\n@@ -72,7 +72,7 @@ public void readFrom(StreamInput in) throws IOException {\n             Term term = new Term(in.readString(), in.readBytesRef());\n             TermStatistics stats = new TermStatistics(in.readBytesRef(), \n                     in.readVLong(), \n-                    DfsSearchResult.toNotAvailable(in.readVLong()));\n+                    DfsSearchResult.subOne(in.readVLong()));\n             termStatistics.put(term, stats);\n         }\n         fieldStatistics = DfsSearchResult.readFieldStats(in);\n@@ -89,7 +89,7 @@ public void writeTo(final StreamOutput out) throws IOException {\n             TermStatistics stats = termTermStatisticsEntry.getValue();\n             out.writeBytesRef(stats.term());\n             out.writeVLong(stats.docFreq());\n-            out.writeVLong(DfsSearchResult.plusOne(stats.totalTermFreq()));\n+            out.writeVLong(DfsSearchResult.addOne(stats.totalTermFreq()));\n         }\n         DfsSearchResult.writeFieldStats(out, fieldStatistics);\n         out.writeVLong(maxDoc);",
    "output": "Fix DfsSearchResult method names in AggregatedDfs"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/highlight/vectorhighlight/FragmentBuilderHelper.java b/src/main/java/org/elasticsearch/search/highlight/vectorhighlight/FragmentBuilderHelper.java\n--- a/src/main/java/org/elasticsearch/search/highlight/vectorhighlight/FragmentBuilderHelper.java\n+++ b/src/main/java/org/elasticsearch/search/highlight/vectorhighlight/FragmentBuilderHelper.java\n@@ -69,7 +69,7 @@ public static WeightedFragInfo fixWeightedFragInfo(FieldMapper<?> mapper, Field[\n                 public int compare(SubInfo o1, SubInfo o2) {\n                     int startOffset = o1.getTermsOffsets().get(0).getStartOffset();\n                     int startOffset2 = o2.getTermsOffsets().get(0).getStartOffset();\n-                    return Integer.compare(startOffset, startOffset2);\n+                    return FragmentBuilderHelper.compare(startOffset, startOffset2);\n                 }\n             });\n             return new WeightedFragInfo(Math.min(fragInfo.getSubInfos().get(0).getTermsOffsets().get(0).getStartOffset(),\n@@ -78,6 +78,10 @@ public int compare(SubInfo o1, SubInfo o2) {\n             return fragInfo;\n         }\n     }\n+    \n+    private static int compare(int x, int y) {\n+        return (x < y) ? -1 : ((x == y) ? 0 : 1);\n+    }\n \n     private static boolean containsBrokenAnalysis(Analyzer analyzer) {\n         // TODO maybe we need a getter on Namedanalyzer that tells if this uses broken Analysis",
    "output": "Remove Java 7 only API We still run on Java 6 as minimum requirement. Integer.compare(int,int) was added in Java 7. This caused compile errors on CI"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java\n@@ -81,7 +81,7 @@ public void deleteIndex(final Request request, final Listener userListener) {\n         }\n \n         final DeleteIndexListener listener = new DeleteIndexListener(mdLock, request, userListener);\n-        clusterService.submitStateUpdateTask(\"delete-index [\" + request.index + \"]\", new ClusterStateUpdateTask() {\n+        clusterService.submitStateUpdateTask(\"delete-index [\" + request.index + \"]\", Priority.URGENT, new ClusterStateUpdateTask() {\n             @Override\n             public ClusterState execute(ClusterState currentState) {\n                 try {",
    "output": "Change the priority of delete-index action to URGENT All index meta data API's have urgent priority when it comes to cluster state updates. We'd like to remove indices asap to avoid things like unnecessary shards relocations"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java b/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.action.admin.indices.status.IndicesStatusResponse;\n import org.elasticsearch.action.admin.indices.status.ShardStatus;\n import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.routing.allocation.allocator.BalancedShardsAllocator;\n import org.elasticsearch.common.Priority;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.common.xcontent.XContentFactory;\n@@ -351,7 +352,9 @@ public void testReusePeerRecovery() throws Exception {\n         ImmutableSettings.Builder settings = ImmutableSettings.settingsBuilder()\n                 .put(\"action.admin.cluster.node.shutdown.delay\", \"10ms\")\n                 .put(\"gateway.recover_after_nodes\", 4)\n-                .put(\"gateway.type\", \"local\");\n+                .put(\"gateway.type\", \"local\")\n+                .put(BalancedShardsAllocator.SETTING_THRESHOLD, 1.1f); // use less agressive settings\n+\n         startNode(\"node1\", settings);\n         startNode(\"node2\", settings);\n         startNode(\"node3\", settings);",
    "output": "Use less agressive threshold to prevent primary relocation in recovery test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/HunspellTokenFilterFactory.java b/src/main/java/org/elasticsearch/index/analysis/HunspellTokenFilterFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/HunspellTokenFilterFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/HunspellTokenFilterFactory.java\n@@ -50,7 +50,7 @@ public HunspellTokenFilterFactory(Index index, @IndexSettings Settings indexSett\n             throw new ElasticSearchIllegalArgumentException(String.format(\"Unknown hunspell dictionary for locale [%s]\", locale));\n         }\n \n-        dedup = settings.getAsBoolean(\"dedup\", false);\n+        dedup = settings.getAsBoolean(\"dedup\", true);\n     }\n \n     @Override",
    "output": "Change hunspell token filter factory to use \"dedup = true\" by default"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -124,9 +124,13 @@ public class Version implements Serializable {\n     public static final Version V_0_90_1 = new Version(V_0_90_1_ID, false, org.apache.lucene.util.Version.LUCENE_42);\n \n     public static final int V_1_0_0_Beta1_ID = /*00*/1000001;\n-    public static final Version V_1_0_0_Beta1 = new Version(V_1_0_0_Beta1_ID, true, org.apache.lucene.util.Version.LUCENE_41);\n+    public static final Version V_1_0_0_Beta1 = new Version(V_1_0_0_Beta1_ID, true, org.apache.lucene.util.Version.LUCENE_42);\n \n     public static final Version CURRENT = V_1_0_0_Beta1;\n+    \n+    static {\n+        assert CURRENT.luceneVersion == Lucene.VERSION: \"Version must be upgraded to [\" + Lucene.VERSION + \"] is still set to [\" + CURRENT.luceneVersion + \"]\";\n+    }\n \n     public static Version readVersion(StreamInput in) throws IOException {\n         return fromId(in.readVInt());",
    "output": "Upgrade Lucene Version to 4.2. The latest Elasticsearch version must use the latest Lucene version as specified in o.e.common.lucene.Lucene and must be upgraded with each lucene release. This commit adds an assert that fails once the actual lucene version that is used is higher than the current releases version"
  },
  {
    "input": "diff --git a/src/main/java/org/apache/lucene/analysis/miscellaneous/XStemmerOverrideFilter.java b/src/main/java/org/apache/lucene/analysis/miscellaneous/XStemmerOverrideFilter.java\n--- a/src/main/java/org/apache/lucene/analysis/miscellaneous/XStemmerOverrideFilter.java\n+++ b/src/main/java/org/apache/lucene/analysis/miscellaneous/XStemmerOverrideFilter.java\n@@ -30,10 +30,12 @@\n import org.apache.lucene.util.CharsRef;\n import org.apache.lucene.util.IntsRef;\n import org.apache.lucene.util.UnicodeUtil;\n+import org.apache.lucene.util.Version;\n import org.apache.lucene.util.fst.ByteSequenceOutputs;\n import org.apache.lucene.util.fst.FST;\n import org.apache.lucene.util.fst.FST.Arc;\n import org.apache.lucene.util.fst.FST.BytesReader;\n+import org.elasticsearch.common.lucene.Lucene;\n \n /**\n  * Provides the ability to override any {@link KeywordAttribute} aware stemmer\n@@ -47,10 +49,13 @@ public final class XStemmerOverrideFilter extends TokenFilter {\n     private final KeywordAttribute keywordAtt = addAttribute(KeywordAttribute.class);\n     private final BytesReader fstReader;\n     private final Arc<BytesRef> scratchArc = new FST.Arc<BytesRef>();\n-  ;\n     private final CharsRef spare = new CharsRef();\n     private final boolean ignoreCase;\n     \n+    static {\n+        assert Version.LUCENE_42 == Lucene.VERSION: \"Elasticsearch has upgraded to Lucene Version: [\" + Lucene.VERSION + \"] this should can be removed\"; \n+    }\n+    \n     /**\n      * Create a new StemmerOverrideFilter, performing dictionary-based stemming\n      * with the provided <code>dictionary</code>.",
    "output": "Add assert that fails one Elasticsearch upgrades to Lucene 4.3 in order to remove the duplicated class"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/ReplicationType.java b/src/main/java/org/elasticsearch/action/support/replication/ReplicationType.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/ReplicationType.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/ReplicationType.java\n@@ -56,9 +56,9 @@ public byte id() {\n      */\n     public static ReplicationType fromId(byte id) {\n         if (id == 0) {\n-            return ASYNC;\n-        } else if (id == 1) {\n             return SYNC;\n+        } else if (id == 1) {\n+            return ASYNC;\n         } else if (id == 2) {\n             return DEFAULT;\n         } else {",
    "output": "Fix serialization of sync/async replication type"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/ScriptDocValues.java b/src/main/java/org/elasticsearch/index/fielddata/ScriptDocValues.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/ScriptDocValues.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/ScriptDocValues.java\n@@ -235,6 +235,33 @@ public boolean isEmpty() {\n         public GeoPoint getValue() {\n             return values.getValue(docId);\n         }\n+\n+        public double getLat() {\n+            return getValue().lat();\n+        }\n+\n+        public double[] getLats() {\n+            List<GeoPoint> points = getValues();\n+            double[] lats = new double[points.size()];\n+            for (int i = 0; i < points.size(); i++) {\n+                lats[i] = points.get(i).lat();\n+            }\n+            return lats;\n+        }\n+\n+        public double [] getLons() {\n+            List<GeoPoint> points = getValues();\n+            double[] lons = new double[points.size()];\n+            for (int i = 0; i < points.size(); i++) {\n+                lons[i] = points.get(i).lon();\n+            }\n+            return lons;\n+        }\n+\n+        public double getLon() {\n+            return getValue().lon();\n+        }\n+\n         \n         public List<GeoPoint> getValues() {\n             if (!listLoaded) {",
    "output": "Add missing support for lat, lats, lon, lons for doc notation in scripts"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/BaseFilterBuilder.java b/src/main/java/org/elasticsearch/index/query/BaseFilterBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/BaseFilterBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/BaseFilterBuilder.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.index.query;\n \n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n \n import java.io.IOException;\n \n@@ -28,6 +29,18 @@\n  */\n public abstract class BaseFilterBuilder implements FilterBuilder {\n \n+    @Override\n+    public String toString() {\n+        try {\n+            XContentBuilder builder = XContentFactory.jsonBuilder();\n+            builder.prettyPrint();\n+            toXContent(builder, EMPTY_PARAMS);\n+            return builder.string();\n+        } catch (Exception e) {\n+            throw new QueryBuilderException(\"Failed to build filter\", e);\n+        }\n+    }\n+\n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n         builder.startObject();\n@@ -37,4 +50,4 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n     }\n \n     protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;\n-}\n\\ No newline at end of file\n+}",
    "output": "Add toString() for FilterBuilders"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java b/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java\n@@ -95,6 +95,7 @@ public void run() {\n         });\n         client1.admin().cluster().prepareUpdateSettings().setTransientSettings(settingsBuilder().put(\"threadpool.search.type\", \"fixed\").build()).execute().actionGet();\n         barrier.await();\n+        Thread.sleep(200);\n \n         // Check that node info is correct\n         NodesInfoResponse nodesInfoResponse = client2.admin().cluster().prepareNodesInfo().all().execute().actionGet();",
    "output": "Make sure that settings are propagated to all nodes"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/nodesinfo/SimpleNodesInfoTests.java b/src/test/java/org/elasticsearch/test/integration/nodesinfo/SimpleNodesInfoTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/nodesinfo/SimpleNodesInfoTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/nodesinfo/SimpleNodesInfoTests.java\n@@ -199,6 +199,10 @@ private String startNodeWithPlugins(String name) throws URISyntaxException {\n         }\n \n         startNode(name, settings);\n+\n+        // We wait for a Green status\n+        client(name).admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();\n+\n         String serverNodeId = ((InternalNode) node(name)).injector()\n                 .getInstance(ClusterService.class).state().nodes().localNodeId();\n         logger.debug(\"--> server {} started\" + serverNodeId);",
    "output": "Fix test for #2668"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java b/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n--- a/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n+++ b/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n@@ -68,6 +68,8 @@ public S3Gateway(Settings settings, ThreadPool threadPool, ClusterService cluste\n                     region = \"us-west-1\";\n                 } else if (\"us-west-1\".equals(regionSetting.toLowerCase())) {\n                     region = \"us-west-1\";\n+                } else if (\"us-west-2\".equals(regionSetting.toLowerCase())) {\n+                    region = \"us-west-2\";\n                 } else if (\"ap-southeast\".equals(regionSetting.toLowerCase())) {\n                     region = \"ap-southeast-1\";\n                 } else if (\"ap-southeast-1\".equals(regionSetting.toLowerCase())) {",
    "output": "Upgrade S3Gateway to add us-west-2"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java b/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n@@ -121,6 +121,10 @@ public synchronized AmazonS3 client() {\n                 endpoint = \"s3-eu-west-1.amazonaws.com\";\n             } else if (\"eu-west-1\".equals(region)) {\n                 endpoint = \"s3-eu-west-1.amazonaws.com\";\n+            } else if (\"sa-east\".equals(region)) {\n+                endpoint = \"s3-sa-east-1.amazonaws.com\";\n+            } else if (\"sa-east-1\".equals(region)) {\n+                endpoint = \"s3-sa-east-1.amazonaws.com\";\n             } else {\n                 throw new ElasticSearchIllegalArgumentException(\"No automatic endpoint could be derived from region [\" + region + \"]\");\n             }",
    "output": "Add sa-east-1 region"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java b/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n@@ -120,6 +120,8 @@ public synchronized AmazonEC2 client() {\n                 endpoint = \"ec2.ap-northeast-1.amazonaws.com\";\n             } else if (region.equals(\"eu-west\") || region.equals(\"eu-west-1\")) {\n                 endpoint = \"ec2.eu-west-1.amazonaws.com\";\n+            } else if (region.equals(\"sa-east\") || region.equals(\"sa-east-1\")) {\n+                endpoint = \"ec2.sa-east-1.amazonaws.com\";\n             } else {\n                 throw new ElasticSearchIllegalArgumentException(\"No automatic endpoint could be derived from region [\" + region + \"]\");\n             }",
    "output": "Add sa-east-1 region"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/cluster/ClusterHealthTests.java b/src/test/java/org/elasticsearch/test/integration/cluster/ClusterHealthTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/cluster/ClusterHealthTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/cluster/ClusterHealthTests.java\n@@ -47,7 +47,7 @@ public void testHealth() {\n         assertThat(healthResponse.getIndices().isEmpty(), equalTo(true));\n \n         logger.info(\"--> running cluster wide health\");\n-        healthResponse = node1.client().admin().cluster().prepareHealth().setWaitForYellowStatus().setTimeout(\"1s\").execute().actionGet();\n+        healthResponse = node1.client().admin().cluster().prepareHealth().setWaitForYellowStatus().setTimeout(\"10s\").execute().actionGet();\n         assertThat(healthResponse.isTimedOut(), equalTo(false));\n         assertThat(healthResponse.getStatus(), equalTo(ClusterHealthStatus.GREEN));\n         assertThat(healthResponse.getIndices().isEmpty(), equalTo(true));\n@@ -58,7 +58,7 @@ public void testHealth() {\n                 .execute().actionGet();\n \n         logger.info(\"--> running cluster health on an index that does exists\");\n-        healthResponse = node1.client().admin().cluster().prepareHealth(\"test1\").setWaitForYellowStatus().setTimeout(\"1s\").execute().actionGet();\n+        healthResponse = node1.client().admin().cluster().prepareHealth(\"test1\").setWaitForYellowStatus().setTimeout(\"10s\").execute().actionGet();\n         assertThat(healthResponse.isTimedOut(), equalTo(false));\n         assertThat(healthResponse.getStatus(), equalTo(ClusterHealthStatus.GREEN));\n         assertThat(healthResponse.getIndices().get(\"test1\").getStatus(), equalTo(ClusterHealthStatus.GREEN));",
    "output": "Improve stability of ClusterHealthTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java b/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java\n@@ -104,6 +104,8 @@ public void simpleMinimumMasterNodes() throws Exception {\n         for (int i = 0; i < 100; i++) {\n             client(\"node1\").prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(\"field\", \"value\").execute().actionGet();\n         }\n+        // make sure that all shards recovered before trying to flush\n+        assertThat(client(\"node1\").admin().cluster().prepareHealth(\"test\").setWaitForActiveShards(2).execute().actionGet().getActiveShards(), equalTo(2));\n         // flush for simpler debugging\n         client(\"node1\").admin().indices().prepareFlush().execute().actionGet();\n \n@@ -261,6 +263,8 @@ public void multipleNodesShutdownNonMasterNodes() throws Exception {\n         for (int i = 0; i < 100; i++) {\n             client(\"node1\").prepareIndex(\"test\", \"type1\", Integer.toString(i)).setSource(\"field\", \"value\").execute().actionGet();\n         }\n+        // make sure that all shards recovered before trying to flush\n+        assertThat(client(\"node1\").admin().cluster().prepareHealth(\"test\").setWaitForActiveShards(10).execute().actionGet().isTimedOut(), equalTo(false));\n         // flush for simpler debugging\n         client(\"node1\").admin().indices().prepareFlush().execute().actionGet();\n ",
    "output": "Improve stability of MinimumMasterNodesTests"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/cache/filter/weighted/WeightedFilterCache.java b/src/main/java/org/elasticsearch/index/cache/filter/weighted/WeightedFilterCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/filter/weighted/WeightedFilterCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/filter/weighted/WeightedFilterCache.java\n@@ -162,9 +162,12 @@ public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws\n             if (cacheValue == null) {\n                 if (!cache.seenReaders.containsKey(context.reader().getCoreCacheKey())) {\n                     Boolean previous = cache.seenReaders.putIfAbsent(context.reader().getCoreCacheKey(), Boolean.TRUE);\n-                    if (previous == null && (context.reader() instanceof SegmentReader)) {\n-                        ((SegmentReader) context.reader()).addCoreClosedListener(cache);\n+                    if (previous == null) {\n                         cache.seenReadersCount.inc();\n+                        // we add a core closed listener only, for non core IndexReaders we rely on clear being called (percolator for example)\n+                        if (context.reader() instanceof SegmentReader) {\n+                            ((SegmentReader) context.reader()).addCoreClosedListener(cache);\n+                        }\n                     }\n                 }\n ",
    "output": "Fix seen readers counter since clear can be called on percolator as well, we need to make sure we inc the counter even for non segment readers"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java b/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n--- a/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n+++ b/src/main/java/org/elasticsearch/gateway/s3/S3Gateway.java\n@@ -68,6 +68,8 @@ public S3Gateway(Settings settings, ThreadPool threadPool, ClusterService cluste\n                     region = \"us-west-1\";\n                 } else if (\"us-west-1\".equals(regionSetting.toLowerCase())) {\n                     region = \"us-west-1\";\n+                } else if (\"us-west-2\".equals(regionSetting.toLowerCase())) {\n+                    region = \"us-west-2\";\n                 } else if (\"ap-southeast\".equals(regionSetting.toLowerCase())) {\n                     region = \"ap-southeast-1\";\n                 } else if (\"ap-southeast-1\".equals(regionSetting.toLowerCase())) {",
    "output": "Upgrade S3Gateway to add us-west-2"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/cache/query/parser/resident/ResidentQueryParserCache.java b/src/main/java/org/elasticsearch/index/cache/query/parser/resident/ResidentQueryParserCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/query/parser/resident/ResidentQueryParserCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/query/parser/resident/ResidentQueryParserCache.java\n@@ -49,8 +49,8 @@ public class ResidentQueryParserCache extends AbstractIndexComponent implements\n     public ResidentQueryParserCache(Index index, @IndexSettings Settings indexSettings) {\n         super(index, indexSettings);\n \n-        this.maxSize = indexSettings.getAsInt(\"index.cache.field.max_size\", componentSettings.getAsInt(\"max_size\", 100));\n-        this.expire = indexSettings.getAsTime(\"index.cache.field.expire\", componentSettings.getAsTime(\"expire\", null));\n+        this.maxSize = componentSettings.getAsInt(\"max_size\", 100);\n+        this.expire = componentSettings.getAsTime(\"expire\", null);\n         logger.debug(\"using [resident] query cache with max_size [{}], expire [{}]\", maxSize, expire);\n \n         CacheBuilder cacheBuilder = CacheBuilder.newBuilder().maximumSize(maxSize);",
    "output": "Remove the field settings for query parser cache, not really relevant"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/gateway/local/state/meta/LocalGatewayMetaState.java b/src/main/java/org/elasticsearch/gateway/local/state/meta/LocalGatewayMetaState.java\n--- a/src/main/java/org/elasticsearch/gateway/local/state/meta/LocalGatewayMetaState.java\n+++ b/src/main/java/org/elasticsearch/gateway/local/state/meta/LocalGatewayMetaState.java\n@@ -219,7 +219,7 @@ public void clusterChanged(ClusterChangedEvent event) {\n                         continue;\n                     }\n                     if (!newMetaData.hasIndex(current.index())) {\n-                        logger.debug(\"[{}] deleting index that is no longer part of the metadata\");\n+                        logger.debug(\"[{}] deleting index that is no longer part of the metadata (indices: [{}])\", current.index(), newMetaData.indices().keySet());\n                         FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new Index(current.index())));\n                     }\n                 }",
    "output": "Fix logging message to include the index also add the list of current indices"
  },
  {
    "input": "diff --git a/src/main/java/org/apache/lucene/store/RateLimitedFSDirectory.java b/src/main/java/org/apache/lucene/store/RateLimitedFSDirectory.java\n--- a/src/main/java/org/apache/lucene/store/RateLimitedFSDirectory.java\n+++ b/src/main/java/org/apache/lucene/store/RateLimitedFSDirectory.java\n@@ -18,11 +18,11 @@\n  */\n package org.apache.lucene.store;\n \n+import org.apache.lucene.store.IOContext.Context;\n+\n import java.io.IOException;\n import java.util.Collection;\n \n-import org.apache.lucene.store.IOContext.Context;\n-\n public final class RateLimitedFSDirectory extends Directory {\n     private final FSDirectory delegate;\n \n@@ -31,7 +31,7 @@ public final class RateLimitedFSDirectory extends Directory {\n     private final StoreRateLimiting.Listener rateListener;\n \n     public RateLimitedFSDirectory(FSDirectory wrapped, StoreRateLimiting.Provider rateLimitingProvider,\n-            StoreRateLimiting.Listener rateListener) {\n+                                  StoreRateLimiting.Listener rateListener) {\n         this.delegate = wrapped;\n         this.rateLimitingProvider = rateLimitingProvider;\n         this.rateListener = rateListener;\n@@ -160,7 +160,7 @@ static final class RateLimitedIndexOutput extends BufferedIndexOutput {\n         private final StoreRateLimiting.Listener rateListener;\n \n         RateLimitedIndexOutput(final RateLimiter rateLimiter, final StoreRateLimiting.Listener rateListener, final IndexOutput delegate) {\n-            // TODO should we make buffer size configurable\n+            // TODO if Lucene exposed in BufferedIndexOutput#getBufferSize, we could initialize it if the delegate is buffered\n             if (delegate instanceof BufferedIndexOutput) {\n                 bufferedDelegate = (BufferedIndexOutput) delegate;\n                 this.delegate = delegate;",
    "output": "Improve TODO comment"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/sort/SortParseElement.java b/src/main/java/org/elasticsearch/search/sort/SortParseElement.java\n--- a/src/main/java/org/elasticsearch/search/sort/SortParseElement.java\n+++ b/src/main/java/org/elasticsearch/search/sort/SortParseElement.java\n@@ -136,7 +136,7 @@ private void addCompoundSortField(XContentParser parser, SearchContext context,\n                             } else if (token.isValue()) {\n                                 if (\"reverse\".equals(innerJsonName)) {\n                                     reverse = parser.booleanValue();\n-                                } else if (\"order\".equals(innerJsonName)) {\n+                                } else if (\"order\".equals(innerJsonName) || \"sort_order\".equals(innerJsonName) || \"sortOrder\".equals(innerJsonName)) {\n                                     if (\"asc\".equals(parser.text())) {\n                                         reverse = SCORE_FIELD_NAME.equals(fieldName);\n                                     } else if (\"desc\".equals(parser.text())) {",
    "output": "Add `sort_oder` and `sortOrder` as valid field names for defining the sort order in a Sort object"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java b/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java\n--- a/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java\n+++ b/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java\n@@ -111,7 +111,7 @@ public void recover(boolean indexShouldExists, RecoveryStatus recoveryStatus) th\n                     // ignore\n                 }\n                 if (indexShouldExists && indexShard.store().indexStore().persistent()) {\n-                    throw new IndexShardGatewayRecoveryException(shardId(), \"shard allocated for local recovery (post api), should exists, but doesn't, current files: \" + files, e);\n+                    throw new IndexShardGatewayRecoveryException(shardId(), \"shard allocated for local recovery (post api), should exist, but doesn't, current files: \" + files, e);\n                 }\n             }\n             if (si != null) {",
    "output": "Fix a typo in an error message \"should exists\" -> \"should exist\""
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java b/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java\n--- a/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java\n+++ b/src/main/java/org/elasticsearch/index/gateway/local/LocalIndexShardGateway.java\n@@ -49,6 +49,7 @@\n import java.io.File;\n import java.io.FileInputStream;\n import java.io.IOException;\n+import java.util.Arrays;\n import java.util.concurrent.ScheduledFuture;\n \n /**\n@@ -103,9 +104,15 @@ public void recover(boolean indexShouldExists, RecoveryStatus recoveryStatus) th\n             SegmentInfos si = null;\n             try {\n                 si = Lucene.readSegmentInfos(indexShard.store().directory());\n-            } catch (IOException e) {\n+            } catch (Exception e) {\n+                String files = \"_unknown_\";\n+                try {\n+                    files = Arrays.toString(indexShard.store().directory().listAll());\n+                } catch (Exception e1) {\n+                    // ignore\n+                }\n                 if (indexShouldExists && indexShard.store().indexStore().persistent()) {\n-                    throw new IndexShardGatewayRecoveryException(shardId(), \"shard allocated for local recovery (post api), should exists, but doesn't\", e);\n+                    throw new IndexShardGatewayRecoveryException(shardId(), \"shard allocated for local recovery (post api), should exists, but doesn't, current files: \" + files, e);\n                 }\n             }\n             if (si != null) {",
    "output": "Add a list of files that exists in the index to the failure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java b/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java\n@@ -82,7 +82,7 @@ public void writeTo(StreamOutput out) throws IOException {\n \n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n-        builder.startObject(Fields.FIELD_DATA);\n+        builder.startObject(Fields.FIELDDATA);\n         builder.field(Fields.MEMORY_SIZE, getMemorySize().toString());\n         builder.field(Fields.MEMORY_SIZE_IN_BYTES, memorySize);\n         builder.field(Fields.EVICTIONS, getEvictions());\n@@ -91,7 +91,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n     }\n \n     static final class Fields {\n-        static final XContentBuilderString FIELD_DATA = new XContentBuilderString(\"field_data\");\n+        static final XContentBuilderString FIELDDATA = new XContentBuilderString(\"fielddata\");\n         static final XContentBuilderString MEMORY_SIZE = new XContentBuilderString(\"memory_size\");\n         static final XContentBuilderString MEMORY_SIZE_IN_BYTES = new XContentBuilderString(\"memory_size_in_bytes\");\n         static final XContentBuilderString EVICTIONS = new XContentBuilderString(\"evictions\");",
    "output": "Change field data stats header from `field_data` to `fielddata`"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java b/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java\n@@ -78,13 +78,4 @@ public void testRedirectSitePlugin() throws Exception {\n         assertThat(response.errorCode(), equalTo(RestStatus.OK.getStatus()));\n         assertThat(response.response(), containsString(\"<title>Dummy Site Plugin</title>\"));\n     }\n-\n-    @Test\n-    public void testListSitePlugin() throws Exception {\n-        // We use an HTTP Client to test redirection\n-        HttpClientResponse response = httpClient(\"test\").request(\"/_plugin/\");\n-        assertThat(response.errorCode(), equalTo(RestStatus.OK.getStatus()));\n-        assertThat(response.response(), containsString(\"dummy\"));\n-        assertThat(response.response(), containsString(\"anotherplugin\"));\n-    }\n }",
    "output": "Remove obsolete test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java b/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/FieldDataStats.java\n@@ -83,8 +83,8 @@ public void writeTo(StreamOutput out) throws IOException {\n     @Override\n     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n         builder.startObject(Fields.FIELD_DATA);\n-        builder.field(Fields.MEMORY_SIZE, memorySize);\n-        builder.field(Fields.MEMORY_SIZE_IN_BYTES, getMemorySize().toString());\n+        builder.field(Fields.MEMORY_SIZE, getMemorySize().toString());\n+        builder.field(Fields.MEMORY_SIZE_IN_BYTES, memorySize);\n         builder.field(Fields.EVICTIONS, getEvictions());\n         builder.endObject();\n         return builder;",
    "output": "Fix interchanged values in field_data stats"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java b/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java\n@@ -74,6 +74,11 @@ protected ClusterHealthResponse newResponse() {\n         return new ClusterHealthResponse();\n     }\n \n+    @Override\n+    protected boolean localExecute(ClusterHealthRequest request) {\n+        return request.local();\n+    }\n+\n     @Override\n     protected ClusterHealthResponse masterOperation(ClusterHealthRequest request, ClusterState unusedState) throws ElasticSearchException {\n         long endTime = System.currentTimeMillis() + request.timeout().millis();",
    "output": "Fix local flag in cluster health"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/search/basic/TransportTwoNodesSearchTests.java b/src/test/java/org/elasticsearch/test/integration/search/basic/TransportTwoNodesSearchTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/search/basic/TransportTwoNodesSearchTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/search/basic/TransportTwoNodesSearchTests.java\n@@ -357,15 +357,15 @@ public void testFailedSearchWithWrongFrom() throws Exception {\n         assertThat(response.getFailedShards(), equalTo(0));\n \n         response = client.search(searchRequest(\"test\").searchType(QUERY_THEN_FETCH).source(source)).actionGet();\n-        assertThat(response.getShardFailures().length, equalTo(0));\n+        assertThat(Arrays.toString(response.getShardFailures()), response.getShardFailures().length, equalTo(0));\n         assertThat(response.getHits().hits().length, equalTo(0));\n \n         response = client.search(searchRequest(\"test\").searchType(DFS_QUERY_AND_FETCH).source(source)).actionGet();\n-        assertThat(response.getShardFailures().length, equalTo(0));\n+        assertThat(Arrays.toString(response.getShardFailures()), response.getShardFailures().length, equalTo(0));\n         assertThat(response.getHits().hits().length, equalTo(0));\n \n         response = client.search(searchRequest(\"test\").searchType(DFS_QUERY_THEN_FETCH).source(source)).actionGet();\n-        assertThat(response.getShardFailures().length, equalTo(0));\n+        assertThat(Arrays.toString(response.getShardFailures()), response.getShardFailures().length, equalTo(0));\n         assertThat(response.getHits().hits().length, equalTo(0));\n \n         logger.info(\"Done Testing failed search\");",
    "output": "Add info in test for actual search failures"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java b/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n@@ -3,7 +3,7 @@\n import com.ibm.icu.text.Collator;\n import com.ibm.icu.text.RuleBasedCollator;\n import com.ibm.icu.util.ULocale;\n-import org.apache.lucene.analysis.KeywordTokenizer;\n+import org.apache.lucene.analysis.core.KeywordTokenizer;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.elasticsearch.common.inject.Injector;",
    "output": "Upgrade to Lucene 4.1"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java b/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java\n--- a/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java\n+++ b/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java\n@@ -66,7 +66,7 @@ public String getName() {\n     @Override\n     public void contribute(Dump dump) throws DumpContributionFailedException {\n         if (heapDumpMethod == null) {\n-            throw new DumpContributionFailedException(getName(), \"Heap dump not enalbed on this JVM\");\n+            throw new DumpContributionFailedException(getName(), \"Heap dump not enabled on this JVM\");\n         }\n         try {\n             heapDumpMethod.invoke(diagnosticMBean, dump.createFile(\"heap.hprof\").getAbsolutePath(), true);",
    "output": "Fix exception typo"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java b/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java\n--- a/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java\n+++ b/src/main/java/org/elasticsearch/monitor/dump/heap/HeapDumpContributor.java\n@@ -66,7 +66,7 @@ public String getName() {\n     @Override\n     public void contribute(Dump dump) throws DumpContributionFailedException {\n         if (heapDumpMethod == null) {\n-            throw new DumpContributionFailedException(getName(), \"Heap dump not enalbed on this JVM\");\n+            throw new DumpContributionFailedException(getName(), \"Heap dump not enabled on this JVM\");\n         }\n         try {\n             heapDumpMethod.invoke(diagnosticMBean, dump.createFile(\"heap.hprof\").getAbsolutePath(), true);",
    "output": "Fix typo in exception"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthRequest.java b/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthRequest.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthRequest.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthRequest.java\n@@ -134,7 +134,7 @@ public ClusterHealthRequest setLocal(boolean local) {\n         return this;\n     }\n \n-    public boolean getLocal() {\n+    public boolean isLocal() {\n         return this.local;\n     }\n \n\ndiff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n@@ -51,7 +51,7 @@ public RestClusterHealthAction(Settings settings, Client client, RestController\n     @Override\n     public void handleRequest(final RestRequest request, final RestChannel channel) {\n         ClusterHealthRequest clusterHealthRequest = clusterHealthRequest(RestActions.splitIndices(request.param(\"index\")));\n-        clusterHealthRequest.setLocal(request.paramAsBoolean(\"local\", clusterHealthRequest.getLocal()));\n+        clusterHealthRequest.setLocal(request.paramAsBoolean(\"local\", clusterHealthRequest.isLocal()));\n         clusterHealthRequest.setListenerThreaded(false);\n         int level = 0;\n         try {",
    "output": "Fix boolean to is from get relates to"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n--- a/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n+++ b/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n@@ -234,9 +234,10 @@ public void close() {\n         if (locks != null) {\n             for (Lock lock : locks) {\n                 try {\n+                    logger.trace(\"releasing lock [{}]\", lock);\n                     lock.release();\n                 } catch (IOException e) {\n-                    // ignore\n+                    logger.trace(\"failed to release lock [{}]\", e, lock);\n                 }\n             }\n         }",
    "output": "Add logging information for releasing node lock"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java b/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/plugin/SitePluginTests.java\n@@ -30,6 +30,8 @@\n import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.Test;\n \n+import java.io.File;\n+\n import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.containsString;\n@@ -42,9 +44,10 @@ public class SitePluginTests extends AbstractNodesTests {\n \n \n     @BeforeClass\n-    public void setupPluginDirectory() {\n+    public void setupPluginDirectory() throws Exception {\n+        File pluginDir = new File(SitePluginTests.class.getResource(\"/org/elasticsearch/test/integration/plugin\").toURI());\n         putDefaultSettings(settingsBuilder()\n-                .put(\"path.plugins\", \"target/test-classes/org/elasticsearch/test/integration/plugin/\")\n+                .put(\"path.plugins\", pluginDir.getAbsolutePath())\n                 .build());\n     }\n ",
    "output": "Fix test for Support trailing slashes on plugin _site URLs"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java b/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n@@ -78,6 +78,7 @@ public void shardsCleanup() throws Exception {\n \n         logger.info(\"--> running cluster_health\");\n         ClusterHealthResponse clusterHealth = client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus()).actionGet();\n+        assertThat(clusterHealth.isTimedOut(), equalTo(false));\n         logger.info(\"--> done cluster_health, status \" + clusterHealth.getStatus());\n \n \n@@ -98,6 +99,7 @@ public void shardsCleanup() throws Exception {\n \n         logger.info(\"--> running cluster_health\");\n         clusterHealth = client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus().setWaitForNodes(\"2\")).actionGet();\n+        assertThat(clusterHealth.isTimedOut(), equalTo(false));\n         logger.info(\"--> done cluster_health, status \" + clusterHealth.getStatus());\n \n         logger.info(\"--> making sure that shard and it's replica exist on server1, server2 and server3\");\n@@ -110,6 +112,7 @@ public void shardsCleanup() throws Exception {\n \n         logger.info(\"--> running cluster_health\");\n         clusterHealth = client(\"server2\").admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus()).actionGet();\n+        assertThat(clusterHealth.isTimedOut(), equalTo(false));\n         logger.info(\"--> done cluster_health, status \" + clusterHealth.getStatus());\n \n         logger.info(\"--> making sure that shard and it's replica are allocated on server1 and server3 but not on server2\");",
    "output": "Add check for health timeout to shardCleanup test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java b/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/health/TransportClusterHealthAction.java\n@@ -182,6 +182,9 @@ protected ClusterHealthResponse masterOperation(ClusterHealthRequest request, Cl\n     }\n \n     private ClusterHealthResponse clusterHealth(ClusterHealthRequest request, ClusterState clusterState) {\n+        if (logger.isTraceEnabled()) {\n+            logger.trace(\"Calculating health based on state version [{}]\", clusterState.version());\n+        }\n         RoutingTableValidation validation = clusterState.routingTable().validate(clusterState.metaData());\n         ClusterHealthResponse response = new ClusterHealthResponse(clusterName.value(), validation.failures());\n         response.numberOfNodes = clusterState.nodes().size();",
    "output": "Make it simpler to determine which version of state was used to calculate health"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java b/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n@@ -97,7 +97,7 @@ public void shardsCleanup() throws Exception {\n         assertThat(server2Shard.exists(), equalTo(true));\n \n         logger.info(\"--> running cluster_health\");\n-        clusterHealth = client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus()).actionGet();\n+        clusterHealth = client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus().setWaitForNodes(\"2\")).actionGet();\n         logger.info(\"--> done cluster_health, status \" + clusterHealth.getStatus());\n \n         logger.info(\"--> making sure that shard and it's replica exist on server1, server2 and server3\");",
    "output": "Improve stability of shardsCleanup test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n--- a/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n+++ b/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n@@ -189,19 +189,19 @@ public void remove(LocalNodeMasterListener listener) {\n         localNodeMasterListeners.remove(listener);\n     }\n \n-    public void add(TimeValue timeout, final TimeoutClusterStateListener listener) {\n+    public void add(final TimeValue timeout, final TimeoutClusterStateListener listener) {\n         if (lifecycle.stoppedOrClosed()) {\n             listener.onClose();\n             return;\n         }\n-        NotifyTimeout notifyTimeout = new NotifyTimeout(listener, timeout);\n-        notifyTimeout.future = threadPool.schedule(timeout, ThreadPool.Names.GENERIC, notifyTimeout);\n-        onGoingTimeouts.add(notifyTimeout);\n-        clusterStateListeners.add(listener);\n         // call the post added notification on the same event thread\n         updateTasksExecutor.execute(new Runnable() {\n             @Override\n             public void run() {\n+                NotifyTimeout notifyTimeout = new NotifyTimeout(listener, timeout);\n+                notifyTimeout.future = threadPool.schedule(timeout, ThreadPool.Names.GENERIC, notifyTimeout);\n+                onGoingTimeouts.add(notifyTimeout);\n+                clusterStateListeners.add(listener);\n                 listener.postAdded();\n             }\n         });",
    "output": "Fix race condition in adding TimeoutClusterStateListener"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java b/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n@@ -1352,7 +1352,7 @@ public void onRefreshSettings(Settings settings) {\n             int indexConcurrency = settings.getAsInt(\"index.index_concurrency\", RobinEngine.this.indexConcurrency);\n             String codecName = settings.get(\"index.codec\", RobinEngine.this.codecName);\n             boolean requiresFlushing = false;\n-            if (termIndexInterval != RobinEngine.this.termIndexInterval || termIndexDivisor != RobinEngine.this.termIndexDivisor) {\n+            if (termIndexInterval != RobinEngine.this.termIndexInterval || termIndexDivisor != RobinEngine.this.termIndexDivisor || indexConcurrency != RobinEngine.this.indexConcurrency || !codecName.equals(RobinEngine.this.codecName)) {\n                 rwl.readLock().lock();\n                 try {\n                     if (termIndexInterval != RobinEngine.this.termIndexInterval) {\n@@ -1376,7 +1376,7 @@ public void onRefreshSettings(Settings settings) {\n                     if (!codecName.equals(RobinEngine.this.codecName)) {\n                         logger.info(\"updating index.codec from [{}] to [{}]\", RobinEngine.this.codecName, codecName);\n                         RobinEngine.this.codecName = codecName;\n-                        // TODO: Lucene 4, I think once someones changes codec, it should be reflected immediately\n+                        // we want to flush in this case, so the new codec will be reflected right away...\n                         requiresFlushing = true;\n                     }\n                 } finally {",
    "output": "Fix check on which settings to change on"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -106,6 +106,8 @@ public class Version implements Serializable {\n     public static final Version V_0_20_4 = new Version(V_0_20_4_ID, false);\n     public static final int V_0_20_5_ID = /*00*/200599;\n     public static final Version V_0_20_5 = new Version(V_0_20_5_ID, false);\n+    public static final int V_0_20_6_ID = /*00*/200699;\n+    public static final Version V_0_20_6 = new Version(V_0_20_6_ID, false);\n \n     public static final int V_0_21_0_Beta1_ID = /*00*/210001;\n     public static final Version V_0_21_0_Beta1 = new Version(V_0_21_0_Beta1_ID, true);\n@@ -121,6 +123,8 @@ public static Version fromId(int id) {\n             case V_0_21_0_Beta1_ID:\n                 return V_0_21_0_Beta1;\n \n+            case V_0_20_6_ID:\n+                return V_0_20_6;\n             case V_0_20_5_ID:\n                 return V_0_20_5;\n             case V_0_20_4_ID:",
    "output": "Add 0.20.6 ver"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java b/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/StemmerTokenFilterFactory.java\n@@ -40,6 +40,7 @@\n import org.apache.lucene.analysis.id.IndonesianStemFilter;\n import org.apache.lucene.analysis.it.ItalianLightStemFilter;\n import org.apache.lucene.analysis.lv.LatvianStemFilter;\n+import org.apache.lucene.analysis.no.NorwegianMinimalStemFilter;\n import org.apache.lucene.analysis.pt.PortugueseLightStemFilter;\n import org.apache.lucene.analysis.pt.PortugueseMinimalStemFilter;\n import org.apache.lucene.analysis.pt.PortugueseStemFilter;\n@@ -110,6 +111,8 @@ public TokenStream create(TokenStream tokenStream) {\n             return new LatvianStemFilter(tokenStream);\n         } else if (\"norwegian\".equalsIgnoreCase(language)) {\n             return new SnowballFilter(tokenStream, new NorwegianStemmer());\n+        } else if (\"minimal_norwegian\".equalsIgnoreCase(language)) {\n+            return new NorwegianMinimalStemFilter(tokenStream);\n         } else if (\"porter\".equalsIgnoreCase(language)) {\n             return new PorterStemFilter(tokenStream);\n         } else if (\"porter2\".equalsIgnoreCase(language)) {",
    "output": "Add norwegian minimal stemmer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java b/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java\n--- a/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java\n+++ b/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java\n@@ -49,7 +49,7 @@ public PrioritizedEsThreadPoolExecutor(int corePoolSize, int initialWorkQueuSize\n \n     @Override\n     public void execute(Runnable command) {\n-        if (!(command instanceof PrioritizedRunnable)) {\n+        if (!(command instanceof Comparable)) {\n             command = PrioritizedRunnable.wrap(command, Priority.NORMAL);\n         }\n         super.execute(command);",
    "output": "Fix a bug in PrioritizedThreadPoolExecutor: now execute(Runnable) verifies the command is added as Comparable"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java b/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java\n--- a/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java\n+++ b/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java\n@@ -47,6 +47,14 @@ public PrioritizedEsThreadPoolExecutor(int corePoolSize, int initialWorkQueuSize\n         super(corePoolSize, maximumPoolSize, keepAliveTime, unit, new PriorityBlockingQueue<Runnable>(initialWorkQueuSize), threadFactory, handler);\n     }\n \n+    @Override\n+    public void execute(Runnable command) {\n+        if (!(command instanceof PrioritizedRunnable)) {\n+            command = PrioritizedRunnable.wrap(command, Priority.NORMAL);\n+        }\n+        super.execute(command);\n+    }\n+\n     @Override\n     protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {\n         if (!(runnable instanceof PrioritizedRunnable)) {",
    "output": "Fix a bug in PrioritizedThreadPoolExecutor: now execute(Runnable) verifies the command is added as PrioritizedRunnable"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java b/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/search/suggest/SuggestSearchTests.java\n@@ -304,7 +304,7 @@ public void testSizeAndSort() throws Exception {\n                 .addSuggestion(fuzzySuggestion(\"size3SortScoreFirst\")\n                         .setSize(3).setMinDocFreq(0).setField(\"field1\").setSuggestMode(\"always\"))\n                 .addSuggestion(fuzzySuggestion(\"size10SortScoreFirst\")\n-                        .setSize(10).setMinDocFreq(0).setField(\"field1\").setSuggestMode(\"always\"))\n+                        .setSize(10).setMinDocFreq(0).setField(\"field1\").setSuggestMode(\"always\").setShardSize(50))\n                 .addSuggestion(fuzzySuggestion(\"size3SortScoreFirstMaxEdits1\")\n                         .setMaxEdits(1)\n                         .setSize(10).setMinDocFreq(0).setField(\"field1\").setSuggestMode(\"always\"))",
    "output": "Fix size assertion failure"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java b/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java\n--- a/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java\n+++ b/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java\n@@ -78,7 +78,7 @@ public void inStage(Stage stage) {\n     }\n \n     public void finishStage(Stage stage) {\n-        assert currentState == stage;\n+        assert currentState == stage : \"Expected stage \" + stage + \" but was stage \" + currentState;\n         this.currentState = Stage.NA;\n     }\n ",
    "output": "Add more info to assert"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java b/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/percolator/RecoveryPercolatorTests.java\n@@ -62,7 +62,7 @@ public void testRestartNodePercolator1() throws Exception {\n         cleanAndCloseNodes();\n \n         logger.info(\"--> starting 1 nodes\");\n-        startNode(\"node1\", settingsBuilder().put(\"gateway.type\", \"local\"));\n+        startNode(\"node1\", settingsBuilder().put(\"gateway.type\", \"local\").put(\"action.wait_on_mapping_change\", true));\n \n         Client client = client(\"node1\");\n         client.admin().indices().prepareCreate(\"test\").setSettings(settingsBuilder().put(\"index.number_of_shards\", 1)).execute().actionGet();\n@@ -108,7 +108,7 @@ public void testRestartNodePercolator2() throws Exception {\n         cleanAndCloseNodes();\n \n         logger.info(\"--> starting 1 nodes\");\n-        startNode(\"node1\", settingsBuilder().put(\"gateway.type\", \"local\"));\n+        startNode(\"node1\", settingsBuilder().put(\"gateway.type\", \"local\").put(\"action.wait_on_mapping_change\", true));\n \n         Client client = client(\"node1\");\n         client.admin().indices().prepareCreate(\"test\").setSettings(settingsBuilder().put(\"index.number_of_shards\", 1)).execute().actionGet();",
    "output": "Improve stability of RecoveryPercolatorTests Without \"action.wait_on_mapping_change\" setting set to true, the test node might get shutdown before updated mapping is saved"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/unit/node/internal/InternalSettingsPerparerTests.java b/src/test/java/org/elasticsearch/test/unit/node/internal/InternalSettingsPerparerTests.java\n--- a/src/test/java/org/elasticsearch/test/unit/node/internal/InternalSettingsPerparerTests.java\n+++ b/src/test/java/org/elasticsearch/test/unit/node/internal/InternalSettingsPerparerTests.java\n@@ -23,16 +23,27 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.env.Environment;\n import org.elasticsearch.node.internal.InternalSettingsPerparer;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.Test;\n \n import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.equalTo;\n \n public class InternalSettingsPerparerTests {\n+    @BeforeMethod\n+    public void setupSystemProperties() {\n+        System.setProperty(\"es.node.zone\", \"foo\");\n+    }\n+\n+    @AfterMethod\n+    public void cleanupSystemProperties() {\n+        System.clearProperty(\"es.node.zone\");\n+    }\n+\n     @Test\n     public void testIgnoreSystemProperties() {\n-        System.setProperty(\"es.node.zone\", \"foo\");\n         Tuple<Settings, Environment> tuple = InternalSettingsPerparer.prepareSettings(settingsBuilder().put(\"node.zone\", \"bar\").build(), true);\n         // Should use setting from the system property\n         assertThat(tuple.v1().get(\"node.zone\"), equalTo(\"foo\"));",
    "output": "Add proper cleanup to InternalSettingsPerparerTests"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java b/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n--- a/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n+++ b/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java\n@@ -3,7 +3,7 @@\n import com.ibm.icu.text.Collator;\n import com.ibm.icu.text.RuleBasedCollator;\n import com.ibm.icu.util.ULocale;\n-import org.apache.lucene.analysis.KeywordTokenizer;\n+import org.apache.lucene.analysis.core.KeywordTokenizer;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.elasticsearch.common.inject.Injector;",
    "output": "Upgrade to Lucene 4.1"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java b/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java\n--- a/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java\n@@ -92,12 +92,18 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n                     minimumShouldMatch = parser.textOrNull();\n                 } else if (\"boost\".equals(currentFieldName)) {\n                     boost = parser.floatValue();\n+                } else {\n+                    throw new QueryParsingException(parseContext.index(), \"[terms] query does not support [\" + currentFieldName + \"]\");\n                 }\n             } else {\n                 throw new QueryParsingException(parseContext.index(), \"[terms] query does not support [\" + currentFieldName + \"]\");\n             }\n         }\n \n+        if (fieldName == null) {\n+            throw new QueryParsingException(parseContext.index(), \"No field specified for terms query\");\n+        }\n+\n         FieldMapper mapper = null;\n         MapperService.SmartNameFieldMappers smartNameFieldMappers = parseContext.smartFieldMappers(fieldName);\n         String[] previousTypes = null;",
    "output": "Add additional query validation to the terms query parser"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/ordinals/SparseMultiArrayOrdinals.java b/src/main/java/org/elasticsearch/index/fielddata/ordinals/SparseMultiArrayOrdinals.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/ordinals/SparseMultiArrayOrdinals.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/ordinals/SparseMultiArrayOrdinals.java\n@@ -76,9 +76,7 @@ public Object getBackingStorage() {\n     @Override\n     public long getMemorySizeInBytes() {\n         if (size == -1) {\n-            long size = 0;\n-            size += RamUsage.NUM_BYTES_ARRAY_HEADER;\n-            this.size = pool.getMemorySizeInBytes();\n+            size = (RamUsage.NUM_BYTES_ARRAY_HEADER + (RamUsage.NUM_BYTES_INT * lookup.length)) + pool.getMemorySizeInBytes();\n         }\n         return size;\n     }",
    "output": "Fix getMemorySizeInBytes in SparseMultiArrayOrdinals"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/search/stats/SearchStatsTests.java b/src/test/java/org/elasticsearch/test/integration/search/stats/SearchStatsTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/search/stats/SearchStatsTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/search/stats/SearchStatsTests.java\n@@ -63,11 +63,16 @@ public void testSimpleStats() throws Exception {\n \n         for (int i = 0; i < 500; i++) {\n             client.prepareIndex(\"test1\", \"type\", Integer.toString(i)).setSource(\"field\", \"value\").execute().actionGet();\n+            if (i == 10) {\n+                client.admin().indices().prepareRefresh(\"test1\").execute().actionGet();\n+            }\n         }\n         for (int i = 0; i < 500; i++) {\n             client.prepareIndex(\"test2\", \"type\", Integer.toString(i)).setSource(\"field\", \"value\").execute().actionGet();\n+            if (i == 10) {\n+                client.admin().indices().prepareRefresh(\"test1\").execute().actionGet();\n+            }\n         }\n-\n         for (int i = 0; i < 200; i++) {\n             client.prepareSearch().setQuery(QueryBuilders.termQuery(\"field\", \"value\")).setStats(\"group1\", \"group2\").execute().actionGet();\n         }",
    "output": "Improve SearchStatsTests Added refresh to guarantee that at least something will be fetched on a fast computer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/nested/BlockJoinQuery.java b/src/main/java/org/elasticsearch/index/search/nested/BlockJoinQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/nested/BlockJoinQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/nested/BlockJoinQuery.java\n@@ -295,11 +295,11 @@ public int nextDoc() throws IOException {\n                 }\n \n                 int totalScore = 0;\n-                int totalFreq = 0;\n                 float maxScore = Float.NEGATIVE_INFINITY;\n                 int maxFreq = 0;\n \n                 childDocUpto = 0;\n+                parentFreq = 0;\n                 do {\n \n                     //System.out.println(\"  c=\" + nextChildDoc);\n@@ -318,7 +318,7 @@ public int nextDoc() throws IOException {\n                         maxScore = Math.max(childScore, maxScore);\n                         maxFreq = Math.max(childFreq, maxFreq);\n                         totalScore += childScore;\n-                        totalFreq += childFreq;\n+                        parentFreq += childFreq;\n                     }\n \n                     // CHANGE:\n@@ -334,15 +334,12 @@ public int nextDoc() throws IOException {\n                 switch (scoreMode) {\n                     case Avg:\n                         parentScore = totalScore / childDocUpto;\n-                        parentFreq = totalFreq / childDocUpto;\n                         break;\n                     case Max:\n                         parentScore = maxScore;\n-                        parentFreq = maxFreq;\n                         break;\n                     case Total:\n                         parentScore = totalScore;\n-                        parentFreq = totalFreq;\n                         break;\n                     case None:\n                         break;",
    "output": "Make BlockJoinScorer#freq() method handle freqs correctly (as is done in ToParentBlockJoinQuery)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java b/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java\n@@ -113,10 +113,10 @@ public <IFD extends IndexFieldData> IFD getForField(FieldMapper mapper) {\n     }\n \n     public <IFD extends IndexFieldData> IFD getForField(FieldMapper.Names fieldNames, FieldDataType type) {\n-        IndexFieldData fieldData = loadedFieldData.get(type.getType());\n+        IndexFieldData fieldData = loadedFieldData.get(fieldNames.indexName());\n         if (fieldData == null) {\n             synchronized (loadedFieldData) {\n-                fieldData = loadedFieldData.get(type.getType());\n+                fieldData = loadedFieldData.get(fieldNames.indexName());\n                 if (fieldData == null) {\n                     IndexFieldData.Builder builder = null;\n                     if (type.getFormat() != null) {",
    "output": "Fix small bug. Index name should be used to lookup entry"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n--- a/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n+++ b/src/main/java/org/elasticsearch/common/lucene/Lucene.java\n@@ -42,7 +42,7 @@\n  */\n public class Lucene {\n \n-    public static final Version VERSION = Version.LUCENE_40;\n+    public static final Version VERSION = Version.LUCENE_41;\n     public static final Version ANALYZER_VERSION = VERSION;\n     public static final Version QUERYPARSER_VERSION = VERSION;\n \n@@ -57,6 +57,9 @@ public static Version parseVersion(@Nullable String version, Version defaultVers\n         if (version == null) {\n             return defaultVersion;\n         }\n+        if (\"4.1\".equals(version)) {\n+            return Version.LUCENE_41;\n+        }\n         if (\"4.0\".equals(version)) {\n             return Version.LUCENE_40;\n         }",
    "output": "Upgrade Lucene version"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java b/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/store/IndicesStoreTests.java\n@@ -108,7 +108,7 @@ public void shardsCleanup() {\n         startNode(\"server2\");\n \n         logger.info(\"--> running cluster_health\");\n-        clusterHealth = client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();\n+        clusterHealth = client(\"server2\").admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();\n         logger.info(\"--> done cluster_health, status \" + clusterHealth.status());\n \n         logger.info(\"--> making sure that shard and it's replica are allocated on server1 and server3 but not on server2\");",
    "output": "Improve stability of the shardsCleanup test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/facet/statistical/StatisticalFacetProcessor.java b/src/main/java/org/elasticsearch/search/facet/statistical/StatisticalFacetProcessor.java\n--- a/src/main/java/org/elasticsearch/search/facet/statistical/StatisticalFacetProcessor.java\n+++ b/src/main/java/org/elasticsearch/search/facet/statistical/StatisticalFacetProcessor.java\n@@ -91,7 +91,7 @@ public FacetCollector parse(String facetName, XContentParser parser, SearchConte\n         if (fieldsNames != null) {\n             IndexNumericFieldData[] indexFieldDatas = new IndexNumericFieldData[fieldsNames.length];\n             for (int i = 0; i < fieldsNames.length; i++) {\n-                FieldMapper fieldMapper = context.mapperService().smartNameFieldMapper(fieldsNames[i]);\n+                FieldMapper fieldMapper = context.smartNameFieldMapper(fieldsNames[i]);\n                 if (fieldMapper == null) {\n                     throw new FacetPhaseExecutionException(facetName, \"No mapping found for field [\" + fieldsNames[i] + \"]\");\n                 }\n@@ -103,7 +103,7 @@ public FacetCollector parse(String facetName, XContentParser parser, SearchConte\n             throw new FacetPhaseExecutionException(facetName, \"statistical facet requires either [script] or [field] to be set\");\n         }\n         if (field != null) {\n-            FieldMapper fieldMapper = context.mapperService().smartNameFieldMapper(field);\n+            FieldMapper fieldMapper = context.smartNameFieldMapper(field);\n             if (fieldMapper == null) {\n                 throw new FacetPhaseExecutionException(facetName, \"No mapping found for field [\" + field + \"]\");\n             }",
    "output": "Use smartNameMapper on context"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/fielddata/ordinals/SingleArrayOrdinals.java b/src/main/java/org/elasticsearch/index/fielddata/ordinals/SingleArrayOrdinals.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/ordinals/SingleArrayOrdinals.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/ordinals/SingleArrayOrdinals.java\n@@ -112,7 +112,7 @@ public int getOrd(int docId) {\n         public IntArrayRef getOrds(int docId) {\n             int ordinal = ordinals[docId];\n             if (ordinal == 0) return IntArrayRef.EMPTY;\n-            intsScratch.values[0] = docId;\n+            intsScratch.values[0] = ordinal;\n             return intsScratch;\n         }\n \n\ndiff --git a/src/main/java/org/elasticsearch/index/fielddata/ordinals/SinglePackedOrdinals.java b/src/main/java/org/elasticsearch/index/fielddata/ordinals/SinglePackedOrdinals.java\n--- a/src/main/java/org/elasticsearch/index/fielddata/ordinals/SinglePackedOrdinals.java\n+++ b/src/main/java/org/elasticsearch/index/fielddata/ordinals/SinglePackedOrdinals.java\n@@ -116,7 +116,7 @@ public int getOrd(int docId) {\n         public IntArrayRef getOrds(int docId) {\n             int ordinal = (int) reader.get(docId);\n             if (ordinal == 0) return IntArrayRef.EMPTY;\n-            intsScratch.values[0] = docId;\n+            intsScratch.values[0] = ordinal;\n             return intsScratch;\n         }\n ",
    "output": "Fix getOrds on single array ords"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/TransportAction.java b/src/main/java/org/elasticsearch/action/support/TransportAction.java\n--- a/src/main/java/org/elasticsearch/action/support/TransportAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/TransportAction.java\n@@ -60,6 +60,7 @@ public void execute(Request request, ActionListener<Response> listener) {\n         try {\n             doExecute(request, listener);\n         } catch (Exception e) {\n+            logger.trace(\"Error during transport action execution.\", e);\n             listener.onFailure(e);\n         }\n     }",
    "output": "Add trace log statement, to catch stacktraces"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n@@ -701,7 +701,7 @@ public int numberOfShards() {\n         return this.numberOfShards;\n     }\n \n-    public int getnumberOfShards() {\n+    public int getNumberOfShards() {\n         return numberOfShards();\n     }\n ",
    "output": "Use camelcase for getters"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java b/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java\n--- a/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java\n+++ b/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java\n@@ -52,6 +52,7 @@\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.xcontent.XContentHelper;\n import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.engine.DocumentAlreadyExistsException;\n import org.elasticsearch.index.engine.DocumentMissingException;\n import org.elasticsearch.index.engine.DocumentSourceMissingException;\n import org.elasticsearch.index.engine.VersionConflictEngineException;\n@@ -252,7 +253,7 @@ public void onResponse(IndexResponse response) {\n                 @Override\n                 public void onFailure(Throwable e) {\n                     e = ExceptionsHelper.unwrapCause(e);\n-                    if (e instanceof VersionConflictEngineException) {\n+                    if (e instanceof VersionConflictEngineException || e instanceof DocumentAlreadyExistsException) {\n                         if (retryCount < request.retryOnConflict()) {\n                             threadPool.executor(executor()).execute(new Runnable() {\n                                 @Override",
    "output": "Fix document already exists error when concurrently sending update request with upsert using the same id"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java\n--- a/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java\n+++ b/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java\n@@ -192,6 +192,15 @@ public String readOptionalUTF() throws IOException {\n         return null;\n     }\n \n+    @Nullable\n+    public Text readOptionalText() throws IOException {\n+        int length = readInt();\n+        if (length == -1) {\n+            return null;\n+        }\n+        return new StringAndBytesText(readBytesReference(length));\n+    }\n+\n     public Text readText() throws IOException {\n         // use StringAndBytes so we can cache the string if its ever converted to it\n         int length = readInt();\n\ndiff --git a/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java b/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java\n--- a/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java\n+++ b/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java\n@@ -184,6 +184,14 @@ public void writeOptionalString(@Nullable String str) throws IOException {\n         }\n     }\n \n+    public void writeOptionalText(@Nullable Text text) throws IOException {\n+        if (text == null) {\n+            writeInt(-1);\n+        } else {\n+            writeText(text);\n+        }\n+    }\n+\n     public void writeText(Text text) throws IOException {\n         if (!text.hasBytes() && seekPositionSupported()) {\n             long pos1 = position();",
    "output": "Add read/write optional text"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java b/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/gateway/local/SimpleRecoveryLocalGatewayTests.java\n@@ -95,6 +95,7 @@ public void testX() throws Exception {\n         assertThat(clusterHealth.timedOut(), equalTo(false));\n         assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.YELLOW));\n \n+        node1.client().admin().indices().prepareRefresh().execute().actionGet();\n         assertThat(node1.client().prepareCount().setQuery(termQuery(\"appAccountIds\", 179)).execute().actionGet().count(), equalTo(2l));\n \n         closeNode(\"node1\");\n@@ -106,6 +107,7 @@ public void testX() throws Exception {\n         assertThat(clusterHealth.timedOut(), equalTo(false));\n         assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.YELLOW));\n \n+        node1.client().admin().indices().prepareRefresh().execute().actionGet();\n         assertThat(node1.client().prepareCount().setQuery(termQuery(\"appAccountIds\", 179)).execute().actionGet().count(), equalTo(2l));\n     }\n ",
    "output": "Add refresh before calling count"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java b/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java\n@@ -28,8 +28,7 @@\n import org.elasticsearch.node.Node;\n import org.elasticsearch.node.internal.InternalNode;\n import org.elasticsearch.test.integration.AbstractNodesTests;\n-import org.testng.annotations.AfterClass;\n-import org.testng.annotations.AfterTest;\n+import org.testng.annotations.AfterMethod;\n import org.testng.annotations.Test;\n \n import static org.hamcrest.MatcherAssert.assertThat;\n@@ -42,7 +41,7 @@\n public class HunspellServiceTests extends AbstractNodesTests {\n \n \n-    @AfterTest\n+    @AfterMethod\n     public void closeNodes() {\n         closeAllNodes();\n     }",
    "output": "Fix hunspell test to clean up properly, this time, for realz"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java b/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/indices/analyze/HunspellServiceTests.java\n@@ -29,6 +29,7 @@\n import org.elasticsearch.node.internal.InternalNode;\n import org.elasticsearch.test.integration.AbstractNodesTests;\n import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterTest;\n import org.testng.annotations.Test;\n \n import static org.hamcrest.MatcherAssert.assertThat;\n@@ -41,7 +42,7 @@\n public class HunspellServiceTests extends AbstractNodesTests {\n \n \n-    @AfterClass\n+    @AfterTest\n     public void closeNodes() {\n         closeAllNodes();\n     }",
    "output": "Fix hunspell test to clean up properly"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/Mapper.java b/src/main/java/org/elasticsearch/index/mapper/Mapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/Mapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/Mapper.java\n@@ -20,6 +20,8 @@\n package org.elasticsearch.index.mapper;\n \n import com.google.common.collect.ImmutableMap;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.cluster.metadata.IndexMetaData;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.settings.Settings;\n@@ -55,6 +57,14 @@ public ContentPath path() {\n         public Settings indexSettings() {\n             return this.indexSettings;\n         }\n+\n+        @Nullable\n+        public Version indexCreatedVersion() {\n+            if (indexSettings == null) {\n+                return null;\n+            }\n+            return indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED, null);\n+        }\n     }\n \n     public static abstract class Builder<T extends Builder, Y extends Mapper> {",
    "output": "Add simple way to get the index creation version when building a mapper"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java\n@@ -117,10 +117,6 @@ public String value(Object value) {\n         return value.toString();\n     }\n \n-    public Term term(String value) {\n-        return names().createIndexNameTerm(value);\n-    }\n-\n     @Override\n     public Query termQuery(Object value, @Nullable QueryParseContext context) {\n         return new XConstantScoreQuery(context.cacheFilter(termFilter(value, context), null));",
    "output": "Remove unused method"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/threadpool/ThreadPoolStats.java b/src/main/java/org/elasticsearch/threadpool/ThreadPoolStats.java\n--- a/src/main/java/org/elasticsearch/threadpool/ThreadPoolStats.java\n+++ b/src/main/java/org/elasticsearch/threadpool/ThreadPoolStats.java\n@@ -153,7 +153,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n                 builder.field(Fields.REJECTED, rejected);\n             }\n             if (largest != -1) {\n-                builder.field(Fields.LARGEST, rejected);\n+                builder.field(Fields.LARGEST, largest);\n             }\n             if (completed != -1) {\n                 builder.field(Fields.COMPLETED, completed);",
    "output": "Fix thread pool stats largest"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java\n@@ -324,7 +324,7 @@ public XContentBuilder toXContent(XContentBuilder builder, Params params) throws\n             builder.field(\"store\", fieldType.stored());\n         }\n         if (fieldType.indexed() != Defaults.FIELD_TYPE.indexed()) {\n-            builder.field(\"index\", fieldType.indexed());\n+            builder.field(\"index\", indexTokenizeOptionToString(fieldType.indexed(), fieldType.tokenized()));\n         }\n         if (path != Defaults.PATH) {\n             builder.field(\"path\", path);",
    "output": "Fix index xcontent flag with id"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java b/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/threadpool/SimpleThreadPoolTests.java\n@@ -122,6 +122,7 @@ public void run() {\n                 .put(\"threadpool.search.keep_alive\", \"15s\")\n                 .put(\"threadpool.search.capacity\", \"100\")\n                 .build()).execute().actionGet();\n+        Thread.sleep(200);\n         nodesInfoResponse = client2.admin().cluster().prepareNodesInfo().all().execute().actionGet();\n         for (int i = 0; i < 2; i++) {\n             NodeInfo nodeInfo = nodesInfoResponse.nodes()[i];",
    "output": "Add a sleep to make sure settings are applied"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java b/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java\n--- a/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java\n+++ b/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java\n@@ -129,7 +129,7 @@ public MultiSearchRequest add(BytesReference data, boolean contentUnsafe,\n                             } else if (token == XContentParser.Token.START_ARRAY) {\n                                 if (\"index\".equals(currentFieldName) || \"indices\".equals(currentFieldName)) {\n                                     searchRequest.indices(parseArray(parser));\n-                                } else if (\"type\".equals(currentFieldName) || \"type\".equals(currentFieldName)) {\n+                                } else if (\"type\".equals(currentFieldName) || \"types\".equals(currentFieldName)) {\n                                     searchRequest.types(parseArray(parser));\n                                 } else {\n                                     throw new ElasticSearchParseException(currentFieldName + \" doesn't support arrays\");",
    "output": "Fix type to types"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/Analysis.java b/src/main/java/org/elasticsearch/index/analysis/Analysis.java\n--- a/src/main/java/org/elasticsearch/index/analysis/Analysis.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/Analysis.java\n@@ -163,7 +163,7 @@ public static CharArraySet parseStopWords(Environment env, Settings settings, Ch\n         }\n         List<String> pathLoadedStopWords = getWordList(env, settings, \"stopwords\");\n         if (pathLoadedStopWords != null) {\n-            return resolveNamedStopWords(stopWords, version, ignore_case);\n+            return resolveNamedStopWords(pathLoadedStopWords, version, ignore_case);\n         }\n \n         return defaultStopWords;",
    "output": "Fix copy/paste bug where null stopWords is passed causing an NPE"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/child/TopChildrenQuery.java b/src/main/java/org/elasticsearch/index/search/child/TopChildrenQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/child/TopChildrenQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/child/TopChildrenQuery.java\n@@ -240,10 +240,6 @@ public Query getQuery() {\n             return TopChildrenQuery.this;\n         }\n \n-        public float getValue() {\n-            return getBoost();\n-        }\n-\n         @Override\n         public float getValueForNormalization() throws IOException {\n             float sum = queryWeight.getValueForNormalization();",
    "output": "Remove unused code"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/Uid.java b/src/main/java/org/elasticsearch/index/mapper/Uid.java\n--- a/src/main/java/org/elasticsearch/index/mapper/Uid.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/Uid.java\n@@ -103,8 +103,8 @@ public static Uid createUid(String uid) {\n     public static BytesRef createUidAsBytes(String type, String id) {\n         BytesRef ref = new BytesRef(type.length() + 1 + id.length());\n         ref.copyChars(type);\n-        ref.copyBytes(DELIMITER_BYTES);\n-        ref.copyChars(id);\n+        ref.append(DELIMITER_BYTES);\n+        ref.append(new BytesRef(id));\n         return ref;\n     }\n ",
    "output": "Fix creating uid to bytes"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java\n@@ -21,7 +21,6 @@\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import org.apache.lucene.document.Document;\n import org.apache.lucene.document.Field;\n import org.apache.lucene.document.FieldType;\n import org.apache.lucene.index.FieldInfo.IndexOptions;\n@@ -134,11 +133,6 @@ public String path() {\n         return this.path;\n     }\n \n-    public String value(Document document) {\n-        Field field = (Field) document.getField(names.indexName());\n-        return field == null ? null : value(field);\n-    }\n-\n     @Override\n     public String value(Object value) {\n         return String.valueOf(value);",
    "output": "Remove unused code"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java b/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/FieldMapper.java\n@@ -48,8 +48,6 @@ public static class Names {\n \n         private final String sourcePath;\n \n-        private final Term indexNameTermFactory;\n-\n         public Names(String name) {\n             this(name, name, name, name);\n         }\n@@ -64,7 +62,6 @@ public Names(String name, String indexName, String indexNameClean, String fullNa\n             this.indexNameClean = indexNameClean.intern();\n             this.fullName = fullName.intern();\n             this.sourcePath = sourcePath == null ? this.fullName : sourcePath.intern();\n-            this.indexNameTermFactory = new Term(indexName, \"\");\n         }\n \n         /**\n@@ -103,13 +100,6 @@ public String sourcePath() {\n             return sourcePath;\n         }\n \n-        /**\n-         * The index name term that can be used as a factory.\n-         */\n-        public Term indexNameTerm() {\n-            return this.indexNameTermFactory;\n-        }\n-\n         /**\n          * Creates a new index term based on the provided value.\n          */",
    "output": "Remove unused code"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/field/data/strings/StringFieldData.java b/src/main/java/org/elasticsearch/index/field/data/strings/StringFieldData.java\n--- a/src/main/java/org/elasticsearch/index/field/data/strings/StringFieldData.java\n+++ b/src/main/java/org/elasticsearch/index/field/data/strings/StringFieldData.java\n@@ -46,7 +46,8 @@ protected long computeSizeInBytes() {\n         long size = RamUsage.NUM_BYTES_ARRAY_HEADER;\n         for (BytesRef value : values) {\n             if (value != null) {\n-                size += RamUsage.NUM_BYTES_OBJECT_HEADER + (value.length + (2 * RamUsage.NUM_BYTES_INT));\n+                size += RamUsage.NUM_BYTES_OBJECT_REF + RamUsage.NUM_BYTES_OBJECT_HEADER +\n+                        RamUsage.NUM_BYTES_ARRAY_HEADER + (value.length + (2 * RamUsage.NUM_BYTES_INT));\n             }\n         }\n         return size;",
    "output": "Improve the size computation in StringFieldData#computeSizeInBytes()"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/mapper/internal/AnalyzerMapper.java b/src/main/java/org/elasticsearch/index/mapper/internal/AnalyzerMapper.java\n--- a/src/main/java/org/elasticsearch/index/mapper/internal/AnalyzerMapper.java\n+++ b/src/main/java/org/elasticsearch/index/mapper/internal/AnalyzerMapper.java\n@@ -20,11 +20,13 @@\n package org.elasticsearch.index.mapper.internal;\n \n import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.index.IndexableField;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.index.mapper.*;\n \n import java.io.IOException;\n+import java.util.List;\n import java.util.Map;\n \n import static org.elasticsearch.index.mapper.MapperBuilders.analyzer;\n@@ -83,7 +85,7 @@ public AnalyzerMapper() {\n     }\n \n     public AnalyzerMapper(String path) {\n-        this.path = path;\n+        this.path = path.intern();\n     }\n \n     @Override\n@@ -99,7 +101,15 @@ public void preParse(ParseContext context) throws IOException {\n     public void postParse(ParseContext context) throws IOException {\n         Analyzer analyzer = context.docMapper().mappers().indexAnalyzer();\n         if (path != null) {\n-            String value = context.doc().get(path);\n+            String value = null;\n+            List<IndexableField> fields = context.doc().getFields();\n+            for (int i = 0, fieldsSize = fields.size(); i < fieldsSize; i++) {\n+                IndexableField field = fields.get(i);\n+                if (field.name() == path) {\n+                    value = field.stringValue();\n+                    break;\n+                }\n+            }\n             if (value == null) {\n                 value = context.ignoredValue(path);\n             }",
    "output": "Improve fields iteration trying to find customer valued analyzer"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -96,6 +96,10 @@ public class Version implements Serializable {\n     public static final Version V_0_20_0_RC1 = new Version(V_0_20_0_RC1_ID, false);\n     public static final int V_0_20_0_ID = /*00*/200099;\n     public static final Version V_0_20_0 = new Version(V_0_20_0_ID, false);\n+    public static final int V_0_20_1_ID = /*00*/200199;\n+    public static final Version V_0_20_1 = new Version(V_0_20_1_ID, false);\n+    public static final int V_0_20_2_ID = /*00*/200299;\n+    public static final Version V_0_20_2 = new Version(V_0_20_2_ID, false);\n \n     public static final int V_0_21_0_Beta1_ID = /*00*/210001;\n     public static final Version V_0_21_0_Beta1 = new Version(V_0_21_0_Beta1_ID, true);\n@@ -111,6 +115,10 @@ public static Version fromId(int id) {\n             case V_0_21_0_Beta1_ID:\n                 return V_0_21_0_Beta1;\n \n+            case V_0_20_2_ID:\n+                return V_0_20_2;\n+            case V_0_20_1_ID:\n+                return V_0_20_1;\n             case V_0_20_0_ID:\n                 return V_0_20_0;\n             case V_0_20_0_RC1_ID:",
    "output": "Add 0.20 versions"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -94,8 +94,8 @@ public class Version implements Serializable {\n \n     public static final int V_0_20_0_RC1_ID = /*00*/200051;\n     public static final Version V_0_20_0_RC1 = new Version(V_0_20_0_RC1_ID, false);\n-    public static final int V_0_20_0_RC2_ID = /*00*/200052;\n-    public static final Version V_0_20_0_RC2 = new Version(V_0_20_0_RC2_ID, false);\n+    public static final int V_0_20_0_ID = /*00*/200099;\n+    public static final Version V_0_20_0 = new Version(V_0_20_0_ID, false);\n \n     public static final int V_0_21_0_Beta1_ID = /*00*/210001;\n     public static final Version V_0_21_0_Beta1 = new Version(V_0_21_0_Beta1_ID, true);\n@@ -111,8 +111,8 @@ public static Version fromId(int id) {\n             case V_0_21_0_Beta1_ID:\n                 return V_0_21_0_Beta1;\n \n-            case V_0_20_0_RC2_ID:\n-                return V_0_20_0_RC2;\n+            case V_0_20_0_ID:\n+                return V_0_20_0;\n             case V_0_20_0_RC1_ID:\n                 return V_0_20_0_RC1;\n ",
    "output": "Use the 0.20.0 version"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/node/service/NodeService.java b/src/main/java/org/elasticsearch/node/service/NodeService.java\n--- a/src/main/java/org/elasticsearch/node/service/NodeService.java\n+++ b/src/main/java/org/elasticsearch/node/service/NodeService.java\n@@ -61,7 +61,7 @@ public class NodeService extends AbstractComponent {\n     @Nullable\n     private String hostname;\n \n-    private final String version;\n+    private final Version version;\n \n     @Inject\n     public NodeService(Settings settings, ThreadPool threadPool, MonitorService monitorService, Discovery discovery, ClusterService clusterService, TransportService transportService, IndicesService indicesService) {\n@@ -76,7 +76,7 @@ public NodeService(Settings settings, ThreadPool threadPool, MonitorService moni\n         if (address != null) {\n             this.hostname = address.getHostName();\n         }\n-        this.version = Version.CURRENT.toString();\n+        this.version = Version.CURRENT;\n     }\n \n     public void setHttpServer(@Nullable HttpServer httpServer) {",
    "output": "Change es version from string to class Version"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java b/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n@@ -111,6 +111,8 @@ public synchronized AmazonS3 client() {\n                 endpoint = \"s3-ap-southeast-1.amazonaws.com\";\n             } else if (\"ap-southeast-1\".equals(region)) {\n                 endpoint = \"s3-ap-southeast-1.amazonaws.com\";\n+            } else if (\"ap-southeast-2\".equals(region)) {\n+                endpoint = \"s3-ap-southeast-2.amazonaws.com\";\n             } else if (\"ap-northeast\".equals(region)) {\n                 endpoint = \"s3-ap-northeast-1.amazonaws.com\";\n             } else if (\"ap-northeast-1\".equals(region)) {",
    "output": "Upgrade src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java Add support for Asia Pacific (Sydney) Region"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/index/IndexRequest.java b/src/main/java/org/elasticsearch/action/index/IndexRequest.java\n--- a/src/main/java/org/elasticsearch/action/index/IndexRequest.java\n+++ b/src/main/java/org/elasticsearch/action/index/IndexRequest.java\n@@ -133,13 +133,22 @@ public IndexRequest() {\n     }\n \n     /**\n-     * Constructs a new index request against the specific index. The {@link #type(String)},\n-     * {@link #id(String)} and {@link #source(byte[])} must be set.\n+     * Constructs a new index request against the specific index. The {@link #type(String)}\n+     * {@link #source(byte[])} must be set. \n      */\n     public IndexRequest(String index) {\n         this.index = index;\n     }\n \n+    /**\n+     * Constructs a new index request against the specific index and type. The \n+     * {@link #source(byte[])} must be set.\n+     */\n+    public IndexRequest(String index, String type) {\n+        this.index = index;\n+        this.type = type;\n+   }\n+\n     /**\n      * Constructs a new index request against the index, type, id and using the source.\n      *",
    "output": "Add constructor IndexRequest(String index, String type) and fix javadoc"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/search/MultiSearchResponse.java b/src/main/java/org/elasticsearch/action/search/MultiSearchResponse.java\n--- a/src/main/java/org/elasticsearch/action/search/MultiSearchResponse.java\n+++ b/src/main/java/org/elasticsearch/action/search/MultiSearchResponse.java\n@@ -9,6 +9,7 @@\n import org.elasticsearch.common.xcontent.ToXContent;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.common.xcontent.XContentBuilderString;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n \n import java.io.IOException;\n import java.util.Iterator;\n@@ -168,4 +169,17 @@ static final class Fields {\n         static final XContentBuilderString RESPONSES = new XContentBuilderString(\"responses\");\n         static final XContentBuilderString ERROR = new XContentBuilderString(\"error\");\n     }\n+    \n+    @Override\n+    public String toString() {\n+        try {\n+            XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();\n+            builder.startObject();\n+            toXContent(builder, EMPTY_PARAMS);\n+            builder.endObject();\n+            return builder.string();\n+        } catch (IOException e) {\n+            return \"{ \\\"error\\\" : \\\"\" + e.getMessage() + \"\\\"}\";\n+        }\n+    }\n }",
    "output": "Add a toString() method to MultiSearchResponse"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/codecs/CodecTests.java b/src/test/java/org/elasticsearch/test/integration/codecs/CodecTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/codecs/CodecTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/codecs/CodecTests.java\n@@ -56,7 +56,7 @@ protected Client getClient() {\n     }\n \n     @Test\n-    public void testIndexOptionsWithConfiguredPostingsFormat() throws Exception {\n+    public void testFieldsWithCustomPostingsFormat() throws Exception {\n         try {\n             client.admin().indices().prepareDelete(\"test\").execute().actionGet();\n         } catch (Exception e) {\n@@ -85,7 +85,7 @@ public void testIndexOptionsWithConfiguredPostingsFormat() throws Exception {\n     }\n \n     @Test\n-    public void testIndexOptionsWithSimpleTextCodec() throws Exception {\n+    public void testIndexingWithSimpleTextCodec() throws Exception {\n         try {\n             client.admin().indices().prepareDelete(\"test\").execute().actionGet();\n         } catch (Exception e) {",
    "output": "Change test method names"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/node/internal/InternalNode.java b/src/main/java/org/elasticsearch/node/internal/InternalNode.java\n--- a/src/main/java/org/elasticsearch/node/internal/InternalNode.java\n+++ b/src/main/java/org/elasticsearch/node/internal/InternalNode.java\n@@ -88,6 +88,7 @@\n import org.elasticsearch.transport.TransportModule;\n import org.elasticsearch.transport.TransportService;\n \n+import java.util.Arrays;\n import java.util.concurrent.TimeUnit;\n \n /**\n@@ -117,6 +118,13 @@ public InternalNode(Settings pSettings, boolean loadConfigSettings) throws Elast\n         ESLogger logger = Loggers.getLogger(Node.class, tuple.v1().get(\"name\"));\n         logger.info(\"{{}}[{}]: initializing ...\", Version.CURRENT, JvmInfo.jvmInfo().pid());\n \n+        if (logger.isDebugEnabled()) {\n+            Environment env = tuple.v2();\n+            logger.debug(\"using home [{}], config [{}], data [{}], logs [{}], work [{}], plugins [{}]\",\n+                    env.homeFile(), env.configFile(), Arrays.toString(env.dataFiles()), env.logsFile(),\n+                    env.workFile(), env.pluginsFile());\n+        }\n+\n         this.pluginsService = new PluginsService(tuple.v1(), tuple.v2());\n         this.settings = pluginsService.updatedSettings();\n         this.environment = tuple.v2();",
    "output": "Add logging for environment paths on startup"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/BoolFilterBuilder.java b/src/main/java/org/elasticsearch/index/query/BoolFilterBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/BoolFilterBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/BoolFilterBuilder.java\n@@ -55,6 +55,36 @@ public BoolFilterBuilder mustNot(FilterBuilder filterBuilder) {\n         return this;\n     }\n \n+    /**\n+     * Adds multiple <i>should</i> filters.\n+     */\n+    public BoolFilterBuilder should(FilterBuilder... filterBuilders) {\n+        for (FilterBuilder filterBuilder : filterBuilders) {\n+            clauses.add(new Clause(filterBuilder, BooleanClause.Occur.SHOULD));\n+        }\n+        return this;\n+    }\n+\n+    /**\n+     * Adds multiple <i>must</i> filters.\n+     */\n+    public BoolFilterBuilder must(FilterBuilder... filterBuilders) {\n+        for (FilterBuilder filterBuilder : filterBuilders) {\n+            clauses.add(new Clause(filterBuilder, BooleanClause.Occur.MUST));\n+        }\n+        return this;\n+    }\n+\n+    /**\n+     * Adds multiple <i>must not</i> filters.\n+     */\n+    public BoolFilterBuilder mustNot(FilterBuilder... filterBuilders) {\n+        for (FilterBuilder filterBuilder : filterBuilders) {\n+            clauses.add(new Clause(filterBuilder, BooleanClause.Occur.MUST_NOT));\n+        }\n+        return this;\n+    }\n+\n     /**\n      * Adds a filter that <i>should</i> appear in the matching documents. For a boolean filter\n      * with no <tt>MUST</tt> clauses one or more <code>SHOULD</code> clauses must match a document",
    "output": "Add must/should/mustNot method variants that accepts vararg FilterBuilder instances"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java b/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java\n@@ -63,7 +63,7 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n         String[] types = RestActions.splitTypes(request.param(\"type\"));\n         IgnoreIndices ignoreIndices = null;\n         if (request.hasParam(\"ignore_indices\")) {\n-            IgnoreIndices.fromString(request.param(\"ignore_indices\"));\n+            ignoreIndices = IgnoreIndices.fromString(request.param(\"ignore_indices\"));\n         }\n \n         try {",
    "output": "Fix that the `ignore_indices` option isn't set in multi search api"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -85,6 +85,10 @@ public class Version implements Serializable {\n     public static final Version V_0_19_9 = new Version(V_0_19_9_ID, false);\n     public static final int V_0_19_10_ID = /*00*/191099;\n     public static final Version V_0_19_10 = new Version(V_0_19_10_ID, false);\n+    public static final int V_0_19_11_ID = /*00*/191199;\n+    public static final Version V_0_19_11 = new Version(V_0_19_11_ID, false);\n+    public static final int V_0_19_12_ID = /*00*/191299;\n+    public static final Version V_0_19_12 = new Version(V_0_19_12_ID, false);\n \n     public static final int V_0_20_0_RC1_ID = /*00*/200051;\n     public static final Version V_0_20_0_RC1 = new Version(V_0_20_0_RC1_ID, false);\n@@ -138,6 +142,10 @@ public static Version fromId(int id) {\n                 return V_0_19_9;\n             case V_0_19_10_ID:\n                 return V_0_19_10;\n+            case V_0_19_11_ID:\n+                return V_0_19_11;\n+            case V_0_19_12_ID:\n+                return V_0_19_12;\n \n             case V_0_18_0_ID:\n                 return V_0_18_0;",
    "output": "Add 0.19.11 and 0.19.12 versions"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n@@ -29,6 +29,7 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.settings.SettingsFilter;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentBuilderString;\n import org.elasticsearch.rest.*;\n import org.elasticsearch.rest.action.support.RestActions;\n import org.elasticsearch.rest.action.support.RestXContentBuilder;\n@@ -69,6 +70,7 @@ public void onResponse(ClusterStateResponse response) {\n                 try {\n                     XContentBuilder builder = RestXContentBuilder.restContentBuilder(request);\n                     builder.startObject();\n+                    builder.field(Fields.CLUSTER_NAME, response.clusterName().value());\n                     response.state().settingsFilter(settingsFilter).toXContent(builder, request);\n                     builder.endObject();\n                     channel.sendResponse(new XContentRestResponse(request, RestStatus.OK, builder));\n@@ -90,4 +92,8 @@ public void onFailure(Throwable e) {\n             }\n         });\n     }\n+\n+    static final class Fields {\n+        static final XContentBuilderString CLUSTER_NAME = new XContentBuilderString(\"cluster_name\");\n+    }\n }\n\\ No newline at end of file",
    "output": "Add cluster name back to cluster state API"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -88,6 +88,8 @@ public class Version implements Serializable {\n \n     public static final int V_0_20_0_RC1_ID = /*00*/200051;\n     public static final Version V_0_20_0_RC1 = new Version(V_0_20_0_RC1_ID, false);\n+    public static final int V_0_20_0_RC2_ID = /*00*/200052;\n+    public static final Version V_0_20_0_RC2 = new Version(V_0_20_0_RC2_ID, false);\n \n     public static final int V_0_21_0_Beta1_ID = /*00*/210001;\n     public static final Version V_0_21_0_Beta1 = new Version(V_0_21_0_Beta1_ID, true);\n@@ -103,6 +105,8 @@ public static Version fromId(int id) {\n             case V_0_21_0_Beta1_ID:\n                 return V_0_21_0_Beta1;\n \n+            case V_0_20_0_RC2_ID:\n+                return V_0_20_0_RC2;\n             case V_0_20_0_RC1_ID:\n                 return V_0_20_0_RC1;\n ",
    "output": "Add 0.20.0.RC2 to versions on master"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/sort/ScriptSortBuilder.java b/src/main/java/org/elasticsearch/search/sort/ScriptSortBuilder.java\n--- a/src/main/java/org/elasticsearch/search/sort/ScriptSortBuilder.java\n+++ b/src/main/java/org/elasticsearch/search/sort/ScriptSortBuilder.java\n@@ -65,6 +65,16 @@ public ScriptSortBuilder param(String name, Object value) {\n         return this;\n     }\n \n+    /**\n+     * Sets parameters for the script.\n+     *\n+     * @param params The script parameters\n+     */\n+    public ScriptSortBuilder setParams(Map<String, Object> params) {\n+        this.params = params;\n+        return this;\n+    }\n+\n     /**\n      * Sets the sort order.\n      */",
    "output": "Add method that accepts a map as script parameters"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bulk/udp/BulkUdpService.java b/src/main/java/org/elasticsearch/bulk/udp/BulkUdpService.java\n--- a/src/main/java/org/elasticsearch/bulk/udp/BulkUdpService.java\n+++ b/src/main/java/org/elasticsearch/bulk/udp/BulkUdpService.java\n@@ -176,6 +176,7 @@ class Handler extends SimpleChannelUpstreamHandler {\n         @Override\n         public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {\n             ChannelBuffer buffer = (ChannelBuffer) e.getMessage();\n+            logger.trace(\"received message size [{}]\", buffer.readableBytes());\n             try {\n                 bulkProcessor.add(new ChannelBufferBytesReference(buffer), false, null, null);\n             } catch (Exception e1) {",
    "output": "Add logging on the size of message received"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java b/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java\n--- a/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java\n+++ b/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java\n@@ -66,7 +66,7 @@ public TieredMergePolicyProvider(Store store, IndexSettingsService indexSettings\n         this.maxMergeAtOnceExplicit = componentSettings.getAsInt(\"max_merge_at_once_explicit\", 30);\n         // TODO is this really a good default number for max_merge_segment, what happens for large indices, won't they end up with many segments?\n         this.maxMergedSegment = componentSettings.getAsBytesSize(\"max_merged_segment\", componentSettings.getAsBytesSize(\"max_merge_segment\", new ByteSizeValue(5, ByteSizeUnit.GB)));\n-        this.segmentsPerTier = componentSettings.getAsDouble(\"segments_per_tier\", 9.2d);\n+        this.segmentsPerTier = componentSettings.getAsDouble(\"segments_per_tier\", 10.0d);\n         this.reclaimDeletesWeight = componentSettings.getAsDouble(\"reclaim_deletes_weight\", 2.0d);\n \n         fixSettingsIfNeeded();",
    "output": "Fix segments per tier to the proper 10 default"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/geo/ShapesAvailability.java b/src/main/java/org/elasticsearch/common/geo/ShapesAvailability.java\n--- a/src/main/java/org/elasticsearch/common/geo/ShapesAvailability.java\n+++ b/src/main/java/org/elasticsearch/common/geo/ShapesAvailability.java\n@@ -19,8 +19,7 @@\n \n package org.elasticsearch.common.geo;\n \n-import com.spatial4j.core.shape.impl.PointImpl;\n-import com.vividsolutions.jts.geom.GeometryFactory;\n+import org.elasticsearch.common.Classes;\n \n /**\n  */\n@@ -32,7 +31,7 @@ public class ShapesAvailability {\n     static {\n         boolean xSPATIAL4J_AVAILABLE;\n         try {\n-            new PointImpl(0, 0, GeoShapeConstants.SPATIAL_CONTEXT);\n+            Classes.getDefaultClassLoader().loadClass(\"com.spatial4j.core.shape.impl.PointImpl\");\n             xSPATIAL4J_AVAILABLE = true;\n         } catch (Throwable t) {\n             xSPATIAL4J_AVAILABLE = false;\n@@ -41,7 +40,7 @@ public class ShapesAvailability {\n \n         boolean xJTS_AVAILABLE;\n         try {\n-            new GeometryFactory();\n+            Classes.getDefaultClassLoader().loadClass(\"com.vividsolutions.jts.geom.GeometryFactory\");\n             xJTS_AVAILABLE = true;\n         } catch (Throwable t) {\n             xJTS_AVAILABLE = false;",
    "output": "Fix detection when JTS / spatial4j are not available"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n--- a/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n+++ b/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n@@ -112,6 +112,7 @@ public void handleException(TransportException exp) {\n     class PublishClusterStateRequest implements Streamable {\n \n         BytesReference clusterStateInBytes;\n+        Version version = Version.CURRENT;\n \n         private PublishClusterStateRequest() {\n         }\n@@ -123,6 +124,7 @@ private PublishClusterStateRequest(BytesReference clusterStateInBytes) {\n         @Override\n         public void readFrom(StreamInput in) throws IOException {\n             clusterStateInBytes = in.readBytesReference();\n+            version = in.getVersion();\n         }\n \n         @Override\n@@ -149,6 +151,7 @@ public void messageReceived(PublishClusterStateRequest request, TransportChannel\n             } else {\n                 in = CachedStreamInput.cachedHandles(request.clusterStateInBytes.streamInput());\n             }\n+            in.setVersion(request.version);\n             ClusterState clusterState = ClusterState.Builder.readFrom(in, nodesProvider.nodes().localNode());\n             listener.onNewClusterState(clusterState);\n             channel.sendResponse(VoidStreamable.INSTANCE);",
    "output": "Use the version to deserialize published cluster state"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java b/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java\n--- a/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java\n+++ b/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java\n@@ -73,13 +73,13 @@ public void sendResponse(RestResponse response) {\n             resp = new DefaultHttpResponse(HttpVersion.HTTP_1_1, status);\n         }\n         if (RestUtils.isBrowser(request.getHeader(HttpHeaders.Names.USER_AGENT))) {\n-            // add support for cross origin\n+            // Add support for cross-origin Ajax requests (CORS)\n             resp.addHeader(\"Access-Control-Allow-Origin\", \"*\");\n             if (request.getMethod() == HttpMethod.OPTIONS) {\n-                // also add more access control parameters\n+                // Allow Ajax requests based on the CORS \"preflight\" request\n                 resp.addHeader(\"Access-Control-Max-Age\", 1728000);\n-                resp.addHeader(\"Access-Control-Allow-Methods\", \"PUT, DELETE\");\n-                resp.addHeader(\"Access-Control-Allow-Headers\", \"X-Requested-With\");\n+                resp.addHeader(\"Access-Control-Allow-Methods\", \"OPTIONS, HEAD, GET, POST, PUT, DELETE\");\n+                resp.addHeader(\"Access-Control-Allow-Headers\", \"X-Requested-With, Content-Type, Content-Length\");\n             }\n         }\n ",
    "output": "Add proper headers for cross-origin resource sharing (CORS) with Ajax Previously, when responding to Ajax requests, elasticsearch did not send proper headers for cross-origin resource sharing (CORS) -- see issues #828, #2186. With this commit, Ajax requests should be working. Example: jQuery.ajax({ url: \"http://localhost:9200/_search\", type: \"POST\", contentType: 'application/json; charset=UTF-8', success: function(data) { console.log(data) } }); See: * http://www.nczonline.net/blog/2010/05/25/cross-domain-ajax-with-cross-origin-resource-sharing/ * http://www.w3.org/TR/cors/#access-control-allow-headers-response-header ,"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java b/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n@@ -36,6 +36,7 @@\n import java.io.IOException;\n import java.util.Map;\n import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.TimeUnit;\n \n /**\n  *\n@@ -130,7 +131,7 @@ public FieldData cache(FieldDataType type, IndexReader reader, String fieldName)\n                         fieldDataCache.put(fieldName, fieldData);\n                         long took = System.nanoTime() - time;\n                         if (logger.isTraceEnabled()) {\n-                            logger.trace(\"loaded field [{}] for reader [{}], took [{}], took_millis [{}]\", fieldName, reader, TimeValue.timeValueNanos(took), took / 1000);\n+                            logger.trace(\"loaded field [{}] for reader [{}], took [{}], took_millis [{}]\", fieldName, reader, TimeValue.timeValueNanos(took), TimeUnit.NANOSECONDS.toMillis(took));\n                         }\n                     } catch (OutOfMemoryError e) {\n                         logger.warn(\"loading field [\" + fieldName + \"] caused out of memory failure\", e);",
    "output": "Fix logging if millisecond value in load field data"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java b/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n@@ -58,10 +58,19 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n         updateSettingsRequest.listenerThreaded(false);\n \n         ImmutableSettings.Builder updateSettings = ImmutableSettings.settingsBuilder();\n-        String bodySettings = request.content().toUtf8();\n-        if (Strings.hasText(bodySettings)) {\n+        String bodySettingsStr = request.content().toUtf8();\n+        if (Strings.hasText(bodySettingsStr)) {\n             try {\n-                updateSettings.put(ImmutableSettings.settingsBuilder().loadFromSource(bodySettings).build());\n+                Settings buildSettings = ImmutableSettings.settingsBuilder().loadFromSource(bodySettingsStr).build();\n+                for (Map.Entry<String, String> entry : buildSettings.getAsMap().entrySet()) {\n+                    String key = entry.getKey();\n+                    String value = entry.getValue();\n+                    // clean up in case the body is wrapped with \"settings\" : { ... }\n+                    if (key.startsWith(\"settings.\")) {\n+                        key = key.substring(\"settings.\".length());\n+                    }\n+                    updateSettings.put(key, value);\n+                }\n             } catch (Exception e) {\n                 try {\n                     channel.sendResponse(new XContentThrowableRestResponse(request, BAD_REQUEST, new SettingsException(\"Failed to parse index settings\", e)));",
    "output": "Upgrade Settings API: Allow body request to be wrapped with `settings` element to conform with other APIs,"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactory.java b/src/main/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactory.java\n--- a/src/main/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactory.java\n+++ b/src/main/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactory.java\n@@ -54,10 +54,10 @@ public ShingleTokenFilterFactory(Index index, @IndexSettings Settings indexSetti\n \n     @Override\n     public TokenStream create(TokenStream tokenStream) {\n-        ShingleFilter filter = new ShingleFilter(tokenStream, maxShingleSize, minShingleSize);\n+        ShingleFilter filter = new ShingleFilter(tokenStream, minShingleSize, maxShingleSize);\n         filter.setOutputUnigrams(outputUnigrams);\n         filter.setOutputUnigramsIfNoShingles(outputUnigramsIfNoShingles);\n         filter.setTokenSeparator(tokenSeparator);\n         return filter;\n     }\n-}\n\\ No newline at end of file\n+}",
    "output": "Fix reversed ShingleFilter constructor arguments"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java b/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java\n--- a/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java\n+++ b/src/main/java/org/elasticsearch/action/bulk/BulkProcessor.java\n@@ -243,7 +243,6 @@ private void executeIfNeeded() {\n         if (closed) {\n             throw new ElasticSearchIllegalStateException(\"bulk process already closed\");\n         }\n-        this.closed = true;\n         if (!isOverTheLimit()) {\n             return;\n         }",
    "output": "Fix wrong check on close"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/update/UpdateTests.java b/src/test/java/org/elasticsearch/test/integration/update/UpdateTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/update/UpdateTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/update/UpdateTests.java\n@@ -249,6 +249,9 @@ public void testUpdate() throws Exception {\n                         .endObject())\n                 .setRefresh(true)\n                 .execute().actionGet();\n+        clusterHealth = client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();\n+        assertThat(clusterHealth.timedOut(), equalTo(false));\n+        assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.GREEN));\n         updateResponse = client.prepareUpdate(\"test\", \"type1\", \"1\").setScript(\"ctx._source.field += 1\").setPercolate(\"*\").execute().actionGet();\n         assertThat(updateResponse.matches().size(), equalTo(1));\n ",
    "output": "Improve update test to wait for green cluster state"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/monitor/jvm/HotThreads.java b/src/main/java/org/elasticsearch/monitor/jvm/HotThreads.java\n--- a/src/main/java/org/elasticsearch/monitor/jvm/HotThreads.java\n+++ b/src/main/java/org/elasticsearch/monitor/jvm/HotThreads.java\n@@ -99,7 +99,6 @@ private String innerDetect() throws Exception {\n                     continue;\n                 }\n                 ThreadInfo info = threadBean.getThreadInfo(threadId, 0);\n-                System.out.println(info.getThreadName());\n                 if (info == null) {\n                     continue;\n                 }",
    "output": "Remove rouge sout"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -224,7 +224,7 @@ public void run() {\n                         // bail out\n                     }\n                 }\n-            }, \"elasticsearch[keepAlive]\");\n+            }, \"elasticsearch[keepAlive/\" + Version.CURRENT + \"]\");\n             keepAliveThread.setDaemon(false);\n             keepAliveThread.start();\n         } catch (Throwable e) {",
    "output": "Add to the keep alive thread name the version number, so it will be simpler to know from stack traces the es version"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/TestNGLoggingListener.java b/src/test/java/org/elasticsearch/test/TestNGLoggingListener.java\n--- a/src/test/java/org/elasticsearch/test/TestNGLoggingListener.java\n+++ b/src/test/java/org/elasticsearch/test/TestNGLoggingListener.java\n@@ -54,7 +54,7 @@ public void onTestSuccess(ITestResult result) {\n \n     @Override\n     public void onTestFailure(ITestResult result) {\n-        logger.error(\"==> Test Success [{}]\", extractTestName(result));\n+        logger.error(\"==> Test Failure [{}]\", extractTestName(result));\n     }\n \n     @Override",
    "output": "Fix test failure message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/nested/IncludeAllChildrenQuery.java b/src/main/java/org/elasticsearch/index/search/nested/IncludeAllChildrenQuery.java\n--- a/src/main/java/org/elasticsearch/index/search/nested/IncludeAllChildrenQuery.java\n+++ b/src/main/java/org/elasticsearch/index/search/nested/IncludeAllChildrenQuery.java\n@@ -149,7 +149,7 @@ static class IncludeAllChildrenScorer extends Scorer {\n         }\n \n         @Override\n-        protected void visitSubScorers(Query parent, BooleanClause.Occur relationship, ScorerVisitor<Query, Query, Scorer> visitor) {\n+        public void visitSubScorers(Query parent, BooleanClause.Occur relationship, ScorerVisitor<Query, Query, Scorer> visitor) {\n             super.visitSubScorers(parent, relationship, visitor);\n             parentScorer.visitScorers(visitor);\n         }",
    "output": "Upgrade to Lucene 3.6.1,"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/text/StringAndBytesText.java b/src/main/java/org/elasticsearch/common/text/StringAndBytesText.java\n--- a/src/main/java/org/elasticsearch/common/text/StringAndBytesText.java\n+++ b/src/main/java/org/elasticsearch/common/text/StringAndBytesText.java\n@@ -73,11 +73,12 @@ public boolean hasString() {\n \n     @Override\n     public String string() {\n+        // TODO: we can optimize the conversion based on the bytes reference API similar to UnicodeUtil\n         if (text == null) {\n             if (!bytes.hasArray()) {\n                 bytes = bytes.toBytesArray();\n             }\n-            text = new String(bytes.array(), bytes.arrayOffset(), bytes.length());\n+            text = new String(bytes.array(), bytes.arrayOffset(), bytes.length(), Charsets.UTF_8);\n         }\n         return text;\n     }",
    "output": "Make sure we use utf8 charset"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/FieldQueryParser.java b/src/main/java/org/elasticsearch/index/query/FieldQueryParser.java\n--- a/src/main/java/org/elasticsearch/index/query/FieldQueryParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/FieldQueryParser.java\n@@ -155,6 +155,8 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n             qpSettings.queryString(org.apache.lucene.queryParser.QueryParser.escape(qpSettings.queryString()));\n         }\n \n+        qpSettings.queryTypes(parseContext.queryTypes());\n+\n         Query query = parseContext.indexCache().queryParserCache().get(qpSettings);\n         if (query != null) {\n             return query;",
    "output": "Add query types also to field query"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java b/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n@@ -101,7 +101,7 @@ public synchronized AmazonEC2 client() {\n \n         if (componentSettings.get(\"ec2.endpoint\") != null) {\n             String endpoint = componentSettings.get(\"ec2.endpoint\");\n-            logger.debug(\"using explicit ec2 region [{}]\", endpoint);\n+            logger.debug(\"using explicit ec2 endpoint [{}]\", endpoint);\n             client.setEndpoint(endpoint);\n         } else if (componentSettings.get(\"region\") != null) {\n             String region = componentSettings.get(\"region\").toLowerCase();\n\ndiff --git a/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java b/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n--- a/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n+++ b/src/main/java/org/elasticsearch/cloud/aws/AwsS3Service.java\n@@ -92,7 +92,7 @@ public synchronized AmazonS3 client() {\n \n         if (componentSettings.get(\"s3.endpoint\") != null) {\n             String endpoint = componentSettings.get(\"s3.endpoint\");\n-            logger.debug(\"using explicit s3 region [{}]\", endpoint);\n+            logger.debug(\"using explicit s3 endpoint [{}]\", endpoint);\n             client.setEndpoint(endpoint);\n         } else if (componentSettings.get(\"region\") != null) {\n             String endpoint;",
    "output": "Fix logging message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n--- a/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n+++ b/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n@@ -241,9 +241,17 @@ private ExecutorHolder build(String name, String defaultType, @Nullable Settings\n                 throw new ElasticSearchIllegalArgumentException(\"reject_policy [\" + rejectSetting + \"] not valid for [\" + name + \"] thread pool\");\n             }\n             logger.debug(\"creating thread_pool [{}], type [{}], size [{}], queue_size [{}], reject_policy [{}]\", name, type, size, capacity, rejectSetting);\n+            BlockingQueue<Runnable> workQueue;\n+            if (capacity == null) {\n+                workQueue = new LinkedTransferQueue<Runnable>();\n+            } else if ((int) capacity.singles() > 0) {\n+                workQueue = new ArrayBlockingQueue<Runnable>((int) capacity.singles());\n+            } else {\n+                workQueue = new SynchronousQueue<Runnable>();\n+            }\n             Executor executor = new EsThreadPoolExecutor(size, size,\n                     0L, TimeUnit.MILLISECONDS,\n-                    capacity == null ? new LinkedTransferQueue<Runnable>() : new ArrayBlockingQueue<Runnable>((int) capacity.singles()),\n+                    workQueue,\n                     threadFactory, rejectedExecutionHandler);\n             return new ExecutorHolder(executor, new Info(name, type, size, size, null, capacity));\n         } else if (\"scaling\".equals(type)) {",
    "output": "Add support for zero queue size in the search thread pool"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/store/Store.java b/src/main/java/org/elasticsearch/index/store/Store.java\n--- a/src/main/java/org/elasticsearch/index/store/Store.java\n+++ b/src/main/java/org/elasticsearch/index/store/Store.java\n@@ -110,6 +110,9 @@ public Store(ShardId shardId, @IndexSettings Settings indexSettings, IndexStore\n         this.directory = new StoreDirectory(directoryService.build());\n \n         this.compressedStoredFields = componentSettings.getAsBoolean(\"compress.stored_fields\", false);\n+\n+        logger.debug(\"using compress.stored_fields [{}]\", compressedStoredFields);\n+\n         indexSettingsService.addListener(applySettings);\n     }\n ",
    "output": "Add debug log if using compressed stored fields"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java b/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java\n--- a/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java\n+++ b/src/test/java/org/elasticsearch/test/unit/index/engine/AbstractSimpleEngineTests.java\n@@ -45,6 +45,7 @@\n import org.elasticsearch.index.translog.fs.FsTranslog;\n import org.elasticsearch.test.unit.index.deletionpolicy.SnapshotIndexCommitExistsMatcher;\n import org.elasticsearch.test.unit.index.translog.TranslogSizeMatcher;\n+import org.elasticsearch.threadpool.ThreadPool;\n import org.hamcrest.MatcherAssert;\n import org.testng.annotations.AfterMethod;\n import org.testng.annotations.BeforeMethod;\n@@ -71,6 +72,8 @@ public abstract class AbstractSimpleEngineTests {\n \n     protected final ShardId shardId = new ShardId(new Index(\"index\"), 1);\n \n+    protected ThreadPool threadPool;\n+\n     private Store store;\n     private Store storeReplica;\n \n@@ -79,6 +82,7 @@ public abstract class AbstractSimpleEngineTests {\n \n     @BeforeMethod\n     public void setUp() throws Exception {\n+        threadPool = new ThreadPool();\n         store = createStore();\n         store.deleteContent();\n         storeReplica = createStoreReplica();\n@@ -96,6 +100,10 @@ public void tearDown() throws Exception {\n \n         engine.close();\n         store.close();\n+\n+        if (threadPool != null) {\n+            threadPool.shutdownNow();\n+        }\n     }\n \n     protected Store createStore() throws IOException {",
    "output": "Fix test to shutdown threadpool"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/UidFilter.java b/src/main/java/org/elasticsearch/index/search/UidFilter.java\n--- a/src/main/java/org/elasticsearch/index/search/UidFilter.java\n+++ b/src/main/java/org/elasticsearch/index/search/UidFilter.java\n@@ -57,6 +57,10 @@ public UidFilter(Collection<String> types, List<String> ids, BloomCache bloomCac\n         }\n     }\n \n+    public Term[] getTerms() {\n+        return this.uids;\n+    }\n+\n     // TODO Optimizations\n     // - If we have a single id, we can create a SingleIdDocIdSet to save on mem\n     // - We can use sorted int array DocIdSet to reserve memory compared to OpenBitSet in some cases",
    "output": "Add getTerms for uid filter"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/UidFilter.java b/src/main/java/org/elasticsearch/index/search/UidFilter.java\n--- a/src/main/java/org/elasticsearch/index/search/UidFilter.java\n+++ b/src/main/java/org/elasticsearch/index/search/UidFilter.java\n@@ -39,7 +39,7 @@\n \n public class UidFilter extends Filter {\n \n-    private final Term[] uids;\n+    final Term[] uids;\n \n     private final BloomCache bloomCache;\n \n@@ -96,7 +96,12 @@ public boolean equals(Object o) {\n         if (this == o) return true;\n         if (o == null || getClass() != o.getClass()) return false;\n         UidFilter uidFilter = (UidFilter) o;\n-        return !uids.equals(uidFilter.uids);\n+        return Arrays.equals(uids, uidFilter.uids);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Arrays.hashCode(uids);\n     }\n \n     @Override\n@@ -110,9 +115,4 @@ public String toString() {\n         }\n         return builder.toString();\n     }\n-\n-    @Override\n-    public int hashCode() {\n-        return uids.hashCode();\n-    }\n }\n\\ No newline at end of file",
    "output": "Use an array to represent the keys in the uid filter fix equals and hashcode as well"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java b/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java\n--- a/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java\n+++ b/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java\n@@ -65,7 +65,10 @@ public class IndicesTTLService extends AbstractLifecycleComponent<IndicesTTLServ\n \n     static {\n         MetaData.addDynamicSettings(\n-                \"indices.ttl.interval\",\n+                \"indices.ttl.interval\"\n+        );\n+\n+        IndexMetaData.addDynamicSettings(\n                 \"index.ttl.disable_purge\"\n         );\n     }",
    "output": "Fix bug index.ttl.disable_purge should be in IndexMetaData"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java b/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n--- a/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n+++ b/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n@@ -26,6 +26,7 @@\n import org.apache.lucene.util.UnicodeUtil;\n import org.elasticsearch.ElasticSearchException;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n+import org.elasticsearch.cluster.routing.operation.hash.djb.DjbHashFunction;\n import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.Preconditions;\n import org.elasticsearch.common.Unicode;\n@@ -193,7 +194,7 @@ public RobinEngine(ShardId shardId, @IndexSettings Settings indexSettings, Threa\n \n         this.indexConcurrency = indexSettings.getAsInt(\"index.index_concurrency\", IndexWriterConfig.DEFAULT_MAX_THREAD_STATES);\n         this.versionMap = new ConcurrentHashMap<String, VersionValue>();\n-        this.dirtyLocks = new Object[indexConcurrency * 10]; // we multiply it by 10 to have enough...\n+        this.dirtyLocks = new Object[indexConcurrency * 50]; // we multiply it to have enough...\n         for (int i = 0; i < dirtyLocks.length; i++) {\n             dirtyLocks[i] = new Object();\n         }\n@@ -1251,7 +1252,7 @@ private void innerClose() {\n     }\n \n     private Object dirtyLock(String id) {\n-        int hash = id.hashCode();\n+        int hash = DjbHashFunction.DJB_HASH(id);\n         // abs returns Integer.MIN_VALUE, so we need to protect against it...\n         if (hash == Integer.MIN_VALUE) {\n             hash = 0;",
    "output": "Use djb hash to choose doc lock, and lock pool"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/SearchService.java b/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -27,14 +27,14 @@\n import org.elasticsearch.cluster.ClusterService;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n import org.elasticsearch.common.Nullable;\n-import org.elasticsearch.common.Unicode;\n import org.elasticsearch.common.component.AbstractLifecycleComponent;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.util.concurrent.ConcurrentCollections;\n import org.elasticsearch.common.util.concurrent.ConcurrentMapLong;\n import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n import org.elasticsearch.common.xcontent.XContentParser;\n import org.elasticsearch.index.Index;\n import org.elasticsearch.index.engine.Engine;\n@@ -562,7 +562,7 @@ private void parseSource(SearchContext context, byte[] source, int offset, int l\n         } catch (Exception e) {\n             String sSource = \"_na_\";\n             try {\n-                sSource = Unicode.fromBytes(source, offset, length);\n+                sSource = XContentHelper.convertToJson(source, offset, length, false);\n             } catch (Throwable e1) {\n                 // ignore\n             }",
    "output": "Fix an incorrect error message when query parse fail,"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java b/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/ShardRoutingState.java\n@@ -66,7 +66,7 @@ public static ShardRoutingState fromValue(byte value) {\n             case 4:\n                 return RELOCATING;\n             default:\n-                throw new ElasticSearchIllegalStateException(\"No should routing state mapped for [\" + value + \"]\");\n+                throw new ElasticSearchIllegalStateException(\"No routing state mapped for [\" + value + \"]\");\n         }\n     }\n }",
    "output": "Fix exception message"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/CustomFiltersScoreQueryBuilder.java b/src/main/java/org/elasticsearch/index/query/CustomFiltersScoreQueryBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/CustomFiltersScoreQueryBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/CustomFiltersScoreQueryBuilder.java\n@@ -29,8 +29,6 @@\n \n /**\n  * A query that uses a filters with a script associated with them to compute the score.\n- *\n- *\n  */\n public class CustomFiltersScoreQueryBuilder extends BaseQueryBuilder {\n \n@@ -40,6 +38,8 @@ public class CustomFiltersScoreQueryBuilder extends BaseQueryBuilder {\n \n     private float boost = -1;\n \n+    private Float maxBoost;\n+\n     private Map<String, Object> params = null;\n \n     private String scoreMode;\n@@ -102,6 +102,11 @@ public CustomFiltersScoreQueryBuilder param(String key, Object value) {\n         return this;\n     }\n \n+    public CustomFiltersScoreQueryBuilder maxBoost(float maxBoost) {\n+        this.maxBoost = maxBoost;\n+        return this;\n+    }\n+\n     /**\n      * Sets the boost for this query.  Documents matching this query will (in addition to the normal\n      * weightings) have their score multiplied by the boost provided.\n@@ -135,6 +140,9 @@ protected void doXContent(XContentBuilder builder, Params params) throws IOExcep\n         if (scoreMode != null) {\n             builder.field(\"score_mode\", scoreMode);\n         }\n+        if (maxBoost != null) {\n+            builder.field(\"max_boost\", maxBoost);\n+        }\n \n         if (lang != null) {\n             builder.field(\"lang\", lang);",
    "output": "Add setting max boost on custom filters score query in the Java API as well"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/indices/template/put/RestPutIndexTemplateAction.java b/src/main/java/org/elasticsearch/rest/action/admin/indices/template/put/RestPutIndexTemplateAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/indices/template/put/RestPutIndexTemplateAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/indices/template/put/RestPutIndexTemplateAction.java\n@@ -60,6 +60,9 @@ public void handleRequest(RestRequest request, RestChannel channel) {\n     public void handleRequest(final RestRequest request, final RestChannel channel) {\n         PutIndexTemplateRequest putRequest = new PutIndexTemplateRequest(request.param(\"name\"));\n \n+        putRequest.template(request.param(\"template\", putRequest.template()));\n+        putRequest.order(request.paramAsInt(\"order\", putRequest.order()));\n+\n         try {\n             putRequest.create(request.paramAsBoolean(\"create\", false));\n             putRequest.cause(request.param(\"cause\", \"\"));\n@@ -74,9 +77,6 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n             return;\n         }\n \n-        putRequest.template(request.param(\"template\", putRequest.template()));\n-        putRequest.order(request.paramAsInt(\"order\", putRequest.order()));\n-\n         client.admin().indices().putTemplate(putRequest, new ActionListener<PutIndexTemplateResponse>() {\n             @Override\n             public void onResponse(PutIndexTemplateResponse response) {",
    "output": "Change when setting the order for index templates in the rest API"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/warmer/InternalIndicesWarmer.java b/src/main/java/org/elasticsearch/indices/warmer/InternalIndicesWarmer.java\n--- a/src/main/java/org/elasticsearch/indices/warmer/InternalIndicesWarmer.java\n+++ b/src/main/java/org/elasticsearch/indices/warmer/InternalIndicesWarmer.java\n@@ -71,7 +71,7 @@ public void warm(final ShardId shardId, final Engine.Searcher searcher) {\n         if (indexMetaData == null) {\n             return;\n         }\n-        if (!indexMetaData.settings().getAsBoolean(\"index.warm.enabled\", settings.getAsBoolean(\"index.warm.enabled\", true))) {\n+        if (!indexMetaData.settings().getAsBoolean(\"index.warmer.enabled\", settings.getAsBoolean(\"index.warmer.enabled\", true))) {\n             return;\n         }\n         IndexService indexService = indicesService.indexService(shardId.index().name());",
    "output": "Change setting name from index.warm.enabled to index.warmer.enabled"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -122,7 +122,9 @@ public ImmutableList<DiscoveryNode> connectedNodes() {\n     public TransportClientNodesService addTransportAddress(TransportAddress transportAddress) {\n         synchronized (transportMutex) {\n             ImmutableList.Builder<DiscoveryNode> builder = ImmutableList.builder();\n-            listedNodes = builder.addAll(listedNodes).add(new DiscoveryNode(\"#transport#-\" + tempNodeIdGenerator.incrementAndGet(), transportAddress)).build();\n+            DiscoveryNode node = new DiscoveryNode(\"#transport#-\" + tempNodeIdGenerator.incrementAndGet(), transportAddress);\n+            logger.debug(\"adding address {}\", node);\n+            listedNodes = builder.addAll(listedNodes).add(node).build();\n         }\n         nodesSampler.sample();\n         return this;\n@@ -134,6 +136,8 @@ public TransportClientNodesService removeTransportAddress(TransportAddress trans\n             for (DiscoveryNode otherNode : listedNodes) {\n                 if (!otherNode.address().equals(transportAddress)) {\n                     builder.add(otherNode);\n+                } else {\n+                    logger.debug(\"removing address {}\", otherNode);\n                 }\n             }\n             listedNodes = builder.build();",
    "output": "Add debug message when adding and removing addressing from the transport client"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java b/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n@@ -121,12 +121,12 @@ public FieldData cache(FieldDataType type, IndexReader reader, String fieldName)\n                 fieldData = fieldDataCache.getIfPresent(fieldName);\n                 if (fieldData == null) {\n                     try {\n-                        long time = System.currentTimeMillis();\n+                        long time = System.nanoTime();\n                         fieldData = FieldData.load(type, reader, fieldName);\n                         fieldDataCache.put(fieldName, fieldData);\n-                        long took = System.currentTimeMillis() - time;\n+                        long took = System.nanoTime() - time;\n                         if (logger.isTraceEnabled()) {\n-                            logger.trace(\"loaded field [{}] for reader [{}], took [{}], took_millis [{}]\", fieldName, reader, TimeValue.timeValueMillis(took), took);\n+                            logger.trace(\"loaded field [{}] for reader [{}], took [{}], took_millis [{}]\", fieldName, reader, TimeValue.timeValueNanos(took), took / 1000);\n                         }\n                     } catch (OutOfMemoryError e) {\n                         logger.warn(\"loading field [\" + fieldName + \"] caused out of memory failure\", e);",
    "output": "Use nanoTime instead of millis"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java b/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n--- a/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n+++ b/src/main/java/org/elasticsearch/index/cache/field/data/support/AbstractConcurrentMapFieldDataCache.java\n@@ -24,6 +24,7 @@\n import org.apache.lucene.index.SegmentReader;\n import org.elasticsearch.ElasticSearchException;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.util.concurrent.ConcurrentCollections;\n import org.elasticsearch.index.AbstractIndexComponent;\n import org.elasticsearch.index.Index;\n@@ -120,8 +121,13 @@ public FieldData cache(FieldDataType type, IndexReader reader, String fieldName)\n                 fieldData = fieldDataCache.getIfPresent(fieldName);\n                 if (fieldData == null) {\n                     try {\n+                        long time = System.currentTimeMillis();\n                         fieldData = FieldData.load(type, reader, fieldName);\n                         fieldDataCache.put(fieldName, fieldData);\n+                        long took = System.currentTimeMillis() - time;\n+                        if (logger.isTraceEnabled()) {\n+                            logger.trace(\"loaded field [{}] for reader [{}], took [{}], took_millis [{}]\", fieldName, reader, TimeValue.timeValueMillis(took), took);\n+                        }\n                     } catch (OutOfMemoryError e) {\n                         logger.warn(\"loading field [\" + fieldName + \"] caused out of memory failure\", e);\n                         final OutOfMemoryError outOfMemoryError = new OutOfMemoryError(\"loading field [\" + fieldName + \"] caused out of memory failure\");",
    "output": "Add trace logging for how long it took to load field data cache"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java b/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java\n@@ -538,20 +538,6 @@ public static MappingMetaData readFrom(StreamInput in) throws IOException {\n         return new MappingMetaData(type, source, id, routing, timestamp);\n     }\n \n-    public static class ParseResult {\n-        public final String routing;\n-        public final boolean routingResolved;\n-        public final String timestamp;\n-        public final boolean timestampResolved;\n-\n-        public ParseResult(String routing, boolean routingResolved, String timestamp, boolean timestampResolved) {\n-            this.routing = routing;\n-            this.routingResolved = routingResolved;\n-            this.timestamp = timestamp;\n-            this.timestampResolved = timestampResolved;\n-        }\n-    }\n-\n     public static class ParseContext {\n         final boolean shouldParseId;\n         final boolean shouldParseRouting;",
    "output": "Remove unused class"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/search/slowlog/ShardSlowLogSearchService.java b/src/main/java/org/elasticsearch/index/search/slowlog/ShardSlowLogSearchService.java\n--- a/src/main/java/org/elasticsearch/index/search/slowlog/ShardSlowLogSearchService.java\n+++ b/src/main/java/org/elasticsearch/index/search/slowlog/ShardSlowLogSearchService.java\n@@ -73,7 +73,7 @@ public class ShardSlowLogSearchService extends AbstractIndexShardComponent {\n \n     class ApplySettings implements IndexSettingsService.Listener {\n         @Override\n-        public void onRefreshSettings(Settings settings) {\n+        public synchronized void onRefreshSettings(Settings settings) {\n             long queryWarnThreshold = settings.getAsTime(\"index.search.slowlog.threshold.query.warn\", TimeValue.timeValueNanos(ShardSlowLogSearchService.this.queryWarnThreshold)).nanos();\n             if (queryWarnThreshold != ShardSlowLogSearchService.this.queryWarnThreshold) {\n                 ShardSlowLogSearchService.this.queryWarnThreshold = queryWarnThreshold;",
    "output": "Make the call the apply settings sync'ed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java b/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n--- a/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n+++ b/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n@@ -114,6 +114,8 @@ public class InternalIndexShard extends AbstractIndexShardComponent implements I\n \n \n     private final boolean checkIndexOnStartup;\n+    \n+    private final boolean fixIndexOnStartup;\n \n     private long checkIndexTook = 0;\n \n@@ -163,6 +165,7 @@ public InternalIndexShard(ShardId shardId, @IndexSettings Settings indexSettings\n         logger.debug(\"state: [CREATED]\");\n \n         this.checkIndexOnStartup = indexSettings.getAsBoolean(\"index.shard.check_on_startup\", false);\n+        this.fixIndexOnStartup = indexSettings.getAsBoolean(\"index.shard.check_on_startup_and_fix\", false);\n     }\n \n     public MergeSchedulerProvider mergeScheduler() {\n@@ -866,6 +869,15 @@ private void checkIndex(boolean throwException) throws IndexShardException {\n                 if (logger.isDebugEnabled()) {\n                     logger.debug(\"check index [success]\\n{}\", new String(os.underlyingBytes(), 0, os.size()));\n                 }\n+                if (fixIndexOnStartup) {\n+                    if (logger.isDebugEnabled()) {\n+                        logger.debug(\"fixing index, writing new segments file ...\");\n+                    }\n+                    checkIndex.fixIndex(status);\n+                    if (logger.isDebugEnabled()) {\n+                        logger.debug(\"index fixed, wrote new segments file \\\"{}\\\"\", status.segmentsFileName);\n+                    }\n+                }\n             }\n             checkIndexTook = System.currentTimeMillis() - time;\n         } catch (Exception e) {",
    "output": "Add fixIndex() method"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java b/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java\n--- a/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java\n+++ b/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java\n@@ -76,7 +76,7 @@ public WildcardQueryBuilder boost(float boost) {\n     @Override\n     public void doXContent(XContentBuilder builder, Params params) throws IOException {\n         builder.startObject(WildcardQueryParser.NAME);\n-        if (boost == -1 && rewrite != null) {\n+        if (boost == -1 && rewrite == null) {\n             builder.field(name, wildcard);\n         } else {\n             builder.startObject(name);",
    "output": "Fix WildcardQueryBuilder when only rewrite is changed If only the rewrite field is changed, and not the boost one, the serilization did not write the rewrite field"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -324,6 +324,7 @@ public void run() {\n                         try {\n                             if (!transportService.nodeConnected(listedNode)) {\n                                 try {\n+                                    logger.trace(\"connecting to node [{}]\", listedNode);\n                                     transportService.connectToNode(listedNode);\n                                 } catch (Exception e) {\n                                     logger.debug(\"failed to connect to node [{}], ignoring...\", e, listedNode);\n@@ -389,11 +390,14 @@ public void handleException(TransportException e) {\n             // now, make sure we are connected to all the updated nodes\n             for (Iterator<DiscoveryNode> it = newNodes.iterator(); it.hasNext(); ) {\n                 DiscoveryNode node = it.next();\n-                try {\n-                    transportService.connectToNode(node);\n-                } catch (Exception e) {\n-                    it.remove();\n-                    logger.debug(\"failed to connect to discovered node [\" + node + \"]\", e);\n+                if (!transportService.nodeConnected(node)) {\n+                    try {\n+                        logger.trace(\"connecting to node [{}]\", node);\n+                        transportService.connectToNode(node);\n+                    } catch (Exception e) {\n+                        it.remove();\n+                        logger.debug(\"failed to connect to discovered node [\" + node + \"]\", e);\n+                    }\n                 }\n             }\n             nodes = new ImmutableList.Builder<DiscoveryNode>().addAll(newNodes).build();",
    "output": "Add trace logging to client nodes when sniffing of when ti connects to a node"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -368,7 +368,6 @@ public boolean start(final boolean fromClusterEvent) throws ElasticSearchExcepti\n                     }\n                 }\n                 shardIt = shards(clusterState, request);\n-                shardIt = shards(clusterState, request);\n             } catch (Exception e) {\n                 listener.onFailure(e);\n                 return true;",
    "output": "Remove double call to shards (meaningless, but still)"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -276,7 +276,7 @@ public synchronized void sample() {\n                 try {\n                     NodesInfoResponse nodeInfo = transportService.submitRequest(node, NodesInfoAction.NAME,\n                             Requests.nodesInfoRequest(\"_local\"),\n-                            TransportRequestOptions.options().withTimeout(pingTimeout),\n+                            TransportRequestOptions.options().withHighType().withTimeout(pingTimeout),\n                             new FutureTransportResponseHandler<NodesInfoResponse>() {\n                                 @Override\n                                 public NodesInfoResponse newInstance() {\n@@ -333,7 +333,7 @@ public void run() {\n                             }\n                             transportService.sendRequest(listedNode, NodesInfoAction.NAME,\n                                     Requests.nodesInfoRequest(\"_all\"),\n-                                    TransportRequestOptions.options().withTimeout(pingTimeout),\n+                                    TransportRequestOptions.options().withHighType().withTimeout(pingTimeout),\n                                     new BaseTransportResponseHandler<NodesInfoResponse>() {\n \n                                         @Override",
    "output": "Use the high transport channel for pings with transport client"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n--- a/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n+++ b/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java\n@@ -326,7 +326,8 @@ public void run() {\n                                 try {\n                                     transportService.connectToNode(listedNode);\n                                 } catch (Exception e) {\n-                                    logger.debug(\"failed to connect to node [{}], removed from nodes list\", e, listedNode);\n+                                    logger.debug(\"failed to connect to node [{}], ignoring...\", e, listedNode);\n+                                    latch.countDown();\n                                     return;\n                                 }\n                             }",
    "output": "Fix for issue #1819 where TransportClient (sniff) fails to reconnect to nodes once removed if all nodes are removed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/Strings.java b/src/main/java/org/elasticsearch/common/Strings.java\n--- a/src/main/java/org/elasticsearch/common/Strings.java\n+++ b/src/main/java/org/elasticsearch/common/Strings.java\n@@ -789,7 +789,7 @@ public static boolean pathEquals(String path1, String path2) {\n      */\n     public static Locale parseLocaleString(String localeString) {\n         String[] parts = tokenizeToStringArray(localeString, \"_ \", false, false);\n-        String language = (parts.length > 0 ? parts[0] : \"\");\n+        String language = (parts.length != 0 ? parts[0] : \"\");\n         String country = (parts.length > 1 ? parts[1] : \"\");\n         String variant = \"\";\n         if (parts.length >= 2) {",
    "output": "Fix a random suggestion from a style checker"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/SearchHit.java b/src/main/java/org/elasticsearch/search/SearchHit.java\n--- a/src/main/java/org/elasticsearch/search/SearchHit.java\n+++ b/src/main/java/org/elasticsearch/search/SearchHit.java\n@@ -21,6 +21,7 @@\n \n import org.apache.lucene.search.Explanation;\n import org.elasticsearch.ElasticSearchParseException;\n+import org.elasticsearch.common.BytesHolder;\n import org.elasticsearch.common.io.stream.Streamable;\n import org.elasticsearch.common.xcontent.ToXContent;\n import org.elasticsearch.search.highlight.HighlightField;\n@@ -30,7 +31,6 @@\n /**\n  * A single search hit.\n  *\n- *\n  * @see SearchHits\n  */\n public interface SearchHit extends Streamable, ToXContent, Iterable<SearchHitField> {\n@@ -86,7 +86,13 @@ public interface SearchHit extends Streamable, ToXContent, Iterable<SearchHitFie\n     long getVersion();\n \n     /**\n-     * The source of the document (can be <tt>null</tt>).\n+     * Returns bytes reference, also un compress the source if needed.\n+     */\n+    BytesHolder sourceRef();\n+\n+    /**\n+     * The source of the document (can be <tt>null</tt>). Note, its a copy of the source\n+     * into a byte array, consider using {@link #sourceRef()} so there won't be a need to copy.\n      */\n     byte[] source();\n ",
    "output": "Add sourceRef to SearchHit"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -65,9 +65,10 @@ public class Version implements Serializable {\n \n     public static final int V_0_19_0_ID = /*00*/190099;\n     public static final Version V_0_19_0 = new Version(V_0_19_0_ID, false);\n-\n     public static final int V_0_19_1_ID = /*00*/190199;\n     public static final Version V_0_19_1 = new Version(V_0_19_1_ID, false);\n+    public static final int V_0_19_2_ID = /*00*/190299;\n+    public static final Version V_0_19_2 = new Version(V_0_19_2_ID, false);\n \n     public static final int V_0_20_0_Beta1_ID = /*00*/200001;\n     public static final Version V_0_20_0_Beta1 = new Version(V_0_20_0_Beta1_ID, true);\n@@ -109,6 +110,8 @@ public static Version fromId(int id) {\n                 return V_0_19_0;\n             case V_0_19_1_ID:\n                 return V_0_19_1;\n+            case V_0_19_2_ID:\n+                return V_0_19_2;\n \n             case V_0_20_0_Beta1_ID:\n                 return V_0_20_0_Beta1;",
    "output": "Add 0.19.2 version"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/store/IndicesStore.java b/src/main/java/org/elasticsearch/indices/store/IndicesStore.java\n--- a/src/main/java/org/elasticsearch/indices/store/IndicesStore.java\n+++ b/src/main/java/org/elasticsearch/indices/store/IndicesStore.java\n@@ -77,7 +77,7 @@ public IndicesStore(Settings settings, NodeEnvironment nodeEnv, IndicesService i\n         this.clusterService = clusterService;\n         this.threadPool = threadPool;\n \n-        this.danglingTimeout = componentSettings.getAsTime(\"dangling_timeout\", TimeValue.timeValueMinutes(2));\n+        this.danglingTimeout = componentSettings.getAsTime(\"dangling_timeout\", TimeValue.timeValueHours(2));\n \n         clusterService.addLast(this);\n     }",
    "output": "Change the dangling indices deleting timeout default value to 2h"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n@@ -64,7 +64,7 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n             clusterHealthRequest.waitForNodes(request.param(\"wait_for_nodes\", clusterHealthRequest.waitForNodes()));\n             String sLevel = request.param(\"level\");\n             if (sLevel != null) {\n-                if (\"cluster\".equals(\"sLevel\")) {\n+                if (\"cluster\".equals(sLevel)) {\n                     level = 0;\n                 } else if (\"indices\".equals(sLevel)) {\n                     level = 1;",
    "output": "Fix comparison test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java b/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java\n--- a/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java\n+++ b/src/main/java/org/elasticsearch/indices/ttl/IndicesTTLService.java\n@@ -153,7 +153,7 @@ private List<IndexShard> getShardsToPurge() {\n                 }\n                 if (hasTTLEnabled) {\n                     for (IndexShard indexShard : indexService) {\n-                        if (indexShard.routingEntry().primary() && indexShard.state() == IndexShardState.STARTED && indexShard.routingEntry().started()) {\n+                        if (indexShard.state() == IndexShardState.STARTED && indexShard.routingEntry().primary() && indexShard.routingEntry().started()) {\n                             shardsToPurge.add(indexShard);\n                         }\n                     }",
    "output": "Change order of check since routing entry might be null when the shard is just created"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n@@ -148,9 +148,6 @@ private void validate(PutRequest request) throws ElasticSearchException {\n         if (!request.name.toLowerCase().equals(request.name)) {\n             throw new InvalidIndexTemplateException(request.name, \"name must be lower cased\");\n         }\n-        if (!request.name.toLowerCase().equals(request.name)) {\n-            throw new InvalidIndexTemplateException(request.name, \"name must be lower cased\");\n-        }\n         if (request.template.contains(\" \")) {\n             throw new InvalidIndexTemplateException(request.name, \"template must not contain a space\");\n         }",
    "output": "Remove two similar checks on tempalte name"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java\n@@ -148,6 +148,9 @@ private void validate(PutRequest request) throws ElasticSearchException {\n         if (!request.name.toLowerCase().equals(request.name)) {\n             throw new InvalidIndexTemplateException(request.name, \"name must be lower cased\");\n         }\n+        if (!request.name.toLowerCase().equals(request.name)) {\n+            throw new InvalidIndexTemplateException(request.name, \"name must be lower cased\");\n+        }\n         if (request.template.contains(\" \")) {\n             throw new InvalidIndexTemplateException(request.name, \"template must not contain a space\");\n         }\n@@ -160,9 +163,6 @@ private void validate(PutRequest request) throws ElasticSearchException {\n         if (request.template.startsWith(\"_\")) {\n             throw new InvalidIndexTemplateException(request.name, \"template must not start with '_'\");\n         }\n-        if (!request.name.toLowerCase().equals(request.name)) {\n-            throw new InvalidIndexTemplateException(request.name, \"template must be lower cased\");\n-        }\n         if (!Strings.validFileNameExcludingAstrix(request.template)) {\n             throw new InvalidIndexTemplateException(request.name, \"template must not container the following characters \" + Strings.INVALID_FILENAME_CHARS);\n         }",
    "output": "Fix error message on invalid template name"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/env/Environment.java b/src/main/java/org/elasticsearch/env/Environment.java\n--- a/src/main/java/org/elasticsearch/env/Environment.java\n+++ b/src/main/java/org/elasticsearch/env/Environment.java\n@@ -168,6 +168,7 @@ public String resolveConfigAndLoadToString(String path) throws FailedToResolveCo\n     }\n \n     public URL resolveConfig(String path) throws FailedToResolveConfigException {\n+        String origPath = path;\n         // first, try it as a path on the file system\n         File f1 = new File(path);\n         if (f1.exists()) {\n@@ -201,6 +202,6 @@ public URL resolveConfig(String path) throws FailedToResolveConfigException {\n                 return resource;\n             }\n         }\n-        throw new FailedToResolveConfigException(\"Failed to resolve config path [\" + path + \"], tried file path [\" + f1 + \"], path file [\" + f2 + \"], and classpath\");\n+        throw new FailedToResolveConfigException(\"Failed to resolve config path [\" + origPath + \"], tried file path [\" + f1 + \"], path file [\" + f2 + \"], and classpath\");\n     }\n }",
    "output": "Fix error message when trying to locate path"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java b/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java\n--- a/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java\n+++ b/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java\n@@ -80,7 +80,7 @@ public boolean match(DiscoveryNode node) {\n                     }\n                 }\n                 return false;\n-            } else if (\"_name\".equals(attr)) {\n+            } else if (\"_name\".equals(attr) || \"name\".equals(attr)) {\n                 for (String value : values) {\n                     if (Regex.simpleMatch(value, node.name())) {\n                         return true;",
    "output": "Add an option for name as well as _name for filtering allocation"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/plugins/PluginsService.java b/src/main/java/org/elasticsearch/plugins/PluginsService.java\n--- a/src/main/java/org/elasticsearch/plugins/PluginsService.java\n+++ b/src/main/java/org/elasticsearch/plugins/PluginsService.java\n@@ -74,8 +74,22 @@ public PluginsService(Settings settings, Environment environment) {\n         // first, find all the ones that are in the classpath\n         Map<String, Plugin> plugins = Maps.newHashMap();\n         plugins.putAll(loadPluginsFromClasspath(settings));\n+        Set<String> sitePlugins = sitePlugins();\n+\n+        String[] mandatoryPlugins = settings.getAsArray(\"plugin.mandatory\", null);\n+        if (mandatoryPlugins != null) {\n+            Set<String> missingPlugins = Sets.newHashSet();\n+            for (String mandatoryPlugin : mandatoryPlugins) {\n+                if (!plugins.containsKey(mandatoryPlugin) && !sitePlugins.contains(mandatoryPlugin) && !missingPlugins.contains(mandatoryPlugin)) {\n+                    missingPlugins.add(mandatoryPlugin);\n+                }\n+            }\n+            if (!missingPlugins.isEmpty()) {\n+                throw new ElasticSearchException(\"Missing mandatory plugins \" + missingPlugins);\n+            }\n+        }\n \n-        logger.info(\"loaded {}, sites {}\", plugins.keySet(), sitePlugins());\n+        logger.info(\"loaded {}, sites {}\", plugins.keySet(), sitePlugins);\n \n         this.plugins = ImmutableMap.copyOf(plugins);\n ",
    "output": "Add mandatory plugins support in conf"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java b/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java\n--- a/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java\n+++ b/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java\n@@ -152,6 +152,16 @@ public UpdateRequestBuilder setConsistencyLevel(WriteConsistencyLevel consistenc\n         return this;\n     }\n \n+    /**\n+     * Causes the updated document to be percolated. The parameter is the percolate query\n+     * to use to reduce the percolated queries that are going to run against this doc. Can be\n+     * set to <tt>*</tt> to indicate that all percolate queries should be run.\n+     */\n+    public UpdateRequestBuilder setPercolate(String percolate) {\n+        request.percolate(percolate);\n+        return this;\n+    }\n+\n     @Override\n     protected void doExecute(ActionListener<UpdateResponse> listener) {\n         client.update(request, listener);",
    "output": "Add missing setPercolate method to UpdateRequestBuilder"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/search/lookup/DocLookup.java b/src/main/java/org/elasticsearch/search/lookup/DocLookup.java\n--- a/src/main/java/org/elasticsearch/search/lookup/DocLookup.java\n+++ b/src/main/java/org/elasticsearch/search/lookup/DocLookup.java\n@@ -58,6 +58,14 @@ public class DocLookup implements Map {\n         this.fieldDataCache = fieldDataCache;\n     }\n \n+    public MapperService mapperService() {\n+        return this.mapperService;\n+    }\n+\n+    public FieldDataCache fieldDataCache() {\n+        return this.fieldDataCache;\n+    }\n+\n     public void setNextReader(IndexReader reader) {\n         if (this.reader == reader) { // if we are called with the same reader, don't invalidate source\n             return;",
    "output": "Add getters for mapper service and field data cache in doc lookup"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/Version.java b/src/main/java/org/elasticsearch/Version.java\n--- a/src/main/java/org/elasticsearch/Version.java\n+++ b/src/main/java/org/elasticsearch/Version.java\n@@ -60,7 +60,10 @@ public class Version implements Serializable {\n     public static final int V_0_19_0_RC2_ID = /*00*/190052;\n     public static final Version V_0_19_0_RC2 = new Version(V_0_19_0_RC2_ID, false);\n \n-    public static final Version CURRENT = V_0_19_0_RC2;\n+    public static final int V_0_19_0_RC3_ID = /*00*/190053;\n+    public static final Version V_0_19_0_RC3 = new Version(V_0_19_0_RC3_ID, true);\n+\n+    public static final Version CURRENT = V_0_19_0_RC3;\n \n     public static Version readVersion(StreamInput in) throws IOException {\n         return fromId(in.readVInt());\n@@ -91,6 +94,8 @@ public static Version fromId(int id) {\n                 return V_0_19_0_RC1;\n             case V_0_19_0_RC2_ID:\n                 return V_0_19_0_RC2;\n+            case V_0_19_0_RC3_ID:\n+                return V_0_19_0_RC3;\n             default:\n                 return new Version(id, null);\n         }",
    "output": "Upgrade versions to 0.19.3 snap"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/transport/netty/MessageChannelHandler.java b/src/main/java/org/elasticsearch/transport/netty/MessageChannelHandler.java\n--- a/src/main/java/org/elasticsearch/transport/netty/MessageChannelHandler.java\n+++ b/src/main/java/org/elasticsearch/transport/netty/MessageChannelHandler.java\n@@ -68,8 +68,9 @@ public void writeComplete(ChannelHandlerContext ctx, WriteCompletionEvent e) thr\n \n     // similar logic to FrameDecoder, we don't use FrameDecoder because we can use the data len header value\n     // to guess the size of the cumulation buffer to allocate\n-    // Also strange, is that the FrameDecoder always allocated a cumulation, even if the input bufer is enough\n-    // so we don't allocate a cumulation buffer unless we really need to here (need to post this to the mailing list)\n+\n+    // we don't reuse the cumalation buffer, so it won't grow out of control per channel, as well as\n+    // being able to \"readBytesReference\" from it without worry\n     @Override\n     public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {\n ",
    "output": "Improve comment on usage, also, FrameDecoder usage of cumalation was fixed"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java b/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java\n--- a/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java\n+++ b/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java\n@@ -20,26 +20,20 @@\n package org.elasticsearch.cluster.routing.allocation;\n \n import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.Lists;\n import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocatorModule;\n-import org.elasticsearch.cluster.routing.allocation.decider.AllocationDecider;\n import org.elasticsearch.cluster.routing.allocation.decider.AllocationDecidersModule;\n import org.elasticsearch.common.inject.AbstractModule;\n import org.elasticsearch.common.inject.Module;\n import org.elasticsearch.common.inject.SpawnModules;\n import org.elasticsearch.common.settings.Settings;\n \n-import java.util.List;\n-\n /**\n  *\n  */\n public class AllocationModule extends AbstractModule implements SpawnModules {\n \n     private final Settings settings;\n \n-    private List<Class<? extends AllocationDecider>> allocations = Lists.newArrayList();\n-\n     public AllocationModule(Settings settings) {\n         this.settings = settings;\n     }",
    "output": "Remove unused variable"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/http/HttpServer.java b/src/main/java/org/elasticsearch/http/HttpServer.java\n--- a/src/main/java/org/elasticsearch/http/HttpServer.java\n+++ b/src/main/java/org/elasticsearch/http/HttpServer.java\n@@ -90,12 +90,12 @@ protected void doStart() throws ElasticSearchException {\n         if (logger.isInfoEnabled()) {\n             logger.info(\"{}\", transport.boundAddress());\n         }\n-        nodeService.putNodeAttribute(\"http_address\", transport.boundAddress().publishAddress().toString());\n+        nodeService.putAttribute(\"http_address\", transport.boundAddress().publishAddress().toString());\n     }\n \n     @Override\n     protected void doStop() throws ElasticSearchException {\n-        nodeService.removeNodeAttribute(\"http_address\");\n+        nodeService.removeAttribute(\"http_address\");\n         transport.stop();\n     }\n ",
    "output": "Use non deprecated methods"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java b/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/cluster/MinimumMasterNodesTests.java\n@@ -160,7 +160,9 @@ public void simpleMinimumMasterNodes() throws Exception {\n         logger.info(\"--> starting the previous master node again...\");\n         startNode(nonMasterNodeName, settings);\n \n-        clusterHealthResponse = client(\"node1\").admin().cluster().prepareHealth().setWaitForNodes(\"2\").execute().actionGet();\n+        Thread.sleep(200);\n+\n+        clusterHealthResponse = client(\"node1\").admin().cluster().prepareHealth().setWaitForNodes(\"2\").setWaitForGreenStatus().execute().actionGet();\n         assertThat(clusterHealthResponse.timedOut(), equalTo(false));\n \n         state = client(\"node1\").admin().cluster().prepareState().setLocal(true).execute().actionGet().state();",
    "output": "Improve test, wait for green state post master node startup"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/netty/KeepFrameDecoder.java b/src/main/java/org/elasticsearch/common/netty/KeepFrameDecoder.java\n--- a/src/main/java/org/elasticsearch/common/netty/KeepFrameDecoder.java\n+++ b/src/main/java/org/elasticsearch/common/netty/KeepFrameDecoder.java\n@@ -0,0 +1,19 @@\n+package org.elasticsearch.common.netty;\n+\n+import org.jboss.netty.buffer.ChannelBuffer;\n+import org.jboss.netty.channel.Channel;\n+import org.jboss.netty.channel.ChannelHandlerContext;\n+import org.jboss.netty.handler.codec.frame.FrameDecoder;\n+\n+/**\n+ * A marker to not remove frame decoder from the resulting jar so plugins can use it.\n+ */\n+public class KeepFrameDecoder extends FrameDecoder {\n+\n+    public static final KeepFrameDecoder decoder = new KeepFrameDecoder();\n+\n+    @Override\n+    protected Object decode(ChannelHandlerContext ctx, Channel channel, ChannelBuffer buffer) throws Exception {\n+        return null;\n+    }\n+}",
    "output": "Add a marker class to keep frame decoder around"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java b/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java\n--- a/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java\n+++ b/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java\n@@ -126,9 +126,6 @@ public Query parse(QueryParseContext parseContext) throws IOException, QueryPars\n \n             Filter childFilter = parseContext.cacheFilter(objectMapper.nestedTypeFilter(), null);\n             usAsParentFilter.filter = childFilter;\n-            if (usAsParentFilter.filter == null) {\n-                System.out.println(\"HELLO\");\n-            }\n             // wrap the child query to only work on the nested path type\n             query = new FilteredQuery(query, childFilter);\n ",
    "output": "Remove test sysout"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/gateway/local/QuorumLocalGatewayTests.java b/src/test/java/org/elasticsearch/test/integration/gateway/local/QuorumLocalGatewayTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/gateway/local/QuorumLocalGatewayTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/gateway/local/QuorumLocalGatewayTests.java\n@@ -144,7 +144,7 @@ public void testQuorumRecovery() throws Exception {\n         closeNode(\"node1\");\n \n         logger.info(\"--> running cluster_health (wait for the shards to startup)\");\n-        clusterHealth = client(\"node2\").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForActiveShards(4)).actionGet();\n+        clusterHealth = client(\"node2\").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForNodes(\"2\").waitForActiveShards(4)).actionGet();\n         logger.info(\"--> done cluster_health, status \" + clusterHealth.status());\n         assertThat(clusterHealth.timedOut(), equalTo(false));\n         assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.YELLOW));",
    "output": "Improve test to wait for 2 nodes"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/admin/cluster/node/shutdown/TransportNodesShutdownAction.java b/src/main/java/org/elasticsearch/action/admin/cluster/node/shutdown/TransportNodesShutdownAction.java\n--- a/src/main/java/org/elasticsearch/action/admin/cluster/node/shutdown/TransportNodesShutdownAction.java\n+++ b/src/main/java/org/elasticsearch/action/admin/cluster/node/shutdown/TransportNodesShutdownAction.java\n@@ -62,7 +62,7 @@ public TransportNodesShutdownAction(Settings settings, TransportService transpor\n         super(settings, transportService, clusterService, threadPool);\n         this.node = node;\n         this.clusterName = clusterName;\n-        this.disabled = componentSettings.getAsBoolean(\"disabled\", false);\n+        this.disabled = settings.getAsBoolean(\"action.disable_shutdown\", componentSettings.getAsBoolean(\"disabled\", false));\n         this.delay = componentSettings.getAsTime(\"delay\", TimeValue.timeValueMillis(200));\n \n         this.transportService.registerHandler(NodeShutdownRequestHandler.ACTION, new NodeShutdownRequestHandler());",
    "output": "Add a simplified setting to disable shutdown API: action.disable_shutdown,"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java b/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java\n@@ -29,6 +29,8 @@\n import org.elasticsearch.cluster.metadata.AliasMetaData;\n import org.elasticsearch.cluster.metadata.IndexMetaData;\n import org.elasticsearch.common.StopWatch;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.index.query.FilterBuilder;\n import org.elasticsearch.index.query.QueryBuilders;\n@@ -65,11 +67,14 @@ public class IndexAliasesTests extends AbstractNodesTests {\n     protected Client[] clients;\n     protected Random random = new Random();\n \n-\n     @BeforeClass\n     public void startNodes() {\n-        startNode(\"server1\");\n-        startNode(\"server2\");\n+        Settings nodeSettings = ImmutableSettings.settingsBuilder()\n+                .put(\"action.auto_create_index\", false)\n+                .build();\n+\n+        startNode(\"server1\", nodeSettings);\n+        startNode(\"server2\", nodeSettings);\n         client1 = getClient1();\n         client2 = getClient2();\n         clients = new Client[]{client1, client2};",
    "output": "Remove yml file conf for test"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java b/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n--- a/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n+++ b/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n@@ -53,6 +53,7 @@ public void handleRequest(final RestRequest request, final RestChannel channel)\n         ClusterHealthRequest clusterHealthRequest = clusterHealthRequest(RestActions.splitIndices(request.param(\"index\")));\n         int level = 0;\n         try {\n+            clusterHealthRequest.masterNodeTimeout(request.paramAsTime(\"master_timeout\", clusterHealthRequest.masterNodeTimeout()));\n             clusterHealthRequest.timeout(request.paramAsTime(\"timeout\", clusterHealthRequest.timeout()));\n             String waitForStatus = request.param(\"wait_for_status\");\n             if (waitForStatus != null) {",
    "output": "Add an option to control teh master node timeout in cluster health request"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/master/MasterNodeOperationRequest.java b/src/main/java/org/elasticsearch/action/support/master/MasterNodeOperationRequest.java\n--- a/src/main/java/org/elasticsearch/action/support/master/MasterNodeOperationRequest.java\n+++ b/src/main/java/org/elasticsearch/action/support/master/MasterNodeOperationRequest.java\n@@ -28,12 +28,12 @@\n \n /**\n  * A based request for master based operation.\n- *\n- *\n  */\n public abstract class MasterNodeOperationRequest implements ActionRequest {\n \n-    private TimeValue masterNodeTimeout = TimeValue.timeValueSeconds(30);\n+    public static TimeValue DEFAULT_MASTER_NODE_TIMEOUT = TimeValue.timeValueSeconds(30);\n+\n+    private TimeValue masterNodeTimeout = DEFAULT_MASTER_NODE_TIMEOUT;\n \n     @Override\n     public boolean listenerThreaded() {",
    "output": "Use a constant value for default master node timeout"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java b/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java\n--- a/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java\n+++ b/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java\n@@ -35,24 +35,20 @@\n import org.elasticsearch.index.service.IndexService;\n import org.elasticsearch.index.shard.service.IndexShard;\n import org.elasticsearch.indices.IndicesService;\n-import org.elasticsearch.script.ScriptService;\n import org.elasticsearch.threadpool.ThreadPool;\n import org.elasticsearch.transport.TransportService;\n \n public class TransportShardMultiGetAction extends TransportShardSingleOperationAction<MultiGetShardRequest, MultiGetShardResponse> {\n \n     private final IndicesService indicesService;\n \n-    private final ScriptService scriptService;\n-\n     private final boolean realtime;\n \n     @Inject\n     public TransportShardMultiGetAction(Settings settings, ClusterService clusterService, TransportService transportService,\n-                                        IndicesService indicesService, ScriptService scriptService, ThreadPool threadPool) {\n+                                        IndicesService indicesService, ThreadPool threadPool) {\n         super(settings, threadPool, clusterService, transportService);\n         this.indicesService = indicesService;\n-        this.scriptService = scriptService;\n \n         this.realtime = settings.getAsBoolean(\"action.get.realtime\", true);\n     }",
    "output": "Remove unused script service"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n--- a/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n+++ b/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n@@ -54,7 +54,7 @@ public class MetaData implements Iterable<IndexMetaData> {\n     public static final ClusterBlock CLUSTER_READ_ONLY_BLOCK = new ClusterBlock(6, \"cluster read-only (api)\", false, false, ClusterBlockLevel.WRITE, ClusterBlockLevel.METADATA);\n \n     private static ImmutableSet<String> dynamicSettings = ImmutableSet.<String>builder()\n-            .add(\"cluster.read_only\")\n+            .add(SETTING_READ_ONLY)\n             .build();\n \n     public static ImmutableSet<String> dynamicSettings() {",
    "output": "Fix failed test ClusterAndIndexReaderOnlyTests MetaData uses two different string constants, \"cluster.blocks.read_only\" and \"cluster.read_only\", for one setting. It confuses TransportClusterUpdateSettingsAction and causes lusterAndIndexReaderOnlyTests never finish"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/common/logging/ESLoggerFactory.java b/src/main/java/org/elasticsearch/common/logging/ESLoggerFactory.java\n--- a/src/main/java/org/elasticsearch/common/logging/ESLoggerFactory.java\n+++ b/src/main/java/org/elasticsearch/common/logging/ESLoggerFactory.java\n@@ -32,7 +32,9 @@ public abstract class ESLoggerFactory {\n \n     static {\n         try {\n-            Class.forName(\"org.apache.log4j.Logger\");\n+            Class<?> loggerClazz = Class.forName(\"org.apache.log4j.Logger\");\n+            // below will throw a NoSuchMethod failure with using slf4j log4j bridge\n+            loggerClazz.getMethod(\"setLevel\", Class.forName(\"org.apache.log4j.Level\"));\n             defaultFactory = new Log4jESLoggerFactory();\n         } catch (Throwable e) {\n             // no log4j",
    "output": "Improve detection of which logging library to use, use slf4j if its the log4j jar file used (does not have setLevel method)"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/unit/common/path/PathTrieTests.java b/src/test/java/org/elasticsearch/test/unit/common/path/PathTrieTests.java\n--- a/src/test/java/org/elasticsearch/test/unit/common/path/PathTrieTests.java\n+++ b/src/test/java/org/elasticsearch/test/unit/common/path/PathTrieTests.java\n@@ -98,4 +98,17 @@ public void testSameNameOnDifferentPath() {\n         assertThat(trie.retrieve(\"/b/testX\", params), equalTo(\"test2\"));\n         assertThat(params.get(\"name\"), equalTo(\"testX\"));\n     }\n+\n+    @Test\n+    public void testPreferNonWildcardExecution() {\n+        PathTrie<String> trie = new PathTrie<String>();\n+        trie.insert(\"{test}\", \"test1\");\n+        trie.insert(\"b\", \"test2\");\n+        trie.insert(\"{test}/a\", \"test3\");\n+        trie.insert(\"b/a\", \"test4\");\n+\n+        Map<String, String> params = newHashMap();\n+        assertThat(trie.retrieve(\"/b\", params), equalTo(\"test2\"));\n+        assertThat(trie.retrieve(\"/b/a\", params), equalTo(\"test4\"));\n+    }\n }",
    "output": "Add another path trie test for wildcard vs. contant"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/bootstrap/ElasticSearchF.java b/src/main/java/org/elasticsearch/bootstrap/ElasticSearchF.java\n--- a/src/main/java/org/elasticsearch/bootstrap/ElasticSearchF.java\n+++ b/src/main/java/org/elasticsearch/bootstrap/ElasticSearchF.java\n@@ -0,0 +1,17 @@\n+package org.elasticsearch.bootstrap;\n+\n+/**\n+ * Same as {@link ElasticSearch} just runs it in the foreground by default (does not close\n+ * sout and serr).\n+ */\n+public class ElasticSearchF {\n+\n+    public static void close(String[] args) {\n+        Bootstrap.close(args);\n+    }\n+\n+    public static void main(String[] args) {\n+        System.setProperty(\"es-foreground\", \"yes\");\n+        Bootstrap.main(args);\n+    }\n+}",
    "output": "Add a utility main class that will automatically run it in the foreground without setting a system property"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java b/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java\n--- a/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java\n+++ b/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java\n@@ -23,7 +23,6 @@\n import com.google.common.collect.Sets;\n import org.apache.lucene.store.IndexInput;\n import org.elasticsearch.ElasticSearchException;\n-import org.elasticsearch.cluster.metadata.MetaData;\n import org.elasticsearch.common.StopWatch;\n import org.elasticsearch.common.component.AbstractComponent;\n import org.elasticsearch.common.inject.Inject;\n@@ -53,10 +52,6 @@\n  */\n public class RecoverySource extends AbstractComponent {\n \n-    static {\n-        MetaData.addDynamicSettings(\"index.shard.recovery.concurrent_streams\");\n-    }\n-\n     public static class Actions {\n         public static final String START_RECOVERY = \"index/shard/recovery/startRecovery\";\n     }",
    "output": "Remove unused setting"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java b/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n--- a/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n+++ b/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n@@ -21,6 +21,7 @@\n \n import org.elasticsearch.ElasticSearchException;\n import org.elasticsearch.ElasticSearchIllegalStateException;\n+import org.elasticsearch.Version;\n import org.elasticsearch.cluster.ClusterName;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n import org.elasticsearch.cluster.node.DiscoveryNodes;\n@@ -445,6 +446,7 @@ private void handleExternalPingRequest(Map<String, Object> externalPingData, XCo\n                 XContentBuilder builder = XContentFactory.contentBuilder(contentType);\n                 builder.startObject().startObject(\"response\");\n                 builder.field(\"cluster_name\", MulticastZenPing.this.clusterName.value());\n+                builder.startObject(\"version\").field(\"number\", Version.CURRENT.number()).field(\"snapshot_build\", Version.CURRENT.snapshot).endObject();\n                 builder.field(\"transport_address\", localNode.address().toString());\n \n                 if (nodesProvider.nodeService() != null) {",
    "output": "Add the version number to the json multicast response"
  },
  {
    "input": "diff --git a/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java b/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java\n--- a/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java\n+++ b/src/test/java/org/elasticsearch/test/integration/aliases/IndexAliasesTests.java\n@@ -45,6 +45,7 @@\n import java.util.Set;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n \n import static com.google.common.collect.Sets.newHashSet;\n import static org.elasticsearch.client.Requests.*;\n@@ -516,6 +517,11 @@ public void run() {\n             });\n         }\n         executor.shutdown();\n+        boolean done = executor.awaitTermination(10, TimeUnit.SECONDS);\n+        assertThat(done, equalTo(true));\n+        if (!done) {\n+            executor.shutdownNow();\n+        }\n     }\n \n ",
    "output": "Fix test to wait for async indexing to finish"
  },
  {
    "input": "diff --git a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -533,7 +533,7 @@ void performReplicas(final PrimaryResponse<Response, ReplicaRequest> response) {\n                 // async replication, notify the listener\n                 listener.onResponse(response.response());\n                 // now, trick the counter so it won't decrease to 0 and notify the listeners\n-                replicaCounter = -100;\n+                replicaCounter = Integer.MIN_VALUE;\n             }\n \n             // we add one to the replica count to do the postPrimaryOperation",
    "output": "Use the smaller value possible"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/node/NodeClosedException.java b/modules/elasticsearch/src/main/java/org/elasticsearch/node/NodeClosedException.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/node/NodeClosedException.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/node/NodeClosedException.java\n@@ -29,14 +29,7 @@\n  */\n public class NodeClosedException extends ElasticSearchException {\n \n-    private final DiscoveryNode node;\n-\n     public NodeClosedException(DiscoveryNode node) {\n         super(\"node closed \" + node);\n-        this.node = node;\n-    }\n-\n-    public DiscoveryNode node() {\n-        return node;\n     }\n }",
    "output": "Make node closed exception serializable"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/common/path/PathTrieTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/common/path/PathTrieTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/common/path/PathTrieTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/common/path/PathTrieTests.java\n@@ -78,4 +78,18 @@ public class PathTrieTests {\n         assertThat(trie.retrieve(\"/b/testX\", params), equalTo(\"test2\"));\n         assertThat(params.get(\"name\"), equalTo(\"testX\"));\n     }\n+\n+    @Test public void testSameNameOnDifferentPath() {\n+        PathTrie<String> trie = new PathTrie<String>();\n+        trie.insert(\"/a/c/{name}\", \"test1\");\n+        trie.insert(\"/b/{name}\", \"test2\");\n+\n+        Map<String, String> params = newHashMap();\n+        assertThat(trie.retrieve(\"/a/c/test\", params), equalTo(\"test1\"));\n+        assertThat(params.get(\"name\"), equalTo(\"test\"));\n+\n+        params.clear();\n+        assertThat(trie.retrieve(\"/b/testX\", params), equalTo(\"test2\"));\n+        assertThat(params.get(\"name\"), equalTo(\"testX\"));\n+    }\n }",
    "output": "Add another path trie test"
  },
  {
    "input": "diff --git a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n--- a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n+++ b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n@@ -353,11 +353,13 @@ private class Indexer implements Runnable {\n                             // bigcouch uses array for the seq\n                             try {\n                                 XContentBuilder builder = XContentFactory.jsonBuilder();\n-                                builder.startObject();\n+                                //builder.startObject();\n+                                builder.startArray();\n                                 for (Object value : ((List) lastSeq)) {\n                                     builder.value(value);\n                                 }\n-                                builder.endObject();\n+                                builder.endArray();\n+                                //builder.endObject();\n                                 lastSeqAsString = builder.string();\n                             } catch (Exception e) {\n                                 logger.error(\"failed to convert last_seq to a json string\", e);",
    "output": "Change writeObject to writeArray dealing with json array not json map"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/gateway/none/RecoverAfterNodesTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/gateway/none/RecoverAfterNodesTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/gateway/none/RecoverAfterNodesTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/gateway/none/RecoverAfterNodesTests.java\n@@ -68,7 +68,7 @@ public class RecoverAfterNodesTests extends AbstractNodesTests {\n                 equalTo(true));\n     }\n \n-    @Test public void testRecoverAfterMasterNodes() {\n+    @Test public void testRecoverAfterMasterNodes() throws Exception {\n         logger.info(\"--> start master_node (1)\");\n         startNode(\"master1\", settingsBuilder().put(\"gateway.recover_after_master_nodes\", 2).put(\"node.data\", false).put(\"node.master\", true));\n         assertThat(client(\"master1\").admin().cluster().prepareState().setLocal(true).execute().actionGet()\n@@ -98,6 +98,7 @@ public class RecoverAfterNodesTests extends AbstractNodesTests {\n \n         logger.info(\"--> start master_node (2)\");\n         startNode(\"master2\", settingsBuilder().put(\"gateway.recover_after_master_nodes\", 2).put(\"node.data\", false).put(\"node.master\", true));\n+        Thread.sleep(300);\n         assertThat(client(\"master1\").admin().cluster().prepareState().setLocal(true).execute().actionGet()\n                 .state().blocks().global(ClusterBlockLevel.METADATA).isEmpty(),\n                 equalTo(true));",
    "output": "Add a sleep to fix test (need to think of a better fix)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java\n@@ -181,7 +181,11 @@ private Analyzer findAnalyzer(ParseContext context) {\n         if (analyzer == null) {\n             analyzer = context.analyzer();\n             if (analyzer == null) {\n-                analyzer = Lucene.STANDARD_ANALYZER;\n+                analyzer = context.docMapper().indexAnalyzer();\n+                if (analyzer == null) {\n+                    // This should not happen, should we log warn it?\n+                    analyzer = Lucene.STANDARD_ANALYZER;\n+                }\n             }\n         }\n         return analyzer;",
    "output": "Make sure we use the default index analyzer for _all field, even though it works well without it now because the _analyzer field comes before it and sets the context.analyzer"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java\n@@ -172,8 +172,6 @@ private static void writeValue(XContentGenerator gen, Object value) throws IOExc\n             gen.writeBinary((byte[]) value);\n         } else if (value instanceof Date) {\n             gen.writeString(XContentBuilder.defaultDatePrinter.print(((Date) value).getTime()));\n-        } else if (type == java.sql.Date.class) {\n-            gen.writeString(XContentBuilder.defaultDatePrinter.print(((java.sql.Date) value).getTime()));\n         } else {\n             gen.writeString(value.toString());\n         }",
    "output": "Add another instanceof check on Date and not direct check"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapConverter.java\n@@ -24,7 +24,12 @@\n import org.elasticsearch.common.xcontent.XContentParser;\n \n import java.io.IOException;\n-import java.util.*;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n \n /**\n  * @author kimchy (shay.banon)\n@@ -165,7 +170,7 @@ private static void writeValue(XContentGenerator gen, Object value) throws IOExc\n             writeObjectArray(gen, (Object[]) value);\n         } else if (type == byte[].class) {\n             gen.writeBinary((byte[]) value);\n-        } else if (type == Date.class) {\n+        } else if (value instanceof Date) {\n             gen.writeString(XContentBuilder.defaultDatePrinter.print(((Date) value).getTime()));\n         } else if (type == java.sql.Date.class) {\n             gen.writeString(XContentBuilder.defaultDatePrinter.print(((java.sql.Date) value).getTime()));",
    "output": "Add another instanceof check on Date and not direct check"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n@@ -44,6 +44,8 @@ public class Version {\n     public static final Version V_0_18_3 = new Version(V_0_18_3_ID, false);\n     public static final int V_0_18_4_ID = /*00*/180499;\n     public static final Version V_0_18_4 = new Version(V_0_18_4_ID, false);\n+    public static final int V_0_18_5_ID = /*00*/180599;\n+    public static final Version V_0_18_5 = new Version(V_0_18_5_ID, false);\n \n     public static final int V_0_19_0_ID = /*00*/190099;\n     public static final Version V_0_19_0 = new Version(V_0_19_0_ID, true);\n@@ -66,6 +68,8 @@ private static Version fromId(int id) {\n                 return V_0_18_3;\n             case V_0_18_4_ID:\n                 return V_0_18_4;\n+            case V_0_18_5_ID:\n+                return V_0_18_5;\n             case V_0_19_0_ID:\n                 return V_0_19_0;\n             default:",
    "output": "Add 0.18.5 version"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n@@ -42,6 +42,8 @@ public class Version {\n     public static final Version V_0_18_2 = new Version(V_0_18_2_ID, false);\n     public static final int V_0_18_3_ID = /*00*/180399;\n     public static final Version V_0_18_3 = new Version(V_0_18_3_ID, false);\n+    public static final int V_0_18_4_ID = /*00*/180499;\n+    public static final Version V_0_18_4 = new Version(V_0_18_4_ID, false);\n \n     public static final int V_0_19_0_ID = /*00*/190099;\n     public static final Version V_0_19_0 = new Version(V_0_19_0_ID, true);\n@@ -62,6 +64,8 @@ private static Version fromId(int id) {\n                 return V_0_18_2;\n             case V_0_18_3_ID:\n                 return V_0_18_3;\n+            case V_0_18_4_ID:\n+                return V_0_18_4;\n             case V_0_19_0_ID:\n                 return V_0_19_0;\n             default:",
    "output": "Add 0.18.4 version"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetCollector.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetCollector.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetCollector.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetCollector.java\n@@ -211,10 +211,14 @@ public TermsStringOrdinalsFacetCollector(String facetName, String fieldName, int\n             } while (agg != null && value.equals(agg.current));\n \n             if (count > minCount) {\n-                if (excluded == null || !excluded.contains(value)) {\n-                    InternalStringTermsFacet.StringEntry entry = new InternalStringTermsFacet.StringEntry(value, count);\n-                    ordered.add(entry);\n+                if (excluded != null && excluded.contains(value)) {\n+                    continue;\n+                }\n+                if (matcher != null && !matcher.reset(value).matches()) {\n+                    continue;\n                 }\n+                InternalStringTermsFacet.StringEntry entry = new InternalStringTermsFacet.StringEntry(value, count);\n+                ordered.add(entry);\n             }\n         }\n ",
    "output": "Fix processing of regex patterns in large terms facet requests"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java\n@@ -321,7 +321,7 @@ public QueryStringQueryBuilder boost(float boost) {\n             builder.field(\"rewrite\", rewrite);\n         }\n         if (minimumShouldMatch != null) {\n-            builder.field(\"minimum_should_write\", minimumShouldMatch);\n+            builder.field(\"minimum_should_match\", minimumShouldMatch);\n         }\n         builder.endObject();\n     }",
    "output": "Fix minimum_should_match in query_string builder"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStats.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStats.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStats.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStats.java\n@@ -159,7 +159,7 @@ public CommonStats primaries() {\n         builder.endObject();\n \n         builder.startObject(\"total\");\n-        primaries().toXContent(builder, params);\n+        total().toXContent(builder, params);\n         builder.endObject();\n \n         builder.startObject(Fields.INDICES);",
    "output": "Fix reporting of total indexing stats"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/TransportNodesListGatewayStartedShards.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/TransportNodesListGatewayStartedShards.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/TransportNodesListGatewayStartedShards.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/TransportNodesListGatewayStartedShards.java\n@@ -111,10 +111,13 @@ public ActionFuture<NodesLocalGatewayStartedShards> list(ShardId shardId, Set<St\n     }\n \n     @Override protected NodeLocalGatewayStartedShards nodeOperation(NodeRequest request) throws ElasticSearchException {\n-        for (Map.Entry<ShardId, Long> entry : gateway.currentStartedShards().shards().entrySet()) {\n-            if (entry.getKey().equals(request.shardId)) {\n-                assert entry.getValue() != null;\n-                return new NodeLocalGatewayStartedShards(clusterService.localNode(), entry.getValue());\n+        LocalGatewayStartedShards startedShards = gateway.currentStartedShards();\n+        if (startedShards != null) {\n+            for (Map.Entry<ShardId, Long> entry : startedShards.shards().entrySet()) {\n+                if (entry.getKey().equals(request.shardId)) {\n+                    assert entry.getValue() != null;\n+                    return new NodeLocalGatewayStartedShards(clusterService.localNode(), entry.getValue());\n+                }\n             }\n         }\n         return new NodeLocalGatewayStartedShards(clusterService.localNode(), -1);",
    "output": "Fix possible NPE in TransportNodesListGatewayStartedShards operation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n@@ -27,6 +27,7 @@\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.io.FileSystemUtils;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n import org.elasticsearch.index.Index;\n import org.elasticsearch.index.shard.ShardId;\n \n@@ -123,6 +124,13 @@ public class NodeEnvironment extends AbstractComponent {\n         if (logger.isDebugEnabled()) {\n             logger.debug(\"using node location [{}], local_node_id [{}]\", nodesFiles, localNodeId);\n         }\n+        if (logger.isTraceEnabled()) {\n+            StringBuilder sb = new StringBuilder(\"node data locations details:\\n\");\n+            for (File file : nodesFiles) {\n+                sb.append(\" -> \").append(file.getAbsolutePath()).append(\", free_space [\").append(new ByteSizeValue(file.getFreeSpace())).append(\", usable_space [\").append(new ByteSizeValue(file.getUsableSpace())).append(\"\\n\");\n+            }\n+            logger.trace(sb.toString());\n+        }\n \n         this.nodeIndicesLocations = new File[nodeFiles.length];\n         for (int i = 0; i < nodeFiles.length; i++) {",
    "output": "Add more details logging on info of data path"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n@@ -38,6 +38,8 @@ public class Version {\n     public static final Version V_0_18_0 = new Version(V_0_18_0_ID, false);\n     public static final int V_0_18_1_ID = /*00*/180199;\n     public static final Version V_0_18_1 = new Version(V_0_18_1_ID, false);\n+    public static final int V_0_18_2_ID = /*00*/180299;\n+    public static final Version V_0_18_2 = new Version(V_0_18_2_ID, false);\n \n     public static final int V_0_19_0_ID = /*00*/190099;\n     public static final Version V_0_19_0 = new Version(V_0_19_0_ID, true);\n@@ -54,6 +56,8 @@ private static Version fromId(int id) {\n                 return V_0_18_0;\n             case V_0_18_1_ID:\n                 return V_0_18_1;\n+            case V_0_18_2_ID:\n+                return V_0_18_2;\n             case V_0_19_0_ID:\n                 return V_0_19_0;\n             default:",
    "output": "Add 0.18.2 option"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/stream/CachedStreamOutput.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/stream/CachedStreamOutput.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/stream/CachedStreamOutput.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/stream/CachedStreamOutput.java\n@@ -101,8 +101,8 @@ public void clear() {\n \n     private static final SoftWrapper<Queue<Entry>> cache = new SoftWrapper<Queue<Entry>>();\n     private static final AtomicInteger counter = new AtomicInteger();\n-    private static final int BYTES_LIMIT = 10 * 1024 * 1024; // don't cache entries that are bigger than that...\n-    private static final int COUNT_LIMIT = 100;\n+    public static int BYTES_LIMIT = 10 * 1024 * 1024; // don't cache entries that are bigger than that...\n+    public static int COUNT_LIMIT = 100;\n \n     public static void clear() {\n         cache.clear();",
    "output": "Make flags public just so people can hack it if needed"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayStartedShards.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayStartedShards.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayStartedShards.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayStartedShards.java\n@@ -36,24 +36,6 @@\n  */\n public class LocalGatewayStartedShards {\n \n-    public static class StartedShard {\n-        private final long version;\n-        private final ShardId shardId;\n-\n-        public StartedShard(long version, ShardId shardId) {\n-            this.version = version;\n-            this.shardId = shardId;\n-        }\n-\n-        public long version() {\n-            return version;\n-        }\n-\n-        public ShardId shardId() {\n-            return shardId;\n-        }\n-    }\n-\n     private final long version;\n \n     private final ImmutableMap<ShardId, Long> shards;",
    "output": "Remove unused class"
  },
  {
    "input": "diff --git a/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java b/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n--- a/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n+++ b/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n@@ -265,8 +265,8 @@ public class TwitterRiver extends AbstractRiverComponent implements River {\n         }\n         currentRequest = client.prepareBulk();\n         if (streamType.equals(\"filter\") || filterQuery != null) {\n-   \n-                stream.filter(filterQuery);\n+\n+            stream.filter(filterQuery);\n \n         } else if (streamType.equals(\"firehose\")) {\n             stream.firehose(0);\n@@ -416,7 +416,9 @@ private class StatusHandler extends StatusAdapter {\n                     for (URLEntity url : status.getURLEntities()) {\n                         if (url != null) {\n                             builder.startObject();\n-                            builder.field(\"url\", url.getURL().toExternalForm());\n+                            if (url.getURL() != null) {\n+                                builder.field(\"url\", url.getURL().toExternalForm());\n+                            }\n                             if (url.getDisplayURL() != null) {\n                                 builder.field(\"display_url\", url.getDisplayURL());\n                             }",
    "output": "Use twitter4j 2.5 snapshot version as its the only version that works with the change of the endpoint"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java\n@@ -169,9 +169,9 @@ public int compare(TextFragment o1, TextFragment o2) {\n                             }\n                         });\n                     }\n-                    String[] fragments;\n+                    String[] fragments = null;\n                     // number_of_fragments is set to 0 but we have a multivalued field\n-                    if (field.numberOfFragments() == 0 && textsToHighlight.size() > 1) {\n+                    if (field.numberOfFragments() == 0 && textsToHighlight.size() > 1 && fragsList.size() > 0) {\n                         fragments = new String[1];\n                         for (int i = 0; i < fragsList.size(); i++) {\n                             fragments[0] = (fragments[0] != null ? (fragments[0] + \" \") : \"\") + fragsList.get(i).toString();\n@@ -185,7 +185,7 @@ public int compare(TextFragment o1, TextFragment o2) {\n                         }\n                     }\n \n-                    if (fragments.length > 0) {\n+                    if (fragments != null && fragments.length > 0) {\n                         HighlightField highlightField = new HighlightField(field.field(), fragments);\n                         highlightFields.put(highlightField.name(), highlightField);\n                     }",
    "output": "Fix NPE in HighlightField serialization"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/range/InternalRangeFacet.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/range/InternalRangeFacet.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/range/InternalRangeFacet.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/range/InternalRangeFacet.java\n@@ -180,8 +180,11 @@ static final class Fields {\n                 builder.field(Fields.TO_STR, entry.toAsString);\n             }\n             builder.field(Fields.COUNT, entry.count());\n-            builder.field(Fields.MIN, entry.min());\n-            builder.field(Fields.MAX, entry.max());\n+            // only output min and max if there are actually documents matching this range...\n+            if (entry.totalCount() > 0) {\n+                builder.field(Fields.MIN, entry.min());\n+                builder.field(Fields.MAX, entry.max());\n+            }\n             builder.field(Fields.TOTAL_COUNT, entry.totalCount());\n             builder.field(Fields.TOTAL, entry.total());\n             builder.field(Fields.MEAN, entry.mean());",
    "output": "Remove Infinity values for Range facets when no docs match the range,"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java\n@@ -194,13 +194,16 @@ public List<MutableShardRouting> shardsRoutingFor(ShardRouting shardRouting) {\n     public List<MutableShardRouting> shardsRoutingFor(String index, int shardId) {\n         List<MutableShardRouting> shards = newArrayList();\n         for (RoutingNode routingNode : this) {\n-            for (MutableShardRouting shardRouting : routingNode) {\n+            List<MutableShardRouting> nShards = routingNode.shards();\n+            for (int i = 0; i < nShards.size(); i++) {\n+                MutableShardRouting shardRouting = nShards.get(i);\n                 if (shardRouting.index().equals(index) && shardRouting.id() == shardId) {\n                     shards.add(shardRouting);\n                 }\n             }\n         }\n-        for (MutableShardRouting shardRouting : unassigned) {\n+        for (int i = 0; i < unassigned.size(); i++) {\n+            MutableShardRouting shardRouting = unassigned.get(i);\n             if (shardRouting.index().equals(index) && shardRouting.id() == shardId) {\n                 shards.add(shardRouting);\n             }",
    "output": "Use index iteration over iterator"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/SameShardAllocationDecider.java\n@@ -26,6 +26,8 @@\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.Settings;\n \n+import java.util.List;\n+\n /**\n  * An allocation strategy that does not allow for the same shard instance to be allocated on the same node.\n  */\n@@ -36,9 +38,10 @@ public class SameShardAllocationDecider extends AllocationDecider {\n     }\n \n     @Override public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {\n-        for (MutableShardRouting current : node.shards()) {\n+        List<MutableShardRouting> shards = node.shards();\n+        for (int i = 0; i < shards.size(); i++) {\n             // we do not allow for two shards of the same shard id to exists on the same node\n-            if (current.shardId().equals(shardRouting.shardId())) {\n+            if (shards.get(i).shardId().equals(shardRouting.shardId())) {\n                 return Decision.NO;\n             }\n         }",
    "output": "Use index iteration over iterator"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/RoutingFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/RoutingFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/RoutingFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/RoutingFieldMapper.java\n@@ -171,9 +171,6 @@ public String value(Document document) {\n             if (value == null) {\n                 value = context.ignoredValue(path);\n             }\n-            if (value == null) {\n-                // maybe its a numeric field\n-            }\n             if (!routing.equals(value)) {\n                 throw new MapperParsingException(\"External routing [\" + routing + \"] and document path routing [\" + value + \"] mismatch\");\n             }",
    "output": "Remove unnecessary check"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java\n@@ -113,7 +113,7 @@ public static class TypeParser implements Mapper.TypeParser {\n                     builder.nullValue(propNode.toString());\n                 } else if (propName.equals(\"format\")) {\n                     builder.dateTimeFormatter(parseDateTimeFormatter(propName, propNode));\n-                } else if (propName.equals(\"numeric_precision\")) {\n+                } else if (propName.equals(\"numeric_resolution\")) {\n                     builder.timeUnit(TimeUnit.valueOf(propNode.toString().toUpperCase()));\n                 }\n             }\n@@ -348,7 +348,7 @@ protected DateFieldMapper(Names names, FormatDateTimeFormatter dateTimeFormatter\n             builder.field(\"include_in_all\", includeInAll);\n         }\n         if (timeUnit != Defaults.TIME_UNIT) {\n-            builder.field(\"numeric_precision\", timeUnit);\n+            builder.field(\"numeric_resolution\", timeUnit);\n         }\n     }\n ",
    "output": "Use \"numeric_resolution\" instead of \"numeric_precision\" as the field name"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/transport/NetworkExceptionHelper.java\n@@ -52,6 +52,9 @@ public static boolean isCloseConnectionException(Throwable e) {\n             if (e.getMessage().contains(\"Broken pipe\")) {\n                 return true;\n             }\n+            if (e.getMessage().contains(\"Connection timed out\")) {\n+                return true;\n+            }\n         }\n         return false;\n     }",
    "output": "Add timeout to list of connection failures"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n@@ -833,7 +833,19 @@ private void innerDelete(Delete delete, IndexWriter writer) throws IOException {\n                             long translogId = translogIdGenerator.incrementAndGet();\n                             translog.newTransientTranslog(translogId);\n                             indexWriter.commit(MapBuilder.<String, String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY, Long.toString(translogId)).map());\n-                            translog.makeTransientCurrent();\n+                            if (flush.force()) {\n+                                // if we force, we might not have committed, we need to check that its the same id\n+                                Map<String, String> commitUserData = IndexReader.getCommitUserData(store.directory());\n+                                long committedTranslogId = Long.parseLong(commitUserData.get(Translog.TRANSLOG_ID_KEY));\n+                                if (committedTranslogId != translogId) {\n+                                    // we did not commit anything, revert to the old translog\n+                                    translog.revertTransient();\n+                                } else {\n+                                    translog.makeTransientCurrent();\n+                                }\n+                            } else {\n+                                translog.makeTransientCurrent();\n+                            }\n                         } catch (Exception e) {\n                             translog.revertTransient();\n                             throw new FlushFailedEngineException(shardId, e);",
    "output": "Fix full flush when no changes happen in the index, so the updated trans id is not written"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryBufferController.java b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryBufferController.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryBufferController.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryBufferController.java\n@@ -142,7 +142,7 @@ class ShardsIndicesStatusChecker implements Runnable {\n                             // inactive?\n                             if (!status.inactive) {\n                                 // mark it as inactive only if enough time has passed and there are no ongoing merges going on...\n-                                if ((time - status.time) > inactiveTime.millis() && ((InternalIndexShard) indexShard).mergeScheduler().stats().current() == 0) {\n+                                if ((time - status.time) > inactiveTime.millis() && indexShard.mergeStats().current() == 0) {\n                                     try {\n                                         ((InternalIndexShard) indexShard).engine().updateIndexingBufferSize(Engine.INACTIVE_SHARD_INDEXING_BUFFER);\n                                     } catch (EngineClosedException e) {",
    "output": "Use a simpler API call"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/TTLFieldMapper.java\n@@ -22,7 +22,9 @@\n import org.apache.lucene.document.Field;\n import org.apache.lucene.document.Fieldable;\n import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.unit.TimeValue;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n import org.elasticsearch.index.AlreadyExpiredException;\n import org.elasticsearch.index.mapper.InternalMapper;\n import org.elasticsearch.index.mapper.Mapper;\n@@ -136,7 +138,12 @@ public Object valueForSearch(long expirationTime) {\n \n     @Override public void parse(ParseContext context) throws IOException, MapperParsingException {\n         if (context.sourceToParse().ttl() < 0) { // no ttl has been provided externally\n-            long ttl = context.parser().longValue();\n+            long ttl;\n+            if (context.parser().currentToken() == XContentParser.Token.VALUE_STRING) {\n+                ttl = TimeValue.parseTimeValue(context.parser().text(), null).millis();\n+            } else {\n+                ttl = context.parser().longValue();\n+            }\n             if (ttl <= 0) {\n                 throw new MapperParsingException(\"TTL value must be > 0. Illegal value provided [\" + ttl + \"]\");\n             }",
    "output": "Add time value definition of ttl inside source"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n@@ -64,6 +64,7 @@ public void clear() {\n         value = null;\n         valueLoaded = false;\n         values.clear();\n+        valuesLoaded = false;\n         doc = null;\n     }\n ",
    "output": "Fix wrong removal of flag"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n@@ -64,7 +64,6 @@ public void clear() {\n         value = null;\n         valueLoaded = false;\n         values.clear();\n-        valuesLoaded = false;\n         doc = null;\n     }\n ",
    "output": "Remove double setting clear"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/FieldLookup.java\n@@ -64,7 +64,7 @@ public void clear() {\n         value = null;\n         valueLoaded = false;\n         values.clear();\n-        valuesLoaded = true;\n+        valuesLoaded = false;\n         doc = null;\n     }\n ",
    "output": "Fix clear for FieldLookup values"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java\n@@ -50,7 +50,7 @@ public class PercolateRequest extends SingleCustomOperationRequest {\n     private int sourceLength;\n     private boolean sourceUnsafe;\n \n-    PercolateRequest() {\n+    public PercolateRequest() {\n \n     }\n ",
    "output": "Add percolate api to groovy client"
  },
  {
    "input": "diff --git a/plugins/cloud/aws/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java b/plugins/cloud/aws/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n--- a/plugins/cloud/aws/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n+++ b/plugins/cloud/aws/src/main/java/org/elasticsearch/cloud/aws/AwsEc2Service.java\n@@ -65,10 +65,10 @@ public synchronized AmazonEC2 client() {\n         String key = componentSettings.get(\"secret_key\", settings.get(\"cloud.key\"));\n \n         if (account == null) {\n-            throw new ElasticSearchIllegalArgumentException(\"No s3 access_key defined for s3 gateway\");\n+            throw new ElasticSearchIllegalArgumentException(\"No aws access_key defined for ec2 discovery\");\n         }\n         if (key == null) {\n-            throw new ElasticSearchIllegalArgumentException(\"No s3 secret_key defined for s3 gateway\");\n+            throw new ElasticSearchIllegalArgumentException(\"No aws secret_key defined for ec2 discovery\");\n         }\n \n         String proxyHost = componentSettings.get(\"proxy_host\");",
    "output": "Fix failure message"
  },
  {
    "input": "diff --git a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n--- a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n+++ b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n@@ -254,7 +254,6 @@ private String processLine(String s, BulkRequestBuilder bulk) {\n             }\n             \n \t\t\t// Remove _attachement from doc if needed\n-            // TODO : check if couchDB support now attachment filter : https://issues.apache.org/jira/browse/COUCHDB-1263\n \t\t\tif (couchIgnoreAttachements) {\n \t\t\t\tif (doc.containsKey(\"_attachments\")) {\n \t\t\t\t\tMap<String, Object> _attachments = (Map<String, Object>) doc\n@@ -266,6 +265,9 @@ private String processLine(String s, BulkRequestBuilder bulk) {\n \t\t\t\t\t\t}\n \t\t\t\t\t}\n \t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\t// TODO by now, couchDB river does not really store attachments in Elastic Search but only attachments meta informations\n+\t\t\t\t// So we perhaps need to fully support attachments\n \t\t\t}\n \n \t\t\tbulk.add(indexRequest(index).type(type).id(id).source(doc).routing(extractRouting(ctx)));\n@@ -403,7 +405,6 @@ private class Slurper implements Runnable {\n                         file = file + couchFilterParamsUrl;\n                     }\n                 }\n-                // TODO : check if couchDB support now attachment filter : https://issues.apache.org/jira/browse/COUCHDB-1263\n                 \n                 if (lastSeq != null) {\n                     file = file + \"&since=\" + lastSeq;",
    "output": "Upgrade TODO after a brief talk with couchDB team, attachment filter doesn't make sense on server side but only on client side. BTW, we may like to fully support attachments in ES couchDB river as by now only meta information are sent to Elastic Search"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java\n@@ -64,7 +64,7 @@ public class TransportIndicesStatsAction extends TransportBroadcastOperationActi\n     }\n \n     @Override protected String transportAction() {\n-        return TransportActions.Admin.Indices.STATUS;\n+        return TransportActions.Admin.Indices.STATS;\n     }\n \n     @Override protected String transportShardAction() {",
    "output": "Fix stats action registration"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java\n@@ -141,7 +141,7 @@ public class HighlighterParseElement implements SearchParseElement {\n                                         field.fragmentOffset(parser.intValue());\n                                     } else if (\"highlight_filter\".equals(fieldName) || \"highlightFilter\".equals(fieldName)) {\n                                         field.highlightFilter(parser.booleanValue());\n-                                    } else if (\"score\".equals(fieldName)) {\n+                                    } else if (\"order\".equals(fieldName)) {\n                                         field.scoreOrdered(\"score\".equals(parser.text()));\n                                     }\n                                 }",
    "output": "Fix highlight score ordering for a field"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/process/ProcessStats.java b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/process/ProcessStats.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/process/ProcessStats.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/process/ProcessStats.java\n@@ -54,6 +54,14 @@ public long getTimestamp() {\n         return timestamp();\n     }\n \n+    public long openFileDescriptors() {\n+        return this.openFileDescriptors;\n+    }\n+\n+    public long getOpenFileDescriptors() {\n+        return openFileDescriptors;\n+    }\n+\n     public Cpu cpu() {\n         return cpu;\n     }",
    "output": "Add getter for open file desc"
  },
  {
    "input": "diff --git a/plugins/mapper/attachments/src/test/java/org/elasticsearch/index/mapper/xcontent/SimpleAttachmentMapperTests.java b/plugins/mapper/attachments/src/test/java/org/elasticsearch/index/mapper/xcontent/SimpleAttachmentMapperTests.java\n--- a/plugins/mapper/attachments/src/test/java/org/elasticsearch/index/mapper/xcontent/SimpleAttachmentMapperTests.java\n+++ b/plugins/mapper/attachments/src/test/java/org/elasticsearch/index/mapper/xcontent/SimpleAttachmentMapperTests.java\n@@ -55,6 +55,7 @@ public class SimpleAttachmentMapperTests {\n \n         Document doc = docMapper.parse(json).rootDoc();\n \n+        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"application/xhtml+xml\"));\n         assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"XHTML test document\"));\n         assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"This document tests the ability of Apache Tika to extract content\"));\n \n@@ -66,6 +67,7 @@ public class SimpleAttachmentMapperTests {\n \n         doc = docMapper.parse(json).rootDoc();\n \n+        assertThat(doc.get(docMapper.mappers().smartName(\"file.content_type\").mapper().names().indexName()), equalTo(\"application/xhtml+xml\"));\n         assertThat(doc.get(docMapper.mappers().smartName(\"file.title\").mapper().names().indexName()), equalTo(\"XHTML test document\"));\n         assertThat(doc.get(docMapper.mappers().smartName(\"file\").mapper().names().indexName()), containsString(\"This document tests the ability of Apache Tika to extract content\"));\n     }",
    "output": "Add a test to the new content_type field"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobStoreGateway.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobStoreGateway.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobStoreGateway.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobStoreGateway.java\n@@ -196,11 +196,13 @@ private int findLatestIndex() throws IOException {\n             int fileIndex = Integer.parseInt(name.substring(name.indexOf('-') + 1));\n             if (fileIndex >= index) {\n                 // try and read the meta data\n+                byte[] data = null;\n                 try {\n-                    readMetaData(metaDataBlobContainer.readBlobFully(name));\n+                    data = metaDataBlobContainer.readBlobFully(name);\n+                    readMetaData(data);\n                     index = fileIndex;\n                 } catch (IOException e) {\n-                    logger.warn(\"[findLatestMetadata]: Failed to read metadata from [\" + name + \"], ignoring...\", e);\n+                    logger.warn(\"[findLatestMetadata]: failed to read metadata from [{}], data_length [{}] ignoring...\", e, name, data == null ? \"na\" : data.length);\n                 }\n             }\n         }",
    "output": "Add more info to logging failure"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/XContentFactory.java\n@@ -178,7 +178,7 @@ public static XContent xContent(byte[] data) {\n     public static XContent xContent(byte[] data, int offset, int length) {\n         XContentType type = xContentType(data, offset, length);\n         if (type == null) {\n-            throw new ElasticSearchParseException(\"Failed to derive xcontent from \" + Arrays.toString(data));\n+            throw new ElasticSearchParseException(\"Failed to derive xcontent from (offset=\" + offset + \", length=\" + length + \"): \" + Arrays.toString(data));\n         }\n         return xContent(type);\n     }",
    "output": "Add more info on failure to derive xcontent"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/nested/SimpleNestedTests.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.action.delete.DeleteResponse;\n import org.elasticsearch.action.get.GetResponse;\n import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.action.search.SearchType;\n import org.elasticsearch.client.Client;\n import org.elasticsearch.common.settings.ImmutableSettings;\n import org.elasticsearch.search.facet.FacetBuilders;\n@@ -116,6 +117,10 @@ public class SimpleNestedTests extends AbstractNodesTests {\n         assertThat(Arrays.toString(searchResponse.shardFailures()), searchResponse.failedShards(), equalTo(0));\n         assertThat(searchResponse.hits().totalHits(), equalTo(1l));\n \n+        searchResponse = client.prepareSearch(\"test\").setQuery(nestedQuery(\"nested1\", termQuery(\"nested1.n_field1\", \"n_value1_1\"))).setSearchType(SearchType.DFS_QUERY_THEN_FETCH).execute().actionGet();\n+        assertThat(Arrays.toString(searchResponse.shardFailures()), searchResponse.failedShards(), equalTo(0));\n+        assertThat(searchResponse.hits().totalHits(), equalTo(1l));\n+\n         // add another doc, one that would match if it was not nested...\n \n         client.prepareIndex(\"test\", \"type1\", \"2\").setSource(jsonBuilder().startObject()",
    "output": "Add dfs test"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n@@ -186,6 +186,9 @@ public NettyTransport(Settings settings, ThreadPool threadPool) {\n         this.connectionsPerNodeLow = componentSettings.getAsInt(\"connections_per_node.low\", settings.getAsInt(\"transport.connections_per_node.low\", 2));\n         this.connectionsPerNodeMed = componentSettings.getAsInt(\"connections_per_node.med\", settings.getAsInt(\"transport.connections_per_node.med\", 7));\n         this.connectionsPerNodeHigh = componentSettings.getAsInt(\"connections_per_node.high\", settings.getAsInt(\"transport.connections_per_node.high\", 1));\n+\n+        logger.debug(\"using worker_count[{}], port[{}], bind_host[{}], publish_host[{}], compress[{}], connect_timeout[{}], connections_per_node[{}/{}/{}]\",\n+                workerCount, port, bindHost, publishHost, compress, connectTimeout, connectionsPerNodeLow, connectionsPerNodeMed, connectionsPerNodeHigh);\n     }\n \n     public Settings settings() {",
    "output": "Add debug logging to netty transport tcp config"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n@@ -183,9 +183,9 @@ public NettyTransport(Settings settings, ThreadPool threadPool) {\n         this.reuseAddress = componentSettings.getAsBoolean(\"reuse_address\", settings.getAsBoolean(TCP_REUSE_ADDRESS, NetworkUtils.defaultReuseAddress()));\n         this.tcpSendBufferSize = componentSettings.getAsBytesSize(\"tcp_send_buffer_size\", settings.getAsBytesSize(TCP_SEND_BUFFER_SIZE, TCP_DEFAULT_SEND_BUFFER_SIZE));\n         this.tcpReceiveBufferSize = componentSettings.getAsBytesSize(\"tcp_receive_buffer_size\", settings.getAsBytesSize(TCP_RECEIVE_BUFFER_SIZE, TCP_DEFAULT_RECEIVE_BUFFER_SIZE));\n-        this.connectionsPerNodeLow = componentSettings.getAsInt(\"connections_per_node.low\", 2);\n-        this.connectionsPerNodeMed = componentSettings.getAsInt(\"connections_per_node.med\", 7);\n-        this.connectionsPerNodeHigh = componentSettings.getAsInt(\"connections_per_node.high\", 1);\n+        this.connectionsPerNodeLow = componentSettings.getAsInt(\"connections_per_node.low\", settings.getAsInt(\"transport.connections_per_node.low\", 2));\n+        this.connectionsPerNodeMed = componentSettings.getAsInt(\"connections_per_node.med\", settings.getAsInt(\"transport.connections_per_node.med\", 7));\n+        this.connectionsPerNodeHigh = componentSettings.getAsInt(\"connections_per_node.high\", settings.getAsInt(\"transport.connections_per_node.high\", 1));\n     }\n \n     public Settings settings() {",
    "output": "Add transport.connections_per_node prefix setting as well as the netty specific one"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java\n@@ -162,7 +162,7 @@ private void getPrefixTerms(List<Term> terms, final Term prefix, final IndexRead\n                 } else {\n                     break;\n                 }\n-                if (terms.size() > maxExpansions) {\n+                if (terms.size() >= maxExpansions) {\n                     break;\n                 }\n             } while (enumerator.next());",
    "output": "Fix the maxExpansion of a prefix query"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -142,6 +142,11 @@ public static void main(String[] args) {\n         Bootstrap bootstrap = new Bootstrap();\n         String pidFile = System.getProperty(\"es-pidfile\");\n \n+        // enable jline by default when running form \"main\"\n+        if (System.getProperty(\"jline.enabled\") == null) {\n+            System.setProperty(\"jline.enabled\", \"true\");\n+        }\n+\n         boolean foreground = System.getProperty(\"es-foreground\") != null;\n         // handle the wrapper system property, if its a service, don't run as a service\n         if (System.getProperty(\"wrapper.service\", \"XXX\").equalsIgnoreCase(\"true\")) {",
    "output": "Remove the jline flag and automatically detect it"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -134,9 +134,11 @@ public void downloadAndExtract(String name) throws IOException {\n                 }\n             } else {\n                 System.out.println(\"Using plugin from local fs: \" + pluginFile.getAbsolutePath());\n+                downloaded = true;\n             }\n         } else {\n             System.out.println(\"Using plugin from local fs: \" + pluginFile.getAbsolutePath());\n+            downloaded = true;\n         }\n \n         if (!downloaded) {",
    "output": "Fix bug when installing local plugins"
  },
  {
    "input": "diff --git a/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java b/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n--- a/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n+++ b/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n@@ -437,9 +437,11 @@ private class StatusHandler extends StatusAdapter {\n                 }\n                 if (status.getAnnotations() != null) {\n                     builder.startObject(\"annotation\");\n-                    for (Annotation ann : status.getAnnotations().getAnnotations()) {\n+                    List<Annotation> annotations = status.getAnnotations().getAnnotations();\n+                    for (Annotation ann : annotations) {\n                         builder.startObject(ann.getType());\n-                        for (Map.Entry<String, String> entry : ann.getAttributes().entrySet()) {\n+                        Map<String, String> attributes = ann.getAttributes();\n+                        for (Map.Entry<String, String> entry : attributes.entrySet()) {\n                             builder.field(entry.getKey(), entry.getValue());\n                         }\n                         builder.endObject();",
    "output": "Fix strange compilation failure under jdk7"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java\n@@ -127,6 +127,9 @@ public static ParsedScrollId parseScrollId(String scrollId) {\n         for (int i = 0; i < contextSize; i++) {\n             String element = elements[index++];\n             int sep = element.indexOf(':');\n+            if (sep == -1) {\n+                throw new ElasticSearchIllegalArgumentException(\"Malformed scrollId [\" + scrollId + \"]\");\n+            }\n             context[i] = new Tuple<String, Long>(element.substring(sep + 1), Long.parseLong(element.substring(0, sep)));\n         }\n         Map<String, String> attributes;",
    "output": "Add handling a failure of malformed scroll id, and throw back the scroll id itself for simpler debugging"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java\n@@ -53,6 +53,7 @@\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.HashMap;\n+import java.util.List;\n import java.util.Map;\n \n /**\n@@ -172,8 +173,12 @@ private Uid extractUid(SearchContext context, Document doc) {\n         if (sUid != null) {\n             return Uid.createUid(sUid);\n         }\n-        // no type, nothing to do (should not really happen\n-        throw new FetchPhaseExecutionException(context, \"Failed to load uid from the index\");\n+        // no type, nothing to do (should not really happen)\n+        List<String> fieldNames = new ArrayList<String>();\n+        for (Fieldable field : doc.getFields()) {\n+            fieldNames.add(field.name());\n+        }\n+        throw new FetchPhaseExecutionException(context, \"Failed to load uid from the index, missing internal _uid field, current fields in the doc [\" + fieldNames + \"]\");\n     }\n \n     private Document loadDocument(SearchContext context, FieldSelector fieldSelector, int docId) {",
    "output": "Improve failure message when not finding _uid field in the doc"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/SearchRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/SearchRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/SearchRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/SearchRequest.java\n@@ -145,7 +145,7 @@ public void beforeLocalFork() {\n     /**\n      * Sets the indices the search will be executed on.\n      */\n-    public SearchRequest indices(String[] indices) {\n+    public SearchRequest indices(String... indices) {\n         this.indices = indices;\n         return this;\n     }",
    "output": "Change indices sig"
  },
  {
    "input": "diff --git a/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java b/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java\n--- a/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java\n+++ b/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/AwsEc2UnicastHostsProvider.java\n@@ -20,7 +20,12 @@\n package org.elasticsearch.discovery.ec2;\n \n import com.amazonaws.services.ec2.AmazonEC2;\n-import com.amazonaws.services.ec2.model.*;\n+import com.amazonaws.services.ec2.model.DescribeInstancesRequest;\n+import com.amazonaws.services.ec2.model.DescribeInstancesResult;\n+import com.amazonaws.services.ec2.model.Instance;\n+import com.amazonaws.services.ec2.model.InstanceState;\n+import com.amazonaws.services.ec2.model.Reservation;\n+import com.amazonaws.services.ec2.model.Tag;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.collect.ImmutableMap;\n@@ -83,6 +88,10 @@ private static enum HostType {\n             availabilityZones.addAll(Strings.commaDelimitedListToSet(componentSettings.get(\"availability_zones\")));\n         }\n         this.availabilityZones = ImmutableSet.copyOf(availabilityZones);\n+\n+        if (logger.isDebugEnabled()) {\n+            logger.debug(\"using host_type [{}], tags [{}], groups [{}] with any_group [{}], availability_zones [{}]\", hostType, tags, groups, bindAnyGroup, availabilityZones);\n+        }\n     }\n \n     @Override public List<DiscoveryNode> buildDynamicNodes() {",
    "output": "Add debug logging for parameters used for ec2 unicast disco"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/routing/AliasRoutingTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/routing/AliasRoutingTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/routing/AliasRoutingTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/routing/AliasRoutingTests.java\n@@ -86,7 +86,6 @@ protected Client getClient() {\n \n         logger.info(\"--> deleting with no routing, should not delete anything\");\n         client.prepareDelete(\"test\", \"type1\", \"1\").setRefresh(true).execute().actionGet();\n-        client.admin().indices().prepareRefresh().execute().actionGet();\n         for (int i = 0; i < 5; i++) {\n             assertThat(client.prepareGet(\"test\", \"type1\", \"1\").execute().actionGet().exists(), equalTo(false));\n             assertThat(client.prepareGet(\"test\", \"type1\", \"1\").setRouting(\"0\").execute().actionGet().exists(), equalTo(true));\n@@ -95,7 +94,6 @@ protected Client getClient() {\n \n         logger.info(\"--> deleting with routing alias, should delete\");\n         client.prepareDelete(\"alias0\", \"type1\", \"1\").setRefresh(true).execute().actionGet();\n-        client.admin().indices().prepareRefresh().execute().actionGet();\n         for (int i = 0; i < 5; i++) {\n             assertThat(client.prepareGet(\"test\", \"type1\", \"1\").execute().actionGet().exists(), equalTo(false));\n             assertThat(client.prepareGet(\"test\", \"type1\", \"1\").setRouting(\"0\").execute().actionGet().exists(), equalTo(false));",
    "output": "Remove unnecessary refresh after delete"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/ShardSearchFailure.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/ShardSearchFailure.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/ShardSearchFailure.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/ShardSearchFailure.java\n@@ -68,6 +68,7 @@ public ShardSearchFailure(Throwable t) {\n     public ShardSearchFailure(String reason, SearchShardTarget shardTarget) {\n         this.shardTarget = shardTarget;\n         this.reason = reason;\n+        this.status = RestStatus.INTERNAL_SERVER_ERROR;\n     }\n \n     /**",
    "output": "Fix NullPointerException when search request partially fails on one or more shards"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/index/translog/AbstractSimpleTranslogTests.java\n@@ -106,7 +106,7 @@ public abstract class AbstractSimpleTranslogTests {\n         assertThat(snapshot.estimatedTotalOperations(), equalTo(3));\n         snapshot.release();\n \n-        translog.add(new Translog.DeleteByQuery(new byte[]{4}, null, null));\n+        translog.add(new Translog.DeleteByQuery(new byte[]{4}, null));\n         snapshot = translog.snapshot();\n         assertThat(snapshot, translogSize(4));\n         assertThat(snapshot.estimatedTotalOperations(), equalTo(4));",
    "output": "Fix non-varargs call of varargs method with inexact argument type for last parameter exception warning"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/Analysis.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/Analysis.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/Analysis.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/Analysis.java\n@@ -23,6 +23,7 @@\n import org.apache.lucene.analysis.bg.BulgarianAnalyzer;\n import org.apache.lucene.analysis.br.BrazilianAnalyzer;\n import org.apache.lucene.analysis.ca.CatalanAnalyzer;\n+import org.apache.lucene.analysis.cz.CzechAnalyzer;\n import org.apache.lucene.analysis.da.DanishAnalyzer;\n import org.apache.lucene.analysis.de.GermanAnalyzer;\n import org.apache.lucene.analysis.el.GreekAnalyzer;\n@@ -96,6 +97,7 @@ public static Set<?> parseStemExclusion(Settings settings, Set<?> defaultStemExc\n             .put(\"_brazilian_\", BrazilianAnalyzer.getDefaultStopSet())\n             .put(\"_bulgarian_\", BulgarianAnalyzer.getDefaultStopSet())\n             .put(\"_catalan_\", CatalanAnalyzer.getDefaultStopSet())\n+            .put(\"_czech_\", CzechAnalyzer.getDefaultStopSet())\n             .put(\"_danish_\", DanishAnalyzer.getDefaultStopSet())\n             .put(\"_dutch_\", DutchAnalyzer.getDefaultStopSet())\n             .put(\"_english_\", EnglishAnalyzer.getDefaultStopSet())",
    "output": "Add Czech default stopwords into named stopwords map"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/network/NetworkService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/network/NetworkService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/network/NetworkService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/network/NetworkService.java\n@@ -70,12 +70,12 @@ public static interface CustomNameResolver {\n         /**\n          * Resolves the default value if possible. If not, return <tt>null</tt>.\n          */\n-        InetAddress resolveDefault();\n+        InetAddress resolveDefault() throws IOException;\n \n         /**\n          * Resolves a custom value handling, return <tt>null</tt> if can't handle it.\n          */\n-        InetAddress resolveIfPossible(String value);\n+        InetAddress resolveIfPossible(String value) throws IOException;\n     }\n \n     private final List<CustomNameResolver> customNameResolvers = new CopyOnWriteArrayList<CustomNameResolver>();",
    "output": "Add throws IOException to CustomNameResolver interface"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java\n@@ -62,7 +62,7 @@ public class SpanOrQueryParser implements QueryParser {\n                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                         Query query = parseContext.parseInnerQuery();\n                         if (!(query instanceof SpanQuery)) {\n-                            throw new QueryParsingException(parseContext.index(), \"spanNear [clauses] must be of type span query\");\n+                            throw new QueryParsingException(parseContext.index(), \"spanOr [clauses] must be of type span query\");\n                         }\n                         clauses.add((SpanQuery) query);\n                     }",
    "output": "Fix error message"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java\n@@ -267,6 +267,7 @@ class GatewayRecoveryListener implements Gateway.GatewayStateRecoveredListener {\n                             routingTableBuilder.add(indexRoutingBuilder);\n                         }\n                     }\n+                    routingTableBuilder.version(recoveredState.version());\n \n                     // now, reroute\n                     RoutingAllocation.Result routingResult = shardsAllocation.reroute(newClusterStateBuilder().state(updatedState).routingTable(routingTableBuilder).build());",
    "output": "Make sure to initialize the routing table version with the cluster state version as well"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/ActionRequestValidationException.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/ActionRequestValidationException.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/ActionRequestValidationException.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/ActionRequestValidationException.java\n@@ -54,7 +54,7 @@ public List<String> validationErrors() {\n         sb.append(\"Validation Failed: \");\n         int index = 0;\n         for (String error : validationErrors) {\n-            sb.append(++index).append(\": \").append(error);\n+            sb.append(++index).append(\": \").append(error).append(\";\");\n         }\n         return sb.toString();\n     }",
    "output": "Add separator to several validation failures"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/MonitorModule.java b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/MonitorModule.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/MonitorModule.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/MonitorModule.java\n@@ -23,6 +23,7 @@\n import org.elasticsearch.common.inject.Scopes;\n import org.elasticsearch.common.inject.assistedinject.FactoryProvider;\n import org.elasticsearch.common.inject.multibindings.MapBinder;\n+import org.elasticsearch.common.logging.Loggers;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.monitor.dump.DumpContributorFactory;\n import org.elasticsearch.monitor.dump.DumpMonitorService;\n@@ -82,6 +83,7 @@ public MonitorModule(Settings settings) {\n             }\n         } catch (Throwable e) {\n             // no sigar\n+            Loggers.getLogger(MonitorModule.class).debug(\"failed to load sigar\", e);\n         }\n         if (!sigarLoaded) {\n             // bind non sigar implementations",
    "output": "Add debug logging to print when sigar is not loaded"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/ip/IpFieldMapper.java\n@@ -76,7 +76,7 @@ public static long ipToLong(String ip) throws ElasticSearchIllegalArgumentExcept\n         try {\n             String[] octets = pattern.split(ip);\n             if (octets.length != 4) {\n-                throw new ElasticSearchIllegalArgumentException(\"failed ot parse ip [\" + ip + \"], not full ip address (4 dots)\");\n+                throw new ElasticSearchIllegalArgumentException(\"failed to parse ip [\" + ip + \"], not full ip address (4 dots)\");\n             }\n             return (Long.parseLong(octets[0]) << 24) + (Integer.parseInt(octets[1]) << 16) +\n                     (Integer.parseInt(octets[2]) << 8) + Integer.parseInt(octets[3]);\n@@ -158,7 +158,7 @@ protected IpFieldMapper(Names names, int precisionStep,\n     }\n \n     /**\n-     * Dates should return as a string, delegates to {@link #valueAsString(org.apache.lucene.document.Fieldable)}.\n+     * IPs should return as a string, delegates to {@link #valueAsString(org.apache.lucene.document.Fieldable)}.\n      */\n     @Override public Object valueForSearch(Fieldable field) {\n         return valueAsString(field);\n@@ -322,4 +322,4 @@ public NumericIpTokenizer(Reader reader, int precisionStep, char[] buffer) throw\n             tokenStream.setLongValue(ipToLong(value));\n         }\n     }\n-}\n\\ No newline at end of file\n+}",
    "output": "Fix some typos"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/TieredMergePolicyProvider.java\n@@ -139,7 +139,7 @@ class ApplySettings implements IndexSettingsService.Listener {\n             }\n \n             int maxMergeAtOnceExplicit = settings.getAsInt(\"index.merge.policy.max_merge_at_once_explicit\", TieredMergePolicyProvider.this.maxMergeAtOnceExplicit);\n-            if (maxMergeAtOnce != TieredMergePolicyProvider.this.maxMergeAtOnceExplicit) {\n+            if (maxMergeAtOnceExplicit != TieredMergePolicyProvider.this.maxMergeAtOnceExplicit) {\n                 logger.info(\"updating [max_merge_at_once_explicit] from [{}] to [{}]\", TieredMergePolicyProvider.this.maxMergeAtOnceExplicit, maxMergeAtOnceExplicit);\n                 TieredMergePolicyProvider.this.maxMergeAtOnceExplicit = maxMergeAtOnceExplicit;\n                 for (CustomTieredMergePolicyProvider policy : policies) {",
    "output": "Fix check for dynamic update of a setting in tiered merge policy"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -21,7 +21,11 @@\n \n import org.elasticsearch.ElasticSearchException;\n import org.elasticsearch.ElasticSearchIllegalStateException;\n-import org.elasticsearch.cluster.*;\n+import org.elasticsearch.cluster.ClusterName;\n+import org.elasticsearch.cluster.ClusterService;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateUpdateTask;\n+import org.elasticsearch.cluster.ProcessedClusterStateUpdateTask;\n import org.elasticsearch.cluster.block.ClusterBlocks;\n import org.elasticsearch.cluster.metadata.MetaData;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n@@ -113,7 +117,7 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen\n         this.initialPingTimeout = componentSettings.getAsTime(\"ping_timeout\", componentSettings.getAsTime(\"initial_ping_timeout\", timeValueSeconds(3)));\n         this.sendLeaveRequest = componentSettings.getAsBoolean(\"send_leave_request\", true);\n \n-        logger.debug(\"using initial_ping_timeout [{}]\", initialPingTimeout);\n+        logger.debug(\"using ping_timeout [{}]\", initialPingTimeout);\n \n         this.electMaster = new ElectMasterService(settings);\n ",
    "output": "Change logging statement to indicate ping_timeout, not initial_ping_timeout"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java\n@@ -29,7 +29,12 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.settings.SettingsException;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n-import org.elasticsearch.rest.*;\n+import org.elasticsearch.rest.BaseRestHandler;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestController;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.XContentRestResponse;\n+import org.elasticsearch.rest.XContentThrowableRestResponse;\n import org.elasticsearch.rest.action.support.RestXContentBuilder;\n \n import java.io.IOException;\n@@ -67,6 +72,9 @@ public class RestUpdateSettingsAction extends BaseRestHandler {\n             }\n         }\n         for (Map.Entry<String, String> entry : request.params().entrySet()) {\n+            if (entry.getKey().equals(\"pretty\")) {\n+                continue;\n+            }\n             updateSettings.put(entry.getKey(), entry.getValue());\n         }\n         updateSettingsRequest.settings(updateSettings);",
    "output": "Remove pretty from parameter when doing update settings"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/StringFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/StringFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/StringFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/StringFieldMapper.java\n@@ -89,10 +89,6 @@ public static class TypeParser implements XContentMapper.TypeParser {\n         }\n     }\n \n-    static class FieldWrapper {\n-        public Field field;\n-    }\n-\n     private String nullValue;\n \n     private Boolean includeInAll;",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java\n@@ -698,8 +698,6 @@ private void innerDelete(Delete delete, IndexWriter writer) throws IOException {\n             throw new FlushNotAllowedEngineException(shardId, \"Already flushing...\");\n         }\n \n-        // We can't do prepareCommit here, since we rely on the the segment version for the translog version\n-\n         try {\n \n             if (flush.full()) {",
    "output": "Remove comment that is no longer relevant"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/LimitFilter.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/LimitFilter.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/LimitFilter.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/LimitFilter.java\n@@ -28,6 +28,7 @@\n public class LimitFilter extends NoCacheFilter {\n \n     private final int limit;\n+    private int counter;\n \n     public LimitFilter(int limit) {\n         this.limit = limit;\n@@ -38,13 +39,15 @@ public int getLimit() {\n     }\n \n     @Override public DocIdSet getDocIdSet(IndexReader reader) throws IOException {\n+        if (counter > limit) {\n+            return null;\n+        }\n         return new LimitDocSet(reader.maxDoc(), limit);\n     }\n \n-    public static class LimitDocSet extends GetDocSet {\n+    public class LimitDocSet extends GetDocSet {\n \n         private final int limit;\n-        private int counter;\n \n         public LimitDocSet(int maxDoc, int limit) {\n             super(maxDoc);",
    "output": "Fix limit filter to properly handle cross segments cases"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/http/HttpServer.java b/modules/elasticsearch/src/main/java/org/elasticsearch/http/HttpServer.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/http/HttpServer.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/http/HttpServer.java\n@@ -49,6 +49,8 @@ public class HttpServer extends AbstractLifecycleComponent<HttpServer> {\n \n     private final TransportNodesInfoAction nodesInfoAction;\n \n+    private final boolean disableSites;\n+\n     @Inject public HttpServer(Settings settings, Environment environment, HttpServerTransport transport,\n                               RestController restController, TransportNodesInfoAction nodesInfoAction) {\n         super(settings);\n@@ -57,6 +59,8 @@ public class HttpServer extends AbstractLifecycleComponent<HttpServer> {\n         this.restController = restController;\n         this.nodesInfoAction = nodesInfoAction;\n \n+        this.disableSites = componentSettings.getAsBoolean(\"disable_sites\", false);\n+\n         transport.httpServerAdapter(new Dispatcher(this));\n     }\n \n@@ -107,6 +111,10 @@ public void internalDispatchRequest(final HttpRequest request, final HttpChannel\n     }\n \n     private void handlePluginSite(HttpRequest request, HttpChannel channel) {\n+        if (disableSites) {\n+            channel.sendResponse(new StringRestResponse(FORBIDDEN));\n+            return;\n+        }\n         if (request.method() != RestRequest.Method.GET) {\n             channel.sendResponse(new StringRestResponse(FORBIDDEN));\n             return;",
    "output": "Add a flag to allow and disable sites (http.disable_sites)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -189,6 +189,8 @@ public void downloadAndExtract(String name) throws IOException {\n                 tmpLocation.renameTo(site);\n             }\n         }\n+\n+        System.out.println(\"Installed \" + name);\n     }\n \n     public void removePlugin(String name) throws IOException {",
    "output": "Add installed message at the end of a plugin installation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -78,7 +78,7 @@ public void downloadAndExtract(String name) throws IOException {\n                         pluginFile = new File(environment.pluginsFile(), name + \".zip\");\n                         if (version == null) {\n                             // try with ES version from downloads\n-                            URL pluginUrl = new URL(\"http://github.com/downloads/\" + userName + \"/\" + repoName + \"/\" + repoName + \"-\" + Version.number());\n+                            URL pluginUrl = new URL(\"http://github.com/downloads/\" + userName + \"/\" + repoName + \"/\" + repoName + \"-\" + Version.number() + \".zip\");\n                             System.out.println(\"Trying \" + pluginUrl.toExternalForm() + \"...\");\n                             try {\n                                 downloadHelper.download(pluginUrl, pluginFile, new HttpDownloadHelper.VerboseProgress(System.out));\n@@ -104,7 +104,7 @@ public void downloadAndExtract(String name) throws IOException {\n                             }\n                         } else {\n                             // download explicit version\n-                            URL pluginUrl = new URL(\"http://github.com/downloads/\" + userName + \"/\" + repoName + \"/\" + repoName + \"-\" + version);\n+                            URL pluginUrl = new URL(\"http://github.com/downloads/\" + userName + \"/\" + repoName + \"/\" + repoName + \"-\" + version + \".zip\");\n                             System.out.println(\"Trying \" + pluginUrl.toExternalForm() + \"...\");\n                             try {\n                                 downloadHelper.download(pluginUrl, pluginFile, new HttpDownloadHelper.VerboseProgress(System.out));",
    "output": "Add zip to explicit download plugin"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java\n@@ -59,6 +59,8 @@ public static enum Type {\n \n     private String analyzer;\n \n+    private Float boost;\n+\n     private Integer slop;\n \n     private String fuzziness;\n@@ -100,6 +102,14 @@ public TextQueryBuilder analyzer(String analyzer) {\n         return this;\n     }\n \n+    /**\n+     * Set the boost to apply to the query.\n+     */\n+    public TextQueryBuilder boost(float boost) {\n+        this.boost = boost;\n+        return this;\n+    }\n+\n     /**\n      * Set the phrase slop if evaluated to a phrase query type.\n      */\n@@ -139,6 +149,9 @@ public TextQueryBuilder maxExpansions(int maxExpansions) {\n         if (analyzer != null) {\n             builder.field(\"analyzer\", analyzer);\n         }\n+        if (boost != null) {\n+            builder.field(\"boost\", boost);\n+        }\n         if (slop != null) {\n             builder.field(\"slop\", slop);\n         }",
    "output": "Add support for setting the boost to a text query in the Java client"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/Streams.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/Streams.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/Streams.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/io/Streams.java\n@@ -20,6 +20,8 @@\n package org.elasticsearch.common.io;\n \n import org.elasticsearch.common.Preconditions;\n+import org.elasticsearch.common.io.stream.BytesStreamOutput;\n+import org.elasticsearch.common.io.stream.CachedStreamOutput;\n \n import java.io.*;\n \n@@ -160,9 +162,14 @@ public static void copy(byte[] in, OutputStream out) throws IOException {\n      * @throws IOException in case of I/O errors\n      */\n     public static byte[] copyToByteArray(InputStream in) throws IOException {\n-        FastByteArrayOutputStream out = FastByteArrayOutputStream.Cached.cached();\n-        copy(in, out);\n-        return out.copiedByteArray();\n+        CachedStreamOutput.Entry cachedEntry = CachedStreamOutput.popEntry();\n+        try {\n+            BytesStreamOutput out = cachedEntry.cachedBytes();\n+            copy(in, out);\n+            return out.copiedByteArray();\n+        } finally {\n+            CachedStreamOutput.pushEntry(cachedEntry);\n+        }\n     }\n \n ",
    "output": "Use cache streams to copy over byes, not the byte array"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/TextQueryBuilder.java\n@@ -129,7 +129,7 @@ public TextQueryBuilder maxExpansions(int maxExpansions) {\n         builder.startObject(TextQueryParser.NAME);\n         builder.startObject(name);\n \n-        builder.field(\"text\", text);\n+        builder.field(\"query\", text);\n         if (type != null) {\n             builder.field(\"type\", type.toString().toLowerCase());\n         }",
    "output": "Fix the build of a phrase query in the java client"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n@@ -49,7 +49,7 @@\n  *\n  * @author kimchy (shay.banon)\n  */\n-public abstract class AbstractConcurrentMapFilterCache extends AbstractIndexComponent implements FilterCache {\n+public abstract class AbstractConcurrentMapFilterCache extends AbstractIndexComponent implements FilterCache, IndexReader.ReaderFinishedListener {\n \n     final ConcurrentMap<Object, ReaderValue> cache;\n \n@@ -97,6 +97,14 @@ protected ConcurrentMap<Filter, DocSet> buildFilterMap() {\n         cache.clear();\n     }\n \n+    @Override public void finished(IndexReader reader) {\n+        ReaderValue readerValue = cache.remove(reader.getCoreCacheKey());\n+        // help soft/weak handling GC\n+        if (readerValue != null) {\n+            readerValue.filters().clear();\n+        }\n+    }\n+\n     @Override public void clear(IndexReader reader) {\n         ReaderValue readerValue = cache.remove(reader.getCoreCacheKey());\n         // help soft/weak handling GC\n@@ -156,6 +164,8 @@ static class FilterCacheFilterWrapper extends Filter {\n                 ReaderValue prev = cache.cache.putIfAbsent(reader.getCoreCacheKey(), readerValue);\n                 if (prev != null) {\n                     readerValue = prev;\n+                } else {\n+                    reader.addReaderFinishedListener(cache);\n                 }\n             }\n             DocSet docSet = readerValue.filters().get(filter);",
    "output": "Add explicit filter clears on reader finished"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/ElisionTokenFilterFactory.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/ElisionTokenFilterFactory.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/ElisionTokenFilterFactory.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/ElisionTokenFilterFactory.java\n@@ -39,14 +39,14 @@ public class ElisionTokenFilterFactory extends AbstractTokenFilterFactory {\n \n     @Inject public ElisionTokenFilterFactory(Index index, @IndexSettings Settings indexSettings, Environment env, @Assisted String name, @Assisted Settings settings) {\n         super(index, indexSettings, name, settings);\n-\tthis.articles = Analysis.parseArticles(env, settings);\n+        this.articles = Analysis.parseArticles(env, settings);\n     }\n \n     @Override public TokenStream create(TokenStream tokenStream) {\n-\tif (articles == null) {\n-\t    return new ElisionFilter(version, tokenStream);\n-\t} else {\n-\t    return new ElisionFilter(version, tokenStream, articles);\n-\t}\n+        if (articles == null) {\n+            return new ElisionFilter(version, tokenStream);\n+        } else {\n+            return new ElisionFilter(version, tokenStream, articles);\n+        }\n     }\n }\n\\ No newline at end of file",
    "output": "Fix indentation mistake"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n@@ -116,7 +116,7 @@ protected ConcurrentMap<Filter, DocSet> buildFilterMap() {\n                 totalCount++;\n             }\n         }\n-        return new EntriesStats(sizeInBytes, totalCount / segmentsCount);\n+        return new EntriesStats(sizeInBytes, segmentsCount == 0 ? 0 : totalCount / segmentsCount);\n     }\n \n     @Override public Filter cache(Filter filterToCache) {",
    "output": "Fix division by zero error"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MappingMetaData.java\n@@ -23,8 +23,6 @@\n import org.elasticsearch.common.compress.CompressedString;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n-import org.elasticsearch.common.logging.ESLogger;\n-import org.elasticsearch.common.logging.ESLoggerFactory;\n import org.elasticsearch.common.xcontent.XContentFactory;\n import org.elasticsearch.common.xcontent.XContentParser;\n import org.elasticsearch.index.mapper.DocumentMapper;\n@@ -39,8 +37,6 @@\n  */\n public class MappingMetaData {\n \n-    private static ESLogger logger = ESLoggerFactory.getLogger(MappingMetaData.class.getName());\n-\n     public static class Routing {\n \n         public static final Routing EMPTY = new Routing(false, null);",
    "output": "Remove unused logger"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n@@ -177,13 +177,14 @@ public String[] concreteIndices(String[] indices, boolean ignoreMissing) throws\n         for (String index : indices) {\n             if (!this.indices.containsKey(index)) {\n                 possiblyAliased = true;\n+                break;\n             }\n         }\n         if (!possiblyAliased) {\n             return indices;\n         }\n \n-        ArrayList<String> actualIndices = Lists.newArrayListWithCapacity(indices.length);\n+        Set<String> actualIndices = Sets.newHashSetWithExpectedSize(indices.length);\n         for (String index : indices) {\n             String[] actualLst = aliasAndIndexToIndexMap.get(index);\n             if (actualLst == null) {",
    "output": "Fix double counts when count is executed on two aliases pointing to the same index"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/SpanishAnalyzerProvider.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/SpanishAnalyzerProvider.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/SpanishAnalyzerProvider.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/SpanishAnalyzerProvider.java\n@@ -20,7 +20,6 @@\n package org.elasticsearch.index.analysis;\n \n import org.apache.lucene.analysis.CharArraySet;\n-import org.apache.lucene.analysis.ar.ArabicAnalyzer;\n import org.apache.lucene.analysis.es.SpanishAnalyzer;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.inject.assistedinject.Assisted;\n@@ -38,7 +37,7 @@ public class SpanishAnalyzerProvider extends AbstractIndexAnalyzerProvider<Spani\n     @Inject public SpanishAnalyzerProvider(Index index, @IndexSettings Settings indexSettings, @Assisted String name, @Assisted Settings settings) {\n         super(index, indexSettings, name, settings);\n         analyzer = new SpanishAnalyzer(version,\n-                Analysis.parseStopWords(settings, ArabicAnalyzer.getDefaultStopSet()),\n+                Analysis.parseStopWords(settings, SpanishAnalyzer.getDefaultStopSet()),\n                 Analysis.parseStemExclusion(settings, CharArraySet.EMPTY_SET));\n     }\n ",
    "output": "Fix stop words for spanish analyzer"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java\n@@ -55,7 +55,6 @@ public class MetaData implements Iterable<IndexMetaData> {\n     private final ImmutableSet<String> aliases;\n \n     private final ImmutableMap<String, String[]> aliasAndIndexToIndexMap;\n-    private final ImmutableMap<String, ImmutableSet<String>> aliasAndIndexToIndexMap2;\n \n     private MetaData(ImmutableMap<String, IndexMetaData> indices, ImmutableMap<String, IndexTemplateMetaData> templates) {\n         this.indices = ImmutableMap.copyOf(indices);\n@@ -105,12 +104,6 @@ private MetaData(ImmutableMap<String, IndexMetaData> indices, ImmutableMap<Strin\n             aliasAndIndexToIndexBuilder.put(entry.getKey(), entry.getValue().toArray(new String[entry.getValue().size()]));\n         }\n         this.aliasAndIndexToIndexMap = aliasAndIndexToIndexBuilder.immutableMap();\n-\n-        MapBuilder<String, ImmutableSet<String>> aliasAndIndexToIndexBuilder2 = newMapBuilder();\n-        for (Map.Entry<String, Set<String>> entry : tmpAliasAndIndexToIndexBuilder.map().entrySet()) {\n-            aliasAndIndexToIndexBuilder2.put(entry.getKey(), ImmutableSet.copyOf(entry.getValue()));\n-        }\n-        this.aliasAndIndexToIndexMap2 = aliasAndIndexToIndexBuilder2.immutableMap();\n     }\n \n     public ImmutableSet<String> aliases() {\n@@ -227,7 +220,7 @@ public boolean hasIndex(String index) {\n     }\n \n     public boolean hasConcreteIndex(String index) {\n-        return aliasAndIndexToIndexMap2.containsKey(index);\n+        return aliasAndIndexToIndexMap.containsKey(index);\n     }\n \n     public IndexMetaData index(String index) {",
    "output": "Remove unnecessary aliasAndIndexToIndex map"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -463,7 +463,6 @@ private void parseSource(SearchContext context, byte[] source, int offset, int l\n                     break;\n                 }\n             }\n-            parser.close();\n         } catch (Exception e) {\n             String sSource = \"_na_\";\n             try {",
    "output": "Make sure we close the parser even if it failed to parse a search request"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -446,8 +446,9 @@ private void parseSource(SearchContext context, byte[] source, int offset, int l\n         if (source == null || length == 0) {\n             return;\n         }\n+        XContentParser parser = null;\n         try {\n-            XContentParser parser = XContentFactory.xContent(source, offset, length).createParser(source, offset, length);\n+            parser = XContentFactory.xContent(source, offset, length).createParser(source, offset, length);\n             XContentParser.Token token;\n             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n                 if (token == XContentParser.Token.FIELD_NAME) {\n@@ -471,6 +472,10 @@ private void parseSource(SearchContext context, byte[] source, int offset, int l\n                 // ignore\n             }\n             throw new SearchParseException(context, \"Failed to parse source [\" + sSource + \"]\", e);\n+        } finally {\n+            if (parser != null) {\n+                parser.close();\n+            }\n         }\n     }\n ",
    "output": "Make sure we close the parser even if it failed to parse a search request"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/geo/GeoPointFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/geo/GeoPointFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/geo/GeoPointFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/geo/GeoPointFieldMapper.java\n@@ -340,8 +340,18 @@ private void parseGeohash(ParseContext context, String geohash) throws IOExcepti\n     }\n \n     @Override public void close() {\n-        latMapper.close();\n-        lonMapper.close();\n+        if (latMapper != null) {\n+            latMapper.close();\n+        }\n+        if (lonMapper != null) {\n+            lonMapper.close();\n+        }\n+        if (geohashMapper != null) {\n+            geohashMapper.close();\n+        }\n+        if (geoStringMapper != null) {\n+            geoStringMapper.close();\n+        }\n     }\n \n     @Override public void merge(XContentMapper mergeWith, MergeContext mergeContext) throws MergeMappingException {",
    "output": "Fix wrong closing of possible null mappings in geo point mapping"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/highlight/HighlighterSearchTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/highlight/HighlighterSearchTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/highlight/HighlighterSearchTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/highlight/HighlighterSearchTests.java\n@@ -292,6 +292,8 @@ public XContentBuilder type1TermVectorMapping() throws IOException {\n                 .execute().actionGet();\n \n         assertThat(search.hits().totalHits(), equalTo(5l));\n+        assertThat(search.hits().hits().length, equalTo(5));\n+        assertThat(search.getFailedShards(), equalTo(0));\n \n         for (SearchHit hit : search.hits()) {\n             // LUCENE 3.1 UPGRADE: Caused adding the space at the end...",
    "output": "Improve test: check hits length and zero failures"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java b/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java\n@@ -40,16 +40,16 @@ public class ConcurrentIndexingVersioningTest {\n     public static void main(String[] args) throws Exception {\n \n         Settings settings = settingsBuilder()\n-                .put(\"gateway\", \"none\")\n+                .put(\"gateway.type\", \"none\")\n                 .build();\n \n         Node node1 = nodeBuilder().settings(settings).node();\n         Node node2 = nodeBuilder().settings(settings).node();\n         final Node client = nodeBuilder().settings(settings).client(true).node();\n \n-        final int NUMBER_OF_DOCS = 1000;\n+        final int NUMBER_OF_DOCS = 10000;\n         final int NUMBER_OF_THREADS = 10;\n-        final long NUMBER_OF_ITERATIONS = SizeValue.parseSizeValue(\"100k\").singles();\n+        final long NUMBER_OF_ITERATIONS = SizeValue.parseSizeValue(\"10k\").singles();\n         final long DELETE_EVERY = 10;\n \n         final CountDownLatch latch = new CountDownLatch(NUMBER_OF_THREADS);",
    "output": "Change defaults in stress test"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java b/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/stress/indexing/ConcurrentIndexingVersioningTest.java\n@@ -78,6 +78,7 @@ public static void main(String[] args) throws Exception {\n \n         latch.await();\n         System.out.println(\"done indexing, verifying docs\");\n+        client.client().admin().indices().prepareRefresh().execute().actionGet();\n         for (int i = 0; i < NUMBER_OF_DOCS; i++) {\n             for (int j = 0; j < 5; j++) {\n                 SearchResponse response = client.client().prepareSearch().setQuery(QueryBuilders.termQuery(\"_id\", Integer.toString(i))).execute().actionGet();",
    "output": "Add refresh before verifying in the test"
  },
  {
    "input": "diff --git a/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/search/facet/TermsFacetSearchBenchmark.java b/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/search/facet/TermsFacetSearchBenchmark.java\n--- a/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/search/facet/TermsFacetSearchBenchmark.java\n+++ b/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/search/facet/TermsFacetSearchBenchmark.java\n@@ -51,7 +51,7 @@\n  */\n public class TermsFacetSearchBenchmark {\n \n-    static long COUNT = SizeValue.parseSizeValue(\"100k\").singles();\n+    static long COUNT = SizeValue.parseSizeValue(\"1m\").singles();\n     static int BATCH = 100;\n     static int QUERY_WARMUP = 20;\n     static int QUERY_COUNT = 200;\n@@ -156,6 +156,7 @@ public static void main(String[] args) throws Exception {\n \n         stats.add(termsStats(\"terms_stats_s_l\", \"s_value\", \"l_value\", null));\n         stats.add(termsStats(\"terms_stats_s_lm\", \"s_value\", \"lm_value\", null));\n+        stats.add(termsStats(\"terms_stats_sm_l\", \"sm_value\", \"l_value\", null));\n \n         System.out.println(\"------------------ SUMMARY -------------------------------\");\n         System.out.format(\"%25s%10s%10s\\n\", \"name\", \"took\", \"millis\");",
    "output": "Add more terms stats bench"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/delete/TransportDeleteIndexAction.java\n@@ -85,6 +85,9 @@ public class TransportDeleteIndexAction extends TransportMasterNodeOperationActi\n     }\n \n     @Override protected DeleteIndexResponse masterOperation(DeleteIndexRequest request, final ClusterState state) throws ElasticSearchException {\n+        if (request.indices().length == 0) {\n+            return new DeleteIndexResponse(true);\n+        }\n         final AtomicReference<DeleteIndexResponse> responseRef = new AtomicReference<DeleteIndexResponse>();\n         final AtomicReference<Throwable> failureRef = new AtomicReference<Throwable>();\n         final CountDownLatch latch = new CountDownLatch(request.indices().length);",
    "output": "Fix error when trying to delete all indices and none exists"
  },
  {
    "input": "diff --git a/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/time/SimpleTimeBenchmark.java b/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/time/SimpleTimeBenchmark.java\n--- a/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/time/SimpleTimeBenchmark.java\n+++ b/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/time/SimpleTimeBenchmark.java\n@@ -28,6 +28,7 @@\n  */\n public class SimpleTimeBenchmark {\n \n+    private static boolean USE_NANO_TIME = false;\n     private static long NUMBER_OF_ITERATIONS = 1000000;\n     private static int NUMBER_OF_THREADS = 100;\n \n@@ -45,8 +46,14 @@ public static void main(String[] args) throws Exception {\n         for (int i = 0; i < threads.length; i++) {\n             threads[i] = new Thread(new Runnable() {\n                 @Override public void run() {\n-                    for (long i = 0; i < NUMBER_OF_ITERATIONS; i++) {\n-                        System.currentTimeMillis();\n+                    if (USE_NANO_TIME) {\n+                        for (long i = 0; i < NUMBER_OF_ITERATIONS; i++) {\n+                            System.nanoTime();\n+                        }\n+                    } else {\n+                        for (long i = 0; i < NUMBER_OF_ITERATIONS; i++) {\n+                            System.currentTimeMillis();\n+                        }\n                     }\n                     latch.countDown();\n                 }",
    "output": "Add bench on nano time"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/env/NodeEnvironment.java\n@@ -62,6 +62,7 @@ public class NodeEnvironment extends AbstractComponent {\n             if (!dir.exists()) {\n                 dir.mkdirs();\n             }\n+            logger.trace(\"obtaining node lock on {} ...\", dir.getAbsolutePath());\n             try {\n                 NativeFSLockFactory lockFactory = new NativeFSLockFactory(dir);\n                 Lock tmpLock = lockFactory.makeLock(\"node.lock\");\n@@ -70,8 +71,11 @@ public class NodeEnvironment extends AbstractComponent {\n                     lock = tmpLock;\n                     localNodeId = i;\n                     break;\n+                } else {\n+                    logger.trace(\"failed to obtain node lock on {}\", dir.getAbsolutePath());\n                 }\n             } catch (IOException e) {\n+                logger.trace(\"failed to obtain node lock on {}\", e, dir.getAbsolutePath());\n                 lastException = e;\n             }\n         }",
    "output": "Add logging when trying to obtain node lock"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/store/support/AbstractStore.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/store/support/AbstractStore.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/store/support/AbstractStore.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/store/support/AbstractStore.java\n@@ -38,7 +38,7 @@\n import java.io.IOException;\n import java.util.HashMap;\n import java.util.Map;\n-import java.util.zip.CRC32;\n+import java.util.zip.Adler32;\n import java.util.zip.Checksum;\n \n /**\n@@ -391,7 +391,10 @@ class StoreIndexOutput extends IndexOutput {\n                     // and since we, in any case, always recover the segments files\n                     this.digest = null;\n                 } else {\n-                    this.digest = new CRC32();\n+//                    this.digest = new CRC32();\n+                    // adler is faster, and we compare on length as well, should be enough to check for difference\n+                    // between files\n+                    this.digest = new Adler32();\n                 }\n             } else {\n                 this.digest = null;",
    "output": "Add adler to checksum, faster and is good enough with length check for our use case"
  },
  {
    "input": "diff --git a/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/checksum/ChecksumBenchmarkTest.java b/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/checksum/ChecksumBenchmarkTest.java\n--- a/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/checksum/ChecksumBenchmarkTest.java\n+++ b/modules/benchmark/micro/src/main/java/org/elasticsearch/benchmark/checksum/ChecksumBenchmarkTest.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.common.unit.TimeValue;\n \n import java.security.MessageDigest;\n+import java.util.zip.Adler32;\n import java.util.zip.CRC32;\n \n /**\n@@ -36,6 +37,7 @@ public class ChecksumBenchmarkTest {\n     public static void main(String[] args) {\n         long dataSize = ByteSizeValue.parseBytesSizeValue(\"1g\", null).bytes();\n         crc(dataSize);\n+        adler(dataSize);\n         md5(dataSize);\n     }\n \n@@ -51,6 +53,18 @@ private static void crc(long dataSize) {\n         System.out.println(\"CRC took \" + new TimeValue(System.currentTimeMillis() - start));\n     }\n \n+    private static void adler(long dataSize) {\n+        long start = System.currentTimeMillis();\n+        Adler32 crc = new Adler32();\n+        byte[] data = new byte[BATCH_SIZE];\n+        long iter = dataSize / BATCH_SIZE;\n+        for (long i = 0; i < iter; i++) {\n+            crc.update(data);\n+        }\n+        crc.getValue();\n+        System.out.println(\"Adler took \" + new TimeValue(System.currentTimeMillis() - start));\n+    }\n+\n     private static void md5(long dataSize) {\n         long start = System.currentTimeMillis();\n         byte[] data = new byte[BATCH_SIZE];",
    "output": "Add adler to checksum tests"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetProcessor.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetProcessor.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetProcessor.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetProcessor.java\n@@ -74,6 +74,8 @@ public class TermsStatsFacetProcessor extends AbstractComponent implements Facet\n                     valueField = parser.text();\n                 } else if (\"script_field\".equals(currentFieldName)) {\n                     script = parser.text();\n+                } else if (\"value_script\".equals(currentFieldName)) {\n+                    script = parser.text();\n                 } else if (\"size\".equals(currentFieldName)) {\n                     size = parser.intValue();\n                 } else if (\"all_terms\".equals(currentFieldName) || \"allTerms\".equals(currentFieldName)) {",
    "output": "Add value_script as an option to terms stats"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java\n@@ -21,6 +21,7 @@\n \n import org.elasticsearch.cluster.*;\n import org.elasticsearch.cluster.routing.RoutingTable;\n+import org.elasticsearch.common.Booleans;\n import org.elasticsearch.common.component.AbstractComponent;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.settings.ImmutableSettings;\n@@ -51,7 +52,7 @@ public class MetaDataUpdateSettingsService extends AbstractComponent implements\n         // TODO we only need to do that on first create of an index, or the number of nodes changed\n         for (final IndexMetaData indexMetaData : event.state().metaData()) {\n             String autoExpandReplicas = indexMetaData.settings().get(IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS);\n-            if (autoExpandReplicas != null) {\n+            if (autoExpandReplicas != null && Booleans.parseBoolean(autoExpandReplicas, true)) { // Booleans only work for false values, just as we want it here\n                 try {\n                     final int numberOfReplicas = event.state().nodes().dataNodes().size() - 1;\n ",
    "output": "Upgrade Settings: Allow to control `index.auto_expand_replicas`,"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java\n@@ -66,7 +66,7 @@ public class MetaDataUpdateSettingsService extends AbstractComponent implements\n                             max = Integer.parseInt(sMax);\n                         }\n                     } catch (Exception e) {\n-                        logger.warn(\"failed to set [{}], wrong format [{}]\", IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, autoExpandReplicas);\n+                        logger.warn(\"failed to set [{}], wrong format [{}]\", e, IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS, autoExpandReplicas);\n                         continue;\n                     }\n ",
    "output": "Add the exception as well to the logging"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java\n@@ -103,6 +103,10 @@ public ShardIterator shardsIt() {\n         return new PlainShardIterator(shardId, shards);\n     }\n \n+    public ShardIterator shardsIt(int index) {\n+        return new PlainShardIterator(shardId, shards, index);\n+    }\n+\n     public ShardIterator shardsRandomIt() {\n         return new PlainShardIterator(shardId, shards, counter.getAndIncrement());\n     }",
    "output": "Add iterator based on specific index"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/field/data/bytes/ByteFieldDataComparator.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/field/data/bytes/ByteFieldDataComparator.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/field/data/bytes/ByteFieldDataComparator.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/field/data/bytes/ByteFieldDataComparator.java\n@@ -46,7 +46,7 @@ public ByteFieldDataComparator(int numHits, String fieldName, FieldDataCache fie\n     }\n \n     @Override public int compareBottom(int doc) {\n-        return bottom - currentFieldData.shortValue(doc);\n+        return bottom - currentFieldData.byteValue(doc);\n     }\n \n     @Override public void copy(int slot, int doc) {",
    "output": "Use byte value"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n@@ -153,6 +153,9 @@ private void add(DocumentMapper mapper) {\n             if (mapper.type().contains(\"#\")) {\n                 throw new InvalidTypeNameException(\"mapping type name [\" + mapper.type() + \"] should not include '#' in it\");\n             }\n+            if (mapper.type().contains(\".\")) {\n+                logger.warn(\"Type [{}] contains a '.', it is recommended not to include it within a type name\", mapper.type());\n+            }\n             remove(mapper.type()); // first remove it (in case its an update, we need to remove the aggregated mappers)\n             mappers = newMapBuilder(mappers).put(mapper.type(), mapper).immutableMap();\n             mapper.addFieldMapperListener(fieldMapperListener, true);",
    "output": "Add a warning for types not to include dots (can't really throw a failure because of it since it will break backward)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/ElasticSearch.java b/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/ElasticSearch.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/ElasticSearch.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/ElasticSearch.java\n@@ -0,0 +1,30 @@\n+/*\n+ * Licensed to Elastic Search and Shay Banon under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership. Elastic Search licenses this\n+ * file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.bootstrap;\n+\n+/**\n+ * A wrapper around {@link Bootstrap} just so the process will look nicely on things like jps.\n+ */\n+public class ElasticSearch extends Bootstrap {\n+\n+    public static void main(String[] args) {\n+        Bootstrap.main(args);\n+    }\n+}\n\\ No newline at end of file",
    "output": "Change scripts to start the ElasticSearch main class (a wrapper around Bootstrap) just so the process name will look nicely on jps"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/MapperService.java\n@@ -223,7 +223,7 @@ public DocumentMapper documentMapperWithAutoCreate(String type) {\n             return mapper;\n         }\n         if (!dynamic) {\n-            return null;\n+            throw new TypeMissingException(index, type, \"typing to auto create mapping, but dynamic mapping is disabled\");\n         }\n         // go ahead and dynamically create it\n         synchronized (mutex) {",
    "output": "Improve failure when disabling dynamic creating of types, and trying to index into a non existing type"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/termsstats/TermsStatsFacetBuilder.java\n@@ -147,6 +147,8 @@ public TermsStatsFacetBuilder param(String name, Object value) {\n \n         builder.endObject();\n \n+        addFilterFacetAndGlobal(builder, params);\n+\n         builder.endObject();\n \n         return builder;",
    "output": "Add filter and scope parameters when creating terms stats facet"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/TermsFacetProcessor.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/TermsFacetProcessor.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/TermsFacetProcessor.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/terms/TermsFacetProcessor.java\n@@ -114,7 +114,7 @@ public class TermsFacetProcessor extends AbstractComponent implements FacetProce\n                     regex = parser.text();\n                 } else if (\"regex_flags\".equals(currentFieldName) || \"regexFlags\".equals(currentFieldName)) {\n                     regexFlags = parser.text();\n-                } else if (\"order\".equals(currentFieldName) || \"comparator\".equals(field)) {\n+                } else if (\"order\".equals(currentFieldName) || \"comparator\".equals(currentFieldName)) {\n                     comparatorType = TermsFacet.ComparatorType.fromString(parser.text());\n                 } else if (\"script\".equals(currentFieldName)) {\n                     script = parser.text();",
    "output": "Use parsing field to check for order"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPool.java\n@@ -137,7 +137,10 @@ private Executor build(String name, String defaultType, @Nullable Settings setti\n         }\n         String type = settings.get(\"type\", defaultType);\n         ThreadFactory threadFactory = EsExecutors.daemonThreadFactory(settings, \"[\" + name + \"]\");\n-        if (\"cached\".equals(type)) {\n+        if (\"same\".equals(type)) {\n+            logger.debug(\"creating thread_pool [{}], type [{}]\", name, type);\n+            return MoreExecutors.sameThreadExecutor();\n+        } else if (\"cached\".equals(type)) {\n             TimeValue keepAlive = settings.getAsTime(\"keep_alive\", defaultSettings.getAsTime(\"keep_alive\", timeValueMinutes(5)));\n             logger.debug(\"creating thread_pool [{}], type [{}], keep_alive [{}]\", name, type, keepAlive);\n             return new ThreadPoolExecutor(0, Integer.MAX_VALUE,",
    "output": "Add \"same\" thread pool type (really, just for testing)"
  },
  {
    "input": "diff --git a/plugins/transport/thrift/src/test/java/org/elasticsearch/thrift/test/SimpleThriftTests.java b/plugins/transport/thrift/src/test/java/org/elasticsearch/thrift/test/SimpleThriftTests.java\n--- a/plugins/transport/thrift/src/test/java/org/elasticsearch/thrift/test/SimpleThriftTests.java\n+++ b/plugins/transport/thrift/src/test/java/org/elasticsearch/thrift/test/SimpleThriftTests.java\n@@ -72,7 +72,7 @@ public class SimpleThriftTests {\n                 .endObject().copiedBytes()));\n         RestResponse response = client.execute(request);\n         Map<String, Object> map = parseBody(response);\n-        assertThat(response.getStatus(), equalTo(Status.OK));\n+        assertThat(response.getStatus(), equalTo(Status.CREATED));\n         assertThat(map.get(\"ok\").toString(), equalTo(\"true\"));\n         assertThat(map.get(\"_index\").toString(), equalTo(\"test\"));\n         assertThat(map.get(\"_type\").toString(), equalTo(\"type1\"));",
    "output": "Fix thrift test to take into account that index can return CREATED status code now"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n@@ -635,7 +635,7 @@ private class EngineRefresher implements Runnable {\n                         logger.warn(\"Failed to perform scheduled engine refresh\", e);\n                     }\n                     if (state != IndexShardState.CLOSED) {\n-                        refreshScheduledFuture = threadPool.schedule(refreshInterval, ThreadPool.Names.SAME, this);\n+                        refreshScheduledFuture = threadPool.schedule(refreshInterval, ThreadPool.Names.SAME, EngineRefresher.this);\n                     }\n                 }\n             });\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/TranslogService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/TranslogService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/TranslogService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/TranslogService.java\n@@ -127,7 +127,7 @@ private void asyncFlushAndReschedule() {\n                     lastFlushTime = System.currentTimeMillis();\n \n                     if (indexShard.state() != IndexShardState.CLOSED) {\n-                        future = threadPool.schedule(interval, ThreadPool.Names.SAME, this);\n+                        future = threadPool.schedule(interval, ThreadPool.Names.SAME, TranslogBasedFlush.this);\n                     }\n                 }\n             });",
    "output": "Fix scheduling to actually schedule the correct runnable"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpChannel.java\n@@ -70,6 +70,7 @@ public NettyHttpChannel(Channel channel, org.elasticsearch.common.netty.handler.\n             // also add more access control parameters\n             resp.addHeader(\"Access-Control-Max-Age\", 1728000);\n             resp.addHeader(\"Access-Control-Allow-Methods\", \"PUT, DELETE\");\n+            resp.addHeader(\"Access-Control-Allow-Headers\", \"X-Requested-With\");\n         }\n \n         // Convert the response content to a ChannelBuffer.",
    "output": "Add new Access-Control-Allow-Headers value into http response header,"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java\n@@ -148,8 +148,10 @@ public int compare(TextFragment o1, TextFragment o2) {\n                     for (int i = 0; i < fragments.length; i++) {\n                         fragments[i] = fragsList.get(i).toString();\n                     }\n-                    HighlightField highlightField = new HighlightField(field.field(), fragments);\n-                    highlightFields.put(highlightField.name(), highlightField);\n+                    if (fragments.length>0){\n+                        HighlightField highlightField = new HighlightField(field.field(), fragments);\n+                        highlightFields.put(highlightField.name(), highlightField);\n+                    }\n                 } else {\n                     FastVectorHighlighter highlighter = buildHighlighter(context, mapper, field);\n                     FieldQuery fieldQuery = buildFieldQuery(highlighter, context.query(), hitContext.reader(), field);\n@@ -162,8 +164,10 @@ public int compare(TextFragment o1, TextFragment o2) {\n                     } catch (IOException e) {\n                         throw new FetchPhaseExecutionException(context, \"Failed to highlight field [\" + field.field() + \"]\", e);\n                     }\n-                    HighlightField highlightField = new HighlightField(field.field(), fragments);\n-                    highlightFields.put(highlightField.name(), highlightField);\n+                    if (fragments.length>0){\n+                        HighlightField highlightField = new HighlightField(field.field(), fragments);\n+                        highlightFields.put(highlightField.name(), highlightField);\n+                    }\n                 }\n             }\n ",
    "output": "Remove empty fragments in highlight results"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/bloom/simple/SimpleBloomCache.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/bloom/simple/SimpleBloomCache.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/bloom/simple/SimpleBloomCache.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/bloom/simple/SimpleBloomCache.java\n@@ -132,10 +132,10 @@ public class SimpleBloomCache extends AbstractIndexComponent implements BloomCac\n                 filter = fieldCache.get(fieldName);\n                 if (filter == null) {\n                     filter = new BloomFilterEntry(currentNumDocs, BloomFilter.NONE);\n-                    filter.loading.set(true);\n                     fieldCache.put(fieldName, filter);\n                     // now, do the async load of it...\n                     if (currentNumDocs < maxSize) {\n+                        filter.loading.set(true);\n                         BloomFilterLoader loader = new BloomFilterLoader(reader, fieldName);\n                         if (asyncLoad) {\n                             threadPool.cached().execute(loader);",
    "output": "Add max_size to bloom filter, defaults to 500m"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/percolator/PercolatorExecutor.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/percolator/PercolatorExecutor.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/percolator/PercolatorExecutor.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/percolator/PercolatorExecutor.java\n@@ -29,6 +29,7 @@\n import org.apache.lucene.search.Scorer;\n import org.elasticsearch.ElasticSearchException;\n import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.Preconditions;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.collect.ImmutableMap;\n import org.elasticsearch.common.collect.MapBuilder;\n@@ -243,6 +244,7 @@ public Query parseQuery(String name, byte[] source, int sourceOffset, int source\n     }\n \n     public synchronized void addQuery(String name, Query query) {\n+        Preconditions.checkArgument(query != null, \"query must be provided for percolate request\");\n         this.queries = MapBuilder.newMapBuilder(queries).put(name, query).immutableMap();\n     }\n ",
    "output": "Improve error when creating a percolator with no query,"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/scheduler/ConcurrentMergeSchedulerProvider.java\n@@ -45,12 +45,18 @@ public class ConcurrentMergeSchedulerProvider extends AbstractIndexShardComponen\n     }\n \n     @Override public MergeScheduler newMergeScheduler() {\n-        ConcurrentMergeScheduler concurrentMergeScheduler = new CustomConcurrentMergeScheduler();\n+        ConcurrentMergeScheduler concurrentMergeScheduler = new CustomConcurrentMergeScheduler(shardId);\n         concurrentMergeScheduler.setMaxThreadCount(maxThreadCount);\n         return concurrentMergeScheduler;\n     }\n \n-    private class CustomConcurrentMergeScheduler extends ConcurrentMergeScheduler {\n+    private static class CustomConcurrentMergeScheduler extends ConcurrentMergeScheduler {\n+\n+        private final ShardId shardId;\n+\n+        private CustomConcurrentMergeScheduler(ShardId shardId) {\n+            this.shardId = shardId;\n+        }\n \n         @Override public void merge(IndexWriter writer) throws CorruptIndexException, IOException {\n             // if merge is not enabled, don't do any merging...",
    "output": "Make custom CMS static"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/GeoBoundingBoxFilterParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/GeoBoundingBoxFilterParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/GeoBoundingBoxFilterParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/GeoBoundingBoxFilterParser.java\n@@ -43,14 +43,14 @@\n  */\n public class GeoBoundingBoxFilterParser extends AbstractIndexComponent implements XContentFilterParser {\n \n-    public static final String NAME = \"geo_bounding_box\";\n+    public static final String NAME = \"geo_bbox\";\n \n     @Inject public GeoBoundingBoxFilterParser(Index index, @IndexSettings Settings indexSettings) {\n         super(index, indexSettings);\n     }\n \n     @Override public String[] names() {\n-        return new String[]{NAME, \"geoBoundingBox\"};\n+        return new String[]{NAME, \"geoBbox\", \"geo_bounding_box\", \"geoBoundingBox\"};\n     }\n \n     @Override public Filter parse(QueryParseContext parseContext) throws IOException, QueryParsingException {",
    "output": "Add geo_bbox as an alias to geo bounding box"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/DocLookup.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/DocLookup.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/DocLookup.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/lookup/DocLookup.java\n@@ -24,7 +24,9 @@\n import org.elasticsearch.ElasticSearchIllegalArgumentException;\n import org.elasticsearch.common.collect.Maps;\n import org.elasticsearch.index.cache.field.data.FieldDataCache;\n+import org.elasticsearch.index.field.data.DocFieldData;\n import org.elasticsearch.index.field.data.FieldData;\n+import org.elasticsearch.index.field.data.NumericDocFieldData;\n import org.elasticsearch.index.mapper.FieldMapper;\n import org.elasticsearch.index.mapper.MapperService;\n \n@@ -66,6 +68,14 @@ public void setNextDocId(int docId) {\n         this.docId = docId;\n     }\n \n+    public <T extends DocFieldData> T field(String key) {\n+        return (T) get(key);\n+    }\n+\n+    public <T extends NumericDocFieldData> T numeric(String key) {\n+        return (T) get(key);\n+    }\n+\n     @Override public Object get(Object key) {\n         // assume its a string...\n         String fieldName = key.toString();",
    "output": "Add explicit internal methods for getting doc fields"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/common/lucene/uid/UidFieldTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/common/lucene/uid/UidFieldTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/common/lucene/uid/UidFieldTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/common/lucene/uid/UidFieldTests.java\n@@ -62,5 +62,10 @@ public class UidFieldTests {\n         reader = writer.getReader();\n         assertThat(UidField.loadVersion(reader, new Term(\"_uid\", \"1\")), equalTo(2l));\n         assertThat(UidField.loadDocIdAndVersion(reader, new Term(\"_uid\", \"1\")).version, equalTo(2l));\n+\n+        writer.deleteDocuments(new Term(\"_uid\", \"1\"));\n+        reader = writer.getReader();\n+        assertThat(UidField.loadVersion(reader, new Term(\"_uid\", \"1\")), equalTo(-1l));\n+        assertThat(UidField.loadDocIdAndVersion(reader, new Term(\"_uid\", \"1\")).version, equalTo(-1l));\n     }\n }",
    "output": "Add a test for term docs version deletes"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n@@ -580,7 +580,7 @@ private void startScheduledTasksIfNeeded() {\n         }\n         // since we can do async merging, it will not be called explicitly when indexing (adding / deleting docs), and only when flushing\n         // so, make sure we periodically call it\n-        TimeValue optimizeInterval = indexSettings.getAsTime(\"index.merge.async_interval\", TimeValue.timeValueSeconds(30));\n+        TimeValue optimizeInterval = indexSettings.getAsTime(\"index.merge.async_interval\", TimeValue.timeValueSeconds(1));\n         if (optimizeInterval.millis() > 0) {\n             optimizeScheduleFuture = threadPool.scheduleWithFixedDelay(new EngineOptimizer(), optimizeInterval);\n             logger.debug(\"scheduling optimizer / merger every {}\", optimizeInterval);",
    "output": "Change default async interval to 1 second, to do merges (if needed) more often"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/fs/FsGateway.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/fs/FsGateway.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/fs/FsGateway.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/fs/FsGateway.java\n@@ -59,7 +59,7 @@ public class FsGateway extends BlobStoreGateway {\n         }\n \n         int concurrentStreams = componentSettings.getAsInt(\"concurrent_streams\", 5);\n-        this.concurrentStreamPool = DynamicExecutors.newScalingThreadPool(1, concurrentStreams, TimeValue.timeValueSeconds(5).millis(), EsExecutors.daemonThreadFactory(settings, \"[s3_stream]\"));\n+        this.concurrentStreamPool = DynamicExecutors.newScalingThreadPool(1, concurrentStreams, TimeValue.timeValueSeconds(5).millis(), EsExecutors.daemonThreadFactory(settings, \"[fs_stream]\"));\n \n         initialize(new FsBlobStore(componentSettings, concurrentStreamPool, gatewayFile), clusterName, null);\n     }",
    "output": "Fix thread name"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGateway.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGateway.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGateway.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGateway.java\n@@ -306,7 +306,7 @@ private synchronized void lazyInitialize() {\n                         this.currentMetaState = readMetaState(Streams.copyToByteArray(new FileInputStream(new File(location, \"metadata-\" + version))));\n                     }\n                 } catch (Exception e) {\n-                    logger.warn(\"failed to read local state\", e);\n+                    logger.warn(\"failed to read local state (metadata)\", e);\n                 }\n             }\n \n@@ -317,7 +317,7 @@ private synchronized void lazyInitialize() {\n                         this.currentStartedShards = readStartedShards(Streams.copyToByteArray(new FileInputStream(new File(location, \"shards-\" + version))));\n                     }\n                 } catch (Exception e) {\n-                    logger.warn(\"failed to read local state\", e);\n+                    logger.warn(\"failed to read local state (started shards)\", e);\n                 }\n             }\n         }",
    "output": "Add logging on which state file failed to load"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/MultiCollector.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/MultiCollector.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/MultiCollector.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/MultiCollector.java\n@@ -21,6 +21,7 @@\n \n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.search.Collector;\n+import org.apache.lucene.search.ScoreCachingWrappingScorer;\n import org.apache.lucene.search.Scorer;\n \n import java.io.IOException;\n@@ -40,6 +41,9 @@ public MultiCollector(Collector collector, Collector[] collectors) {\n     }\n \n     @Override public void setScorer(Scorer scorer) throws IOException {\n+        if (collectors.length > 0) {\n+            scorer = new ScoreCachingWrappingScorer(scorer);\n+        }\n         collector.setScorer(scorer);\n         for (Collector collector : collectors) {\n             collector.setScorer(scorer);",
    "output": "Use caching scorer when there are multiple collectors, so if they call score as well, it will not be computed again"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/RangeFilterBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/RangeFilterBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/RangeFilterBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/RangeFilterBuilder.java\n@@ -313,6 +313,15 @@ public RangeFilterBuilder lte(double to) {\n         return this;\n     }\n \n+    /**\n+     * The to part of the filter query. Null indicates unbounded.\n+     */\n+    public RangeFilterBuilder lte(Object to) {\n+        this.to = to;\n+        this.includeUpper = true;\n+        return this;\n+    }\n+\n     /**\n      * Should the lower bound be included or not. Defaults to <tt>true</tt>.\n      */",
    "output": "Add lt(Object) to range filter builder"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java\n@@ -188,6 +188,9 @@ private void onOperation(NodeResponse nodeResponse) {\n         private void onFailure(String nodeId, Throwable t) {\n             int idx = index.getAndIncrement();\n             if (accumulateExceptions()) {\n+                if (logger.isDebugEnabled()) {\n+                    logger.debug(\"failed to execute on node [{}]\", t, nodeId);\n+                }\n                 responses.set(idx, new FailedNodeException(nodeId, \"Failed node [\" + nodeId + \"]\", t));\n             }\n             if (counter.incrementAndGet() == responses.length()) {",
    "output": "Add logging if failing to execute on a node"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/field/data/FieldDataCacheModule.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/field/data/FieldDataCacheModule.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/field/data/FieldDataCacheModule.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/field/data/FieldDataCacheModule.java\n@@ -41,7 +41,7 @@ public FieldDataCacheModule(Settings settings) {\n \n     @Override protected void configure() {\n         bind(FieldDataCache.class)\n-                .to(settings.getAsClass(FieldDataCacheSettings.FIELD_DATA_CACHE_TYPE, SoftFieldDataCache.class, \"org.elasticsearch.index.cache.field.\", \"FieldDataCache\"))\n+                .to(settings.getAsClass(FieldDataCacheSettings.FIELD_DATA_CACHE_TYPE, SoftFieldDataCache.class, \"org.elasticsearch.index.cache.field.data.\", \"FieldDataCache\"))\n                 .in(Scopes.SINGLETON);\n     }\n }",
    "output": "Fix field data cache setting: used under index.cache.field.type, available values: resident, soft, weak"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContentGenerator.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContentGenerator.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContentGenerator.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/xcontent/smile/SmileXContentGenerator.java\n@@ -25,6 +25,7 @@\n import org.elasticsearch.common.xcontent.json.JsonXContentGenerator;\n \n import java.io.IOException;\n+import java.io.InputStream;\n import java.io.OutputStream;\n \n /**\n@@ -40,6 +41,17 @@ public SmileXContentGenerator(JsonGenerator generator) {\n         return XContentType.SMILE;\n     }\n \n+    @Override public void writeRawField(String fieldName, InputStream content, OutputStream bos) throws IOException {\n+        writeFieldName(fieldName);\n+        SmileParser parser = SmileXContent.smileFactory.createJsonParser(content);\n+        try {\n+            parser.nextToken();\n+            generator.copyCurrentStructure(parser);\n+        } finally {\n+            parser.close();\n+        }\n+    }\n+\n     @Override public void writeRawField(String fieldName, byte[] content, OutputStream bos) throws IOException {\n         writeFieldName(fieldName);\n         SmileParser parser = SmileXContent.smileFactory.createJsonParser(content);",
    "output": "Upgrade to jackson 1.7, also fix (really unused case) of getting compressed smile stored through REST with smile context type"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/support/RestUtils.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/support/RestUtils.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/support/RestUtils.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/support/RestUtils.java\n@@ -39,10 +39,9 @@ public static void decodeQueryString(String queryString, int fromIndex, Map<Stri\n         int toIndex;\n         while ((toIndex = queryString.indexOf('&', fromIndex)) >= 0) {\n             int idx = queryString.indexOf('=', fromIndex);\n-            if (idx < 0) {\n-                continue;\n+            if (fromIndex < idx && idx < toIndex) {\n+                params.put(decodeComponent(queryString.substring(fromIndex, idx)), decodeComponent(queryString.substring(idx + 1, toIndex)));\n             }\n-            params.put(decodeComponent(queryString.substring(fromIndex, idx)), decodeComponent(queryString.substring(idx + 1, toIndex)));\n             fromIndex = toIndex + 1;\n         }\n         int idx = queryString.indexOf('=', fromIndex);",
    "output": "Make RestUtils.decodeQueryString() more robust in edge cases The code of decodeQueryString() had some trouble with weird URLs: (1) an input like \"uri?param&p=v\" causes an exception to be thrown (2) an input like \"uri?param1&param2\" causes an infinite loop This could be verified against an ES server with requests like curl -XGET localhost:9200/test/_analyze?t&text=this+is+a+test # the exception stack trace shows up in logs curl -XGET localhost:9200/test/_analyze?t1&t2&text=this+is+a+test # never returns, never ends This change fixes these issues"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/count/ShardCountRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/count/ShardCountRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/count/ShardCountRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/count/ShardCountRequest.java\n@@ -84,7 +84,9 @@ public String[] types() {\n     @Override public void readFrom(StreamInput in) throws IOException {\n         super.readFrom(in);\n         minScore = in.readFloat();\n-        querySource = new byte[in.readVInt()];\n+        querySourceLength = in.readVInt();\n+        querySourceOffset = 0;\n+        querySource = new byte[querySourceLength];\n         in.readFully(querySource);\n         if (in.readBoolean()) {\n             queryParserName = in.readUTF();\n@@ -101,8 +103,8 @@ public String[] types() {\n     @Override public void writeTo(StreamOutput out) throws IOException {\n         super.writeTo(out);\n         out.writeFloat(minScore);\n-        out.writeVInt(querySource.length);\n-        out.writeBytes(querySource);\n+        out.writeVInt(querySourceLength);\n+        out.writeBytes(querySource, querySourceOffset, querySourceLength);\n         if (queryParserName == null) {\n             out.writeBoolean(false);\n         } else {",
    "output": "Fix serialization of count request"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java\n@@ -62,7 +62,7 @@ public class JvmMonitorService extends AbstractLifecycleComponent<JvmMonitorServ\n         this.dumpMonitorService = dumpMonitorService;\n \n         this.enabled = componentSettings.getAsBoolean(\"enabled\", true);\n-        this.interval = componentSettings.getAsTime(\"interval\", timeValueSeconds(10));\n+        this.interval = componentSettings.getAsTime(\"interval\", timeValueSeconds(1));\n         this.gcThreshold = componentSettings.getAsTime(\"gc_threshold\", timeValueMillis(5000));\n     }\n ",
    "output": "Change the default interval for gc checks to 1 second"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/deps/joda/SimpleJodaTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/deps/joda/SimpleJodaTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/deps/joda/SimpleJodaTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/deps/joda/SimpleJodaTests.java\n@@ -70,6 +70,10 @@ public class SimpleJodaTests {\n         } catch (IllegalArgumentException e) {\n             // all is well\n         }\n+\n+        // test offset in format\n+        millis = formatter.parseMillis(\"1970-01-01T00:00:00-02:00\");\n+        assertThat(millis, equalTo(TimeValue.timeValueHours(2).millis()));\n     }\n \n     @Test public void testIsoVsCustom() {",
    "output": "Add some sanity tests with joda for date time manipulation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java\n@@ -57,7 +57,7 @@ public String description() {\n     }\n \n     public ClusterBlockLevel[] levels() {\n-        return this.levels();\n+        return this.levels;\n     }\n \n     public boolean contains(ClusterBlockLevel level) {",
    "output": "Remove infinite loop typo"
  },
  {
    "input": "diff --git a/modules/test/testng/src/main/java/org/elasticsearch/util/testng/Listeners.java b/modules/test/testng/src/main/java/org/elasticsearch/util/testng/Listeners.java\n--- a/modules/test/testng/src/main/java/org/elasticsearch/util/testng/Listeners.java\n+++ b/modules/test/testng/src/main/java/org/elasticsearch/util/testng/Listeners.java\n@@ -28,7 +28,7 @@\n  */\n public class Listeners implements ITestListener {\n \n-    private final ITestListener[] listeners = new ITestListener[]{new DotTestListener(), new LoggingListener()};\n+    private final ITestListener[] listeners = new ITestListener[]{new LoggingListener()};\n \n     @Override public void onTestStart(ITestResult result) {\n         for (ITestListener listener : listeners) {\n\ndiff --git a/modules/test/testng/src/main/java/org/elasticsearch/util/testng/LoggingListener.java b/modules/test/testng/src/main/java/org/elasticsearch/util/testng/LoggingListener.java\n--- a/modules/test/testng/src/main/java/org/elasticsearch/util/testng/LoggingListener.java\n+++ b/modules/test/testng/src/main/java/org/elasticsearch/util/testng/LoggingListener.java\n@@ -37,6 +37,8 @@ public class LoggingListener extends TestListenerAdapter {\n         String logsDir = context.getOutputDirectory() + \"/logs\";\n         deleteRecursively(new File(logsDir), false);\n         System.setProperty(\"test.log.dir\", logsDir);\n+        System.setProperty(\"es.path.data\", context.getOutputDirectory() + \"/data\");\n+        System.setProperty(\"es.path.work\", context.getOutputDirectory() + \"/work\");\n     }\n \n     @Override public void onTestStart(ITestResult result) {",
    "output": "Upgrade testing framework jars, improve build scripts to share the testing jars"
  },
  {
    "input": "diff --git a/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java b/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java\n--- a/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java\n+++ b/plugins/cloud/aws/src/main/java/org/elasticsearch/discovery/ec2/Ec2Discovery.java\n@@ -49,10 +49,14 @@ public class Ec2Discovery extends ZenDiscovery {\n                     break;\n                 }\n             }\n-            // update the unicast zen ping to add cloud hosts provider\n-            // and, while we are at it, use only it and not the multicast for example\n-            unicastZenPing.addHostsProvider(new AwsEc2UnicastHostsProvider(settings, ec2Service.client()));\n-            pingService.zenPings(ImmutableList.of(unicastZenPing));\n+            if (unicastZenPing != null) {\n+                // update the unicast zen ping to add cloud hosts provider\n+                // and, while we are at it, use only it and not the multicast for example\n+                unicastZenPing.addHostsProvider(new AwsEc2UnicastHostsProvider(settings, ec2Service.client()));\n+                pingService.zenPings(ImmutableList.of(unicastZenPing));\n+            } else {\n+                logger.warn(\"failed to apply ec2 unicast discovery, no unicast ping found\");\n+            }\n         }\n     }\n }",
    "output": "Add a warn and don't apply ec2 unicast discovery if not found (will not really happen)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPing.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPing.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPing.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/ZenPing.java\n@@ -93,9 +93,6 @@ public static PingResponse readPingResponse(StreamInput in) throws IOException {\n \n         @Override public void writeTo(StreamOutput out) throws IOException {\n             clusterName.writeTo(out);\n-            if (target == null) {\n-                System.out.println(\"ARGH!\");\n-            }\n             target.writeTo(out);\n             if (master == null) {\n                 out.writeBoolean(false);",
    "output": "Remove debugging dead code"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n@@ -67,11 +67,15 @@ public void publish(ClusterState clusterState) {\n                 // no need to send to our self\n                 continue;\n             }\n-            transportService.sendRequest(node, PublishClusterStateRequestHandler.ACTION, new PublishClusterStateRequest(clusterState), new VoidTransportResponseHandler(false) {\n-                @Override public void handleException(TransportException exp) {\n-                    logger.debug(\"failed to send cluster state to [{}], should be detected as failed soon...\", exp, node);\n-                }\n-            });\n+            transportService.sendRequest(node, PublishClusterStateRequestHandler.ACTION,\n+                    new PublishClusterStateRequest(clusterState),\n+                    TransportRequestOptions.options().withHighType(),\n+\n+                    new VoidTransportResponseHandler(false) {\n+                        @Override public void handleException(TransportException exp) {\n+                            logger.debug(\"failed to send cluster state to [{}], should be detected as failed soon...\", exp, node);\n+                        }\n+                    });\n         }\n     }\n ",
    "output": "Use high transport type when sending the cluster state"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java\n@@ -85,7 +85,7 @@ public class InternalClusterService extends AbstractLifecycleComponent<ClusterSe\n         this.threadPool = threadPool;\n         this.timerService = timerService;\n \n-        this.reconnectInterval = componentSettings.getAsTime(\"reconnect_interval\", TimeValue.timeValueSeconds(30));\n+        this.reconnectInterval = componentSettings.getAsTime(\"reconnect_interval\", TimeValue.timeValueSeconds(10));\n     }\n \n     @Override protected void doStart() throws ElasticSearchException {",
    "output": "Add reconnection code between nodes that are not masters"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n@@ -271,7 +271,7 @@ class Adapter implements TransportServiceAdapter {\n         }\n \n         @Override public void raiseNodeDisconnected(final DiscoveryNode node) {\n-            threadPool.execute(new Runnable() {\n+            threadPool.cached().execute(new Runnable() {\n                 @Override public void run() {\n                     for (TransportConnectionListener connectionListener : connectionListeners) {\n                         connectionListener.onNodeDisconnected(node);\n@@ -284,7 +284,7 @@ class Adapter implements TransportServiceAdapter {\n                             if (holderToNotify != null) {\n                                 // callback that an exception happened, but on a different thread since we don't\n                                 // want handlers to worry about stack overflows\n-                                threadPool.execute(new Runnable() {\n+                                threadPool.cached().execute(new Runnable() {\n                                     @Override public void run() {\n                                         holderToNotify.handler().handleException(new NodeDisconnectedException(node, holderToNotify.action()));\n                                     }",
    "output": "Use cached thread pool for notifying on disconnections"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/ConnectTransportException.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/ConnectTransportException.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/ConnectTransportException.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/ConnectTransportException.java\n@@ -41,7 +41,7 @@ public ConnectTransportException(DiscoveryNode node, String msg, Throwable cause\n     }\n \n     public ConnectTransportException(DiscoveryNode node, String msg, String action, Throwable cause) {\n-        super(node.name(), node.address(), action, cause);\n+        super(node.name(), node.address(), action, msg, cause);\n         this.node = node;\n     }\n ",
    "output": "Add message to connect transport failure exception"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java\n@@ -114,7 +114,7 @@ public class InternalIndicesService extends AbstractLifecycleComponent<IndicesSe\n             logger.trace(\"eager reader based cache eviction enabled\");\n         } catch (NoSuchMethodException e) {\n             // no method\n-            logger.debug(\"lucene default FieldCache is used, not enabling eager reader based cache eviction\");\n+            logger.warn(\"lucene default FieldCache is used, not enabling eager reader based cache eviction\");\n         }\n     }\n ",
    "output": "Add a warn when not using the custom FieldCache with eager reader based eviction"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/compress/CompressedString.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/compress/CompressedString.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/compress/CompressedString.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/compress/CompressedString.java\n@@ -87,4 +87,12 @@ public static CompressedString readCompressedString(StreamInput in) throws IOExc\n     @Override public int hashCode() {\n         return bytes != null ? Arrays.hashCode(bytes) : 0;\n     }\n+\n+    @Override public String toString() {\n+        try {\n+            return string();\n+        } catch (IOException e) {\n+            return \"_na_\";\n+        }\n+    }\n }",
    "output": "Add toString to CompressedString to show when logging it"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n@@ -29,12 +29,16 @@\n import org.elasticsearch.common.collect.MapBuilder;\n import org.elasticsearch.common.collect.MapMaker;\n import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.trove.ExtTObjectIntHasMap;\n+import org.elasticsearch.index.AbstractIndexComponent;\n+import org.elasticsearch.index.Index;\n import org.elasticsearch.index.cache.id.IdCache;\n import org.elasticsearch.index.cache.id.IdReaderCache;\n import org.elasticsearch.index.mapper.ParentFieldMapper;\n import org.elasticsearch.index.mapper.Uid;\n import org.elasticsearch.index.mapper.UidFieldMapper;\n+import org.elasticsearch.index.settings.IndexSettings;\n \n import java.util.ArrayList;\n import java.util.HashMap;\n@@ -45,11 +49,12 @@\n /**\n  * @author kimchy (shay.banon)\n  */\n-public class SimpleIdCache implements IdCache {\n+public class SimpleIdCache extends AbstractIndexComponent implements IdCache {\n \n     private final ConcurrentMap<Object, SimpleIdReaderCache> idReaders;\n \n-    @Inject public SimpleIdCache() {\n+    @Inject public SimpleIdCache(Index index, @IndexSettings Settings indexSettings) {\n+        super(index, indexSettings);\n         idReaders = new MapMaker().weakKeys().makeMap();\n     }\n ",
    "output": "Make id cache an index component, so a new instance will be created per index"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n@@ -237,7 +237,7 @@ private void sendPingRequest(int id) {\n                 }\n             } catch (IOException e) {\n                 receivedResponses.remove(id);\n-                throw new ZenPingException(\"Failed to send ping request over multicast\", e);\n+                throw new ZenPingException(\"Failed to send ping request over multicast on \" + multicastSocket, e);\n             }\n         }\n     }",
    "output": "Add multicast socket to execption message"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java\n@@ -91,7 +91,7 @@ public static class Actions {\n         this.translogBatchSize = componentSettings.getAsInt(\"translog_batch_size\", 100);\n         this.compress = componentSettings.getAsBoolean(\"compress\", true);\n \n-        logger.debug(\"using file_chunk_size [{}], translog_batch_size [{}], and compress [{}]\", fileChunkSize, translogBatchSize, compress);\n+        logger.debug(\"using concurrent_streams [{}], file_chunk_size [{}], translog_batch_size [{}], and compress [{}]\", concurrentStreams, fileChunkSize, translogBatchSize, compress);\n \n         transportService.registerHandler(Actions.START_RECOVERY, new StartRecoveryTransportRequestHandler());\n     }",
    "output": "Add log message on hte concurrent streams used"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java\n@@ -124,6 +124,9 @@ public class TransportShardBulkAction extends TransportShardReplicationOperation\n                         ops[i] = indexShard.prepareCreate(sourceToParse);\n                     }\n                 } catch (Exception e) {\n+                    if (logger.isDebugEnabled()) {\n+                        logger.debug(\"[\" + shardRequest.request.index() + \"][\" + shardRequest.shardId + \"]\" + \": Failed to execute bulk item (index) [\" + indexRequest + \"]\", e);\n+                    }\n                     responses[i] = new BulkItemResponse(item.id(), indexRequest.opType().toString().toLowerCase(),\n                             new BulkItemResponse.Failure(indexRequest.index(), indexRequest.type(), indexRequest.id(), ExceptionsHelper.detailedMessage(e)));\n                 }\n@@ -132,6 +135,9 @@ public class TransportShardBulkAction extends TransportShardReplicationOperation\n                 try {\n                     ops[i] = indexShard.prepareDelete(deleteRequest.type(), deleteRequest.id());\n                 } catch (Exception e) {\n+                    if (logger.isDebugEnabled()) {\n+                        logger.debug(\"[\" + shardRequest.request.index() + \"][\" + shardRequest.shardId + \"]\" + \": Failed to execute bulk item (delete) [\" + deleteRequest + \"]\", e);\n+                    }\n                     responses[i] = new BulkItemResponse(item.id(), \"delete\",\n                             new BulkItemResponse.Failure(deleteRequest.index(), deleteRequest.type(), deleteRequest.id(), ExceptionsHelper.detailedMessage(e)));\n                 }",
    "output": "Add debug logging on failed bug items executions"
  },
  {
    "input": "diff --git a/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java b/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n--- a/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n+++ b/plugins/river/twitter/src/main/java/org/elasticsearch/river/twitter/TwitterRiver.java\n@@ -226,7 +226,7 @@ public class TwitterRiver extends AbstractRiverComponent implements River {\n     @Override public void close() {\n         logger.info(\"closing twitter stream river\");\n         if (stream != null) {\n-            stream.cleanup();\n+            stream.cleanUp();\n             stream.shutdown();\n         }\n     }",
    "output": "Upgrade to not use deprecated method"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoverySource.java\n@@ -78,10 +78,12 @@ public static class Actions {\n         this.transportService = transportService;\n         this.indicesService = indicesService;\n \n-        this.fileChunkSize = componentSettings.getAsBytesSize(\"file_chunk_size\", new ByteSizeValue(100, ByteSizeUnit.KB));\n+        this.fileChunkSize = componentSettings.getAsBytesSize(\"file_chunk_size\", new ByteSizeValue(500, ByteSizeUnit.KB));\n         this.translogBatchSize = componentSettings.getAsInt(\"translog_batch_size\", 100);\n         this.compress = componentSettings.getAsBoolean(\"compress\", true);\n \n+        logger.debug(\"using file_chunk_size [{}], translog_batch_size [{}], and compress [{}]\", fileChunkSize, translogBatchSize, compress);\n+\n         transportService.registerHandler(Actions.START_RECOVERY, new StartRecoveryTransportRequestHandler());\n     }\n ",
    "output": "Change the default chunk size when recovering from the default 100kb to 500kb"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchContextMissingException.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchContextMissingException.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchContextMissingException.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchContextMissingException.java\n@@ -29,7 +29,7 @@ public class SearchContextMissingException extends ElasticSearchException {\n     private final long id;\n \n     public SearchContextMissingException(long id) {\n-        super(\"No search context found for id [\" + id + \"], timed out\");\n+        super(\"No search context found for id [\" + id + \"]\");\n         this.id = id;\n     }\n ",
    "output": "Remove the timed out message, can be misleading"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -414,10 +414,10 @@ private void parseSource(SearchContext context, byte[] source, int offset, int l\n             String sSource = \"_na_\";\n             try {\n                 sSource = Unicode.fromBytes(source, offset, length);\n-            } catch (Error e1) {\n+            } catch (Throwable e1) {\n                 // ignore\n             }\n-            throw new SearchParseException(context, \"Failed to parse [\" + sSource + \"]\", e);\n+            throw new SearchParseException(context, \"Failed to parse source [\" + sSource + \"]\", e);\n         }\n     }\n ",
    "output": "Improve error handling, we can't always parse the source to a stirng"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java\n@@ -70,6 +70,7 @@ public class RestDeleteByQueryAction extends BaseRestHandler {\n             deleteByQueryRequest.types(splitTypes(request.param(\"type\")));\n             deleteByQueryRequest.timeout(request.paramAsTime(\"timeout\", ShardDeleteByQueryRequest.DEFAULT_TIMEOUT));\n \n+            deleteByQueryRequest.routing(request.param(\"routing\"));\n             String replicationType = request.param(\"replication\");\n             if (replicationType != null) {\n                 deleteByQueryRequest.replicationType(ReplicationType.fromString(replicationType));",
    "output": "Add routing to delete by query rest endpoint"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.common.xcontent.builder;\n \n+import org.elasticsearch.common.collect.Lists;\n import org.elasticsearch.common.io.FastByteArrayOutputStream;\n import org.elasticsearch.common.io.FastCharArrayWriter;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n@@ -67,6 +68,12 @@ public class XContentBuilderTests {\n         assertThat(builder.string(), equalTo(\"{\\\"test\\\":\\\"value\\\"}\"));\n     }\n \n+    @Test public void testOverloadedList() throws Exception {\n+        XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON);\n+        builder.startObject().field(\"test\", Lists.newArrayList(\"1\", \"2\")).endObject();\n+        assertThat(builder.string(), equalTo(\"{\\\"test\\\":[\\\"1\\\",\\\"2\\\"]}\"));\n+    }\n+\n     @Test public void testWritingBinaryToStream() throws Exception {\n         FastByteArrayOutputStream bos = new FastByteArrayOutputStream();\n ",
    "output": "Add a test for overloaded method of builder and List"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/Strings.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/Strings.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/Strings.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/Strings.java\n@@ -1220,9 +1220,16 @@ public static String toUnderscoreCase(String value, StringBuilder sb) {\n                         sb.append(value.charAt(j));\n                     }\n                     changed = true;\n+                    if (i == 0) {\n+                        sb.append(Character.toLowerCase(c));\n+                    } else {\n+                        sb.append('_');\n+                        sb.append(Character.toLowerCase(c));\n+                    }\n+                } else {\n+                    sb.append('_');\n+                    sb.append(Character.toLowerCase(c));\n                 }\n-                sb.append('_');\n-                sb.append(Character.toLowerCase(c));\n             } else {\n                 if (changed) {\n                     sb.append(c);\n\ndiff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/util/StringsTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/util/StringsTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/util/StringsTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/util/StringsTests.java\n@@ -44,6 +44,8 @@ public class StringsTests {\n         String testValue = \"test_value\";\n         assertThat(toUnderscoreCase(testValue), equalTo(testValue));\n         assertThat(toUnderscoreCase(testValue), sameInstance(testValue));\n+\n+        assertThat(toUnderscoreCase(\"Name\"), equalTo(\"name\"));\n     }\n \n //    @Test public void testHasTextBlank() throws Exception {",
    "output": "Fix underscore casing to transform Name to name, and not _name"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java\n@@ -60,7 +60,9 @@ public class Bootstrap {\n \n     private void setup(boolean addShutdownHook, Tuple<Settings, Environment> tuple) throws Exception {\n //        Loggers.getLogger(Bootstrap.class, tuple.v1().get(\"name\")).info(\"heap_size {}/{}\", JvmStats.jvmStats().mem().heapCommitted(), JvmInfo.jvmInfo().mem().heapMax());\n-        Natives.tryMlockall();\n+        if (tuple.v1().getAsBoolean(\"bootstrap.mlockall\", true)) {\n+            Natives.tryMlockall();\n+        }\n         tuple = setupJmx(tuple);\n \n         NodeBuilder nodeBuilder = NodeBuilder.nodeBuilder().settings(tuple.v1()).loadConfigSettings(false);",
    "output": "Add bootstrap.mlockall setting to control if mlockall should be called or not"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/QueryBuilders.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/QueryBuilders.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/QueryBuilders.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/QueryBuilders.java\n@@ -304,11 +304,22 @@ public static FieldMaskingSpanQueryBuilder fieldMaskingSpanQuery(XContentSpanQue\n      *\n      * @param queryBuilder  The query to apply the filter to\n      * @param filterBuilder The filter to apply on the query\n+     * @deprecated Use filteredQuery instead (rename)\n      */\n     public static FilteredQueryBuilder filtered(XContentQueryBuilder queryBuilder, XContentFilterBuilder filterBuilder) {\n         return new FilteredQueryBuilder(queryBuilder, filterBuilder);\n     }\n \n+    /**\n+     * A query that applies a filter to the results of another query.\n+     *\n+     * @param queryBuilder  The query to apply the filter to\n+     * @param filterBuilder The filter to apply on the query\n+     */\n+    public static FilteredQueryBuilder filteredQuery(XContentQueryBuilder queryBuilder, XContentFilterBuilder filterBuilder) {\n+        return new FilteredQueryBuilder(queryBuilder, filterBuilder);\n+    }\n+\n     /**\n      * A query that wraps a filter and simply returns a constant score equal to the\n      * query boost for every document in the filter.",
    "output": "Add filteredQuery to QueryBuilders to conform with xxxQuery notation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java\n@@ -60,6 +60,16 @@ public boolean routingTableChanged() {\n         return state.routingTable() != previousState.routingTable();\n     }\n \n+    public boolean indexRoutingTableChanged(String index) {\n+        if (!state.routingTable().hasIndex(index) && !previousState.routingTable().hasIndex(index)) {\n+            return false;\n+        }\n+        if (state.routingTable().hasIndex(index) && previousState.routingTable().hasIndex(index)) {\n+            return state.routingTable().index(index) != previousState.routingTable().index(index);\n+        }\n+        return true;\n+    }\n+\n     public boolean metaDataChanged() {\n         return state.metaData() != previousState.metaData();\n     }",
    "output": "Add index routing table changed"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlock.java\n@@ -104,6 +104,15 @@ public static ClusterBlock readClusterBlock(StreamInput in) throws IOException {\n         }\n     }\n \n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(id).append(\",\").append(description).append(\", blocks \");\n+        for (ClusterBlockLevel level : levels) {\n+            sb.append(level.name()).append(\",\");\n+        }\n+        return sb.toString();\n+    }\n+\n     @Override public boolean equals(Object o) {\n         if (this == o) return true;\n         if (o == null || getClass() != o.getClass()) return false;",
    "output": "Add toString to cluster block"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java\n@@ -199,6 +199,9 @@ public Builder removeIndexBlock(String index, ClusterBlock block) {\n                 return this;\n             }\n             indices.get(index).remove(block);\n+            if (indices.get(index).isEmpty()) {\n+                indices.remove(index);\n+            }\n             return this;\n         }\n ",
    "output": "Remove an index level block if its empty (make no sense to keep an empty set for it, also, shouldn't shot it back in APIs)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/GatewayService.java\n@@ -86,9 +86,9 @@ public class GatewayService extends AbstractLifecycleComponent<GatewayService> i\n         this.recoverAfterNodes = componentSettings.getAsInt(\"recover_after_nodes\", -1);\n         this.expectedNodes = componentSettings.getAsInt(\"expected_nodes\", -1);\n         this.recoverAfterDataNodes = componentSettings.getAsInt(\"recover_after_data_nodes\", -1);\n-        this.expectedDataNodes = componentSettings.getAsInt(\"expected__data_nodes\", -1);\n+        this.expectedDataNodes = componentSettings.getAsInt(\"expected_data_nodes\", -1);\n         this.recoverAfterMasterNodes = componentSettings.getAsInt(\"recover_after_master_nodes\", -1);\n-        this.expectedMasterNodes = componentSettings.getAsInt(\"expected__master_nodes\", -1);\n+        this.expectedMasterNodes = componentSettings.getAsInt(\"expected_master_nodes\", -1);\n     }\n \n     @Override protected void doStart() throws ElasticSearchException {",
    "output": "Fix expected setting, had an additional _ by mistake"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -85,8 +85,6 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen\n     // a flag that should be used only for testing\n     private final boolean sendLeaveRequest;\n \n-    private final boolean blockClusterOnNoMaster;\n-\n     private final ElectMasterService electMaster;\n \n \n@@ -112,7 +110,6 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen\n \n         this.initialPingTimeout = componentSettings.getAsTime(\"initial_ping_timeout\", timeValueSeconds(3));\n         this.sendLeaveRequest = componentSettings.getAsBoolean(\"send_leave_request\", true);\n-        this.blockClusterOnNoMaster = componentSettings.getAsBoolean(\"block_on_no_master\", true);\n \n         logger.debug(\"using initial_ping_timeout [{}]\", initialPingTimeout);\n ",
    "output": "Remove unused variable"
  },
  {
    "input": "diff --git a/plugins/hadoop/src/test/java/org/elasticsearch/hadoop/gateway/HdfsGatewayTests.java b/plugins/hadoop/src/test/java/org/elasticsearch/hadoop/gateway/HdfsGatewayTests.java\n--- a/plugins/hadoop/src/test/java/org/elasticsearch/hadoop/gateway/HdfsGatewayTests.java\n+++ b/plugins/hadoop/src/test/java/org/elasticsearch/hadoop/gateway/HdfsGatewayTests.java\n@@ -66,7 +66,7 @@ private Node buildNode() {\n                 .put(\"gateway.type\", \"hdfs\")\n                 .put(\"gateway.hdfs.uri\", \"file:///\")\n //                .put(\"gateway.hdfs.uri\", \"hdfs://training-vm.local:8022\")\n-                .put(\"gateway.hdfs.path\", \"work/hdfs/gateway\")\n+                .put(\"gateway.hdfs.path\", \"data/hdfs/gateway\")\n                 .build();\n         return nodeBuilder().settings(settingsBuilder().put(settings).put(\"node.name\", \"node1\")).build();\n     }",
    "output": "Change hdfs location test"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MatchAllDocsFilter.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MatchAllDocsFilter.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MatchAllDocsFilter.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/MatchAllDocsFilter.java\n@@ -55,4 +55,8 @@ public class MatchAllDocsFilter extends Filter {\n \n         return false;\n     }\n+\n+    @Override public String toString() {\n+        return \"*:*\";\n+    }\n }",
    "output": "Add toString to match_all docs"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java\n@@ -129,9 +129,7 @@ public static ByteSizeValue parseBytesSizeValue(String sValue, ByteSizeValue def\n         }\n         long bytes;\n         try {\n-            if (sValue.endsWith(\"b\")) {\n-                bytes = Long.parseLong(sValue.substring(0, sValue.length() - 1));\n-            } else if (sValue.endsWith(\"k\") || sValue.endsWith(\"K\")) {\n+            if (sValue.endsWith(\"k\") || sValue.endsWith(\"K\")) {\n                 bytes = (long) (Double.parseDouble(sValue.substring(0, sValue.length() - 1)) * ByteSizeUnit.C1);\n             } else if (sValue.endsWith(\"kb\")) {\n                 bytes = (long) (Double.parseDouble(sValue.substring(0, sValue.length() - 2)) * ByteSizeUnit.C1);\n@@ -143,6 +141,8 @@ public static ByteSizeValue parseBytesSizeValue(String sValue, ByteSizeValue def\n                 bytes = (long) (Double.parseDouble(sValue.substring(0, sValue.length() - 1)) * ByteSizeUnit.C3);\n             } else if (sValue.endsWith(\"gb\")) {\n                 bytes = (long) (Double.parseDouble(sValue.substring(0, sValue.length() - 2)) * ByteSizeUnit.C3);\n+            } else if (sValue.endsWith(\"b\")) {\n+                bytes = Long.parseLong(sValue.substring(0, sValue.length() - 1));\n             } else {\n                 bytes = Long.parseLong(sValue);\n             }",
    "output": "Fix parsing of bytes value"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/store/SwitchDirectory.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/store/SwitchDirectory.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/store/SwitchDirectory.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/store/SwitchDirectory.java\n@@ -26,6 +26,7 @@\n import org.elasticsearch.index.store.support.ForceSyncDirectory;\n \n import java.io.IOException;\n+import java.util.HashSet;\n import java.util.Set;\n \n /**\n@@ -86,12 +87,14 @@ public Directory secondaryDir() {\n     }\n \n     @Override public String[] listAll() throws IOException {\n-        String[] primaryFiles = primaryDir.listAll();\n-        String[] secondaryFiles = secondaryDir.listAll();\n-        String[] files = new String[primaryFiles.length + secondaryFiles.length];\n-        System.arraycopy(primaryFiles, 0, files, 0, primaryFiles.length);\n-        System.arraycopy(secondaryFiles, 0, files, primaryFiles.length, secondaryFiles.length);\n-        return files;\n+        Set<String> files = new HashSet<String>();\n+        for (String f : primaryDir.listAll()) {\n+            files.add(f);\n+        }\n+        for (String f : secondaryDir.listAll()) {\n+            files.add(f);\n+        }\n+        return files.toArray(new String[files.size()]);\n     }\n \n     /**",
    "output": "Fix listAll when using switch dir to return unique list of files"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/TermFilter.java\n@@ -76,4 +76,8 @@ public boolean equals(Object o) {\n     public int hashCode() {\n         return term != null ? term.hashCode() : 0;\n     }\n+\n+    @Override public String toString() {\n+        return term.field() + \":\" + term.text();\n+    }\n }",
    "output": "Add term filter toString"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/network/SigarNetworkProbe.java b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/network/SigarNetworkProbe.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/network/SigarNetworkProbe.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/monitor/network/SigarNetworkProbe.java\n@@ -88,6 +88,7 @@ public class SigarNetworkProbe extends AbstractComponent implements NetworkProbe\n                     ifconfig = sigar.getNetInterfaceConfig(ifname);\n                 } catch (SigarException e) {\n                     sb.append(ifname + \"\\t\" + \"Not Avaialbe [\" + e.getMessage() + \"]\");\n+                    continue;\n                 }\n                 long flags = ifconfig.getFlags();\n ",
    "output": "Fix NPE when enabling trace logging"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPoolModule.java b/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPoolModule.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPoolModule.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/threadpool/ThreadPoolModule.java\n@@ -25,7 +25,7 @@\n import org.elasticsearch.common.inject.Modules;\n import org.elasticsearch.common.inject.SpawnModules;\n import org.elasticsearch.common.settings.Settings;\n-import org.elasticsearch.threadpool.scaling.ScalingThreadPoolModule;\n+import org.elasticsearch.threadpool.cached.CachedThreadPoolModule;\n \n /**\n  * @author kimchy (shay.banon)\n@@ -39,7 +39,7 @@ public ThreadPoolModule(Settings settings) {\n     }\n \n     @Override public Iterable<? extends Module> spawnModules() {\n-        return ImmutableList.of(Modules.createModule(settings.getAsClass(\"threadpool.type\", ScalingThreadPoolModule.class, \"org.elasticsearch.threadpool.\", \"ThreadPoolModule\"), settings));\n+        return ImmutableList.of(Modules.createModule(settings.getAsClass(\"threadpool.type\", CachedThreadPoolModule.class, \"org.elasticsearch.threadpool.\", \"ThreadPoolModule\"), settings));\n     }\n \n     @Override protected void configure() {",
    "output": "Change back to cached thread pool"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/DistanceUnit.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/DistanceUnit.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/DistanceUnit.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/DistanceUnit.java\n@@ -35,7 +35,7 @@ public enum DistanceUnit {\n         }@Override public double toMiles(double distance) {\n             return distance;\n         }@Override public double toKilometers(double distance) {\n-            return distance / MILES_KILOMETRES_RATIO;\n+            return distance * MILES_KILOMETRES_RATIO;\n         }\n         @Override public String toString(double distance) {\n             return distance + \"mi\";\n@@ -44,7 +44,7 @@ public enum DistanceUnit {\n         @Override public String toString() {\n             return \"km\";\n         }@Override public double toMiles(double distance) {\n-            return distance * MILES_KILOMETRES_RATIO;\n+            return distance / MILES_KILOMETRES_RATIO;\n         }@Override public double toKilometers(double distance) {\n             return distance;\n         }",
    "output": "Fix MILES.toKilometers() and KILOMETERS.toMiles() This mistake should have been caught by DistanceUnitTests. But the problem is that the tests in this file does not run during the execution of the test suite, and I don't have a clue why this is so"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n@@ -248,7 +248,7 @@ class Adapter implements TransportServiceAdapter {\n                 // lets see if its in the timeout holder\n                 TimeoutInfoHolder timeoutInfoHolder = timeoutInfoHandlers.remove(requestId);\n                 if (timeoutInfoHolder != null) {\n-                    logger.warn(\"Transport response handler timed out, action [{}], node [{}], id [{}]\", timeoutInfoHolder.action(), timeoutInfoHolder.node(), requestId);\n+                    logger.warn(\"Received response for a request that has timed out, action [{}], node [{}], id [{}]\", timeoutInfoHolder.action(), timeoutInfoHolder.node(), requestId);\n                 } else {\n                     logger.warn(\"Transport response handler not found of id [{}]\", requestId);\n                 }",
    "output": "Add the request id to the timeout message"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/TransportService.java\n@@ -248,7 +248,7 @@ class Adapter implements TransportServiceAdapter {\n                 // lets see if its in the timeout holder\n                 TimeoutInfoHolder timeoutInfoHolder = timeoutInfoHandlers.remove(requestId);\n                 if (timeoutInfoHolder != null) {\n-                    logger.warn(\"Transport response handler timed out, action [{}], node [{}]\", timeoutInfoHolder.action(), timeoutInfoHolder.node());\n+                    logger.warn(\"Transport response handler timed out, action [{}], node [{}], id [{}]\", timeoutInfoHolder.action(), timeoutInfoHolder.node(), requestId);\n                 } else {\n                     logger.warn(\"Transport response handler not found of id [{}]\", requestId);\n                 }",
    "output": "Add the request id to the timeout message"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayNodeAllocation.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayNodeAllocation.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayNodeAllocation.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/local/LocalGatewayNodeAllocation.java\n@@ -155,6 +155,11 @@ public class LocalGatewayNodeAllocation extends NodeAllocation {\n                 continue;\n             }\n \n+            // the index might be created, but shards not instantiated yet, ignore this state\n+            if (indexRoutingTable.shards().isEmpty()) {\n+                continue;\n+            }\n+\n             if (indexRoutingTable.allPrimaryShardsUnassigned()) {\n                 // all primary are unassigned for the index, see if we can allocate it on existing nodes, if not, don't assign\n                 Set<String> nodesIds = Sets.newHashSet();",
    "output": "Add test in node allocation is there are no shards, no need to do local gateway allocation"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/SimpleRecoveryTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/SimpleRecoveryTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/SimpleRecoveryTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/SimpleRecoveryTests.java\n@@ -66,7 +66,7 @@ public class SimpleRecoveryTests extends AbstractNodesTests {\n         startNode(\"server2\");\n \n         logger.info(\"Running Cluster Health\");\n-        clusterHealth = client(\"server1\").admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();\n+        clusterHealth = client(\"server1\").admin().cluster().health(clusterHealthRequest().waitForGreenStatus().waitForNodes(\"2\")).actionGet();\n         logger.info(\"Done Cluster Health, status \" + clusterHealth.status());\n         assertThat(clusterHealth.timedOut(), equalTo(false));\n         assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.GREEN));",
    "output": "Improve test to wait for 2 nodes"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/Queries.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/Queries.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/Queries.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/search/Queries.java\n@@ -82,7 +82,7 @@ public static boolean isNegativeQuery(Query q) {\n     public static Query fixNegativeQueryIfNeeded(Query q) {\n         if (isNegativeQuery(q)) {\n             BooleanQuery newBq = (BooleanQuery) q.clone();\n-            newBq.add(new MatchAllDocsQuery(), BooleanClause.Occur.MUST);\n+            newBq.add(MATCH_ALL_QUERY, BooleanClause.Occur.MUST);\n             return newBq;\n         }\n         return q;",
    "output": "Improve fixing negative query with adding the optimized match_all query"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java\n@@ -250,7 +250,7 @@ public void start() {\n         public boolean start(final boolean fromClusterEvent) throws ElasticSearchException {\n             ClusterState clusterState = clusterService.state();\n             nodes = clusterState.nodes();\n-            if (!indicesService.hasIndex(request.index()) || !clusterState.routingTable().hasIndex(request.index())) {\n+            if (!clusterState.routingTable().hasIndex(request.index())) {\n                 retryPrimary(fromClusterEvent, null);\n                 return false;\n             }\n@@ -264,7 +264,7 @@ public boolean start(final boolean fromClusterEvent) throws ElasticSearchExcepti\n             boolean foundPrimary = false;\n             for (final ShardRouting shard : shards) {\n                 if (shard.primary()) {\n-                    if (!shard.active() || !nodes.nodeExists(shard.currentNodeId()) || !indicesService.hasIndex(request.index())) {\n+                    if (!shard.active() || !nodes.nodeExists(shard.currentNodeId())) {\n                         retryPrimary(fromClusterEvent, shard.shardId());\n                         return false;\n                     }",
    "output": "Remove check on if indices has an index, cluster state is enough"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/health/RestClusterHealthAction.java\n@@ -84,6 +84,7 @@ public class RestClusterHealthAction extends BaseRestHandler {\n                     XContentBuilder builder = RestXContentBuilder.restContentBuilder(request);\n                     builder.startObject();\n \n+                    builder.field(\"cluster_name\", response.clusterName());\n                     builder.field(\"status\", response.status().name().toLowerCase());\n                     builder.field(\"timed_out\", response.timedOut());\n                     builder.field(\"number_of_nodes\", response.numberOfNodes());",
    "output": "Add cluster name to cluster health response"
  },
  {
    "input": "diff --git a/plugins/lang/python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java b/plugins/lang/python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n--- a/plugins/lang/python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n+++ b/plugins/lang/python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java\n@@ -47,7 +47,7 @@ public class PythonScriptEngineService extends AbstractComponent implements Scri\n     }\n \n     @Override public String[] types() {\n-        return new String[]{\"python\"};\n+        return new String[]{\"python\", \"py\"};\n     }\n \n     @Override public String[] extensions() {",
    "output": "Add py as lang"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java\n@@ -559,6 +559,23 @@ protected Client getClient() {\n         assertThat(facet.max(), equalTo(4d));\n         assertThat(facet.mean(), equalTo(3d));\n         assertThat(facet.sumOfSquares(), equalTo(20d));\n+\n+        // test cross field facet using the same facet name...\n+        searchResponse = client.prepareSearch()\n+                .setQuery(matchAllQuery())\n+                .addFacet(statisticalFacet(\"stats\").field(\"num\"))\n+                .addFacet(statisticalFacet(\"stats\").field(\"multi_num\"))\n+                .execute().actionGet();\n+\n+\n+        facet = searchResponse.facets().facet(\"stats\");\n+        assertThat(facet.name(), equalTo(facet.name()));\n+        assertThat(facet.count(), equalTo(6l));\n+        assertThat(facet.total(), equalTo(13d));\n+        assertThat(facet.min(), equalTo(1d));\n+        assertThat(facet.max(), equalTo(4d));\n+        assertThat(facet.mean(), equalTo(13d / 6d));\n+        assertThat(facet.sumOfSquares(), equalTo(35d));\n     }\n \n     @Test public void testHistoFacets() throws Exception {",
    "output": "Add test for merging two stats field facet using same facet name"
  },
  {
    "input": "diff --git a/plugins/transport/thrift/src/main/java/org/elasticsearch/thrift/ThriftRestImpl.java b/plugins/transport/thrift/src/main/java/org/elasticsearch/thrift/ThriftRestImpl.java\n--- a/plugins/transport/thrift/src/main/java/org/elasticsearch/thrift/ThriftRestImpl.java\n+++ b/plugins/transport/thrift/src/main/java/org/elasticsearch/thrift/ThriftRestImpl.java\n@@ -45,6 +45,9 @@ public class ThriftRestImpl extends AbstractComponent implements Rest.Iface {\n     }\n \n     @Override public org.elasticsearch.thrift.RestResponse execute(RestRequest request) throws TException {\n+        if (logger.isTraceEnabled()) {\n+            logger.trace(\"thrift message {}\", request);\n+        }\n         final CountDownLatch latch = new CountDownLatch(1);\n         final AtomicReference<RestResponse> ref = new AtomicReference<RestResponse>();\n         restController.dispatchRequest(new ThriftRestRequest(request), new RestChannel() {",
    "output": "Add trace logging for thrift"
  },
  {
    "input": "diff --git a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n--- a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n+++ b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n@@ -182,7 +182,7 @@ private String processLine(String s, BulkRequestBuilder bulk) {\n \n         // Ignore design documents\n         if (id.startsWith(\"_design/\")) {\n-            logger.info(\"ignoring design document {}\", id);\n+            logger.trace(\"ignoring design document {}\", id);\n             return seq;\n         }\n ",
    "output": "Change logging level"
  },
  {
    "input": "diff --git a/plugins/river/rabbitmq/src/main/java/org/elasticsearch/river/rabbitmq/RabbitmqRiver.java b/plugins/river/rabbitmq/src/main/java/org/elasticsearch/river/rabbitmq/RabbitmqRiver.java\n--- a/plugins/river/rabbitmq/src/main/java/org/elasticsearch/river/rabbitmq/RabbitmqRiver.java\n+++ b/plugins/river/rabbitmq/src/main/java/org/elasticsearch/river/rabbitmq/RabbitmqRiver.java\n@@ -76,9 +76,9 @@ public class RabbitmqRiver extends AbstractRiverComponent implements River {\n             Map<String, Object> rabbitSettings = (Map<String, Object>) settings.settings().get(\"rabbitmq\");\n             rabbitHost = XContentMapValues.nodeStringValue(rabbitSettings.get(\"host\"), ConnectionFactory.DEFAULT_HOST);\n             rabbitPort = XContentMapValues.nodeIntegerValue(rabbitSettings.get(\"port\"), ConnectionFactory.DEFAULT_AMQP_PORT);\n-            rabbitUser = XContentMapValues.nodeStringValue(rabbitSettings.get(\"host\"), ConnectionFactory.DEFAULT_USER);\n-            rabbitPassword = XContentMapValues.nodeStringValue(rabbitSettings.get(\"host\"), ConnectionFactory.DEFAULT_PASS);\n-            rabbitVhost = XContentMapValues.nodeStringValue(rabbitSettings.get(\"host\"), ConnectionFactory.DEFAULT_VHOST);\n+            rabbitUser = XContentMapValues.nodeStringValue(rabbitSettings.get(\"user\"), ConnectionFactory.DEFAULT_USER);\n+            rabbitPassword = XContentMapValues.nodeStringValue(rabbitSettings.get(\"pass\"), ConnectionFactory.DEFAULT_PASS);\n+            rabbitVhost = XContentMapValues.nodeStringValue(rabbitSettings.get(\"vhost\"), ConnectionFactory.DEFAULT_VHOST);\n \n \n             rabbitQueue = XContentMapValues.nodeStringValue(rabbitSettings.get(\"queue\"), \"elasticsearch\");",
    "output": "Fix rabbitmq params parsing"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java\n@@ -389,7 +389,13 @@ private void parseSource(SearchContext context, byte[] source, int offset, int l\n             }\n             parser.close();\n         } catch (Exception e) {\n-            throw new SearchParseException(context, \"Failed to parse [\" + Unicode.fromBytes(source, offset, length) + \"]\", e);\n+            String sSource = \"_na_\";\n+            try {\n+                sSource = Unicode.fromBytes(source, offset, length);\n+            } catch (Exception e1) {\n+                // ignore\n+            }\n+            throw new SearchParseException(context, \"Failed to parse [\" + sSource + \"]\", e);\n         }\n     }\n ",
    "output": "Fix possible problem when trying to convert a binary format to a string"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/support/RestXContentBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/support/RestXContentBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/support/RestXContentBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/support/RestXContentBuilder.java\n@@ -69,8 +69,7 @@ public static void restDocumentSource(byte[] source, XContentBuilder builder, To\n             if (contentType == builder.contentType()) {\n                 builder.rawField(\"_source\", siLzf);\n             } else {\n-                // TODO, should we just return it as binary and not auto convert it?\n-                XContentParser parser = XContentFactory.xContent(builder.contentType()).createParser(siLzf);\n+                XContentParser parser = XContentFactory.xContent(contentType).createParser(siLzf);\n                 try {\n                     parser.nextToken();\n                     builder.field(\"_source\");\n@@ -80,11 +79,11 @@ public static void restDocumentSource(byte[] source, XContentBuilder builder, To\n                 }\n             }\n         } else {\n-            if (XContentFactory.xContentType(source) == builder.contentType()) {\n+            XContentType contentType = XContentFactory.xContentType(source);\n+            if (contentType == builder.contentType()) {\n                 builder.rawField(\"_source\", source);\n             } else {\n-                // TODO, should we just return it as binary and not auto convert it?\n-                XContentParser parser = XContentFactory.xContent(builder.contentType()).createParser(source);\n+                XContentParser parser = XContentFactory.xContent(contentType).createParser(source);\n                 try {\n                     parser.nextToken();\n                     builder.field(\"_source\");",
    "output": "Fix auto conversion from source content type to rest content type"
  },
  {
    "input": "diff --git a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n--- a/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n+++ b/plugins/river/couchdb/src/main/java/org/elasticsearch/river/couchdb/CouchdbRiver.java\n@@ -259,7 +259,7 @@ private class Slurper implements Runnable {\n                     }\n                 }\n \n-                String file = \"/\" + couchDb + \"/_changes?feed=continuous&include_docs=true&&heartbeat=10000\";\n+                String file = \"/\" + couchDb + \"/_changes?feed=continuous&include_docs=true&heartbeat=10000\";\n                 if (couchFilter != null) {\n                     file = file + \"&filter=\" + couchFilter;\n                 }",
    "output": "Remove double & in the url, though seems like couchdb does not mind"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n@@ -120,6 +120,13 @@ public class RestClusterStateAction extends BaseRestHandler {\n                             builder.startObject(node.id());\n                             builder.field(\"name\", node.name());\n                             builder.field(\"transport_address\", node.address().toString());\n+\n+                            builder.startObject(\"attributes\");\n+                            for (Map.Entry<String, String> attr : node.attributes().entrySet()) {\n+                                builder.field(attr.getKey(), attr.getValue());\n+                            }\n+                            builder.endObject();\n+\n                             builder.endObject();\n                         }\n                         builder.endObject();",
    "output": "Add nodes attributes to cluster state"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/Translog.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/Translog.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/Translog.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/Translog.java\n@@ -87,6 +87,11 @@ public interface Translog extends IndexShardComponent {\n      */\n     Snapshot snapshot(Snapshot snapshot);\n \n+    /**\n+     * Flushes the translog.\n+     */\n+    void flush();\n+\n     /**\n      * Closes the transaction log.\n      */\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/fs/FsTranslog.java\n@@ -185,6 +185,18 @@ public File location() {\n         }\n     }\n \n+    @Override public void flush() {\n+        synchronized (mutex) {\n+            if (raf != null) {\n+                try {\n+                    raf.raf().getFD().sync();\n+                } catch (Exception e) {\n+                    // ignore\n+                }\n+            }\n+        }\n+    }\n+\n     @Override public void close(boolean delete) {\n         synchronized (mutex) {\n             if (raf != null) {",
    "output": "Add flush to gateway"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n@@ -229,7 +229,7 @@ public class RestClusterStateAction extends BaseRestHandler {\n                             builder.endArray();\n                             builder.endObject();\n                         }\n-                        builder.endObject();\n+                        builder.endArray();\n                     }\n \n \n@@ -252,6 +252,9 @@ private void jsonShardRouting(XContentBuilder builder, ShardRouting shardRouting\n             }\n \n             @Override public void onFailure(Throwable e) {\n+                if (logger.isDebugEnabled()) {\n+                    logger.debug(\"failed to handle cluster state\", e);\n+                }\n                 try {\n                     channel.sendResponse(new XContentThrowableRestResponse(request, e));\n                 } catch (IOException e1) {",
    "output": "Fix wrong REST response generation of cluster state"
  },
  {
    "input": "diff --git a/plugins/indexer/twitter/src/main/java/org/elasticsearch/indexer/twitter/TwitterIndexer.java b/plugins/indexer/twitter/src/main/java/org/elasticsearch/indexer/twitter/TwitterIndexer.java\n--- a/plugins/indexer/twitter/src/main/java/org/elasticsearch/indexer/twitter/TwitterIndexer.java\n+++ b/plugins/indexer/twitter/src/main/java/org/elasticsearch/indexer/twitter/TwitterIndexer.java\n@@ -85,7 +85,7 @@ public class TwitterIndexer extends AbstractIndexerComponent implements Indexer\n         if (settings.settings().containsKey(\"index\")) {\n             Map<String, Object> indexSettings = (Map<String, Object>) settings.settings().get(\"index\");\n             indexName = XContentMapValues.nodeStringValue(indexSettings.get(\"index\"), indexerName.name());\n-            typeName = XContentMapValues.nodeStringValue(indexSettings.get(\"type\"), indexerName.name());\n+            typeName = XContentMapValues.nodeStringValue(indexSettings.get(\"type\"), \"status\");\n         } else {\n             indexName = indexerName.name();\n             typeName = \"status\";",
    "output": "Add a twitter indexer"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/MatchAllQueryParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/MatchAllQueryParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/MatchAllQueryParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/MatchAllQueryParser.java\n@@ -19,10 +19,12 @@\n \n package org.elasticsearch.index.query.xcontent;\n \n+import org.apache.lucene.search.DeletionAwareConstantScoreQuery;\n import org.apache.lucene.search.MatchAllDocsQuery;\n import org.apache.lucene.search.Query;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.lucene.search.Queries;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.XContentParser;\n import org.elasticsearch.index.AbstractIndexComponent;\n@@ -67,6 +69,10 @@ public class MatchAllQueryParser extends AbstractIndexComponent implements XCont\n             }\n         }\n \n+        if (boost == 1.0f && normsField == null) {\n+            return new DeletionAwareConstantScoreQuery(parseContext.cacheFilterIfPossible(Queries.MATCH_ALL_FILTER));\n+        }\n+\n         MatchAllDocsQuery query = new MatchAllDocsQuery(normsField);\n         query.setBoost(boost);\n         return query;",
    "output": "Improve match_all query to use a filter when possible"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/docset/OpenBitDocSet.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/docset/OpenBitDocSet.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/docset/OpenBitDocSet.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/lucene/docset/OpenBitDocSet.java\n@@ -26,7 +26,7 @@\n import java.io.IOException;\n \n /**\n- * @author kimchy (Shay Banon)\n+ * @author kimchy (shay.banon)\n  */\n public class OpenBitDocSet extends DocSet {\n \n@@ -45,7 +45,7 @@ public OpenBitDocSet(DocIdSetIterator disi, int numBits) throws IOException {\n     }\n \n     @Override public boolean get(int doc) throws IOException {\n-        return set.get(doc);\n+        return set.fastGet(doc);\n     }\n \n     @Override public DocIdSetIterator iterator() throws IOException {",
    "output": "Use fastGet in docset"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java\n@@ -365,7 +365,11 @@ private void parseGeohash(ParseContext context, String geohash) throws IOExcepti\n         builder.field(\"lat_lon\", enableLatLon);\n         builder.field(\"geohash\", enableGeohash);\n         builder.field(\"resolution\", resolution);\n-        builder.field(\"store\", latMapper.name().toLowerCase());\n+        if (latMapper != null) {\n+            builder.field(\"store\", latMapper.store().name().toLowerCase());\n+        } else if (geohashMapper != null) {\n+            builder.field(\"store\", geohashMapper.store().name().toLowerCase());\n+        }\n         builder.field(\"geohash_precision\", geohashPrecision);\n         if (precisionStep != null) {\n             builder.field(\"precision_step\", precisionStep);",
    "output": "Upgrade to joda 1.6"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/script/ScriptService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/script/ScriptService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/script/ScriptService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/script/ScriptService.java\n@@ -19,13 +19,13 @@\n \n package org.elasticsearch.script;\n \n+import org.elasticsearch.common.collect.MapMaker;\n import org.elasticsearch.common.component.AbstractComponent;\n import org.elasticsearch.common.inject.Inject;\n import org.elasticsearch.common.math.UnboxedMathUtils;\n import org.elasticsearch.common.mvel2.MVEL;\n import org.elasticsearch.common.mvel2.ParserContext;\n import org.elasticsearch.common.settings.Settings;\n-import org.elasticsearch.common.util.concurrent.ConcurrentCollections;\n \n import java.lang.reflect.Method;\n import java.lang.reflect.Modifier;\n@@ -37,7 +37,7 @@\n  */\n public class ScriptService extends AbstractComponent {\n \n-    private final ConcurrentMap<String, Object> cache = ConcurrentCollections.newConcurrentMap();\n+    private final ConcurrentMap<String, Object> cache = new MapMaker().softValues().makeMap();\n \n     private final ParserContext parserContext;\n ",
    "output": "Make the cached compile scripts a soft map"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/SendRequestTransportException.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/SendRequestTransportException.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/SendRequestTransportException.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/SendRequestTransportException.java\n@@ -28,6 +28,9 @@ public class SendRequestTransportException extends RemoteTransportException {\n \n     public SendRequestTransportException(DiscoveryNode node, String action, Throwable cause) {\n         super(node == null ? null : node.name(), node == null ? null : node.address(), action, cause);\n-        fillStack();\n+    }\n+\n+    @Override public Throwable fillInStackTrace() {\n+        return super.fillStack();\n     }\n }",
    "output": "Improve stack trace when failing to send a transaction request"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/AndFilterParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/AndFilterParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/AndFilterParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/AndFilterParser.java\n@@ -74,6 +74,10 @@ public class AndFilterParser extends AbstractIndexComponent implements XContentF\n             }\n         }\n \n+        if (filters.isEmpty()) {\n+            throw new QueryParsingException(index, \"[or] filter requires 'filters' to be set on it'\");\n+        }\n+\n         if (cache) {\n             for (int i = 0; i < filters.size(); i++) {\n                 filters.set(i, parseContext.cacheFilterIfPossible(filters.get(i)));\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/OrFilterParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/OrFilterParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/OrFilterParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/xcontent/OrFilterParser.java\n@@ -74,6 +74,10 @@ public class OrFilterParser extends AbstractIndexComponent implements XContentFi\n             }\n         }\n \n+        if (filters.isEmpty()) {\n+            throw new QueryParsingException(index, \"[or] filter requires 'filters' to be set on it'\");\n+        }\n+\n         if (cache) {\n             for (int i = 0; i < filters.size(); i++) {\n                 filters.set(i, parseContext.cacheFilterIfPossible(filters.get(i)));",
    "output": "Add an exception when on filtesr are provided to \"and\" and \"not\" filters"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobReuseExistingNodeAllocation.java b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobReuseExistingNodeAllocation.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobReuseExistingNodeAllocation.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/gateway/blobstore/BlobReuseExistingNodeAllocation.java\n@@ -208,7 +208,7 @@ public class BlobReuseExistingNodeAllocation extends NodeAllocation {\n             if (lastNodeMatched != null) {\n                 if (nodeAllocations.canAllocate(shard, lastNodeMatched, routingNodes) == NodeAllocation.Decision.THROTTLE) {\n                     if (logger.isTraceEnabled()) {\n-                        logger.trace(\"[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]\", shard.index(), shard.id(), shard, lastDiscoNodeMatched, new ByteSizeValue(lastSizeMatched));\n+                        logger.debug(\"[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]\", shard.index(), shard.id(), shard, lastDiscoNodeMatched, new ByteSizeValue(lastSizeMatched));\n                     }\n                     // we are throttling this, but we have enough to allocate to this node, ignore it for now\n                     unassignedIterator.remove();",
    "output": "Change log level"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/shutdown/RestNodesShutdownAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/shutdown/RestNodesShutdownAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/shutdown/RestNodesShutdownAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/shutdown/RestNodesShutdownAction.java\n@@ -42,6 +42,7 @@ public class RestNodesShutdownAction extends BaseRestHandler {\n     @Inject public RestNodesShutdownAction(Settings settings, Client client, RestController controller) {\n         super(settings, client);\n \n+        controller.registerHandler(RestRequest.Method.POST, \"/_shutdown\", this);\n         controller.registerHandler(RestRequest.Method.POST, \"/_cluster/nodes/_shutdown\", this);\n         controller.registerHandler(RestRequest.Method.POST, \"/_cluster/nodes/{nodeId}/_shutdown\", this);\n     }",
    "output": "Add /_shutdown to the REST endpoints"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n@@ -645,6 +645,7 @@ private void recoverFile(final BlobMetaData fileToRecover, final ImmutableMap<St\n         }\n         if (!blobs.containsKey(firstFileToRecover)) {\n             // no file, what to do, what to do?\n+            recoveryThrottler.streamDone(shardId, fileToRecover.name());\n             logger.warn(\"no file [{}] to recover, even though it has md5, ignoring it\", fileToRecover.name());\n             latch.countDown();\n             return;",
    "output": "Add stream done when there is no file (should not happen)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/status/IndexStatus.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/status/IndexStatus.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/status/IndexStatus.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/status/IndexStatus.java\n@@ -135,6 +135,9 @@ public DocsStatus docs() {\n             if (shard.docs() == null) {\n                 continue;\n             }\n+            if (docs == null) {\n+                docs = new DocsStatus();\n+            }\n             docs.numDocs += shard.docs().numDocs();\n             docs.maxDoc += shard.docs().maxDoc();\n             docs.deletedDocs += shard.docs().deletedDocs();",
    "output": "Fix NPE introduced on optimization of index status on docs status creation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/OnGoingRecovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/OnGoingRecovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/OnGoingRecovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/OnGoingRecovery.java\n@@ -24,6 +24,7 @@\n \n import java.util.List;\n import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicLong;\n \n /**\n  * @author kimchy (shay.banon)\n@@ -48,4 +49,5 @@ public static enum Stage {\n \n     volatile Stage stage = Stage.INIT;\n     volatile long currentTranslogOperations = 0;\n+    AtomicLong currentFilesSize = new AtomicLong();\n }\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryTarget.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryTarget.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryTarget.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryTarget.java\n@@ -395,6 +395,7 @@ class FileChunkTransportRequestHandler extends BaseTransportRequestHandler<Recov\n             synchronized (indexOutput) {\n                 try {\n                     indexOutput.writeBytes(request.content(), request.contentLength());\n+                    onGoingRecovery.currentFilesSize.addAndGet(request.contentLength());\n                     if (indexOutput.getFilePointer() == request.length()) {\n                         // we are done\n                         indexOutput.close();",
    "output": "Upgrade the current recvoerd files size in peer recovery"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java\n@@ -291,7 +291,7 @@ public void shard(SearchShardTarget target) {\n             builder.endObject();\n         }\n         if (sortValues != null && sortValues.length > 0) {\n-            builder.startArray(\"sort_values\");\n+            builder.startArray(\"sort\");\n             for (Object sortValue : sortValues) {\n                 builder.value(sortValue);\n             }",
    "output": "Add sort values as part of the response per search hit"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentGeoPointFieldMapper.java\n@@ -72,7 +72,7 @@ public static class Builder extends XContentMapper.Builder<Builder, XContentGeoP\n \n         private boolean enableGeohash = false;\n \n-        private String resolution = \"32\";\n+        private String resolution = \"64\";\n \n         private Integer precisionStep;\n ",
    "output": "Change default geo point resolution from 32 to 64"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/range/RangeFacetCollectorParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/range/RangeFacetCollectorParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/range/RangeFacetCollectorParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/range/RangeFacetCollectorParser.java\n@@ -56,6 +56,10 @@ public class RangeFacetCollectorParser implements FacetCollectorParser {\n             if (token == XContentParser.Token.FIELD_NAME) {\n                 fieldName = parser.currentName();\n             } else if (token == XContentParser.Token.START_ARRAY) {\n+                if (!\"ranges\".equals(fieldName)) {\n+                    // this is the actual field name, so also update the keyField\n+                    keyField = fieldName;\n+                }\n                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\n                     RangeFacet.Entry entry = new RangeFacet.Entry();\n                     while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\n@@ -77,10 +81,6 @@ public class RangeFacetCollectorParser implements FacetCollectorParser {\n                     }\n                     entries.add(entry);\n                 }\n-                if (!\"ranges\".equals(fieldName)) {\n-                    // this is the actual field name, so also update the keyField\n-                    keyField = fieldName;\n-                }\n             } else if (token == XContentParser.Token.START_OBJECT) {\n                 if (\"params\".equals(fieldName)) {\n                     params = parser.map();",
    "output": "Add an option to provide the array of ranges \"on\" the field name itself"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java\n@@ -129,7 +129,7 @@ public class GeoDistanceFacetCollectorParser implements FacetCollectorParser {\n                     unit = DistanceUnit.fromString(parser.text());\n                 } else if (currentName.equals(\"distance_type\") || currentName.equals(\"distanceType\")) {\n                     geoDistance = GeoDistance.fromString(parser.text());\n-                } else if (\"value_field\".equals(currentName) || \"valueName\".equals(currentName)) {\n+                } else if (\"value_field\".equals(currentName) || \"valueField\".equals(currentName)) {\n                     valueFieldName = parser.text();\n                 } else if (\"value_script\".equals(currentName) || \"valueScript\".equals(currentName)) {\n                     valueScript = parser.text();",
    "output": "Fix valueField name"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java\n@@ -24,6 +24,7 @@\n import org.elasticsearch.common.lucene.geo.GeoDistance;\n import org.elasticsearch.common.unit.DistanceUnit;\n import org.elasticsearch.common.xcontent.builder.XContentBuilder;\n+import org.elasticsearch.index.query.xcontent.XContentFilterBuilder;\n import org.elasticsearch.search.builder.SearchSourceBuilderException;\n import org.elasticsearch.search.facets.AbstractFacetBuilder;\n \n@@ -185,6 +186,16 @@ public GeoDistanceFacetBuilder unit(DistanceUnit unit) {\n         return this;\n     }\n \n+    public GeoDistanceFacetBuilder global(boolean global) {\n+        this.global = global;\n+        return this;\n+    }\n+\n+    public GeoDistanceFacetBuilder filter(XContentFilterBuilder filter) {\n+        this.filter = filter;\n+        return this;\n+    }\n+\n     @Override public void toXContent(XContentBuilder builder, Params params) throws IOException {\n         if (fieldName == null) {\n             throw new SearchSourceBuilderException(\"field must be set on geo_distance facet for facet [\" + name + \"]\");",
    "output": "Add filter and global support"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetBuilder.java\n@@ -194,6 +194,7 @@ public GeoDistanceFacetBuilder unit(DistanceUnit unit) {\n         }\n \n         builder.startObject(name);\n+\n         builder.startObject(GeoDistanceFacetCollectorParser.NAME);\n \n         if (geohash != null) {\n@@ -235,6 +236,16 @@ public GeoDistanceFacetBuilder unit(DistanceUnit unit) {\n         }\n \n         builder.endObject();\n+\n+        if (filter != null) {\n+            builder.field(\"filter\");\n+            filter.toXContent(builder, params);\n+        }\n+\n+        if (global != null) {\n+            builder.field(\"global\", global);\n+        }\n+\n         builder.endObject();\n     }\n ",
    "output": "Add filter and global support"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/GeoDistanceFacetCollectorParser.java\n@@ -155,6 +155,10 @@ public class GeoDistanceFacetCollectorParser implements FacetCollectorParser {\n             throw new FacetPhaseExecutionException(facetName, \"lat/lon not set for geo_distance facet\");\n         }\n \n+        if (entries.isEmpty()) {\n+            throw new FacetPhaseExecutionException(facetName, \"no ranges defined for geo_distance facet\");\n+        }\n+\n         if (valueFieldName != null) {\n             return new ValueGeoDistanceFacetCollector(facetName, fieldName, lat, lon, unit, geoDistance, entries.toArray(new GeoDistanceFacet.Entry[entries.size()]),\n                     context.fieldDataCache(), context.mapperService(), valueFieldName);",
    "output": "Add a check for at least one range"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/InternalGeoDistanceFacet.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/InternalGeoDistanceFacet.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/InternalGeoDistanceFacet.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/geodistance/InternalGeoDistanceFacet.java\n@@ -161,7 +161,7 @@ public static InternalGeoDistanceFacet readGeoDistanceFacet(StreamInput in) thro\n \n     @Override public void toXContent(XContentBuilder builder, Params params) throws IOException {\n         builder.startObject(name);\n-        builder.field(\"_type\", \"histogram\");\n+        builder.field(\"_type\", \"geo_distance\");\n         builder.field(\"_field\", fieldName);\n         builder.field(\"_value_field\", valueFieldName);\n         builder.field(\"_unit\", unit);",
    "output": "Fix type on xcontent result"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java\n@@ -127,11 +127,11 @@ public void createIndex(final Request request, final Listener userListener) {\n                     File mappingsDir = new File(environment.configFile(), \"mappings\");\n                     if (mappingsDir.exists() && mappingsDir.isDirectory()) {\n                         File defaultMappingsDir = new File(mappingsDir, \"_default\");\n-                        if (mappingsDir.exists() && mappingsDir.isDirectory()) {\n+                        if (defaultMappingsDir.exists() && defaultMappingsDir.isDirectory()) {\n                             addMappings(mappings, defaultMappingsDir);\n                         }\n                         File indexMappingsDir = new File(mappingsDir, request.index);\n-                        if (mappingsDir.exists() && mappingsDir.isDirectory()) {\n+                        if (indexMappingsDir.exists() && indexMappingsDir.isDirectory()) {\n                             addMappings(mappings, indexMappingsDir);\n                         }\n                     }",
    "output": "Fix test for existance of directory based mappings when creating an index"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n@@ -762,7 +762,7 @@ public static ImmutableMap<String, BlobMetaData> buildVirtualBlobs(ImmutableBlob\n                         cachedMd5.put(name, md5);\n                     }\n                     builder.put(name, new PlainBlobMetaData(name, sizeInBytes, md5));\n-                } catch (IOException e) {\n+                } catch (Exception e) {\n                     // don't add it!\n                 }\n             }",
    "output": "Improve handling of failure when trying to read md5, should be ignored on any exception, not just io exception"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/gateway/blobstore/BlobStoreIndexShardGateway.java\n@@ -324,7 +324,7 @@ protected BlobStoreIndexShardGateway(ShardId shardId, @IndexSettings Settings in\n         if (snapshot.newTranslogCreated()) {\n             try {\n                 translogContainer.deleteBlob(\"translog-\" + snapshot.lastTranslogId());\n-            } catch (IOException e) {\n+            } catch (Exception e) {\n                 // ignore\n             }\n         }",
    "output": "Fix ignored exception"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/PreferUnallocatedShardUnassignedStrategy.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/PreferUnallocatedShardUnassignedStrategy.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/PreferUnallocatedShardUnassignedStrategy.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/PreferUnallocatedShardUnassignedStrategy.java\n@@ -95,7 +95,7 @@ public boolean allocateUnassigned(RoutingNodes routingNodes, DiscoveryNodes node\n \n             TransportNodesListShardStoreMetaData.NodesStoreFilesMetaData nodesStoreFilesMetaData = transportNodesListShardStoreMetaData.list(shard.shardId(), false, nodesIds.toArray(new String[nodesIds.size()])).actionGet();\n \n-            if (logger.isWarnEnabled()) {\n+            if (logger.isDebugEnabled()) {\n                 if (nodesStoreFilesMetaData.failures().length > 0) {\n                     StringBuilder sb = new StringBuilder(shard + \": failures when trying to list stores on nodes:\");\n                     for (int i = 0; i < nodesStoreFilesMetaData.failures().length; i++) {\n@@ -105,7 +105,7 @@ public boolean allocateUnassigned(RoutingNodes routingNodes, DiscoveryNodes node\n                         }\n                         sb.append(\"\\n    -> \").append(nodesStoreFilesMetaData.failures()[i].getDetailedMessage());\n                     }\n-                    logger.warn(sb.toString());\n+                    logger.debug(sb.toString());\n                 }\n             }\n ",
    "output": "Change logging level to debug"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java\n@@ -51,10 +51,10 @@ public class HighlighterParseElement implements SearchParseElement {\n     private static final String[] DEFAULT_POST_TAGS = new String[]{\"</em>\"};\n \n     private static final String[] STYLED_PRE_TAG = {\n-            \"<em class=\\\"hlt1\\\">\", \"<em class=\\\"hlt2\\\">\", \"<em class=\\\"hlt2\\\">\",\n-            \"<em class=\\\"hlt3\\\">\", \"<em class=\\\"hlt4\\\">\", \"<em class=\\\"hlt5\\\">\",\n-            \"<em class=\\\"hlt6\\\">\", \"<em class=\\\"hlt7\\\">\", \"<em class=\\\"hlt8\\\">\",\n-            \"<em class=\\\"hlt9\\\">\"\n+            \"<em class=\\\"hlt1\\\">\", \"<em class=\\\"hlt2\\\">\", \"<em class=\\\"hlt3\\\">\",\n+            \"<em class=\\\"hlt4\\\">\", \"<em class=\\\"hlt5\\\">\", \"<em class=\\\"hlt6\\\">\",\n+            \"<em class=\\\"hlt7\\\">\", \"<em class=\\\"hlt8\\\">\", \"<em class=\\\"hlt9\\\">\",\n+            \"<em class=\\\"hlt10\\\">\"\n     };\n     public static final String[] STYLED_POST_TAGS = {\"</em>\"};\n ",
    "output": "Fix highlighted styled built in schema tags to properly increate from hlt1 to hlt10"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/publish/PublishClusterStateAction.java\n@@ -69,7 +69,7 @@ public void publish(ClusterState clusterState) {\n             }\n             transportService.sendRequest(node, PublishClusterStateRequestHandler.ACTION, new PublishClusterStateRequest(clusterState), new VoidTransportResponseHandler(false) {\n                 @Override public void handleException(RemoteTransportException exp) {\n-                    logger.warn(\"failed to send cluster state to [{}], should be detected as failed soon...\", exp, node);\n+                    logger.debug(\"failed to send cluster state to [{}], should be detected as failed soon...\", exp, node);\n                 }\n             });\n         }",
    "output": "Change logging level, nodes FD will detect it as well"
  },
  {
    "input": "diff --git a/plugins/transport/memcached/src/test/java/org/elasticsearch/memcached/test/AbstractMemcachedActionsTests.java b/plugins/transport/memcached/src/test/java/org/elasticsearch/memcached/test/AbstractMemcachedActionsTests.java\n--- a/plugins/transport/memcached/src/test/java/org/elasticsearch/memcached/test/AbstractMemcachedActionsTests.java\n+++ b/plugins/transport/memcached/src/test/java/org/elasticsearch/memcached/test/AbstractMemcachedActionsTests.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.memcached.test;\n \n import net.spy.memcached.MemcachedClient;\n+import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n import org.elasticsearch.node.Node;\n import org.hamcrest.Matchers;\n import org.testng.annotations.AfterMethod;\n@@ -62,6 +63,9 @@ public void tearDown() {\n         Future<Boolean> setResult = memcachedClient.set(\"/test/person/1\", 0, jsonBuilder().startObject().field(\"test\", \"value\").endObject().copiedBytes());\n         assertThat(setResult.get(10, TimeUnit.SECONDS), equalTo(true));\n \n+        ClusterHealthResponse health = node.client().admin().cluster().prepareHealth().setWaitForYellowStatus().execute().actionGet();\n+        assertThat(health.timedOut(), equalTo(false));\n+\n         String getResult = (String) memcachedClient.get(\"/_refresh\");\n         System.out.println(\"REFRESH \" + getResult);\n         assertThat(getResult, Matchers.containsString(\"\\\"total\\\":10\"));",
    "output": "Improve memcached test"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n@@ -223,6 +223,7 @@ public class RecoveryWhileUnderLoadTests extends AbstractNodesTests {\n \n         stop.set(true);\n         stopLatch.await();\n+        assertThat(client(\"node2\").admin().cluster().prepareHealth().setTimeout(\"1m\").setWaitForYellowStatus().execute().actionGet().status(), equalTo(ClusterHealthStatus.YELLOW));\n \n         client(\"node2\").admin().indices().prepareRefresh().execute().actionGet();\n         for (int i = 0; i < 10; i++) {",
    "output": "Improve load test"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n@@ -243,7 +243,7 @@ private void applyNewOrUpdatedShards(final ClusterChangedEvent event) throws Ela\n \n             if (!indexService.hasShard(shardId) && shardRouting.started()) {\n                 // the master thinks we are started, but we don't have this shard at all, mark it as failed\n-                logger.warn(\"[{}][{}] master [{}] marked shard as started, but shard have not been created, mark shard as failed\");\n+                logger.warn(\"[{}][{}] master [{}] marked shard as started, but shard have not been created, mark shard as failed\", shardRouting.index(), shardId, nodes.masterNode());\n                 shardStateAction.shardFailed(shardRouting, \"master \" + nodes.masterNode() + \" marked shard as started, but shard have not been created, mark shard as failed\");\n                 continue;\n             }",
    "output": "Fix logging to actually pass the actual logging parameters"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/recovery/RecoveryWhileUnderLoadTests.java\n@@ -19,6 +19,7 @@\n \n package org.elasticsearch.test.integration.recovery;\n \n+import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n import org.elasticsearch.common.collect.MapBuilder;\n import org.elasticsearch.test.integration.AbstractNodesTests;\n import org.testng.annotations.AfterMethod;\n@@ -83,6 +84,9 @@ public class RecoveryWhileUnderLoadTests extends AbstractNodesTests {\n         // now start another node, while we index\n         startNode(\"server2\");\n \n+        // make sure the cluster state is green, and all has been recovered\n+        assertThat(client(\"server1\").admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet().status(), equalTo(ClusterHealthStatus.GREEN));\n+\n \n         // wait till we index 10,0000\n         while (client(\"server1\").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count() < 10000) {",
    "output": "Add a recovery test while under indexing load"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n@@ -102,7 +102,7 @@ public void execute(SearchContext searchContext) throws QueryPhaseExecutionExcep\n             boolean sort = false;\n             // try and optimize for a case where the sorting is based on score, this is how we work by default!\n             if (searchContext.sort() != null) {\n-                if (searchContext.sort().getSort().length > 0) {\n+                if (searchContext.sort().getSort().length > 1) {\n                     sort = true;\n                 } else {\n                     SortField sortField = searchContext.sort().getSort()[0];",
    "output": "Fix optimization to not do sorting when searching with score \"desc\" sorting"
  },
  {
    "input": "diff --git a/plugins/cloud/src/main/java/org/elasticsearch/cloud/blobstore/CloudBlobStore.java b/plugins/cloud/src/main/java/org/elasticsearch/cloud/blobstore/CloudBlobStore.java\n--- a/plugins/cloud/src/main/java/org/elasticsearch/cloud/blobstore/CloudBlobStore.java\n+++ b/plugins/cloud/src/main/java/org/elasticsearch/cloud/blobstore/CloudBlobStore.java\n@@ -83,6 +83,10 @@ public CloudBlobStore(Settings settings, BlobStoreContext blobStoreContext, Stri\n         sync().createContainerInLocation(this.location, container);\n     }\n \n+    @Override public String toString() {\n+        return container;\n+    }\n+\n     public int bufferSizeInBytes() {\n         return this.bufferSizeInBytes;\n     }",
    "output": "Add more info"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java\n@@ -226,7 +226,11 @@ public void shard(SearchShardTarget target) {\n //        builder.field(\"_node\", shard.nodeId());\n         builder.field(\"_type\", type());\n         builder.field(\"_id\", id());\n-        builder.field(\"_score\", score);\n+        if (Float.isNaN(score)) {\n+            builder.nullField(\"_score\");\n+        } else {\n+            builder.field(\"_score\", score);\n+        }\n         if (source() != null) {\n             if (XContentFactory.xContentType(source()) == builder.contentType()) {\n                 builder.rawField(\"_source\", source());",
    "output": "Add NaN handling for specific hit score as well"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java\n@@ -190,7 +190,12 @@ public InternalSearchResponse merge(ShardDoc[] sortedDocs, Map<SearchShardTarget\n         float maxScore = Float.NEGATIVE_INFINITY;\n         for (QuerySearchResultProvider queryResultProvider : queryResults.values()) {\n             totalHits += queryResultProvider.queryResult().topDocs().totalHits;\n-            maxScore = Math.max(maxScore, queryResultProvider.queryResult().topDocs().getMaxScore());\n+            if (!Float.isNaN(queryResultProvider.queryResult().topDocs().getMaxScore())) {\n+                maxScore = Math.max(maxScore, queryResultProvider.queryResult().topDocs().getMaxScore());\n+            }\n+        }\n+        if (Float.isInfinite(maxScore)) {\n+            maxScore = Float.NaN;\n         }\n \n         // clean the fetch counter",
    "output": "Fix a problem where max_score was NaN if there were no hits from a shard (though there are hits from other shards), it will still be NaN where there are no hits"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java\n@@ -315,7 +315,7 @@ private void applyInitializingShard(final RoutingTable routingTable, final Disco\n                     return;\n                 }\n                 try {\n-                    RecoveryAction recoveryAction = indexService.shardInjector(shardId).getInstance(RecoveryAction.class);\n+                    RecoveryAction recoveryAction = indexService.shardInjectorSafe(shardId).getInstance(RecoveryAction.class);\n                     if (!shardRouting.primary()) {\n                         // recovery from primary\n                         IndexShardRoutingTable shardRoutingTable = routingTable.index(shardRouting.index()).shard(shardRouting.id());",
    "output": "Use safe method (to get proper exception) to get shard injector"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/facets/SimpleFacetsTests.java\n@@ -183,14 +183,16 @@ protected Client getClient() {\n \n         searchResponse = client.prepareSearch()\n                 .setQuery(matchAllQuery())\n-                .addFacet(termsFacet(\"facet1\").field(\"tag\").size(1))\n+                .addFacet(termsFacet(\"facet1\").field(\"tag\").size(2))\n                 .execute().actionGet();\n \n         facet = searchResponse.facets().facet(TermsFacet.class, \"facet1\");\n         assertThat(facet.name(), equalTo(\"facet1\"));\n-        assertThat(facet.entries().size(), equalTo(1));\n+        assertThat(facet.entries().size(), equalTo(2));\n         assertThat(facet.entries().get(0).term(), equalTo(\"yyy\"));\n         assertThat(facet.entries().get(0).count(), equalTo(2));\n+        assertThat(facet.entries().get(1).term(), anyOf(equalTo(\"xxx\"), equalTo(\"zzz\")));\n+        assertThat(facet.entries().get(1).count(), equalTo(1));\n \n         searchResponse = client.prepareSearch()\n                 .setQuery(matchAllQuery())",
    "output": "Fix terms facets test to take into account distributed terms request"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/memory/MemoryTranslog.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/memory/MemoryTranslog.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/memory/MemoryTranslog.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/translog/memory/MemoryTranslog.java\n@@ -60,7 +60,7 @@ public class MemoryTranslog extends AbstractIndexShardComponent implements Trans\n     }\n \n     @Override public int size() {\n-        return operations.size();\n+        return operationCounter.get();\n     }\n \n     @Override public ByteSizeValue estimateMemorySize() {",
    "output": "Use the atomic integer counter to represent the size"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/ExceptionsHelper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/ExceptionsHelper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/ExceptionsHelper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/ExceptionsHelper.java\n@@ -33,10 +33,10 @@ public static Throwable unwrapCause(Throwable t) {\n         int counter = 0;\n         Throwable result = t;\n         while (result instanceof ElasticSearchWrapperException) {\n-            if (t.getCause() == null) {\n+            if (result.getCause() == null) {\n                 return result;\n             }\n-            if (t.getCause() == t) {\n+            if (result.getCause() == result) {\n                 return result;\n             }\n             if (counter++ > 10) {",
    "output": "Fix unwrapping of exceptions"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/ShardsRoutingStrategy.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/ShardsRoutingStrategy.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/ShardsRoutingStrategy.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/routing/strategy/ShardsRoutingStrategy.java\n@@ -22,6 +22,10 @@\n import org.elasticsearch.cluster.ClusterState;\n import org.elasticsearch.cluster.node.DiscoveryNode;\n import org.elasticsearch.cluster.routing.*;\n+import org.elasticsearch.common.component.AbstractComponent;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.settings.ImmutableSettings;\n+import org.elasticsearch.common.settings.Settings;\n \n import java.util.Iterator;\n import java.util.List;\n@@ -33,7 +37,15 @@\n /**\n  * @author kimchy (shay.banon)\n  */\n-public class ShardsRoutingStrategy {\n+public class ShardsRoutingStrategy extends AbstractComponent {\n+\n+    public ShardsRoutingStrategy() {\n+        super(ImmutableSettings.Builder.EMPTY_SETTINGS);\n+    }\n+\n+    @Inject public ShardsRoutingStrategy(Settings settings) {\n+        super(settings);\n+    }\n \n     /**\n      * Applies the started shards. Note, shards can be called several times within this method.",
    "output": "Make the shard routing an actual component"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/TransferThreadPoolExecutor.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/TransferThreadPoolExecutor.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/TransferThreadPoolExecutor.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/TransferThreadPoolExecutor.java\n@@ -496,7 +496,7 @@ private boolean workerCanExit() {\n         mainLock.lock();\n         boolean canExit;\n         try {\n-            canExit = runState >= STOP || queueSize.get() == 0;\n+            canExit = runState >= STOP || (queueSize.get() == 0 && poolSize.get() > corePoolSize);\n         } finally {\n             mainLock.unlock();\n         }",
    "output": "Add another test if the pool size is greater than the core pool size before a worker can exit"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/strategy/PrimaryElectionRoutingTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/strategy/PrimaryElectionRoutingTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/strategy/PrimaryElectionRoutingTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/strategy/PrimaryElectionRoutingTests.java\n@@ -60,7 +60,7 @@ public class PrimaryElectionRoutingTests {\n \n         ClusterState clusterState = newClusterStateBuilder().metaData(metaData).routingTable(routingTable).build();\n \n-        logger.info(\"Adding three nodes and performing rerouting\");\n+        logger.info(\"Adding two nodes and performing rerouting\");\n         clusterState = newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().put(newNode(\"node1\")).put(newNode(\"node2\"))).build();\n         RoutingTable prevRoutingTable = routingTable;\n         routingTable = strategy.reroute(clusterState);",
    "output": "Fix log message"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java b/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java\n@@ -109,7 +109,7 @@ public double getGbFrac() {\n     @Override public String toString() {\n         long bytes = bytes();\n         double value = bytes;\n-        String suffix = \"\";\n+        String suffix = \"b\";\n         if (bytes >= ByteSizeUnit.C3) {\n             value = gbFrac();\n             suffix = \"gb\";",
    "output": "Fix toString of bytes value"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/LogByteSizeMergePolicyProvider.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/LogByteSizeMergePolicyProvider.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/LogByteSizeMergePolicyProvider.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/merge/policy/LogByteSizeMergePolicyProvider.java\n@@ -44,7 +44,7 @@ public class LogByteSizeMergePolicyProvider extends AbstractIndexShardComponent\n         super(store.shardId(), store.indexSettings());\n         Preconditions.checkNotNull(store, \"Store must be provided to merge policy\");\n \n-        this.minMergeSize = componentSettings.getAsBytesSize(\"min_merge_size\", new ByteSizeValue((long) LogByteSizeMergePolicy.DEFAULT_MIN_MERGE_MB * 1024 * 1024, ByteSizeUnit.BYTES));\n+        this.minMergeSize = componentSettings.getAsBytesSize(\"min_merge_size\", new ByteSizeValue((long) (LogByteSizeMergePolicy.DEFAULT_MIN_MERGE_MB * 1024 * 1024), ByteSizeUnit.BYTES));\n         this.maxMergeSize = componentSettings.getAsBytesSize(\"max_merge_size\", new ByteSizeValue((long) LogByteSizeMergePolicy.DEFAULT_MAX_MERGE_MB, ByteSizeUnit.MB));\n         this.mergeFactor = componentSettings.getAsInt(\"merge_factor\", LogByteSizeMergePolicy.DEFAULT_MERGE_FACTOR);\n         this.maxMergeDocs = componentSettings.getAsInt(\"max_merge_docs\", LogByteSizeMergePolicy.DEFAULT_MAX_MERGE_DOCS);",
    "output": "Fix default merge size to not truncate on long"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/env/Environment.java b/modules/elasticsearch/src/main/java/org/elasticsearch/env/Environment.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/env/Environment.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/env/Environment.java\n@@ -60,7 +60,7 @@ public Environment(Settings settings) {\n         if (settings.get(\"path.home\") != null) {\n             homeFile = new File(cleanPath(settings.get(\"path.home\")));\n         } else {\n-            homeFile = new File(\".\");\n+            homeFile = new File(System.getProperty(\"user.dir\"));\n         }\n         homeFile.mkdirs();\n ",
    "output": "Use java user.dir as the default \"path.home\" location"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/node/internal/InternalSettingsPerparer.java b/modules/elasticsearch/src/main/java/org/elasticsearch/node/internal/InternalSettingsPerparer.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/node/internal/InternalSettingsPerparer.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/node/internal/InternalSettingsPerparer.java\n@@ -49,7 +49,7 @@ public static Tuple<Settings, Environment> prepareSettings(Settings pSettings, b\n         settingsBuilder = settingsBuilder().put(pSettings);\n         settingsBuilder.put(\"path.home\", cleanPath(environment.homeFile().getAbsolutePath()));\n         settingsBuilder.put(\"path.work\", cleanPath(environment.workFile().getAbsolutePath()));\n-        settingsBuilder.put(\"path.workWithCluster\", cleanPath(environment.workWithClusterFile().getAbsolutePath()));\n+        settingsBuilder.put(\"path.work_with_cluster\", cleanPath(environment.workWithClusterFile().getAbsolutePath()));\n         settingsBuilder.put(\"path.logs\", cleanPath(environment.logsFile().getAbsolutePath()));\n \n         if (loadConfigSettings) {",
    "output": "Fix work with cluster setting"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/RestController.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/RestController.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/RestController.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/RestController.java\n@@ -71,8 +71,10 @@ public void registerHandler(RestRequest.Method method, String path, RestHandler\n                 break;\n             case OPTIONS:\n                 optionsHandlers.insert(path, handler);\n+                break;\n             case HEAD:\n                 headHandlers.insert(path, handler);\n+                break;\n             default:\n                 throw new ElasticSearchIllegalArgumentException(\"Can't handle [\" + method + \"] for path [\" + path + \"]\");\n         }",
    "output": "Fix missing break statemetns (via Lukas)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java\n@@ -412,6 +412,17 @@ private void handleJoinRequest(final DiscoveryNode node) {\n     private DiscoveryNode broadPingTillMasterResolved() {\n         while (true) {\n             ZenPing.PingResponse[] pingResponses = pingService.pingAndWait(initialPingTimeout);\n+            if (logger.isDebugEnabled()) {\n+                StringBuilder sb = new StringBuilder(\"ping responses:\");\n+                if (pingResponses.length == 0) {\n+                    sb.append(\" {none}\");\n+                } else {\n+                    for (ZenPing.PingResponse pingResponse : pingResponses) {\n+                        sb.append(\"\\n\\t--> \").append(\"target [\").append(pingResponse.target()).append(\"], master [\").append(pingResponse.master()).append(\"]\");\n+                    }\n+                }\n+                logger.debug(sb.toString());\n+            }\n             List<DiscoveryNode> pingMasters = newArrayList();\n             for (ZenPing.PingResponse pingResponse : pingResponses) {\n                 if (pingResponse.master() != null) {",
    "output": "Add debug logging of the ping responses received"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeOperationAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeOperationAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeOperationAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/master/TransportMasterNodeOperationAction.java\n@@ -20,6 +20,7 @@\n package org.elasticsearch.action.support.master;\n \n import org.elasticsearch.ElasticSearchException;\n+import org.elasticsearch.ElasticSearchIllegalStateException;\n import org.elasticsearch.action.ActionListener;\n import org.elasticsearch.action.ActionResponse;\n import org.elasticsearch.action.support.BaseAction;\n@@ -73,6 +74,9 @@ protected TransportMasterNodeOperationAction(Settings settings, TransportService\n                 }\n             });\n         } else {\n+            if (nodes.masterNode() == null) {\n+                throw new ElasticSearchIllegalStateException(\"No master node discovered or set\");\n+            }\n             transportService.sendRequest(nodes.masterNode(), transportAction(), request, new BaseTransportResponseHandler<Response>() {\n                 @Override public Response newInstance() {\n                     return newResponse();",
    "output": "Add an exception if there is no master node set"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n@@ -93,14 +93,18 @@ public class RestClusterStateAction extends BaseRestHandler {\n                         }\n                         builder.endObject();\n \n-                        builder.startArray(\"mappings\");\n+                        builder.startObject(\"mappings\");\n                         for (Map.Entry<String, String> entry : indexMetaData.mappings().entrySet()) {\n                             XContentParser parser = XContentFactory.xContent(entry.getValue()).createParser(entry.getValue());\n                             Map<String, Object> mapping = parser.map();\n-                            parser.close();\n+                            if (mapping.size() == 1 && mapping.containsKey(entry.getKey())) {\n+                                // the type name is the root value, reduce it\n+                                mapping = (Map<String, Object>) mapping.get(entry.getKey());\n+                            }\n+                            builder.field(entry.getKey());\n                             builder.map(mapping);\n                         }\n-                        builder.endArray();\n+                        builder.endObject();\n \n                         builder.startArray(\"aliases\");\n                         for (String alias : indexMetaData.aliases()) {",
    "output": "Make the rest cluster state return mappings as object keyed type"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n@@ -102,6 +102,12 @@ public class RestClusterStateAction extends BaseRestHandler {\n                         }\n                         builder.endArray();\n \n+                        builder.startArray(\"aliases\");\n+                        for (String alias : indexMetaData.aliases()) {\n+                            builder.value(alias);\n+                        }\n+                        builder.endArray();\n+\n                         builder.endObject();\n                     }\n                     builder.endObject();",
    "output": "Add aliases to cluster state rest response"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n@@ -359,7 +359,7 @@ private void innerDeleteByQuery(byte[] querySource, String queryParserName, Stri\n     @Override public void flush(Engine.Flush flush) throws ElasticSearchException {\n         writeAllowed();\n         if (logger.isTraceEnabled()) {\n-            logger.trace(\"Flush\");\n+            logger.trace(\"Flush with {}\", flush);\n         }\n         engine.flush(flush);\n     }",
    "output": "Add flush logging"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n@@ -279,7 +279,7 @@ private void sendPingRequest(int id) {\n                         multicastSocket.send(datagramPacketSend);\n                         sentToAtLeastOne = true;\n                     } catch (Exception e) {\n-                        logger.trace(\"[{}] Failed to send multicast ping on interface {}\", id, inf);\n+                        logger.trace(\"[{}] Failed to send multicast ping on interface {}\", e, id, inf);\n                         lastException = e;\n                     }\n                 }",
    "output": "Add another trace logging"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/zen/ping/multicast/MulticastZenPing.java\n@@ -279,6 +279,7 @@ private void sendPingRequest(int id) {\n                         multicastSocket.send(datagramPacketSend);\n                         sentToAtLeastOne = true;\n                     } catch (Exception e) {\n+                        logger.trace(\"[{}] Failed to send multicast ping on interface {}\", id, inf);\n                         lastException = e;\n                     }\n                 }",
    "output": "Add another trace logging"
  },
  {
    "input": "diff --git a/plugins/cloud/src/main/java/org/elasticsearch/cloud/jclouds/JCloudsUtils.java b/plugins/cloud/src/main/java/org/elasticsearch/cloud/jclouds/JCloudsUtils.java\n--- a/plugins/cloud/src/main/java/org/elasticsearch/cloud/jclouds/JCloudsUtils.java\n+++ b/plugins/cloud/src/main/java/org/elasticsearch/cloud/jclouds/JCloudsUtils.java\n@@ -22,14 +22,21 @@\n import com.google.inject.Module;\n import org.elasticsearch.cloud.jclouds.logging.JCloudsLoggingModule;\n import org.elasticsearch.util.collect.ImmutableList;\n+import org.elasticsearch.util.concurrent.DynamicExecutors;\n import org.elasticsearch.util.settings.Settings;\n+import org.jclouds.concurrent.config.ExecutorServiceModule;\n+\n+import java.util.concurrent.Executors;\n \n /**\n  * @author kimchy (shay.banon)\n  */\n public class JCloudsUtils {\n \n     public static Iterable<? extends Module> buildModules(Settings settings) {\n-        return ImmutableList.of(new JCloudsLoggingModule(settings));\n+        return ImmutableList.of(new JCloudsLoggingModule(settings),\n+                new ExecutorServiceModule(\n+                        Executors.newCachedThreadPool(DynamicExecutors.daemonThreadFactory(settings, \"jclouds-user\")),\n+                        Executors.newCachedThreadPool(DynamicExecutors.daemonThreadFactory(settings, \"jclouds-io\"))));\n     }\n }",
    "output": "Change jclouds to use cached thread pool"
  },
  {
    "input": "diff --git a/plugins/cloud/src/main/java/org/elasticsearch/index/gateway/cloud/CloudIndexGateway.java b/plugins/cloud/src/main/java/org/elasticsearch/index/gateway/cloud/CloudIndexGateway.java\n--- a/plugins/cloud/src/main/java/org/elasticsearch/index/gateway/cloud/CloudIndexGateway.java\n+++ b/plugins/cloud/src/main/java/org/elasticsearch/index/gateway/cloud/CloudIndexGateway.java\n@@ -101,7 +101,7 @@ public class CloudIndexGateway extends AbstractIndexComponent implements IndexGa\n             }\n         }\n         this.indexContainer = container;\n-        this.indexDirectory = clusterName.value() + \"/\" + index.name();\n+        this.indexDirectory = clusterName.value() + \"/indices/\" + index.name();\n         this.chunkSize = chunkSize;\n \n         logger.debug(\"Using location [{}], container [{}], index_directory [{}], chunk_size [{}]\", this.location, this.indexContainer, this.indexDirectory, this.chunkSize);",
    "output": "Change index directory in the cloud to be under \"indices\""
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/Facets.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/Facets.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/Facets.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/facets/Facets.java\n@@ -77,7 +77,7 @@ public List<Facet> facets() {\n      * Returns the {@link Facet}s keyed by map.\n      */\n     public Map<String, Facet> getFacets() {\n-        return facetsAsMap;\n+        return facetsAsMap();\n     }\n \n     /**",
    "output": "Fix to build the facets map on getFacets"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/IndicesService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/IndicesService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/IndicesService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/IndicesService.java\n@@ -60,4 +60,9 @@ public interface IndicesService extends Iterable<IndexService>, LifecycleCompone\n     IndexService createIndex(String index, Settings settings, String localNodeId) throws ElasticSearchException;\n \n     void deleteIndex(String index) throws ElasticSearchException;\n+\n+    /**\n+     * Cleans the index without actually deleting any content for it.\n+     */\n+    void cleanIndex(String index) throws ElasticSearchException;\n }\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/indices/InternalIndicesService.java\n@@ -201,7 +201,11 @@ public synchronized IndexService createIndex(String sIndexName, Settings setting\n         return indexService;\n     }\n \n-    public synchronized void deleteIndex(String index) throws ElasticSearchException {\n+    @Override public synchronized void cleanIndex(String index) throws ElasticSearchException {\n+        deleteIndex(index, false);\n+    }\n+\n+    @Override public synchronized void deleteIndex(String index) throws ElasticSearchException {\n         deleteIndex(index, true);\n     }\n ",
    "output": "Add clean index to indices"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java\n@@ -26,7 +26,7 @@\n import org.elasticsearch.util.inject.multibindings.MapBinder;\n import org.elasticsearch.util.settings.Settings;\n \n-import java.util.List;\n+import java.util.LinkedList;\n import java.util.Map;\n \n /**\n@@ -44,7 +44,7 @@ public static interface AnalysisBinderProcessor {\n \n     private final Settings settings;\n \n-    private final List<AnalysisBinderProcessor> processors = Lists.newArrayList();\n+    private final LinkedList<AnalysisBinderProcessor> processors = Lists.newLinkedList();\n \n     public AnalysisModule(Settings settings) {\n         this.settings = settings;\n@@ -57,7 +57,7 @@ public AnalysisModule(Settings settings) {\n     }\n \n     public AnalysisModule addProcessor(AnalysisBinderProcessor processor) {\n-        processors.add(processor);\n+        processors.addFirst(processor);\n         return this;\n     }\n ",
    "output": "Change the addition of analysis processors to override the default ones"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/filter/support/AbstractConcurrentMapFilterCache.java\n@@ -81,12 +81,6 @@ protected AbstractConcurrentMapFilterCache(Index index, @IndexSettings Settings\n         return new FilterCacheFilterWrapper(filterToCache);\n     }\n \n-    private class IndexReaderCleaner implements Runnable {\n-        @Override public void run() {\n-            clearUnreferenced();\n-        }\n-    }\n-\n     protected ConcurrentMap<Filter, DocIdSet> buildFilterMap() {\n         return newConcurrentMap();\n     }",
    "output": "Remove dead code"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleByteBufferStoreTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleByteBufferStoreTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleByteBufferStoreTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleByteBufferStoreTests.java\n@@ -141,6 +141,10 @@ private void verifyData(ByteBufferDirectory dir) throws IOException {\n         indexInput.seek(30);\n         assertThat(indexInput.readByte(), equalTo((byte) 6));\n \n+        indexInput.seek(0);\n+        indexInput.readBytes(test, 0, 5);\n+        assertThat(test[0], equalTo((byte) 8));\n+\n         indexInput.close();\n \n         indexInput = dir.openInput(\"value1\");\n\ndiff --git a/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleHeapStoreTests.java b/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleHeapStoreTests.java\n--- a/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleHeapStoreTests.java\n+++ b/modules/elasticsearch/src/test/java/org/elasticsearch/index/store/memory/SimpleHeapStoreTests.java\n@@ -143,6 +143,10 @@ private void verifyData(HeapDirectory dir) throws IOException {\n         indexInput.seek(30);\n         assertThat(indexInput.readByte(), equalTo((byte) 6));\n \n+        indexInput.seek(0);\n+        indexInput.readBytes(test, 0, 5);\n+        assertThat(test[0], equalTo((byte) 8));\n+\n         indexInput.close();\n \n         indexInput = dir.openInput(\"value1\");",
    "output": "Add seek back on mem directory"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpServerTransport.java\n@@ -101,7 +101,7 @@ public class NettyHttpServerTransport extends AbstractLifecycleComponent<HttpSer\n     @Inject public NettyHttpServerTransport(Settings settings, NetworkService networkService) {\n         super(settings);\n         this.networkService = networkService;\n-        SizeValue maxContentLength = componentSettings.getAsSize(\"max_content_length\", new SizeValue(100, SizeUnit.MB));\n+        SizeValue maxContentLength = componentSettings.getAsSize(\"max_content_length\", settings.getAsSize(\"http.max_content_length\", new SizeValue(100, SizeUnit.MB)));\n         this.workerCount = componentSettings.getAsInt(\"worker_count\", Runtime.getRuntime().availableProcessors());\n         this.port = componentSettings.get(\"port\", settings.get(\"http.port\", \"9200-9300\"));\n         this.bindHost = componentSettings.get(\"bind_host\");",
    "output": "Add common http settings"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java\n@@ -144,9 +144,9 @@ public NettyTransport(Settings settings, ThreadPool threadPool) {\n         this.workerCount = componentSettings.getAsInt(\"worker_count\", Runtime.getRuntime().availableProcessors());\n         this.port = componentSettings.get(\"port\", settings.get(\"transport.tcp.port\", \"9300-9400\"));\n         this.bindHost = componentSettings.get(\"bind_host\");\n-        this.connectionsPerNode = componentSettings.getAsInt(\"connections_per_node\", 5);\n+        this.connectionsPerNode = componentSettings.getAsInt(\"connections_per_node\", settings.getAsInt(\"transport.tcp.connection_per_node\", 5));\n         this.publishHost = componentSettings.get(\"publish_host\");\n-        this.connectTimeout = componentSettings.getAsTime(\"connect_timeout\", timeValueSeconds(1));\n+        this.connectTimeout = componentSettings.getAsTime(\"connect_timeout\", settings.getAsTime(\"transport.tcp.connect_timeout\", timeValueSeconds(1)));\n         this.tcpNoDelay = componentSettings.getAsBoolean(\"tcp_no_delay\", settings.getAsBoolean(TCP_NO_DELAY, true));\n         this.tcpKeepAlive = componentSettings.getAsBoolean(\"tcp_keep_alive\", settings.getAsBoolean(TCP_KEEP_ALIVE, null));\n         this.reuseAddress = componentSettings.getAsBoolean(\"reuse_address\", settings.getAsBoolean(TCP_REUSE_ADDRESS, NetworkUtils.defaultReuseAddress()));",
    "output": "Add common tcp settings"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/plugins/PluginManager.java\n@@ -60,7 +60,7 @@ public static void main(String[] args) {\n             System.out.println(\"    - remove [list of plugin names]: Removes listed plugins\");\n         }\n         String command = args[0];\n-        if (command.equals(\"install\")) {\n+        if (command.equals(\"install\") || command.equals(\"-install\")) {\n             if (args.length < 2) {\n                 System.out.println(\"'install' requires an additional parameter with the plugin name\");\n             }\n@@ -74,7 +74,7 @@ public static void main(String[] args) {\n                     System.out.println(\"Failed to install \" + pluginName + \", reason: \" + e.getMessage());\n                 }\n             }\n-        } else if (command.equals(\"remove\")) {\n+        } else if (command.equals(\"remove\") || command.equals(\"-remove\")) {\n             if (args.length < 2) {\n                 System.out.println(\"'remove' requires an additional parameter with the plugin name\");\n             }",
    "output": "Add '-' option before install and remove"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/util/lucene/search/Queries.java b/modules/elasticsearch/src/main/java/org/elasticsearch/util/lucene/search/Queries.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/util/lucene/search/Queries.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/util/lucene/search/Queries.java\n@@ -54,31 +54,9 @@ public static List<Query> disMaxClauses(DisjunctionMaxQuery query) {\n      * Optimizes the given query and returns the optimized version of it.\n      */\n     public static Query optimizeQuery(Query q) {\n-        if (q instanceof BooleanQuery) {\n-            return optimizeBooleanQuery((BooleanQuery) q);\n-        }\n         return q;\n     }\n \n-    public static BooleanQuery optimizeBooleanQuery(BooleanQuery q) {\n-        BooleanQuery optimized = new BooleanQuery(q.isCoordDisabled());\n-        optimized.setMinimumNumberShouldMatch(q.getMinimumNumberShouldMatch());\n-        optimizeBooleanQuery(optimized, q);\n-        return optimized;\n-    }\n-\n-    public static void optimizeBooleanQuery(BooleanQuery optimized, BooleanQuery q) {\n-        for (BooleanClause clause : q.clauses()) {\n-            Query cq = clause.getQuery();\n-            cq.setBoost(cq.getBoost() * q.getBoost());\n-            if (cq instanceof BooleanQuery && !clause.isRequired() && !clause.isProhibited()) {\n-                optimizeBooleanQuery(optimized, (BooleanQuery) cq);\n-            } else {\n-                optimized.add(clause);\n-            }\n-        }\n-    }\n-\n     public static boolean isNegativeQuery(Query q) {\n         if (!(q instanceof BooleanQuery)) {\n             return false;",
    "output": "Fix wrong optimization on boolean query"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/util/transport/InetSocketTransportAddress.java b/modules/elasticsearch/src/main/java/org/elasticsearch/util/transport/InetSocketTransportAddress.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/util/transport/InetSocketTransportAddress.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/util/transport/InetSocketTransportAddress.java\n@@ -70,7 +70,15 @@ public InetSocketAddress address() {\n     }\n \n     @Override public void writeTo(StreamOutput out) throws IOException {\n-        out.writeUTF(address.getHostName());\n+        if (address.getAddress() != null) {\n+            if (address.getAddress().getHostAddress() != null) {\n+                out.writeUTF(address.getAddress().getHostAddress());\n+            } else {\n+                out.writeUTF(address.getHostName());\n+            }\n+        } else {\n+            out.writeUTF(address.getHostName());\n+        }\n         out.writeInt(address.getPort());\n     }\n ",
    "output": "Use ip address if possible when serializing inet socket transport information"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java\n@@ -25,6 +25,7 @@\n import org.jboss.netty.handler.codec.http.HttpHeaders;\n import org.jboss.netty.handler.codec.http.HttpMethod;\n \n+import java.nio.charset.Charset;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n@@ -99,8 +100,10 @@ public NettyHttpRequest(org.jboss.netty.handler.codec.http.HttpRequest request)\n         return data;\n     }\n \n+    private static Charset UTF8 = Charset.forName(\"UTF-8\");\n+\n     @Override public String contentAsString() {\n-        return request.getContent().toString(\"UTF-8\");\n+        return request.getContent().toString(UTF8);\n     }\n \n     @Override public Set<String> headerNames() {",
    "output": "Remove using deprecated method"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/util/xcontent/XContentFactory.java b/modules/elasticsearch/src/main/java/org/elasticsearch/util/xcontent/XContentFactory.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/util/xcontent/XContentFactory.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/util/xcontent/XContentFactory.java\n@@ -156,7 +156,7 @@ public static XContentType xContentType(byte[] data) {\n      */\n     public static XContentType xContentType(byte[] data, int offset, int length) {\n         length = length < GUESS_HEADER_LENGTH ? length : GUESS_HEADER_LENGTH;\n-        if (length > 1 && data[0] == 0x00 && data[1] == 0x00) {\n+        if (length > 1 && data[offset] == 0x00 && data[offset + 1] == 0x00) {\n             return XContentType.XSON;\n         }\n         for (int i = offset; i < length; i++) {",
    "output": "Use offset when detecting xcontent type"
  },
  {
    "input": "diff --git a/plugins/cloud/src/main/java/org/elasticsearch/discovery/cloud/CloudDiscovery.java b/plugins/cloud/src/main/java/org/elasticsearch/discovery/cloud/CloudDiscovery.java\n--- a/plugins/cloud/src/main/java/org/elasticsearch/discovery/cloud/CloudDiscovery.java\n+++ b/plugins/cloud/src/main/java/org/elasticsearch/discovery/cloud/CloudDiscovery.java\n@@ -39,7 +39,9 @@ public class CloudDiscovery extends ZenDiscovery {\n                                   ClusterService clusterService, ZenPingService pingService, CloudComputeService computeService) {\n         super(settings, clusterName, threadPool, transportService, clusterService, pingService);\n         if (settings.getAsBoolean(\"cloud.enabled\", true)) {\n-            pingService.zenPings(ImmutableList.of(new CloudZenPing(settings, threadPool, transportService, clusterName, computeService)));\n+            CloudZenPing cloudPing = new CloudZenPing(settings, threadPool, transportService, clusterName, computeService);\n+            cloudPing.setNodesProvider(this);\n+            pingService.zenPings(ImmutableList.of(cloudPing));\n         }\n     }\n }",
    "output": "Fix NPE since we need to provide the nodes provider"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/util/guice/inject/multibindings/MapBinder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/util/guice/inject/multibindings/MapBinder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/util/guice/inject/multibindings/MapBinder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/util/guice/inject/multibindings/MapBinder.java\n@@ -19,7 +19,6 @@\n import org.elasticsearch.util.collect.ImmutableSet;\n import org.elasticsearch.util.guice.inject.*;\n import org.elasticsearch.util.guice.inject.binder.LinkedBindingBuilder;\n-import org.elasticsearch.util.guice.inject.multibindings.Multibinder.*;\n import org.elasticsearch.util.guice.inject.spi.Dependency;\n import org.elasticsearch.util.guice.inject.spi.ProviderWithDependencies;\n import org.elasticsearch.util.guice.inject.util.Types;\n@@ -31,6 +30,7 @@\n import java.util.Map.Entry;\n import java.util.Set;\n \n+import static org.elasticsearch.util.guice.inject.multibindings.Multibinder.*;\n import static org.elasticsearch.util.guice.inject.util.Types.*;\n \n /**",
    "output": "Fix failed compilation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentObjectMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentObjectMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentObjectMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/xcontent/XContentObjectMapper.java\n@@ -410,7 +410,7 @@ private void serializeValue(ParseContext context, String currentFieldName, XCont\n                 // check if it fits one of the date formats\n                 boolean isDate = false;\n                 // a safe check since \"1\" gets parsed as well\n-                if (text.contains(\":\") || text.contains(\"-\")) {\n+                if (text.contains(\":\") || text.contains(\"-\") || text.contains(\"/\")) {\n                     for (FormatDateTimeFormatter dateTimeFormatter : dateTimeFormatters) {\n                         try {\n                             dateTimeFormatter.parser().parseMillis(text);",
    "output": "Add '/' to auto detection of dates"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java\n@@ -19,6 +19,8 @@\n \n package org.elasticsearch;\n \n+import org.elasticsearch.monitor.jvm.JvmConfig;\n+\n import java.io.InputStream;\n import java.text.SimpleDateFormat;\n import java.util.Date;\n@@ -72,4 +74,8 @@ public static String full() {\n         }\n         return sb.toString();\n     }\n+\n+    public static void main(String[] args) {\n+        System.out.println(\"ElasticSearch Version: \" + number + \" (\" + date() + \"), JVM: \" + JvmConfig.jvmConfig().vmVersion());\n+    }\n }",
    "output": "Add a -v flag to output version information,"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java\n@@ -27,6 +27,7 @@\n import org.elasticsearch.client.Client;\n import org.elasticsearch.rest.*;\n import org.elasticsearch.search.Scroll;\n+import org.elasticsearch.util.Unicode;\n import org.elasticsearch.util.json.JsonBuilder;\n import org.elasticsearch.util.settings.Settings;\n \n@@ -73,6 +74,11 @@ public class RestMoreLikeThisAction extends BaseRestHandler {\n             }\n             if (request.hasContent()) {\n                 mltRequest.searchSource(request.contentAsBytes());\n+            } else {\n+                String searchSource = request.param(\"search_source\");\n+                if (searchSource != null) {\n+                    mltRequest.searchSource(Unicode.fromStringAsBytes(searchSource));\n+                }\n             }\n         } catch (Exception e) {\n             try {",
    "output": "Add search_source as parameter to mlt to provide the actual search source as a query parameter and not in the body"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java\n@@ -195,7 +195,13 @@ private byte[] parseSearchSource(RestRequest request) {\n                 if (delimiter != -1) {\n                     String sortField = sort.substring(0, delimiter);\n                     String reverse = sort.substring(delimiter + 1);\n-                    searchSourceBuilder.sort(sortField, reverse.equals(\"reverse\"));\n+                    if (\"asc\".equals(reverse)) {\n+                        searchSourceBuilder.sort(sortField, SearchSourceBuilder.Order.ASC);\n+                    } else if (\"desc\".equals(reverse)) {\n+                        searchSourceBuilder.sort(sortField, SearchSourceBuilder.Order.DESC);\n+                    } else {\n+                        searchSourceBuilder.sort(sortField, reverse.equals(\"reverse\"));\n+                    }\n                 } else {\n                     searchSourceBuilder.sort(sort);\n                 }",
    "output": "Add desc/asc to querystring sort option"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/JsonBuilder.java b/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/JsonBuilder.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/JsonBuilder.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/JsonBuilder.java\n@@ -57,7 +57,7 @@ public static enum FieldCaseConversion {\n \n     private final static DateTimeFormatter defaultDatePrinter = ISODateTimeFormat.dateTime().withZone(DateTimeZone.UTC);\n \n-    protected static FieldCaseConversion globalFieldCaseConversion = FieldCaseConversion.CAMELCASE;\n+    protected static FieldCaseConversion globalFieldCaseConversion = FieldCaseConversion.NONE;\n \n     public static void globalFieldCaseConversion(FieldCaseConversion globalFieldCaseConversion) {\n         JsonBuilder.globalFieldCaseConversion = globalFieldCaseConversion;",
    "output": "Add field case casing support for JsonBuilder"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesOperationAction.java\n@@ -105,7 +105,7 @@ private AsyncAction(Request request, ActionListener<Response> listener) {\n             this.listener = listener;\n             clusterState = clusterService.state();\n             String[] nodesIds = request.nodesIds();\n-            if (nodesIds == null || nodesIds.length == 0) {\n+            if (nodesIds == null || nodesIds.length == 0 || (nodesIds.length == 1 && nodesIds[0].equals(\"_al\"))) {\n                 int index = 0;\n                 nodesIds = new String[clusterState.nodes().size()];\n                 for (Node node : clusterState.nodes()) {",
    "output": "Add _all option to nodes based operations"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n@@ -145,6 +145,7 @@ public class JgroupsDiscovery extends AbstractLifecycleComponent<Discovery> impl\n             this.localNode = new Node(settings.get(\"name\"), settings.getAsBoolean(\"node.data\", true), channel.getAddress().toString(), transportService.boundAddress().publishAddress());\n \n             if (isMaster()) {\n+                firstMaster = true;\n                 clusterService.submitStateUpdateTask(\"jgroups-disco-initialconnect(master)\", new ProcessedClusterStateUpdateTask() {\n                     @Override public ClusterState execute(ClusterState currentState) {\n                         Nodes.Builder builder = new Nodes.Builder()\n@@ -159,7 +160,6 @@ public class JgroupsDiscovery extends AbstractLifecycleComponent<Discovery> impl\n                         sendInitialStateEventIfNeeded();\n                     }\n                 });\n-                firstMaster = true;\n                 addressSet = true;\n             } else {\n                 clusterService.submitStateUpdateTask(\"jgroups-disco-initialconnect\", new ClusterStateUpdateTask() {",
    "output": "Upgrade firstMaster before submitting state update"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n@@ -250,6 +250,11 @@ public String nodeDescription() {\n                 BytesStreamInput is = new BytesStreamInput(msg.getBuffer());\n                 final Node newNode = Node.readNode(is);\n                 is.close();\n+\n+                if (logger.isDebugEnabled()) {\n+                    logger.debug(\"Received node information from [{}], node [{}]\", msg.getSrc(), newNode);\n+                }\n+\n                 clusterService.submitStateUpdateTask(\"jgroups-disco-receive(from node[\" + newNode + \"])\", new ClusterStateUpdateTask() {\n                     @Override public ClusterState execute(ClusterState currentState) {\n                         if (currentState.nodes().nodeExists(newNode.id())) {\n@@ -261,7 +266,7 @@ public String nodeDescription() {\n                     }\n                 });\n             } catch (Exception e) {\n-                logger.warn(\"Can't read address from cluster member, message [\" + msg.getClass().getName() + \"/\" + msg + \"]\", e);\n+                logger.warn(\"Can't read address from cluster member [\" + msg.getSrc() + \"] message [\" + msg.getClass().getName() + \"/\" + msg + \"]\", e);\n             }\n \n             return;",
    "output": "Add more logging to jgroups disco"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/mlt/TransportMoreLikeThisAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/mlt/TransportMoreLikeThisAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/mlt/TransportMoreLikeThisAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/mlt/TransportMoreLikeThisAction.java\n@@ -151,6 +151,7 @@ public class TransportMoreLikeThisAction extends BaseAction<MoreLikeThisRequest,\n                     boolBuilder.mustNot(termQuery(uidTerm.field(), uidTerm.text()));\n                 } catch (Exception e) {\n                     listener.onFailure(e);\n+                    return;\n                 }\n \n                 String[] searchIndices = request.searchIndices();\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonDateFieldMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonDateFieldMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonDateFieldMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonDateFieldMapper.java\n@@ -141,7 +141,11 @@ protected JsonDateFieldMapper(Names names, FormatDateTimeFormatter dateTimeForma\n     }\n \n     @Override public String valueAsString(Fieldable field) {\n-        return dateTimeFormatter.printer().print(value(field));\n+        Long value = value(field);\n+        if (value == null) {\n+            return null;\n+        }\n+        return dateTimeFormatter.printer().print(value);\n     }\n \n     @Override public String indexedValue(String value) {",
    "output": "Fix failure in mlt with dates, this does mean that currently, mlt, when based on fetching the source and parsing it, does not do mlt on numbers"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/json/QueryStringJsonQueryParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/json/QueryStringJsonQueryParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/json/QueryStringJsonQueryParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/json/QueryStringJsonQueryParser.java\n@@ -195,7 +195,7 @@ public class QueryStringJsonQueryParser extends AbstractIndexComponent implement\n                 } else if (\"escape\".equals(currentFieldName)) {\n                     escape = jp.getIntValue() != 0;\n                 } else if (\"useDisMax\".equals(currentFieldName)) {\n-                    escape = jp.getIntValue() != 0;\n+                    useDisMax = jp.getIntValue() != 0;\n                 } else if (\"tieBreaker\".equals(currentFieldName)) {\n                     tieBreaker = jp.getFloatValue();\n                 }",
    "output": "Fix wrong parsing of useDisMax with number"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonMapper.java\n@@ -33,6 +33,8 @@\n @ThreadSafe\n public interface JsonMapper extends ToJson {\n \n+    public static final JsonMapper[] EMPTY_ARRAY = new JsonMapper[0];\n+\n     @NotThreadSafe\n     public static class BuilderContext {\n         private final JsonPath jsonPath;\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonObjectMapper.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonObjectMapper.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonObjectMapper.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/json/JsonObjectMapper.java\n@@ -411,7 +411,7 @@ private void serializeValue(JsonParseContext jsonContext, String currentFieldNam\n     }\n \n     @Override public void toJson(JsonBuilder builder, Params params) throws IOException {\n-        toJson(builder, params, null);\n+        toJson(builder, params, JsonMapper.EMPTY_ARRAY);\n     }\n \n     public void toJson(JsonBuilder builder, Params params, JsonMapper... additionalMappers) throws IOException {",
    "output": "Fix compilation warning"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryAction.java\n@@ -107,7 +107,7 @@ public class RecoveryAction extends AbstractIndexShardComponent {\n         snapshotTransportAction = shardId.index().name() + \"/\" + shardId.id() + \"/recovery/snapshot\";\n         transportService.registerHandler(snapshotTransportAction, new SnapshotTransportRequestHandler());\n \n-        this.fileChunkSize = componentSettings.getAsSize(\"fileChunkSize\", new SizeValue(16, SizeUnit.KB));\n+        this.fileChunkSize = componentSettings.getAsSize(\"fileChunkSize\", new SizeValue(100, SizeUnit.KB));\n         logger.trace(\"Recovery Action registered, using fileChunkSize[{}]\", fileChunkSize);\n     }\n ",
    "output": "Change default recovery buffer to 100k from 16k"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/Jackson.java b/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/Jackson.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/Jackson.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/util/json/Jackson.java\n@@ -109,6 +109,10 @@ public final static class DateSerializer extends SerializerBase<Date> {\n \n         private final FormatDateTimeFormatter formatter = Joda.forPattern(\"dateTime\");\n \n+        public DateSerializer() {\n+            super(Date.class);\n+        }\n+\n         @Override public void serialize(Date value, JsonGenerator jgen, SerializerProvider provider) throws IOException, JsonGenerationException {\n             jgen.writeString(formatter.parser().print(value.getTime()));\n         }\n@@ -140,6 +144,10 @@ public final static class DateTimeSerializer extends SerializerBase<DateTime> {\n \n         private final FormatDateTimeFormatter formatter = Joda.forPattern(\"dateTime\");\n \n+        public DateTimeSerializer() {\n+            super(DateTime.class);\n+        }\n+\n         @Override public void serialize(DateTime value, JsonGenerator jgen, SerializerProvider provider) throws IOException, JsonGenerationException {\n             jgen.writeString(formatter.printer().print(value));\n         }",
    "output": "Upgrade to jackson 1.5"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java\n@@ -148,15 +148,15 @@ public NettyHttpRequest(org.jboss.netty.handler.codec.http.HttpRequest request)\n         if (sValue == null) {\n             return defaultValue;\n         }\n-        return sValue.equals(\"true\") || sValue.equals(\"1\") || sValue.equals(\"on\");\n+        return !(sValue.equals(\"false\") || sValue.equals(\"0\") || sValue.equals(\"off\"));\n     }\n \n     @Override public Boolean paramAsBoolean(String key, Boolean defaultValue) {\n         String sValue = param(key);\n         if (sValue == null) {\n             return defaultValue;\n         }\n-        return sValue.equals(\"true\") || sValue.equals(\"1\") || sValue.equals(\"on\");\n+        return !(sValue.equals(\"false\") || sValue.equals(\"0\") || sValue.equals(\"off\"));\n     }\n \n     @Override public TimeValue paramAsTime(String key, TimeValue defaultValue) {",
    "output": "Fix rest boolean"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java\n@@ -22,6 +22,7 @@\n import org.apache.lucene.analysis.Analyzer;\n import org.apache.lucene.queryParser.ParseException;\n import org.apache.lucene.queryParser.QueryParser;\n+import org.apache.lucene.search.BooleanClause;\n import org.apache.lucene.search.MultiTermQuery;\n import org.apache.lucene.search.Query;\n import org.apache.lucene.util.Version;\n@@ -31,6 +32,8 @@\n import org.elasticsearch.index.mapper.MapperService;\n import org.elasticsearch.util.Nullable;\n \n+import java.util.List;\n+\n import static org.elasticsearch.index.query.support.QueryParsers.*;\n \n /**\n@@ -137,6 +140,14 @@ public MapperQueryParser(String defaultField, Analyzer analyzer,\n         return super.getWildcardQuery(indexedNameField, termStr);\n     }\n \n+    @Override protected Query getBooleanQuery(List<BooleanClause> clauses, boolean disableCoord) throws ParseException {\n+        Query q = super.getBooleanQuery(clauses, disableCoord);\n+        if (q == null) {\n+            return null;\n+        }\n+        return fixNegativeQueryIfNeeded(q);\n+    }\n+\n     protected FieldMapper fieldMapper(String smartName) {\n         if (mapperService == null) {\n             return null;",
    "output": "Make non negative query in query parser"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataService.java b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataService.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataService.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/cluster/metadata/MetaDataService.java\n@@ -262,7 +262,7 @@ public synchronized PutMappingResult putMapping(final String[] indices, String m\n                     if (!ignoreConflicts && mergeResult.hasConflicts()) {\n                         throw new MergeMappingException(mergeResult.conflicts());\n                     }\n-                    existingMappers.put(index, newMapper);\n+                    existingMappers.put(index, existingMapper);\n                 }\n             } else {\n                 throw new IndexMissingException(new Index(index));",
    "output": "Use existing mapping when merging"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/mlt/RestMoreLikeThisAction.java\n@@ -47,6 +47,8 @@ public class RestMoreLikeThisAction extends BaseRestHandler {\n         super(settings, client);\n         controller.registerHandler(GET, \"/{index}/{type}/{id}/_moreLikeThis\", this);\n         controller.registerHandler(POST, \"/{index}/{type}/{id}/_moreLikeThis\", this);\n+        controller.registerHandler(GET, \"/{index}/{type}/{id}/_mlt\", this);\n+        controller.registerHandler(POST, \"/{index}/{type}/{id}/_mlt\", this);\n     }\n \n     @Override public void handleRequest(final RestRequest request, final RestChannel channel) {",
    "output": "Add _mlt as well for uri"
  },
  {
    "input": "diff --git a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/document/DocumentActionsTests.java b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/document/DocumentActionsTests.java\n--- a/modules/test/integration/src/test/java/org/elasticsearch/test/integration/document/DocumentActionsTests.java\n+++ b/modules/test/integration/src/test/java/org/elasticsearch/test/integration/document/DocumentActionsTests.java\n@@ -19,6 +19,8 @@\n \n package org.elasticsearch.test.integration.document;\n \n+import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;\n+import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;\n import org.elasticsearch.action.admin.indices.flush.FlushResponse;\n import org.elasticsearch.action.admin.indices.optimize.OptimizeResponse;\n import org.elasticsearch.action.admin.indices.refresh.RefreshResponse;\n@@ -53,7 +55,12 @@ public class DocumentActionsTests extends AbstractServersTests {\n \n         logger.info(\"Creating index test\");\n         client(\"server1\").admin().indices().create(createIndexRequest(\"test\")).actionGet();\n-        Thread.sleep(200);\n+\n+        logger.info(\"Running Cluster Health\");\n+        ClusterHealthResponse clusterHealth = client(\"server1\").admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();\n+        logger.info(\"Done Cluster Health, status \" + clusterHealth.status());\n+        assertThat(clusterHealth.timedOut(), equalTo(false));\n+        assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.GREEN));\n \n         logger.info(\"Indexing [type1/1]\");\n         IndexResponse indexResponse = client(\"server1\").index(indexRequest(\"test\").type(\"type1\").id(\"1\").source(source(\"1\", \"test\"))).actionGet();",
    "output": "Upgrade to lucene 3.0.1"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsResponse.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsResponse.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsResponse.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsResponse.java\n@@ -101,9 +101,9 @@ Map<String, TObjectIntHashMap<String>> fieldsTermsFreqs() {\n             out.writeUTF(entry.getKey());\n             out.writeInt(entry.getValue().size());\n             for (TObjectIntIterator<String> it = entry.getValue().iterator(); it.hasNext();) {\n+                it.advance();\n                 out.writeUTF(it.key());\n                 out.writeInt(it.value());\n-                it.advance();\n             }\n         }\n     }",
    "output": "Fix wrong iteration when getting back terms"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java\n@@ -43,7 +43,7 @@ public class RestNodesInfoAction extends BaseRestHandler {\n         super(settings, client);\n \n         controller.registerHandler(RestRequest.Method.GET, \"/_cluster/nodes\", this);\n-        controller.registerHandler(RestRequest.Method.GET, \"/_cluster/nodes/${nodeId}\", this);\n+        controller.registerHandler(RestRequest.Method.GET, \"/_cluster/nodes/{nodeId}\", this);\n     }\n \n     @Override public void handleRequest(final RestRequest request, final RestChannel channel) {",
    "output": "Fix nodes info to accept node(s) ids as well"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/discovery/jgroups/JgroupsDiscovery.java\n@@ -363,7 +363,7 @@ private byte[] nodeMessagePayload() throws IOException {\n         ByteArrayDataOutputStream os = new ByteArrayDataOutputStream();\n         localNode.writeTo(os);\n         os.close();\n-        return os.unsafeByteArray();\n+        return os.copiedByteArray();\n     }\n \n     private void sendInitialStateEventIfNeeded() {",
    "output": "Fix possible node serialization problem (dont share the byte buffer)"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MapperQueryParser.java\n@@ -37,9 +37,6 @@\n  * A query parser that uses the {@link MapperService} in order to build smarter\n  * queries based on the mapping information.\n  *\n- * <p>Maps a logic name of a field {@link org.elasticsearch.index.mapper.FieldMapper#name()}\n- * into its {@link org.elasticsearch.index.mapper.FieldMapper#indexName()}.\n- *\n  * <p>Also breaks fields with [type].[name] into a boolean query that must include the type\n  * as well as the query on the name.\n  *\n@@ -61,7 +58,6 @@ public MapperQueryParser(String defaultField, Analyzer analyzer,\n     }\n \n     @Override protected Query getFieldQuery(String field, String queryText) throws ParseException {\n-        String indexedNameField = field;\n         if (mapperService != null) {\n             MapperService.SmartNameFieldMappers fieldMappers = mapperService.smartName(field);\n             if (fieldMappers != null) {\n@@ -71,7 +67,7 @@ public MapperQueryParser(String defaultField, Analyzer analyzer,\n                 }\n             }\n         }\n-        return super.getFieldQuery(indexedNameField, queryText);\n+        return super.getFieldQuery(field, queryText);\n     }\n \n     @Override protected Query getRangeQuery(String field, String part1, String part2, boolean inclusive) throws ParseException {",
    "output": "Remove unused field"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsRequest.java\n@@ -38,7 +38,7 @@ public class ShardTermsRequest extends BroadcastShardOperationRequest {\n \n     private boolean fromInclusive = true;\n \n-    private boolean toInclusive = false;\n+    private boolean toInclusive = true;\n \n     private String prefix;\n \n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/TermsRequest.java b/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/TermsRequest.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/TermsRequest.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/TermsRequest.java\n@@ -111,7 +111,7 @@ public static SortType fromString(String value, SortType defaultSort) {\n \n     private String to;\n \n-    private boolean toInclusive = false;\n+    private boolean toInclusive = true;\n \n     private String prefix;\n ",
    "output": "Change toInclusice in terms api to default to true instead of false"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/cluster/state/RestClusterStateAction.java\n@@ -72,7 +72,7 @@ public class RestClusterStateAction extends BaseRestHandler {\n \n                         builder.startObject(\"mappings\");\n                         for (Map.Entry<String, String> entry : indexMetaData.mappings().entrySet()) {\n-                            builder.startObject(\"mapping\").field(\"name\", entry.getKey()).field(\"value\", entry.getValue()).endObject();\n+                            builder.startObject(entry.getKey()).field(\"source\", entry.getValue()).endObject();\n                         }\n                         builder.endObject();\n ",
    "output": "Fix cluster state mapping informaton, return it with the mapping name as key and source field"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/flush/RestFlushAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/flush/RestFlushAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/flush/RestFlushAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/flush/RestFlushAction.java\n@@ -35,6 +35,7 @@\n \n import static org.elasticsearch.rest.RestRequest.Method.*;\n import static org.elasticsearch.rest.RestResponse.Status.*;\n+import static org.elasticsearch.rest.action.support.RestActions.*;\n \n /**\n  * @author kimchy (Shay Banon)\n@@ -65,11 +66,7 @@ public class RestFlushAction extends BaseRestHandler {\n                     builder.startObject();\n                     builder.field(\"ok\", true);\n \n-                    builder.startObject(\"_shards\");\n-                    builder.field(\"total\", response.totalShards());\n-                    builder.field(\"successful\", response.successfulShards());\n-                    builder.field(\"failed\", response.failedShards());\n-                    builder.endObject();\n+                    buildBroadcastShardsHeader(builder, response);\n \n                     builder.endObject();\n                     channel.sendResponse(new JsonRestResponse(request, OK, builder));",
    "output": "Add shard header with failures to flush operation"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhase.java\n@@ -85,7 +85,7 @@ public void execute(SearchContext searchContext) throws QueryPhaseExecutionExcep\n             }\n             searchContext.queryResult().topDocs(topDocs);\n         } catch (Exception e) {\n-            throw new QueryPhaseExecutionException(searchContext);\n+            throw new QueryPhaseExecutionException(searchContext, e);\n         }\n \n         facetsPhase.execute(searchContext);\n\ndiff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhaseExecutionException.java b/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhaseExecutionException.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhaseExecutionException.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/search/query/QueryPhaseExecutionException.java\n@@ -27,7 +27,7 @@\n  */\n public class QueryPhaseExecutionException extends SearchException {\n \n-    public QueryPhaseExecutionException(SearchContext context) {\n-        super(\"Failed to execute query [\" + context.query() + \"], sort [\" + context.sort() + \"], from [\" + context.from() + \"], size [\" + context.size() + \"]\");\n+    public QueryPhaseExecutionException(SearchContext context, Throwable cause) {\n+        super(\"Failed to execute query [\" + context.query() + \"], sort [\" + context.sort() + \"], from [\" + context.from() + \"], size [\" + context.size() + \"]\", cause);\n     }\n }",
    "output": "Add the cause to query phase execption"
  },
  {
    "input": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n--- a/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n+++ b/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/main/RestMainAction.java\n@@ -74,6 +74,7 @@ public class RestMainAction extends BaseRestHandler {\n             }\n             builder.startObject(\"version\").field(\"number\", Version.number()).field(\"date\", Version.date()).field(\"devBuild\", Version.devBuild()).endObject();\n             builder.field(\"version\", Version.number());\n+            builder.field(\"tagline\", \"You Know, for Search\");\n             builder.field(\"cover\", \"DON'T PANIC\");\n             if (rootNode != null) {\n                 builder.startObject(\"quote\");",
    "output": "Add tagline to the main request ;)"
  }
]